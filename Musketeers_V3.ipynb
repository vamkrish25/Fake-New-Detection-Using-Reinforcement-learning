{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "411f0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*\n",
    "#  AUTHOR: Vamsi Krishna MuppalaÂ \n",
    "#          Edwin Sahil Samuel Kathi\n",
    "#          Alekhya Koppaka\n",
    "#          Jayakumar Kukkathotti\n",
    "#          Yaswanth Kumar Chaganti         \n",
    "#  FILENAME: Musketeers_mainCode.py\n",
    "#  SPECIFICATION:  Analyzing the dataset, building and evaluating a Reinofrcement Learning Techniques in neural network model using Python.\n",
    "#  FOR: CS 5392 Reinforcement Learning  Section 001\n",
    "# */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea586019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.7 in c:\\users\\sahil\\appdata\\roaming\\python\\python39\\site-packages (2.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (0.31.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (2.2.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (2.0.7)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (2.12.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (3.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (3.20.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.51.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (3.3.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (16.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.14.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.16.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (4.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (2.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (0.2.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (2.16.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (63.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (0.7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Installing tensorflow of version 2.7\n",
    "!pip install tensorflow==2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1277045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################### Data Pre-Preprocessing ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a9feec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.4\n"
     ]
    }
   ],
   "source": [
    "# /*importing pandas to read csv file */\n",
    "import pandas as pd # Import the pandas library and assign it the alias \"pd\"\n",
    "print(pd.__version__) # Print the version of pandas installed in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "851494dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv #The import statement allows you to import external modules or libraries into your Python code. In this case, we are importing the csv module, which is part of Python's standard library and provides functionality for reading and writing CSV (Comma Separated Values) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2f44bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset \n",
    "df_fake = pd.read_csv(\"Fake.csv\")  #reading fake.csv\n",
    "df_true = pd.read_csv(\"True.csv\")  #reading true.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c26e8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labling the dataset: a label that marks the article as potentially unreliable\n",
    "# False: unreliable\n",
    "# True: reliable \n",
    "df_fake[\"label\"] = False\n",
    "df_true[\"label\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d87baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinating both the dataset and creating a dataframe\n",
    "df1 = pd.concat([df_fake,df_true])\n",
    "df1 = df1.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98902987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREAKING: GA, KY, WV Confirm They Suspect Obam...</td>\n",
       "      <td>Georgia s secretary of state has claimed the D...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Dec 18, 2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obama Shows Why Trump Is Too Much Of A Hothea...</td>\n",
       "      <td>Donald Trump has constantly involved himself i...</td>\n",
       "      <td>News</td>\n",
       "      <td>September 5, 2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. Senate hearings delayed for three wealthy...</td>\n",
       "      <td>WASHINGTON (Reuters) - The U.S. Senate has pos...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>January 11, 2017</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WATCH: Sean Spicer Loses His Sh*t When Report...</td>\n",
       "      <td>Donald Trump s White House mouthpiece just gav...</td>\n",
       "      <td>News</td>\n",
       "      <td>March 22, 2017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russia urges U.S. to start finding way to reso...</td>\n",
       "      <td>MOSCOW (Reuters) - Russian Deputy Foreign Mini...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 11, 2017</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  BREAKING: GA, KY, WV Confirm They Suspect Obam...   \n",
       "1   Obama Shows Why Trump Is Too Much Of A Hothea...   \n",
       "2  U.S. Senate hearings delayed for three wealthy...   \n",
       "3   WATCH: Sean Spicer Loses His Sh*t When Report...   \n",
       "4  Russia urges U.S. to start finding way to reso...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  Georgia s secretary of state has claimed the D...      politics   \n",
       "1  Donald Trump has constantly involved himself i...          News   \n",
       "2  WASHINGTON (Reuters) - The U.S. Senate has pos...  politicsNews   \n",
       "3  Donald Trump s White House mouthpiece just gav...          News   \n",
       "4  MOSCOW (Reuters) - Russian Deputy Foreign Mini...     worldnews   \n",
       "\n",
       "                  date  label  \n",
       "0         Dec 18, 2016  False  \n",
       "1    September 5, 2016  False  \n",
       "2    January 11, 2017    True  \n",
       "3       March 22, 2017  False  \n",
       "4  September 11, 2017    True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5) #Return the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a610bdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Subject :  {'News': 9050, 'politics': 6841, 'left-news': 4459, 'Government News': 1570, 'US_News': 783, 'Middle-east': 778}\n",
      "True News Subject :  {'politicsNews': 11272, 'worldnews': 10145}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# libraries to create two histograms of the subjects of fake and true news articles.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Creating Figure\n",
    "fig, axes = plt.subplots(1,2, figsize = (15,6)) #line creates a figure with two subplots side by side, each with a size of 15 by 6 inches.\n",
    "#Adding the histogram1 - Fake News\n",
    "sns.histplot(df_fake.subject, palette = 'Set1', alpha = 0.5, ax = axes[0]) #creates a histogram of the subjects of fake news articles using the histplot function from seaborn. The palette parameter sets the color scheme, alpha sets the opacity, and ax specifies which subplot to add the histogram to. The same parameters are used for the histogram of true news articles in the next line.\n",
    "axes[0].tick_params(axis = 'x', rotation = 90) # rotates the x-axis tick labels of the first histogram by 90 degrees for better readability.\n",
    "axes[0].set_title('Fake News Subject') # adds a title to the first histogram.\n",
    "#Adding the histogram2 - True News\n",
    "sns.histplot(df_true.subject, palette = 'Set1', alpha = 0.5, ax = axes[1]) #creates a histogram of the subjects of true news articles using the histplot function from seaborn. The palette parameter sets the color scheme, alpha sets the opacity, and ax specifies which subplot to add the histogram to. The same parameters are used for the histogram of true news articles in the next line.\n",
    "axes[1].tick_params(axis = 'x', rotation = 90) # rotates the x-axis tick labels of the first histogram by 90 degrees for better readability.\n",
    "axes[1].set_title('True  News Subject')  # adds a title to the first histogram.\n",
    "#Printing the count of Subject\n",
    "print(\"Fake News Subject : \",dict(df_fake.subject.value_counts())) #prints a dictionary of the count of each subject in the fake news articles dataframe. The value_counts() method counts the number of occurrences of each unique value in the subject column and returns them as a pandas Series object. The dict() function is used to convert this Series object to a dictionary.\n",
    "print(\"True News Subject : \",dict(df_true.subject.value_counts())) #prints a dictionary of the count of each subject in the fake news articles dataframe. The value_counts() method counts the number of occurrences of each unique value in the subject column and returns them as a pandas Series object. The dict() function is used to convert this Series object to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c75b0588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    23481\n",
      "1    21417\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert boolean values in the 'label' column to binary values (0 or 1)\n",
    "df1['label'] = df1['label'].astype(int)\n",
    "\n",
    "# Create a histogram using sns.histplot\n",
    "sns.histplot(df1['label'], palette='Set1', alpha=0.5)# Create a histogram using sns.histplot\n",
    "plt.tick_params(axis='x', rotation=90)# Rotate the x-axis tick labels by 90 degrees for better readability\n",
    "plt.title('True vs Fake News')# Add a title to the histogram\n",
    "\n",
    "# Print the count of each unique value in the 'label' column\n",
    "print(df1['label'].value_counts())# Print the count of each unique value in the 'label' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baa4a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.dropna() #removes the rows that contains NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf2aed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = df1[['title', 'label']] ## Select the 'title' and 'label' columns from the DataFrame 'df1' and store them in the 'selected_columns' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca12edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(selected_columns) # Create a new DataFrame 'df' from the 'selected_columns' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c087081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREAKING: GA, KY, WV Confirm They Suspect Obam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obama Shows Why Trump Is Too Much Of A Hothea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. Senate hearings delayed for three wealthy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WATCH: Sean Spicer Loses His Sh*t When Report...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russia urges U.S. to start finding way to reso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  label\n",
       "0  BREAKING: GA, KY, WV Confirm They Suspect Obam...      0\n",
       "1   Obama Shows Why Trump Is Too Much Of A Hothea...      0\n",
       "2  U.S. Senate hearings delayed for three wealthy...      1\n",
       "3   WATCH: Sean Spicer Loses His Sh*t When Report...      0\n",
       "4  Russia urges U.S. to start finding way to reso...      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5) #Return the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5aaae4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn #scikit-learn, also known as sklearn, is a popular open-source machine learning library for Python. It provides a wide range of tools for machine learning, including classification, regression, clustering, and dimensionality reduction, among others.\n",
    "print(sklearn.__version__) #version of the sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "187c1615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.23.5'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np #Import the NumPy library\n",
    "np.__version__ #version of numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2ef6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ Data Splitting and Vectorization ############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba3d4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#he TfidfTransformer and TfidfVectorizer classes are imported from the sklearn.feature_extraction.text module. These classes are used for text feature extraction using the term frequency-inverse document frequency (TF-IDF) method\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # Import the TfidfTransformer class from the sklearn.feature_extraction.text module\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Import the TfidfVectorizer class from the sklearn.feature_extraction.text module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3555412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorFlow is a popular open-source deep learning framework developed by Google, and it provides a wide range of tools and functionalities for building and training neural networks.\n",
    "#NumPy is a powerful numerical computing library for Python that provides support for arrays, matrices, and other mathematical operations. It is often used in conjunction with TensorFlow for handling numerical data in machine learning and deep learning applications.\n",
    "import tensorflow as tf #Import the TensorFlow library\n",
    "import numpy as np #Import the NumPy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afef23b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36335    0\n",
      "12384    1\n",
      "24419    0\n",
      "24740    1\n",
      "27039    0\n",
      "        ..\n",
      "11284    0\n",
      "44732    0\n",
      "38158    1\n",
      "860      0\n",
      "15795    0\n",
      "Name: label, Length: 35918, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#The train_test_split function is part of the sklearn.model_selection module, which provides various functions for data splitting, cross-validation, and model evaluation in scikit-learn (sklearn), which is a popular machine learning library in Python.\n",
    "from sklearn.model_selection import train_test_split ## Import the train_test_split function from the sklearn.model_selection module\n",
    "\n",
    "#This code uses the train_test_split function from scikit-learn (sklearn) to split the data into training and testing sets.\n",
    "#df['title']: This specifies the input data (features) for training and testing, which is the 'title' column of the DataFrame df.\n",
    "#df['label']: This specifies the target labels for training and testing, which is the 'label' column of the DataFrame df.\n",
    "#test_size=0.2: This specifies the proportion of data to be used for testing, which is set to 20% of the total data. The remaining 80% will be used for training.\n",
    "#random_state=42: This sets the random seed for reproducibility. By setting it to a specific value (e.g., 42), the same split will be obtained every time the code is run, which is useful for reproducible research or model development.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['title'], df['label'], test_size=0.2, random_state=42) \n",
    "print(y_train) #print the y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9858d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "#This code initializes a TfidfVectorizer object from scikit-learn (sklearn) with specified parameters:\n",
    "#stop_words='english': This specifies that common English words (e.g., \"a\", \"an\", \"the\", etc.) should be ignored as stop words during text vectorization. Stop words are common words that do not carry much meaning and are typically removed to reduce noise and improve model performance.\n",
    "#max_df=0.7: This specifies the maximum document frequency (proportion of documents) for a term to be included in the vectorized output. In this case, any term that appears in more than 70% of the documents will be ignored. This is used to filter out very common terms that may not be informative for distinguishing between documents.\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d35a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = vectorizer.fit_transform(X_train) #vectorizer.fit_transform(X_train): This line fits the vectorizer to the training data (X_train) and transforms it into TF-IDF vectors. The resulting X_train_vectors variable will contain the TF-IDF vectors representing the training data.\n",
    "X_test_vectors = vectorizer.transform(X_test) #vectorizer.transform(X_test): This line transforms the test data (X_test) into TF-IDF vectors using the vectorizer object that was fit to the training data. The resulting X_test_vectors variable will contain the TF-IDF vectors representing the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6792363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LSTM #These lines import the Input, Dense, and LSTM classes from the layers module in Keras. These are commonly used layers in building neural networks.\n",
    "from tensorflow.keras.models import Model # This line imports the Model class from the models module in Keras. The Model class is used to define the architecture of a neural network model in Keras, specifying the input and output layers, as well as any intermediate layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f888ff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-rectified-adam in c:\\users\\sahil\\anaconda3\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from keras-rectified-adam) (1.23.5)\n",
      "Requirement already satisfied: Keras in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from keras-rectified-adam) (2.7.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sahil\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "## Install the keras-rectified-adam package for optimized Adam optimizer\n",
    "!pip install keras-rectified-adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0adc2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Adam optimizer from TensorFlow's Keras API\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7e4242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################### NN Model #################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "653897ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## NN_Q-Learning ###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6226e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the necessary libraries to implement a neural network using the TensorFlow library for machine learning\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c10012fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Q-LEARNING Technique for NN model\n",
    "# NAME: q_learning\n",
    "# PURPOSE: to implement the Q-learning technique for training a neural network model (model) using given input data (x) and target labels (y) with a specified optimizer (optimizer). The algorithm is trained for a given number of epochs (epochs) and batch size (batch_size), and uses a discount factor (gamma) for computing the Q-values and rewards. The Q-values and rewards are used to modify the loss function and update the model's weights. The code also includes the visualization of reward and loss histograms for analysis. \n",
    "#          The purpose of this code is to define the Q-learning function for a neural network model, which can be used for reinforcement learning tasks.\n",
    "# INVARIANTS: The input data x should be a sparse matrix, and length is calculated using the getnnz() method of x.\n",
    "#             The input data y should be a numpy array of target labels for each sample in x.\n",
    "#             The model should be a neural network model implemented using TensorFlow.\n",
    "#             The optimizer should be an instance of a TensorFlow optimizer (e.g. Adam optimizer).\n",
    "#             Epochs should be an integer specifying the number of times to iterate over the input data.\n",
    "#             batch_size should be an integer specifying the size of each batch during training.\n",
    "#             gamma should be a float specifying the discount factor for future rewards in the Q-learning algorithm.\n",
    "#             The training process involves iterating over the input data in batches of size batch_size, and for each batch:\n",
    "#             The logits (raw output) of the model for the input data x_batch are computed using model(x_batch).\n",
    "#             The log probabilities of the logits are computed using tf.math.log(tf.clip_by_value(logits, 1e-10, 1.0)).\n",
    "#             One-hot encoded labels are created from the target labels y_batch using tf.one_hot() method.\n",
    "#             The maximum Q-value for each sample in the batch is computed using tf.reduce_max(logits, axis=1).\n",
    "#             The maximum Q-value is used as the reward and is converted to a numpy array using q_values.numpy().\n",
    "#             The policy gradient loss is computed by multiplying the log probabilities with the one-hot encoded labels and taking the negative mean using tf.reduce_mean(tf.reduce_sum(labels * log_probs, axis=1) * rewards).\n",
    "#             The gradients of the policy gradient loss with respect to the model's trainable weights are computed using tape.gradient().\n",
    "#             The gradients are applied to the optimizer using optimizer.apply_gradients() to update the model's weights.\n",
    "#             The average reward for the current batch is computed and used as a baseline.\n",
    "#             The model loss is computed by multiplying the policy gradient loss with the average reward and the discount factor (gamma).\n",
    "#             The gradients of the model loss with respect to the model's trainable weights are computed using tape.gradient().\n",
    "#             The gradients are applied to the optimizer using optimizer.apply_gradients() to update the model's weights.\n",
    "#             The rewards and losses for each epoch are stored in epoch_rewards and epoch_losses, respectively.\n",
    "#             After training, the reward and loss histograms for all epochs are plotted using plt.hist().\n",
    "\n",
    "\n",
    "# Define the Q-learning function\n",
    "def q_learning(x, y, model, optimizer, epochs, batch_size, gamma): #class to define the Q-Learning technique\n",
    "    length = x.getnnz() #Calculates the length of the input data (x) using getnnz() method.\n",
    "    for epoch in range(epochs): #Iterates over each epoch.\n",
    "        epoch_rewards = [] #empty lists that are likely intended to store the rewards for each epoch during the training of a neural network.\n",
    "        epoch_losses = [] #empty lists that are likely intended to store the losses for each epoch during the training of a neural network.\n",
    "        for batch_start in range(0, length, batch_size): #It is used to iterate over the input data (x) in batches of size batch_size during the training process. It starts from the beginning of the input data and increments in steps of batch_size until it reaches the end of the data. \n",
    "            batch_end = min(batch_start + batch_size, length) # # It calculates the ending index (batch_end) of the current batch during the iteration over the input data (x) in batches. It ensures that the ending index does not exceed the total length of the data (length) to avoid accessing data beyond the available range. \n",
    "            x_batch = x[batch_start:batch_end].toarray() #Extracting a batch of data from the array 'x' using the start and end indices of the batch.toarray() converters the batch to an array, if it's in sparse format, for further processing\n",
    "            y_batch = y[batch_start:batch_end] #Extracting a batch of labels from the array 'y' using the start and end indices of the batch\n",
    "            with tf.GradientTape() as tape: #tf.GradientTape() is a TensorFlow API that provides a mechanism for automatic differentiation, which is a key technique used in machine learning optimization algorithms, such as gradient descent. It allows you to compute gradients of a computation with respect to its input variables, which can then be used to update the values of those variables during optimization.\"tape\" refers to a mechanism provided by TensorFlow that records operations for the purpose of computing gradients. The tape acts as a context within which computations are recorded, and these computations can later be used to compute gradients using the tape.gradient() method.\n",
    "                logits = model(x_batch) #Passing the batch of input data 'x_batch' through the model to obtain logits.Logits are the output of the model before applying any activation function, typically used for classification tasks Logits represent the raw, unnormalized scores for each class, which can be used for further processing or prediction.'model' is the trained model that takes 'x_batch' as input and produces logits as output\n",
    "                log_probs = tf.math.log(tf.clip_by_value(logits, 1e-10, 1.0)) # calculates the log probabilities by taking the natural logarithm (tf.math.log()) of the model's predicted logits (logits). The tf.clip_by_value() function is used to clip the logits to a specific range to avoid numerical instability. In this case, the minimum value is set to 1e-10 and the maximum value is set to 1.0. The resulting log probabilities are stored in the log_probs variable.\n",
    "                labels = tf.one_hot(y_batch, depth=output_dim) #Converting the batch of labels 'y_batch' into one-hot encoding using 'tf.one_hot' function One-hot encoding represents categorical labels as binary vectors with a single '1' and remaining '0's.'y_batch' is the input tensor containing the batch of labels to be converted to one-hot encoding.'output_dim' specifies the depth of the one-hot encoding, which should be equal to the number of classes in the classification task\n",
    "                q_values = tf.reduce_max(logits, axis=1) # Compute the maximum Q-value for each sample in the batch\n",
    "                rewards = q_values.numpy() # Use the maximum Q-value as the reward\n",
    "                loss = -tf.reduce_mean(tf.reduce_sum(labels * log_probs, axis=1) * rewards) # Modify the loss function to include the reward\n",
    "                grads = tape.gradient(loss, model.trainable_weights) # #grads typically refers to the computed gradients of the loss function with respect to the trainable weights of a machine learning model.The tape.gradient() function in TensorFlow is used to compute the gradients of a given function (in this case, the loss function) with respect to a list of variables (in this case, the model.trainable_weights). These gradients can then be used in an optimization algorithm, such as gradient descent, to update the model weights and improve the model's performance during training.Compute the gradients of the loss with respect to the trainable weights of the model.loss: The computed loss value.model.trainable_weights: List of trainable weights of the model\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights)) #It applies the computed gradients (grads) to update the model weights (model.trainable_weights) using an optimizer. The zip() function is used to create pairs of gradients and corresponding model weights, which are then passed to the apply_gradients() method of the optimizer to perform the weight update step. This step is a key part of the optimization process in training machine learning models, as it helps to adjust the model weights based on the gradients of the loss function, with the goal of minimizing the loss and improving the model's performance.\n",
    "            epoch_rewards.append(rewards) #appends the rewards obtained by the network during the current epoch to the epoch_rewards list. This allows us to keep track of the rewards obtained by the network during each epoch of training.\n",
    "            epoch_losses.append(loss.numpy()) # appends the loss obtained by the network during the current epoch to the epoch_losses list. This allows us to keep track of the loss obtained by the network during each epoch of training.The numpy() method is used to extract the numerical value of the TensorFlow loss object, which is a symbolic representation of the loss function used to train the network. This numerical value is then appended to the epoch_losses list.\n",
    "            print(\"The rewards are:\", rewards) #prints the rewards\n",
    "            \n",
    "    # Plot reward histogram\n",
    "    plt.hist(epoch_rewards, bins=20) #creates a histogram plot of the distribution of the rewards obtained by the network during training, using 20 bins. This allows us to visualize how often the network obtained rewards in different ranges, which can provide insight into its overall performance.\n",
    "    plt.title(\"Reward Histogram Q-Learning NN\") # sets the title of the plot to \"Reward Histogram Q-Learning NN\", which describes the type of algorithm used and the type of data being plotted.\n",
    "    plt.xlabel(\"Reward\") #sets the x-axis label to \"Reward\", which describes the meaning of the values being plotted on the x-axis.\n",
    "    plt.ylabel(\"Frequency\") #sets the y-axis label to \"Frequency\", which describes the number of occurrences of rewards in each bin.\n",
    "    plt.show() #displays the plot on the screen. This allows us to see the distribution of the rewards obtained by the network during training and gain insights into its performance.\n",
    "    \n",
    "    # Plot loss histogram \n",
    "    plt.hist(epoch_losses, bins=20) # creates a histogram plot of the distribution of the losses obtained by the network during training, using 20 bins. This allows us to visualize how often the network had a certain level of loss during the training process, which can provide insights into how well the network is learning and improving over time.\n",
    "    plt.title(\"Loss Histogram Q-Learning NN\") #sets the title of the plot to \"Loss Histogram Q-Learning NN\", which describes the type of algorithm used and the type of data being plotted.\n",
    "    plt.xlabel(\"Loss\") # sets the x-axis label to \"Loss\", which describes the meaning of the values being plotted on the x-axis.\n",
    "    plt.ylabel(\"Frequency\") #sets the y-axis label to \"Frequency\", which describes the number of occurrences of losses in each bin.\n",
    "    plt.show() # displays the plot on the screen. This allows us to see the distribution of the losses obtained by the network during training and gain insights into its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9028d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters and Neural network model \n",
    "input_dim = X_train_vectors.shape[1] #sets the variable input_dim equal to the number of features in the training data.'X_train_vectors.shape[1]'' retrieves the number of columns (i.e., features) in the feature matrix X_train_vectors. This value represents the number of input dimensions or features for the classification model.\n",
    "output_dim = len(np.unique(y_train)) #sets the variable output_dim equal to the number of unique target labels in the training data. These variables are likely used to define the input and output dimensions of the neural network or classification model being built.np.unique(y_train) returns the unique values of the target variable y_train. The length of this array is equal to the number of distinct target labels in the dataset.len(np.unique(y_train)) returns the number of unique target labels in the dataset. This value represents the number of output dimensions or classes for the classification model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d10f04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the NN model and define the optimizer\n",
    "# Name: Neural Network model\n",
    "# Purpose: to define and create a neural network or classification model for a given dataset.\n",
    "# Invariants: The Input function defines the input layer of the neural network with shape=(input_dim,), where input_dim is the number of features in the training data.        \n",
    "#             Two Dense functions are used to define the hidden layers of the neural network. The first hidden layer has 64 neurons and relu activation function, while the second hidden layer has output_dim neurons and softmax activation function. The output_dim variable represents the number of unique target labels in the training data.\n",
    "#             The Model function is used to create an instance of the neural network or classification model with inputs=inputs and outputs=x. The model takes the input layer and hidden layers as input and outputs the predicted target labels.\n",
    "#             Finally, the Adam optimizer with a learning rate of 0.001 is set to update the weights of the neural network or classification model during training.\n",
    "\n",
    "inputs = Input(shape=(input_dim,)) #defines an input layer for the neural network or classification model with the specified number of features or input dimensions.The Input function takes shape=(input_dim,) as an argument, where input_dim is an integer representing the number of features in the training data. The shape parameter is a tuple that specifies the input shape of the layer.This line of code is important as it initializes the neural network or classification model and sets the input shape for the subsequent layers.\n",
    "x = Dense(32, activation='relu')(inputs) #defines a hidden layer in the neural network or classification model.The Dense function creates a fully connected layer with 64 neurons and relu activation function. The activation parameter specifies the activation function used to introduce non-linearity into the model.The (inputs) at the end of the line specifies that the input to this layer is the inputs layer that was previously defined.This line of code is important because it adds a layer of computation to the neural network or classification model, which helps it learn complex representations of the input data. The relu activation function is commonly used in deep learning models and helps in speeding up the training process by preventing vanishing gradients.\n",
    "x = Dense(output_dim, activation='softmax')(x) #defines the output layer of the neural network or classification model.The Dense function creates a fully connected layer with output_dim neurons and softmax activation function. The output_dim parameter specifies the number of unique target labels in the training data. The softmax activation function converts the output of the layer into a probability distribution over the target labels, where the highest probability is assigned to the predicted target label.The (x) at the end of the line specifies that the input to this layer is the output of the previous hidden layer x.This line of code is important because it is the final layer of the neural network or classification model, which produces the predicted target labels. The softmax activation function is commonly used for multi-class classification problems and ensures that the predicted probabilities sum up to 1.0 over all target labels.\n",
    "model = Model(inputs=inputs, outputs=x) #creates an instance of the neural network or classification model with the specified input and output layers.The Model function takes inputs=inputs and outputs=x as arguments. The inputs parameter specifies the input layer of the model, which was previously defined using the Input function. The outputs parameter specifies the output layer of the model, which was defined using the Dense function.This line of code is important because it connects the input and output layers to create a neural network or classification model. The model is an instance of the Model class from Keras, which provides high-level APIs for building and training deep learning models. The model can be trained using various optimization algorithms and loss functions to minimize the difference between the predicted and actual target labels.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #creates an instance of the Adam optimization algorithm for the neural network or classification model.The optimizers.Adam function is a popular optimization algorithm used for training deep neural networks. The learning_rate parameter specifies the step size or the size of the update made to the model weights during each iteration of the optimization algorithm.This line of code is important because it initializes the optimizer used to update the weights of the neural network or classification model during training. The choice of optimizer can significantly affect the performance of the model, and Adam is a popular choice due to its fast convergence and adaptive learning rate.\n",
    "#optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001) #RMSprop optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # is an important line of code in the process of building a deep learning model using Keras. It compiles the model by specifying the loss function, optimizer, and metrics to be used during training.In particular, the loss parameter specifies the loss function that the model will use to evaluate its performance on the training data. In this case, the 'categorical_crossentropy' loss function is used, which is commonly used for multiclass classification problems.The optimizer parameter specifies the optimization algorithm that will be used to adjust the weights of the model during training in order to minimize the loss function. Here, the optimizer variable is passed in, which should be an instance of a pre-defined optimizer class from Keras, such as Adam or RMSprop.Finally, the metrics parameter specifies the evaluation metrics that will be used to monitor the model's performance during training and testing. In this case, 'accuracy' is the metric used, which is commonly used for classification problems.Overall, model.compile is a crucial step in the process of building and training a deep learning model, as it sets up the model for optimization by specifying the necessary components for the training process.\n",
    "#model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy']) #loss:mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50933b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rewards are: [0.50757366 0.5008864  0.50478524 0.50232923 0.50003326 0.50222594\n",
      " 0.5024114  0.5036894  0.5030033  0.5007171  0.50080556 0.5008106\n",
      " 0.5068415  0.5022695  0.5052227  0.5011695  0.5004357  0.50197315\n",
      " 0.5065968  0.50275964 0.50292075 0.5028307  0.50211275 0.50335646\n",
      " 0.5013122  0.500453   0.5014694  0.5076789  0.5027622  0.50241786\n",
      " 0.5019941  0.5010095 ]\n",
      "The rewards are: [0.5004183  0.5019492  0.5030706  0.5008941  0.50333697 0.5056214\n",
      " 0.50700295 0.5025444  0.50102586 0.5015638  0.50434995 0.5043855\n",
      " 0.50761247 0.5029135  0.50023377 0.50101745 0.50622797 0.5014354\n",
      " 0.50430995 0.5011165  0.5046507  0.5003742  0.50090826 0.5001075\n",
      " 0.5004104  0.50099856 0.50524396 0.504555   0.5019002  0.50393695\n",
      " 0.50453466 0.5007765 ]\n",
      "The rewards are: [0.5017036  0.5029486  0.5021894  0.5026613  0.50136197 0.5052838\n",
      " 0.5008711  0.50553113 0.50241613 0.5039775  0.50020915 0.5055906\n",
      " 0.50473255 0.5078867  0.50425667 0.50553924 0.5032769  0.5090717\n",
      " 0.5079772  0.50537944 0.5010573  0.5033609  0.50580364 0.50636417\n",
      " 0.50332093 0.50039077 0.5011889  0.5035646  0.5011206  0.5067048\n",
      " 0.5056133  0.501091  ]\n",
      "The rewards are: [0.50558716 0.5041433  0.50984544 0.50755674 0.5081245  0.50531775\n",
      " 0.5065491  0.5039621  0.5063546  0.5060115  0.5010492  0.50501716\n",
      " 0.5048624  0.5000976  0.50377214 0.5038485  0.50637144 0.50519615\n",
      " 0.50472546 0.5062328  0.5034152  0.50772566 0.5066426  0.50246745\n",
      " 0.50116056 0.50331056 0.5056702  0.5037643  0.50507754 0.50233555\n",
      " 0.5034001  0.5078044 ]\n",
      "The rewards are: [0.5055693  0.5065941  0.5041566  0.50429946 0.5033804  0.5089189\n",
      " 0.50399953 0.50678307 0.5127032  0.5048616  0.50856423 0.51224524\n",
      " 0.5112734  0.5076971  0.50590336 0.5046227  0.5041159  0.5067691\n",
      " 0.5057765  0.505722   0.50269896 0.5093759  0.5058565  0.5034364\n",
      " 0.5037351  0.50130534 0.5001375  0.5050679  0.50503254 0.5030754\n",
      " 0.5087084  0.50364184]\n",
      "The rewards are: [0.50695664 0.50719196 0.50325066 0.50144225 0.50502867 0.508177\n",
      " 0.502163   0.5072147  0.50431275 0.50675005 0.50432336 0.50493056\n",
      " 0.50951594 0.5037295  0.5099528  0.50569284 0.5031954  0.5033043\n",
      " 0.5018082  0.50817573 0.50237143 0.50941485 0.5063681  0.5057298\n",
      " 0.50839335 0.5022044  0.50508904 0.50644577 0.5022397  0.50667334\n",
      " 0.5012629  0.5045789 ]\n",
      "The rewards are: [0.51313853 0.501512   0.5006594  0.5045788  0.50179523 0.50681114\n",
      " 0.5044472  0.5053839  0.50802046 0.50364757 0.504238   0.50618374\n",
      " 0.5029531  0.5053458  0.50914943 0.5053715  0.5052387  0.507464\n",
      " 0.50423515 0.501065   0.50650406 0.50118697 0.5014329  0.5011947\n",
      " 0.50709087 0.50909024 0.5054244  0.5025221  0.50428545 0.5097458\n",
      " 0.5083015  0.5020908 ]\n",
      "The rewards are: [0.5070934  0.5080473  0.5033912  0.5074717  0.5079914  0.5087648\n",
      " 0.5030067  0.5046702  0.50337046 0.5022157  0.50472164 0.5037593\n",
      " 0.5065939  0.50308233 0.50273305 0.5095347  0.50278795 0.5042403\n",
      " 0.5006146  0.5071312  0.5016835  0.5057514  0.5067062  0.5040344\n",
      " 0.5065457  0.5009981  0.51039046 0.5027634  0.50459045 0.50431466\n",
      " 0.5059175  0.5040105 ]\n",
      "The rewards are: [0.51216877 0.50572556 0.5063629  0.51015645 0.50473714 0.5105743\n",
      " 0.50335807 0.50405604 0.5028641  0.5075136  0.5137053  0.5054835\n",
      " 0.5001007  0.50381976 0.50342816 0.50149703 0.5071662  0.50624037\n",
      " 0.5047796  0.5065842  0.50433785 0.5053005  0.5076806  0.50237983\n",
      " 0.5067178  0.5079982  0.5088515  0.5092925  0.5015575  0.50271964\n",
      " 0.5050095  0.5079296 ]\n",
      "The rewards are: [0.50737464 0.5020762  0.5003706  0.50433123 0.51539767 0.5023811\n",
      " 0.5094968  0.50502104 0.5112555  0.5031017  0.5032642  0.50282216\n",
      " 0.50407726 0.5065165  0.5029423  0.507944   0.50731367 0.5075945\n",
      " 0.50915354 0.5015645  0.50252    0.50991607 0.5044462  0.5017656\n",
      " 0.5041043  0.50565976 0.5017138  0.50420177 0.50652725 0.5036338\n",
      " 0.50222397 0.5027424 ]\n",
      "The rewards are: [0.510815   0.5017238  0.5062245  0.50718343 0.5081234  0.5075609\n",
      " 0.5051772  0.50034964 0.5006346  0.5106758  0.5130473  0.50711685\n",
      " 0.50759137 0.51082295 0.500795   0.50658405 0.50034016 0.50333375\n",
      " 0.5032757  0.5065017  0.51276493 0.50427157 0.5081876  0.5058986\n",
      " 0.50722486 0.5053473  0.50809866 0.5003318  0.50260794 0.5005295\n",
      " 0.5006259  0.5068692 ]\n",
      "The rewards are: [0.50367165 0.50250643 0.5029093  0.50446326 0.5026943  0.5080648\n",
      " 0.5033608  0.51314545 0.5026901  0.51339614 0.5020151  0.5101172\n",
      " 0.511578   0.50002927 0.5069721  0.50330824 0.5094218  0.5048711\n",
      " 0.50123143 0.51216626 0.5101841  0.5050294  0.5054551  0.51206183\n",
      " 0.50128573 0.5086994  0.5038265  0.5048012  0.5014954  0.50210357\n",
      " 0.50963145 0.5077121 ]\n",
      "The rewards are: [0.5133141  0.50518066 0.5006501  0.5115532  0.5047544  0.5038783\n",
      " 0.50730544 0.5015429  0.50747705 0.508762   0.50297    0.50343287\n",
      " 0.50344884 0.5047299  0.51885414 0.50864875 0.5132243  0.5013534\n",
      " 0.5073303  0.5060032  0.5039815  0.5027971  0.5043538  0.5068647\n",
      " 0.5069415  0.5003347  0.50481915 0.51129204 0.51192254 0.5057578\n",
      " 0.5039277  0.50274   ]\n",
      "The rewards are: [0.50330263 0.5005735  0.5043485  0.50870323 0.50183773 0.5061453\n",
      " 0.5039129  0.51348805 0.5060316  0.51322985 0.5100447  0.50486094\n",
      " 0.5005843  0.508046   0.5073361  0.50255793 0.51148915 0.51175207\n",
      " 0.50727266 0.5127742  0.5168229  0.5018966  0.500882   0.5029245\n",
      " 0.5019302  0.50431335 0.50226617 0.51673746 0.5062497  0.51976526\n",
      " 0.5038976  0.5035058 ]\n",
      "The rewards are: [0.50393873 0.50587213 0.50554514 0.50135416 0.5007008  0.5014392\n",
      " 0.50050557 0.5043119  0.51159406 0.5023438  0.5042863  0.51428634\n",
      " 0.5017357  0.50135285 0.5071314  0.50318915 0.5063594  0.50969183\n",
      " 0.5099878  0.5100441  0.51142645 0.50246954 0.50042117 0.50120896\n",
      " 0.50994885 0.5075319  0.50002813 0.50687164 0.5011088  0.5057797\n",
      " 0.5064443  0.5044434 ]\n",
      "The rewards are: [0.50041354 0.5027608  0.5031616  0.5035199  0.5003605  0.5009916\n",
      " 0.5123699  0.50482064 0.5065561  0.51075584 0.50161505 0.50930053\n",
      " 0.51387495 0.503047   0.51010144 0.5063285  0.5188599  0.502251\n",
      " 0.50435764 0.50021696 0.5197908  0.5022048  0.50981635 0.5037178\n",
      " 0.5021073  0.5018337  0.5064528  0.51098377 0.51270235 0.5078616\n",
      " 0.50959885 0.50438553]\n",
      "The rewards are: [0.50132084 0.50123733 0.50405335 0.5029205  0.50046426 0.5021343\n",
      " 0.5027739  0.503451   0.5011288  0.5157085  0.5042722  0.51384246\n",
      " 0.507477   0.5023285  0.50555354 0.5048536  0.5080931  0.50293595\n",
      " 0.504877   0.5108271  0.5019435  0.5103002  0.5072106  0.50411886\n",
      " 0.50813466 0.5053822  0.5115221  0.5040902  0.5043767  0.5016955\n",
      " 0.5045635  0.5035381 ]\n",
      "The rewards are: [0.5088527  0.50612104 0.5052989  0.5019608  0.50377816 0.50984\n",
      " 0.5002291  0.5148498  0.515241   0.5046035  0.5007321  0.51187366\n",
      " 0.50886154 0.50001544 0.5096665  0.5039292  0.5056791  0.5095798\n",
      " 0.5067692  0.50455266 0.5029935  0.5048202  0.50172013 0.5094939\n",
      " 0.50230765 0.5135211  0.5014287  0.5075058  0.50924706 0.50768226\n",
      " 0.5049541  0.5097444 ]\n",
      "The rewards are: [0.5103601  0.50269514 0.5064345  0.5060076  0.5090014  0.50536424\n",
      " 0.50341433 0.50643903 0.5053318  0.5145817  0.51199657 0.51219165\n",
      " 0.5072325  0.5010768  0.50431496 0.50484335 0.5103593  0.5021805\n",
      " 0.5103702  0.5132287  0.5021947  0.50193405 0.5019773  0.51895857\n",
      " 0.5105862  0.5074586  0.50392044 0.50434613 0.5164594  0.50197464\n",
      " 0.5020079  0.50368845]\n",
      "The rewards are: [0.50560224 0.5085638  0.51274097 0.50172704 0.50420415 0.5049752\n",
      " 0.51898617 0.5141485  0.5014833  0.511233   0.5096145  0.5093578\n",
      " 0.50621367 0.50472444 0.5042672  0.5010993  0.5074346  0.51305443\n",
      " 0.5123248  0.5144321  0.5226393  0.50167996 0.5043114  0.5122164\n",
      " 0.51009935 0.51481974 0.51154816 0.50853187 0.5128214  0.5033478\n",
      " 0.50123453 0.5043835 ]\n",
      "The rewards are: [0.5068347  0.50893766 0.5141537  0.5123513  0.50163144 0.509909\n",
      " 0.5075945  0.50805444 0.5186932  0.5118194  0.50303245 0.5036244\n",
      " 0.51909995 0.50178075 0.50827736 0.508833   0.5011314  0.50858945\n",
      " 0.50324565 0.5076683  0.5019987  0.5091996  0.50439423 0.5222206\n",
      " 0.5026851  0.5086769  0.5142557  0.5223658  0.5074559  0.51572704\n",
      " 0.50076157 0.524018  ]\n",
      "The rewards are: [0.5084398  0.50841236 0.50026274 0.5082695  0.509745   0.5034167\n",
      " 0.50216496 0.5090979  0.5051698  0.5036156  0.5096616  0.50188893\n",
      " 0.50857687 0.51619965 0.5223949  0.50416255 0.51212925 0.5107744\n",
      " 0.50852686 0.50814366 0.5046818  0.5094872  0.5024007  0.5035582\n",
      " 0.5021289  0.50177884 0.52105    0.5115819  0.51594937 0.50873554\n",
      " 0.5108081  0.5059906 ]\n",
      "The rewards are: [0.50731295 0.50289375 0.51867235 0.5041057  0.50484157 0.5090425\n",
      " 0.5153647  0.51585954 0.50759417 0.50332135 0.5277143  0.5191778\n",
      " 0.5011699  0.5059302  0.5188393  0.50450224 0.51841676 0.5124901\n",
      " 0.507907   0.5025797  0.51327217 0.50201356 0.5023788  0.50819653\n",
      " 0.502559   0.50299567 0.50694877 0.5035845  0.5061075  0.5033511\n",
      " 0.51490057 0.5065435 ]\n",
      "The rewards are: [0.50715417 0.5033396  0.5087371  0.515526   0.5061973  0.50138575\n",
      " 0.51412755 0.50559103 0.5140248  0.5192883  0.5160195  0.50176597\n",
      " 0.5015813  0.5086808  0.5088975  0.50425804 0.5004527  0.5044837\n",
      " 0.5169463  0.5064942  0.51061475 0.50811315 0.50336504 0.5030771\n",
      " 0.51683825 0.51349235 0.5173755  0.5039524  0.5260164  0.5227465\n",
      " 0.5054398  0.5195845 ]\n",
      "The rewards are: [0.5165679  0.5270349  0.5273576  0.513488   0.5032741  0.5201938\n",
      " 0.51805043 0.50371176 0.5164036  0.5066917  0.51724195 0.5061671\n",
      " 0.51702195 0.5097271  0.5072944  0.523336   0.50457466 0.50097084\n",
      " 0.50459325 0.5271161  0.5077711  0.5244972  0.5167417  0.5239841\n",
      " 0.52179986 0.50176585 0.51726    0.5081793  0.50372005 0.51656574\n",
      " 0.5057235  0.5001783 ]\n",
      "The rewards are: [0.5251329  0.5005737  0.50853705 0.518059   0.50997317 0.5095504\n",
      " 0.5242314  0.5150868  0.5114906  0.5304253  0.503697   0.52450025\n",
      " 0.5065019  0.5193368  0.5055825  0.50729406 0.521817   0.50596017\n",
      " 0.5132158  0.511693   0.50230485 0.5105592  0.50486183 0.5150418\n",
      " 0.50677866 0.51866794 0.5330902  0.51736206 0.5060275  0.5161321\n",
      " 0.51890165 0.50396675]\n",
      "The rewards are: [0.5227363  0.517471   0.5081486  0.5159529  0.51315093 0.5100624\n",
      " 0.5149997  0.50809747 0.50562584 0.5039883  0.5141023  0.5049085\n",
      " 0.5123095  0.5007785  0.5288099  0.51251626 0.5264565  0.50898397\n",
      " 0.5070636  0.5066798  0.530683   0.5078561  0.5186806  0.5104805\n",
      " 0.5026903  0.50583845 0.5154965  0.50642467 0.5038974  0.51122856\n",
      " 0.50521463 0.51276314]\n",
      "The rewards are: [0.50156754 0.50123954 0.53661656 0.51185066 0.5051823  0.51466775\n",
      " 0.50943404 0.5100471  0.5259324  0.5083064  0.51170045 0.5170013\n",
      " 0.5109072  0.5089622  0.5119789  0.5093314  0.5277705  0.50642353\n",
      " 0.5250056  0.5111721  0.5228384  0.5108065  0.5279795  0.52284783\n",
      " 0.5048036  0.5065561  0.51205295 0.5167552  0.5045677  0.5168094\n",
      " 0.51511914 0.50552714]\n",
      "The rewards are: [0.5211188  0.5097229  0.5452129  0.5317749  0.5034807  0.51491994\n",
      " 0.50128525 0.5015781  0.50002956 0.5177985  0.5226269  0.50356376\n",
      " 0.505548   0.5143704  0.515764   0.5066824  0.50393015 0.50491244\n",
      " 0.50671685 0.51601464 0.5287789  0.5025555  0.53152466 0.53583133\n",
      " 0.5295455  0.5163599  0.52202535 0.5087857  0.5022292  0.52511835\n",
      " 0.52544916 0.5052178 ]\n",
      "The rewards are: [0.5058816  0.5227857  0.51341665 0.5076614  0.5139638  0.51999944\n",
      " 0.52656555 0.50011164 0.51853204 0.5195757  0.5397794  0.5028418\n",
      " 0.5316143  0.5166419  0.52070755 0.51132977 0.50324297 0.5251096\n",
      " 0.5212562  0.52162004 0.5029139  0.52575004 0.53567225 0.523073\n",
      " 0.52650076 0.50011957 0.50691193 0.50736207 0.5262599  0.5084119\n",
      " 0.5085782  0.5273419 ]\n",
      "The rewards are: [0.5243833  0.5312612  0.518065   0.5070667  0.5214544  0.51017714\n",
      " 0.523101   0.5001864  0.5021746  0.50362724 0.5130613  0.53358275\n",
      " 0.5019777  0.54140973 0.5182053  0.5128778  0.5026573  0.5042856\n",
      " 0.5159063  0.5186786  0.529283   0.51479036 0.5168979  0.5149297\n",
      " 0.55146307 0.51834315 0.52238965 0.50117373 0.507314   0.52830046\n",
      " 0.5025623  0.52812195]\n",
      "The rewards are: [0.52390426 0.511479   0.5026386  0.51692253 0.5239189  0.51137483\n",
      " 0.5068935  0.5115091  0.52705795 0.5028637  0.517203   0.505412\n",
      " 0.538132   0.52614695 0.52446365 0.5081116  0.5027293  0.50744635\n",
      " 0.53526825 0.5171779  0.509545   0.5343478  0.5408218  0.50948536\n",
      " 0.5006014  0.5349314  0.53281754 0.5274852  0.5197315  0.5060612\n",
      " 0.51629025 0.5084141 ]\n",
      "The rewards are: [0.550301   0.5112385  0.5125131  0.512785   0.5140291  0.5035452\n",
      " 0.5367944  0.50734043 0.5042062  0.5275075  0.50262094 0.5391866\n",
      " 0.5055429  0.50398517 0.5211758  0.53864163 0.53065896 0.54515016\n",
      " 0.51045114 0.5055519  0.5180969  0.5209696  0.5051553  0.52977663\n",
      " 0.52399737 0.5006552  0.5324789  0.53274584 0.51507187 0.5098065\n",
      " 0.50548893 0.54170537]\n",
      "The rewards are: [0.5159791  0.50727487 0.5371282  0.5049541  0.5204847  0.52987045\n",
      " 0.5453269  0.5053904  0.5392554  0.5179198  0.5453205  0.5151374\n",
      " 0.5145084  0.52273667 0.54208326 0.51854223 0.55259496 0.50886583\n",
      " 0.5357832  0.50256467 0.53701675 0.509077   0.51480204 0.5331232\n",
      " 0.5164695  0.52611667 0.50302774 0.50818235 0.5015979  0.5356414\n",
      " 0.50830233 0.5071885 ]\n",
      "The rewards are: [0.54288125 0.51052105 0.5150584  0.52982795 0.50471884 0.5322171\n",
      " 0.52917147 0.54013747 0.52891463 0.501249   0.52919257 0.50008106\n",
      " 0.509301   0.55439454 0.51137817 0.5014458  0.54417175 0.5211322\n",
      " 0.5152654  0.53055054 0.55143434 0.5107875  0.50672644 0.51656884\n",
      " 0.5374742  0.5421377  0.52420616 0.5344371  0.50608444 0.52140874\n",
      " 0.50593144 0.5114729 ]\n",
      "The rewards are: [0.5064224  0.53943855 0.5222035  0.5241823  0.53759474 0.5119062\n",
      " 0.5365505  0.5418918  0.5239091  0.5027195  0.55050874 0.5021538\n",
      " 0.5459729  0.5419125  0.50897825 0.51401824 0.50287163 0.5249738\n",
      " 0.55024457 0.53685457 0.50881654 0.5518496  0.50329924 0.5024721\n",
      " 0.53219503 0.53487664 0.54965425 0.5060889  0.50390136 0.50798774\n",
      " 0.542485   0.5252223 ]\n",
      "The rewards are: [0.53614545 0.52093565 0.5475168  0.5368756  0.5528519  0.54087424\n",
      " 0.5320818  0.5344365  0.51211065 0.50662655 0.5072486  0.50056416\n",
      " 0.5040803  0.5133746  0.5141828  0.5620285  0.52065736 0.5049635\n",
      " 0.527194   0.518223   0.5049817  0.5148068  0.55134714 0.50065976\n",
      " 0.50518167 0.5497374  0.5349571  0.50138557 0.55422884 0.50314873\n",
      " 0.54298615 0.51820016]\n",
      "The rewards are: [0.5029485  0.53097916 0.50066286 0.55479187 0.52060515 0.5067301\n",
      " 0.5076086  0.50712955 0.53781986 0.52144885 0.55036676 0.56259006\n",
      " 0.51526904 0.551072   0.5205776  0.54016787 0.5206981  0.50009245\n",
      " 0.5036243  0.5438206  0.51115716 0.5399075  0.52333546 0.510203\n",
      " 0.5464078  0.52604645 0.50412273 0.5179489  0.5642096  0.55066437\n",
      " 0.5130877  0.500007  ]\n",
      "The rewards are: [0.532782   0.5119662  0.5338379  0.50514805 0.5161497  0.50728136\n",
      " 0.5029915  0.50315404 0.52976316 0.5248834  0.53545094 0.53706175\n",
      " 0.50642264 0.55736995 0.550211   0.5053869  0.50261194 0.55457103\n",
      " 0.5366427  0.5155837  0.5092621  0.50149167 0.5095864  0.5051233\n",
      " 0.50396246 0.51479954 0.5580262  0.526187   0.51838326 0.5318911\n",
      " 0.5228682  0.53374004]\n",
      "The rewards are: [0.5261428  0.5230319  0.5407789  0.5586941  0.5157138  0.57332975\n",
      " 0.5708218  0.5466502  0.518294   0.52123296 0.5418065  0.50170654\n",
      " 0.5565175  0.51281846 0.50812835 0.5357193  0.57283235 0.56520087\n",
      " 0.5042135  0.56067806 0.5101007  0.5476575  0.52894384 0.52385336\n",
      " 0.5430414  0.52681434 0.5392931  0.5428167  0.55273074 0.5220094\n",
      " 0.5813234  0.5023584 ]\n",
      "The rewards are: [0.5282579  0.5027665  0.5182847  0.5058745  0.51550287 0.50680625\n",
      " 0.5061579  0.5149476  0.5426131  0.5174404  0.54115    0.51855236\n",
      " 0.5170016  0.527843   0.5662413  0.5230612  0.5068306  0.55641556\n",
      " 0.5431526  0.5583919  0.51455975 0.5486426  0.57232755 0.553299\n",
      " 0.55236316 0.5065686  0.5080697  0.5357716  0.557775   0.5243095\n",
      " 0.56528056 0.5185446 ]\n",
      "The rewards are: [0.5102464  0.5029427  0.5502596  0.502413   0.5495146  0.5644634\n",
      " 0.5483923  0.5221181  0.5295601  0.5499199  0.5072533  0.53384995\n",
      " 0.5731203  0.50712794 0.532224   0.5287296  0.51358247 0.52816224\n",
      " 0.53605914 0.5056572  0.52818704 0.5017335  0.53648204 0.505619\n",
      " 0.5148227  0.5060074  0.52797365 0.5017114  0.57513744 0.5492477\n",
      " 0.5359808  0.5171795 ]\n",
      "The rewards are: [0.5077802  0.5272651  0.5456642  0.5059123  0.52963173 0.5277691\n",
      " 0.5254591  0.5400022  0.5030662  0.5201295  0.52141994 0.52078384\n",
      " 0.54421514 0.5181139  0.5557427  0.5114515  0.579404   0.5377149\n",
      " 0.51029664 0.5420961  0.51678216 0.5554459  0.5591017  0.5381345\n",
      " 0.53340507 0.5097801  0.54854393 0.51270735 0.5731724  0.5792707\n",
      " 0.56621385 0.5572371 ]\n",
      "The rewards are: [0.50708497 0.5138238  0.50633097 0.56029874 0.5244491  0.54471374\n",
      " 0.5211291  0.5136625  0.5113399  0.5454978  0.5156967  0.5334644\n",
      " 0.52460486 0.51546127 0.5776331  0.503252   0.5079118  0.53525174\n",
      " 0.5752835  0.5382853  0.5565884  0.5245175  0.50384104 0.54044086\n",
      " 0.5426924  0.51523393 0.53588957 0.5018315  0.518316   0.53581566\n",
      " 0.57667077 0.50801724]\n",
      "The rewards are: [0.5185156  0.52513415 0.501199   0.5175645  0.5350085  0.5196485\n",
      " 0.59144926 0.53540695 0.50503296 0.5605738  0.51987535 0.51743054\n",
      " 0.53163177 0.5036973  0.52486545 0.5354985  0.5421243  0.5398765\n",
      " 0.5225726  0.5349491  0.53415275 0.5883931  0.513209   0.5268083\n",
      " 0.5417537  0.50720316 0.5675631  0.5138723  0.5080777  0.51566523\n",
      " 0.53314984 0.51902336]\n",
      "The rewards are: [0.5435737  0.53897965 0.514704   0.5334975  0.5267272  0.56028646\n",
      " 0.5481874  0.50212854 0.5594527  0.5540707  0.54744464 0.5121904\n",
      " 0.5595031  0.5380537  0.54710597 0.5740338  0.5363597  0.5830026\n",
      " 0.5007288  0.58169305 0.61069334 0.51175576 0.5551131  0.58838844\n",
      " 0.5213929  0.53632146 0.5516398  0.5752429  0.5797926  0.5445066\n",
      " 0.5400255  0.51979727]\n",
      "The rewards are: [0.5088693  0.5103706  0.56566095 0.5068096  0.54035074 0.53914404\n",
      " 0.52530503 0.50800997 0.5632721  0.5448593  0.57440436 0.5165618\n",
      " 0.5197762  0.50620145 0.5753919  0.5336633  0.5022826  0.5020297\n",
      " 0.56191546 0.57297546 0.5057603  0.5431547  0.5120959  0.5607437\n",
      " 0.5801195  0.5772874  0.5075179  0.5424635  0.5387706  0.55821496\n",
      " 0.55011845 0.50166607]\n",
      "The rewards are: [0.57105297 0.5632486  0.536212   0.59697086 0.5116472  0.52828234\n",
      " 0.5847375  0.54098517 0.54227084 0.5200877  0.5560046  0.58150285\n",
      " 0.51222676 0.50902104 0.5159761  0.5111863  0.502208   0.5354519\n",
      " 0.5333958  0.57105947 0.56779736 0.5354636  0.5442802  0.5588848\n",
      " 0.54376215 0.5132704  0.5436716  0.54716986 0.57404083 0.51617074\n",
      " 0.52373356 0.53278077]\n",
      "The rewards are: [0.51208633 0.5065507  0.5379058  0.5773712  0.5523772  0.5821134\n",
      " 0.5739046  0.6061083  0.51462823 0.5214266  0.59479576 0.5071204\n",
      " 0.5538975  0.53639174 0.51729804 0.5776621  0.581856   0.525963\n",
      " 0.55552214 0.56129867 0.5133147  0.5230948  0.51986015 0.5099128\n",
      " 0.50753105 0.51247156 0.5565146  0.51522934 0.5314344  0.5093882\n",
      " 0.5309564  0.5242978 ]\n",
      "The rewards are: [0.50954354 0.526782   0.54829353 0.5920323  0.52302706 0.5581046\n",
      " 0.5000454  0.5069404  0.5672037  0.5549724  0.5109107  0.5617296\n",
      " 0.5856552  0.5142013  0.5162175  0.52596784 0.59544796 0.5396862\n",
      " 0.50495297 0.5135221  0.5341908  0.56633854 0.6039006  0.5050301\n",
      " 0.50352293 0.57127535 0.5369191  0.54042065 0.520494   0.50484294\n",
      " 0.55134547 0.5106376 ]\n",
      "The rewards are: [0.5657673  0.5030842  0.6023598  0.56773853 0.5616277  0.5180808\n",
      " 0.5902501  0.50769365 0.5233134  0.5545038  0.56930023 0.5405227\n",
      " 0.55070126 0.59161836 0.54059637 0.5645706  0.5402276  0.5223905\n",
      " 0.5177841  0.5132172  0.5151254  0.5288918  0.59114283 0.5188386\n",
      " 0.5089147  0.51973313 0.5457663  0.589303   0.56426966 0.5272905\n",
      " 0.58420247 0.5679688 ]\n",
      "The rewards are: [0.5283959  0.5355576  0.5550715  0.5278869  0.55628914 0.5455949\n",
      " 0.5071     0.521384   0.56370574 0.5827274  0.56691504 0.52145797\n",
      " 0.50306463 0.5440823  0.5586801  0.61642957 0.5723913  0.5062873\n",
      " 0.5886672  0.54991287 0.53519166 0.51824915 0.5194745  0.50299025\n",
      " 0.529279   0.5946589  0.5772294  0.5603181  0.5175282  0.572762\n",
      " 0.50199914 0.57116103]\n",
      "The rewards are: [0.5346915  0.59019494 0.5656113  0.5020124  0.5320983  0.50059456\n",
      " 0.5565413  0.5981003  0.5607841  0.50798935 0.574951   0.57266337\n",
      " 0.50720626 0.53528965 0.5326669  0.5047796  0.57583314 0.5277746\n",
      " 0.5075422  0.58820057 0.5273724  0.534135   0.50544506 0.5825794\n",
      " 0.508193   0.5790207  0.56698316 0.5893483  0.5317063  0.5224953\n",
      " 0.57103026 0.5153477 ]\n",
      "The rewards are: [0.5303888  0.56031096 0.5599338  0.5650937  0.5502247  0.5282252\n",
      " 0.53190464 0.5993803  0.50300217 0.5322191  0.522093   0.5172323\n",
      " 0.5138462  0.51496035 0.54543704 0.52033365 0.5832533  0.5570157\n",
      " 0.5094063  0.5031712  0.6009443  0.56600153 0.5217515  0.5221923\n",
      " 0.5293004  0.542629   0.5660156  0.5745148  0.511211   0.5914554\n",
      " 0.5685661  0.601847  ]\n",
      "The rewards are: [0.52817166 0.56042445 0.6046356  0.5137063  0.5337279  0.51556015\n",
      " 0.5807862  0.56609654 0.55684394 0.5558546  0.5326282  0.5637531\n",
      " 0.5716199  0.53364885 0.5289944  0.5416635  0.52411246 0.50971746\n",
      " 0.5301856  0.6132717  0.5402489  0.592807   0.5653261  0.53972554\n",
      " 0.5160115  0.52295446 0.5755579  0.51786363 0.6073187  0.50719243\n",
      " 0.52355176 0.5137356 ]\n",
      "The rewards are: [0.5471881  0.5945441  0.5605178  0.6091944  0.58588547 0.60758793\n",
      " 0.5239407  0.58115244 0.5585194  0.55453146 0.5787974  0.5851985\n",
      " 0.5138761  0.5363184  0.50861466 0.5377291  0.5436225  0.5094392\n",
      " 0.50911754 0.62935644 0.5041749  0.51157504 0.5883087  0.554506\n",
      " 0.58222324 0.5937532  0.5430925  0.52295846 0.5495823  0.5281017\n",
      " 0.50397563 0.521858  ]\n",
      "The rewards are: [0.56438446 0.57427    0.5187408  0.519275   0.558638   0.5016287\n",
      " 0.5174743  0.6240725  0.58996105 0.5238718  0.5965557  0.505178\n",
      " 0.5012603  0.56849396 0.50489    0.50166065 0.500226   0.5549228\n",
      " 0.5095722  0.5834061  0.5434857  0.5326511  0.52611524 0.5166508\n",
      " 0.5454897  0.5236092  0.5276203  0.50876594 0.5336226  0.5149527\n",
      " 0.5298102  0.550764  ]\n",
      "The rewards are: [0.5154024  0.53414434 0.5661672  0.54787403 0.5051162  0.596949\n",
      " 0.5614452  0.60449857 0.604171   0.50580704 0.5236418  0.6234488\n",
      " 0.56027675 0.51085615 0.5418485  0.56321084 0.5512923  0.56901014\n",
      " 0.51232696 0.5176532  0.5023333  0.5502249  0.51708204 0.5697188\n",
      " 0.57189596 0.5050483  0.5130333  0.58391297 0.51127774 0.59157413\n",
      " 0.64718306 0.5782917 ]\n",
      "The rewards are: [0.5744264  0.59994    0.5343296  0.5595939  0.5147853  0.6363575\n",
      " 0.5717055  0.53394043 0.5464273  0.59045315 0.52468705 0.6091711\n",
      " 0.5000117  0.57903713 0.5511887  0.53230405 0.53753924 0.54251444\n",
      " 0.5259623  0.6464572  0.5055231  0.5412391  0.60797596 0.59512246\n",
      " 0.5172285  0.5343189  0.5652157  0.5291913  0.60164374 0.6374322\n",
      " 0.5930741  0.60979503]\n",
      "The rewards are: [0.5750241  0.50426954 0.59111947 0.5796965  0.50490916 0.5508783\n",
      " 0.52552325 0.50369513 0.6107964  0.619392   0.547146   0.570965\n",
      " 0.54387045 0.58858603 0.50376016 0.5747845  0.60066664 0.57272494\n",
      " 0.5016894  0.55225515 0.59653175 0.51928836 0.5959262  0.5089254\n",
      " 0.5156637  0.5122305  0.5589934  0.5331324  0.533142   0.5014213\n",
      " 0.59484243 0.59970313]\n",
      "The rewards are: [0.5728469  0.5341026  0.5771988  0.6295875  0.5859595  0.5283451\n",
      " 0.58312315 0.5766713  0.55594295 0.5639828  0.59907633 0.52679586\n",
      " 0.60866636 0.5133193  0.5891108  0.61204314 0.5273668  0.5417784\n",
      " 0.50340396 0.503596   0.58629787 0.52863556 0.5838137  0.5487795\n",
      " 0.62717575 0.58611697 0.51709425 0.5792349  0.52585083 0.54068476\n",
      " 0.62747073 0.54173255]\n",
      "The rewards are: [0.5318638  0.5392764  0.619981   0.5643595  0.53458685 0.5542389\n",
      " 0.55215085 0.5539278  0.5433049  0.6421444  0.5989396  0.55054\n",
      " 0.52737755 0.52895933 0.54185134 0.5441514  0.5808239  0.5732088\n",
      " 0.5010805  0.51193887 0.5292651  0.52710235 0.5252068  0.5663971\n",
      " 0.5759123  0.5282642  0.53243697 0.5061793  0.57821745 0.5189879\n",
      " 0.50221705 0.5591727 ]\n",
      "The rewards are: [0.5027599  0.5182347  0.5263661  0.5380778  0.6043062  0.5241115\n",
      " 0.5510582  0.5431581  0.5237542  0.5526314  0.61187774 0.60789746\n",
      " 0.5645953  0.52244157 0.576283   0.62935954 0.60839593 0.56235754\n",
      " 0.52287364 0.57305413 0.5461374  0.5834684  0.67406356 0.57042867\n",
      " 0.5285719  0.5983135  0.54567945 0.59164846 0.50217646 0.52874875\n",
      " 0.5227804  0.52147835]\n",
      "The rewards are: [0.5280102  0.583467   0.5339934  0.5132181  0.5043732  0.5012841\n",
      " 0.5399376  0.5013961  0.5097256  0.5148617  0.5319647  0.58133644\n",
      " 0.560665   0.64958125 0.5985536  0.52575946 0.5087258  0.6113726\n",
      " 0.5137167  0.51293904 0.54865575 0.59691125 0.54569423 0.55149114\n",
      " 0.5311651  0.56711686 0.50845    0.5643208  0.6117657  0.5552162\n",
      " 0.64853764 0.5729454 ]\n",
      "The rewards are: [0.6102924  0.5546985  0.5358083  0.580104   0.5465841  0.6227055\n",
      " 0.62419677 0.5828908  0.60907066 0.6295764  0.5516783  0.6602589\n",
      " 0.66372216 0.5569817  0.6035205  0.5093086  0.58310324 0.5231853\n",
      " 0.6245111  0.603963   0.6478372  0.5850389  0.5949065  0.53298205\n",
      " 0.525043   0.5227572  0.5250521  0.59544384 0.55928195 0.5214037\n",
      " 0.5926553  0.6184429 ]\n",
      "The rewards are: [0.6222991  0.5158214  0.58613    0.5423331  0.57978535 0.5075125\n",
      " 0.56833994 0.66450506 0.65996104 0.6272891  0.5416364  0.60728514\n",
      " 0.51861304 0.50540197 0.5027904  0.6320693  0.566339   0.65149844\n",
      " 0.59333533 0.55379343 0.6305786  0.5255867  0.5091616  0.52467614\n",
      " 0.5358846  0.5439412  0.5194202  0.55398303 0.5088961  0.5728007\n",
      " 0.51722556 0.59026825]\n",
      "The rewards are: [0.60620636 0.5108816  0.53587264 0.51714975 0.5143774  0.5421353\n",
      " 0.519166   0.52097577 0.5519094  0.50708807 0.5856996  0.594185\n",
      " 0.6217223  0.6096888  0.5205705  0.57371175 0.5476579  0.5133602\n",
      " 0.5212344  0.5731877  0.64259374 0.5039986  0.5633001  0.5968087\n",
      " 0.5036579  0.61449385 0.5812346  0.53902066 0.52402526 0.50021064\n",
      " 0.5922624  0.55099756]\n",
      "The rewards are: [0.54082733 0.5536621  0.5207225  0.5612595  0.69245607 0.5394728\n",
      " 0.57059366 0.5571014  0.60290724 0.52729535 0.549806   0.5584982\n",
      " 0.52947015 0.6174722  0.6673308  0.5575368  0.5039114  0.61295795\n",
      " 0.56272125 0.54695404 0.5075971  0.5436829  0.5249369  0.5142104\n",
      " 0.56016403 0.5448611  0.53377783 0.5896673  0.5159096  0.62627274\n",
      " 0.5875067  0.5560587 ]\n",
      "The rewards are: [0.6205848  0.52454364 0.58767605 0.542825   0.519296   0.53506297\n",
      " 0.5739241  0.5804094  0.51606053 0.6229432  0.56114036 0.5462916\n",
      " 0.56344616 0.59971833 0.5206151  0.5581431  0.53403705 0.65860116\n",
      " 0.51829517 0.5107557  0.526905   0.6000304  0.5412854  0.50055736\n",
      " 0.522563   0.6004028  0.5410678  0.6280113  0.6147413  0.55645055\n",
      " 0.53105116 0.5380679 ]\n",
      "The rewards are: [0.5548679  0.5689903  0.5733784  0.65787196 0.5855931  0.5278602\n",
      " 0.5551006  0.6880343  0.62188303 0.62953764 0.5913946  0.58394724\n",
      " 0.5482992  0.50157595 0.6379952  0.650435   0.56953347 0.51380306\n",
      " 0.6002471  0.6616277  0.54217744 0.56028163 0.57738864 0.5518234\n",
      " 0.5314106  0.6009404  0.6172898  0.5655592  0.6262354  0.5564013\n",
      " 0.5808503  0.5694721 ]\n",
      "The rewards are: [0.53870386 0.5032058  0.5453977  0.6627409  0.53887296 0.5766103\n",
      " 0.50790113 0.5395503  0.5875806  0.63796896 0.5991329  0.5147464\n",
      " 0.61585    0.6688849  0.6918036  0.57020026 0.52553064 0.6181371\n",
      " 0.53463376 0.5132485  0.65808624 0.5513448  0.53394336 0.5744021\n",
      " 0.599426   0.50891036 0.6739952  0.50561744 0.6468025  0.5168998\n",
      " 0.6409275  0.54924434]\n",
      "The rewards are: [0.63056934 0.51705104 0.55310345 0.55088043 0.5447696  0.5276322\n",
      " 0.5401721  0.5379049  0.6104304  0.5174445  0.50843155 0.6224706\n",
      " 0.6599199  0.5275628  0.5324211  0.5274658  0.5082718  0.60870945\n",
      " 0.6079431  0.5390149  0.54619414 0.5805838  0.5224911  0.594729\n",
      " 0.56101143 0.5599025  0.51513976 0.552148   0.59196246 0.6280352\n",
      " 0.5108393  0.55793405]\n",
      "The rewards are: [0.60964715 0.5271428  0.5061481  0.5517703  0.50087994 0.53305626\n",
      " 0.5902761  0.5320901  0.5059832  0.5598699  0.53045166 0.6199242\n",
      " 0.5208375  0.61726874 0.50385225 0.5010788  0.5019237  0.5061384\n",
      " 0.5524715  0.51425016 0.6058912  0.58188283 0.5131644  0.65765333\n",
      " 0.5009428  0.5379907  0.5656045  0.64776874 0.50916463 0.63151705\n",
      " 0.5826645  0.62559336]\n",
      "The rewards are: [0.52022105 0.5756494  0.66955143 0.67944086 0.69571495 0.60346556\n",
      " 0.53192383 0.59038347 0.6014017  0.62809354 0.6379026  0.5472537\n",
      " 0.51742566 0.5380513  0.6266236  0.5202728  0.63428426 0.61823165\n",
      " 0.50235605 0.61826974 0.5594089  0.6107338  0.5051705  0.51717556\n",
      " 0.5868081  0.68548596 0.55490595 0.6544695  0.6752659  0.6366264\n",
      " 0.5332005  0.519398  ]\n",
      "The rewards are: [0.68742216 0.5600408  0.61202264 0.57643193 0.64317995 0.5602288\n",
      " 0.5567958  0.61433345 0.5019064  0.6997299  0.58295393 0.5260633\n",
      " 0.5411546  0.5634441  0.50419766 0.6096136  0.6761753  0.5166388\n",
      " 0.59184945 0.5013463  0.5598895  0.5272051  0.74868435 0.63152593\n",
      " 0.52167284 0.5933848  0.5878465  0.63832957 0.551249   0.52719545\n",
      " 0.5334383  0.5607757 ]\n",
      "The rewards are: [0.5303088  0.66307026 0.65699077 0.68996465 0.51620483 0.6074144\n",
      " 0.5870281  0.6291181  0.54516214 0.509135   0.6028558  0.5831045\n",
      " 0.5239706  0.5684453  0.50030154 0.64529383 0.5105409  0.5957763\n",
      " 0.5437371  0.6979047  0.6701502  0.5905499  0.5263185  0.55516523\n",
      " 0.5715674  0.555297   0.5010683  0.6245126  0.5346564  0.50734174\n",
      " 0.52887696 0.6349267 ]\n",
      "The rewards are: [0.59377253 0.5085125  0.50135565 0.6173536  0.55842435 0.5387097\n",
      " 0.53991115 0.6409     0.5703934  0.57261485 0.52890104 0.594142\n",
      " 0.5105995  0.5491184  0.54143316 0.6051936  0.63381636 0.520841\n",
      " 0.51593596 0.51324946 0.66873795 0.57695496 0.5550184  0.6221579\n",
      " 0.5621106  0.58962494 0.5971906  0.55401474 0.65780216 0.5807079\n",
      " 0.52858555 0.6283526 ]\n",
      "The rewards are: [0.6160166  0.6122853  0.6658955  0.5123257  0.60308444 0.5182836\n",
      " 0.5131228  0.5494766  0.5448416  0.5296048  0.61390656 0.632527\n",
      " 0.6298323  0.5459304  0.5897371  0.61224854 0.5299047  0.55352837\n",
      " 0.55630416 0.67128325 0.5794881  0.51060206 0.5551671  0.5145489\n",
      " 0.5557614  0.528895   0.65907073 0.6112098  0.63684326 0.59388626\n",
      " 0.564717   0.64556456]\n",
      "The rewards are: [0.6845893  0.53456104 0.6092088  0.52735645 0.6491332  0.6068555\n",
      " 0.65318894 0.58521754 0.58940166 0.59458035 0.5682541  0.52239037\n",
      " 0.5191465  0.607488   0.5421896  0.5022319  0.53819025 0.53537583\n",
      " 0.526664   0.5308662  0.6142579  0.5541344  0.6801278  0.5184484\n",
      " 0.560745   0.61065286 0.5927404  0.64815533 0.6138443  0.60305566\n",
      " 0.6845136  0.5013651 ]\n",
      "The rewards are: [0.65008044 0.6187248  0.58522713 0.64737594 0.5657882  0.7128105\n",
      " 0.65110826 0.5971397  0.65846217 0.5310293  0.62206346 0.6338973\n",
      " 0.5187794  0.67195743 0.6571078  0.504751   0.56448376 0.6074875\n",
      " 0.60353136 0.6094092  0.5250905  0.53425616 0.55676174 0.73509777\n",
      " 0.65615886 0.5270653  0.50169617 0.58288574 0.5343381  0.65938485\n",
      " 0.6445333  0.53491557]\n",
      "The rewards are: [0.5094096  0.57710236 0.6896657  0.5175395  0.52387387 0.68786925\n",
      " 0.64655375 0.6151764  0.5724313  0.57208097 0.662507   0.6101743\n",
      " 0.5940738  0.66803086 0.5247309  0.60296726 0.66825485 0.5564063\n",
      " 0.6876367  0.5670231  0.62801075 0.62440306 0.5575179  0.5805098\n",
      " 0.5467624  0.50858045 0.56509405 0.58807355 0.58728325 0.542872\n",
      " 0.5385073  0.5273012 ]\n",
      "The rewards are: [0.5570356  0.52351195 0.60458374 0.5242861  0.51350415 0.6377847\n",
      " 0.54801184 0.6672362  0.57499576 0.5158424  0.5705616  0.59004843\n",
      " 0.5216384  0.54696333 0.5367475  0.53872    0.6582946  0.70819545\n",
      " 0.5981815  0.6143719  0.5449617  0.51210564 0.63522595 0.63818\n",
      " 0.56615055 0.6382211  0.7072602  0.55436957 0.6276369  0.60040444\n",
      " 0.5950685  0.5656944 ]\n",
      "The rewards are: [0.59771436 0.51278996 0.5046273  0.6756601  0.5923203  0.5519528\n",
      " 0.58013576 0.6089376  0.62058794 0.57937336 0.5138106  0.5009229\n",
      " 0.55884063 0.57318026 0.54267687 0.66437113 0.6193258  0.6030262\n",
      " 0.55733967 0.53756225 0.5150598  0.5051127  0.6586351  0.5061836\n",
      " 0.6967465  0.59956723 0.552537   0.5935491  0.5704767  0.6268557\n",
      " 0.5502388  0.51268375]\n",
      "The rewards are: [0.526191   0.633567   0.6321666  0.6334749  0.58975536 0.6651821\n",
      " 0.5337496  0.6710549  0.6519195  0.66419363 0.6182596  0.5172761\n",
      " 0.63112044 0.6942819  0.69359183 0.58199936 0.62287265 0.5328736\n",
      " 0.5316121  0.51064116 0.51518315 0.610102   0.5368206  0.5615303\n",
      " 0.6430285  0.58209044 0.5312481  0.6440994  0.59235644 0.6921144\n",
      " 0.5632767  0.55708045]\n",
      "The rewards are: [0.53984666 0.60287184 0.5668139  0.560758   0.6648368  0.66128707\n",
      " 0.6085672  0.5228496  0.6204678  0.6297882  0.5167062  0.51297325\n",
      " 0.6289763  0.57923084 0.7069506  0.6810704  0.6586934  0.5298398\n",
      " 0.65705264 0.5435659  0.50527835 0.5037681  0.6548861  0.5018085\n",
      " 0.55493015 0.52321625 0.7020726  0.6873221  0.638803   0.7072122\n",
      " 0.599825   0.51080215]\n",
      "The rewards are: [0.5851089  0.5220957  0.53019404 0.65114266 0.531705   0.58509624\n",
      " 0.50034064 0.6155288  0.69160384 0.58250886 0.56297094 0.5471393\n",
      " 0.5764704  0.5251316  0.5116839  0.65093267 0.5979527  0.5673859\n",
      " 0.5647679  0.6349697  0.57066816 0.5491153  0.6695184  0.66276956\n",
      " 0.6780358  0.6547944  0.5138647  0.6902244  0.5849997  0.65397257\n",
      " 0.67250043 0.7020613 ]\n",
      "The rewards are: [0.62421566 0.51722604 0.5440674  0.5717446  0.5522214  0.584645\n",
      " 0.5469915  0.6870779  0.64679724 0.61400855 0.5027132  0.64798254\n",
      " 0.6435944  0.52279264 0.6084908  0.5523767  0.6816011  0.65471375\n",
      " 0.5520381  0.68894464 0.6639599  0.56061983 0.6460932  0.6170734\n",
      " 0.5881631  0.65419245 0.61319077 0.60330063 0.5384295  0.72292906\n",
      " 0.63297826 0.65443   ]\n",
      "The rewards are: [0.66921884 0.6121025  0.5935415  0.51473534 0.6200366  0.5316813\n",
      " 0.52821964 0.6540935  0.5650618  0.56508714 0.5592117  0.6750915\n",
      " 0.518242   0.56464595 0.6158227  0.5291864  0.6445923  0.5397106\n",
      " 0.5108474  0.5028276  0.6038519  0.60394365 0.5625083  0.53080714\n",
      " 0.6034669  0.59235317 0.5597065  0.5480887  0.6219854  0.51865506\n",
      " 0.6580277  0.5595012 ]\n",
      "The rewards are: [0.6294007  0.6611041  0.60992545 0.5936012  0.60899085 0.5418972\n",
      " 0.5820243  0.65498334 0.53157777 0.60041475 0.5515404  0.5859816\n",
      " 0.5127853  0.5470167  0.7165174  0.5929211  0.7204294  0.6258188\n",
      " 0.6184687  0.50583273 0.55293435 0.58134866 0.56554025 0.6549754\n",
      " 0.53819764 0.6579665  0.5280612  0.51903194 0.6086995  0.53439415\n",
      " 0.62493837 0.55943173]\n",
      "The rewards are: [0.57436174 0.64923286 0.5319086  0.6121546  0.551906   0.60510606\n",
      " 0.64111286 0.6244286  0.65049285 0.54886836 0.54269344 0.52015847\n",
      " 0.6338586  0.6343857  0.66164523 0.6837171  0.5313287  0.7036468\n",
      " 0.5894139  0.64130133 0.6265946  0.53180397 0.5732695  0.5599098\n",
      " 0.5170326  0.5351085  0.705844   0.5184362  0.6594972  0.646935\n",
      " 0.7269273  0.6907558 ]\n",
      "The rewards are: [0.5545308  0.55173033 0.7471613  0.68802685 0.6543925  0.54513294\n",
      " 0.5559757  0.63583344 0.6333858  0.58872414 0.66935813 0.5747004\n",
      " 0.7346241  0.6667029  0.71573895 0.6043958  0.60657513 0.6848515\n",
      " 0.6535537  0.5696803  0.5796011  0.60415626 0.63351494 0.71641034\n",
      " 0.59588116 0.6515468  0.5091227  0.51399875 0.6160826  0.585682\n",
      " 0.6338544  0.5266396 ]\n",
      "The rewards are: [0.5332901  0.51752317 0.6352748  0.5458378  0.5609167  0.67952985\n",
      " 0.6139778  0.7100781  0.5121379  0.66240764 0.53066856 0.67815405\n",
      " 0.5039564  0.5422745  0.7161749  0.51159865 0.7122867  0.7174403\n",
      " 0.66195786 0.515625   0.6912455  0.5367737  0.6279401  0.7116936\n",
      " 0.6543624  0.7137108  0.5750226  0.58324486 0.6466199  0.5660124\n",
      " 0.53892034 0.6082946 ]\n",
      "The rewards are: [0.6748602  0.68881226 0.6045492  0.57761085 0.5112999  0.5597894\n",
      " 0.6953183  0.53887874 0.5923564  0.70621544 0.73375857 0.609534\n",
      " 0.5299486  0.6663174  0.76397526 0.70621544 0.6484361  0.59482706\n",
      " 0.6588543  0.66525495 0.62604606 0.5473685  0.50464195 0.6313099\n",
      " 0.61479604 0.53579426 0.6335467  0.7416362  0.57787466 0.6888974\n",
      " 0.6872075  0.62374645]\n",
      "The rewards are: [0.67598355 0.5849796  0.5000816  0.56880105 0.60076755 0.50507826\n",
      " 0.6071658  0.5692098  0.53389776 0.7177133  0.52116513 0.6324968\n",
      " 0.56307125 0.5040133  0.65923476 0.74680406 0.561675   0.63957906\n",
      " 0.6184551  0.54514194 0.54047    0.74787074 0.5634731  0.646321\n",
      " 0.59518874 0.6066513  0.60135466 0.5003498  0.53179955 0.61100763\n",
      " 0.6861035  0.6063518 ]\n",
      "The rewards are: [0.50748354 0.529623   0.6494788  0.75949717 0.62499756 0.54172295\n",
      " 0.6240184  0.6605096  0.66210663 0.7086708  0.60918355 0.7196483\n",
      " 0.5743534  0.6141383  0.59719735 0.62194693 0.61859554 0.7099662\n",
      " 0.6131283  0.62902576 0.571242   0.62964547 0.5137393  0.6559994\n",
      " 0.69436556 0.6854159  0.70568764 0.55759865 0.67331964 0.63269\n",
      " 0.6680771  0.597444  ]\n",
      "The rewards are: [0.77483195 0.6287206  0.6992448  0.5196022  0.7289721  0.56215197\n",
      " 0.5437123  0.5279531  0.61135566 0.62422335 0.7035939  0.7454076\n",
      " 0.53586215 0.6003502  0.5176145  0.5491373  0.5150583  0.690657\n",
      " 0.65709066 0.54055566 0.76755893 0.5053711  0.6155161  0.5298625\n",
      " 0.5835022  0.58112645 0.5429142  0.5006109  0.5691162  0.6716853\n",
      " 0.76570386 0.76944035]\n",
      "The rewards are: [0.67910117 0.7104598  0.5224706  0.5546599  0.6891573  0.77595735\n",
      " 0.7491357  0.7148333  0.67518795 0.6274535  0.7446622  0.5729919\n",
      " 0.5829022  0.65590227 0.5100389  0.5198293  0.7687309  0.7728435\n",
      " 0.67426336 0.5819463  0.57044536 0.61557776 0.6718437  0.6780677\n",
      " 0.6006722  0.50027317 0.76646733 0.66500896 0.5976367  0.50166774\n",
      " 0.6776628  0.68299335]\n",
      "The rewards are: [0.59566194 0.557017   0.65129054 0.5630908  0.577752   0.5680509\n",
      " 0.66639984 0.52370286 0.50658065 0.73554474 0.69354206 0.60230327\n",
      " 0.674379   0.64376795 0.7293711  0.73239094 0.5643032  0.50213456\n",
      " 0.5482349  0.53661543 0.6847688  0.721094   0.5519983  0.5315521\n",
      " 0.66606355 0.5927876  0.6812978  0.54041284 0.5344402  0.5262693\n",
      " 0.7706682  0.5795278 ]\n",
      "The rewards are: [0.5970244  0.5780837  0.5818705  0.58597004 0.59252155 0.6398979\n",
      " 0.67295593 0.64020807 0.74281484 0.6276544  0.530373   0.57672065\n",
      " 0.52343583 0.66871214 0.5231958  0.7126285  0.63688433 0.7572529\n",
      " 0.55053025 0.59657097 0.5702882  0.5131096  0.5817094  0.82713175\n",
      " 0.52885526 0.663087   0.73152876 0.5189588  0.5666273  0.52287817\n",
      " 0.5479683  0.6221103 ]\n",
      "The rewards are: [0.57389295 0.7115747  0.5778763  0.738609   0.59149843 0.68389297\n",
      " 0.5207809  0.5039267  0.5647053  0.5722928  0.77053684 0.59168756\n",
      " 0.5007504  0.5153619  0.7073719  0.50697875 0.5836137  0.6588038\n",
      " 0.7702305  0.57645404 0.7438004  0.6455773  0.749159   0.5088143\n",
      " 0.5116759  0.7441477  0.5076384  0.7384397  0.6115008  0.7123773\n",
      " 0.52884936 0.62948936]\n",
      "The rewards are: [0.6647531  0.57192034 0.65201026 0.5960158  0.7147252  0.7048823\n",
      " 0.63578695 0.7704214  0.58911955 0.5893548  0.84299046 0.60972714\n",
      " 0.60358393 0.5141629  0.60396695 0.67346376 0.7414168  0.75558394\n",
      " 0.6922603  0.5348335  0.7998425  0.5448038  0.5437886  0.5091664\n",
      " 0.53506947 0.50368696 0.5065601  0.6211681  0.63668656 0.56969357\n",
      " 0.63514453 0.5144444 ]\n",
      "The rewards are: [0.58066434 0.6438476  0.69555813 0.5147253  0.5473103  0.5820031\n",
      " 0.6930248  0.62707204 0.5366281  0.6419232  0.744493   0.6343434\n",
      " 0.71689016 0.64431125 0.6834336  0.7255629  0.6584941  0.6729311\n",
      " 0.5714677  0.57898635 0.5576134  0.55653155 0.79184395 0.754538\n",
      " 0.57777876 0.5448461  0.6773757  0.6345479  0.5190085  0.7857873\n",
      " 0.65497875 0.58729213]\n",
      "The rewards are: [0.5495257  0.54312485 0.5332351  0.7346807  0.6977439  0.5190697\n",
      " 0.7244816  0.52445126 0.6206069  0.5297783  0.6228343  0.6443346\n",
      " 0.52004594 0.645481   0.53332615 0.72721004 0.6860577  0.6557135\n",
      " 0.57045054 0.65192306 0.6329811  0.60118884 0.77643585 0.7577473\n",
      " 0.536019   0.6992388  0.7169107  0.8014019  0.59364325 0.569736\n",
      " 0.547607   0.6476744 ]\n",
      "The rewards are: [0.643999   0.5955441  0.5707365  0.6368696  0.6378621  0.5897547\n",
      " 0.6950055  0.5411195  0.6658436  0.68686616 0.61512554 0.562218\n",
      " 0.615037   0.61816245 0.597375   0.5606773  0.5477299  0.5698968\n",
      " 0.7611925  0.6755779  0.59954447 0.7591098  0.57064486 0.58281034\n",
      " 0.5466151  0.5218543  0.79198253 0.67015463 0.7549038  0.5261686\n",
      " 0.71954423 0.5102486 ]\n",
      "The rewards are: [0.5752917  0.5073264  0.5468569  0.5379431  0.53975785 0.6725202\n",
      " 0.5805855  0.53722245 0.70238674 0.5176272  0.7270972  0.76861733\n",
      " 0.5333787  0.54443413 0.6254761  0.7241678  0.55906814 0.5668145\n",
      " 0.53839046 0.52420276 0.5426696  0.5763921  0.6449263  0.6688864\n",
      " 0.6831682  0.5002712  0.6849745  0.6004091  0.5506515  0.74244577\n",
      " 0.5822988  0.66671294]\n",
      "The rewards are: [0.5684712  0.6486841  0.57919425 0.5562607  0.674242   0.74273354\n",
      " 0.65090144 0.77804375 0.752487   0.51308537 0.6998335  0.6839005\n",
      " 0.52474815 0.7631304  0.76363474 0.75915635 0.57732666 0.6764263\n",
      " 0.6390005  0.68153733 0.5306076  0.7104002  0.5294416  0.7447349\n",
      " 0.5112228  0.53155726 0.7439912  0.54312897 0.6733496  0.52411944\n",
      " 0.5661956  0.51775146]\n",
      "The rewards are: [0.5643695  0.5231225  0.5874369  0.5927927  0.61624765 0.58336264\n",
      " 0.5512867  0.76744574 0.5296007  0.50498617 0.5526956  0.7572259\n",
      " 0.5843536  0.7059579  0.59062076 0.7601249  0.6804358  0.78386265\n",
      " 0.5165126  0.5745549  0.703039   0.6083556  0.51263547 0.5201082\n",
      " 0.60714597 0.5966206  0.58237743 0.5097701  0.5384419  0.7297679\n",
      " 0.5457762  0.6074635 ]\n",
      "The rewards are: [0.62097716 0.5479844  0.6914288  0.55355054 0.7793094  0.59405273\n",
      " 0.5118525  0.6540634  0.6563202  0.7887125  0.51490444 0.75820124\n",
      " 0.5264975  0.67160946 0.64681923 0.5209265  0.5313067  0.66660374\n",
      " 0.66915786 0.53748304 0.7142499  0.8066959  0.5152482  0.6281609\n",
      " 0.65762633 0.6388062  0.69853896 0.6546579  0.6195024  0.60707504\n",
      " 0.7415917  0.58413106]\n",
      "The rewards are: [0.62725216 0.5458496  0.5946411  0.57114124 0.70219004 0.66297865\n",
      " 0.51715815 0.74023056 0.5797816  0.726308   0.6078184  0.5368435\n",
      " 0.69943976 0.64790416 0.76351196 0.6883233  0.5015024  0.693444\n",
      " 0.59913427 0.6984241  0.5283362  0.70342845 0.701326   0.6197271\n",
      " 0.6812732  0.635725   0.5254652  0.6631399  0.66177845 0.548677\n",
      " 0.6866896  0.5275676 ]\n",
      "The rewards are: [0.5650569  0.55435956 0.7318689  0.51234406 0.7163722  0.5931505\n",
      " 0.5493804  0.57387614 0.6548703  0.5613302  0.5216346  0.6764941\n",
      " 0.74338806 0.52986634 0.5830875  0.58475477 0.5827463  0.62351006\n",
      " 0.67863667 0.7986356  0.54916143 0.52715707 0.8247325  0.6472413\n",
      " 0.6282904  0.75191057 0.5257121  0.71501076 0.5664376  0.83059967\n",
      " 0.7001027  0.5337564 ]\n",
      "The rewards are: [0.56713855 0.6911429  0.56857455 0.6203446  0.7377396  0.53974265\n",
      " 0.77827704 0.5615674  0.7052478  0.5550822  0.6518542  0.5213756\n",
      " 0.65569204 0.7014233  0.5864783  0.74351776 0.53239554 0.5275294\n",
      " 0.56496465 0.5382588  0.66349536 0.63428134 0.52022505 0.5519244\n",
      " 0.56861037 0.51584625 0.5393027  0.7206138  0.7198787  0.5712639\n",
      " 0.751463   0.6145961 ]\n",
      "The rewards are: [0.69281965 0.5920165  0.7079869  0.72314477 0.6709439  0.66436964\n",
      " 0.6763609  0.5845135  0.5563364  0.6760026  0.6768822  0.72140783\n",
      " 0.5227799  0.7130547  0.5360616  0.7294855  0.66144395 0.59725255\n",
      " 0.5421598  0.6908361  0.5361416  0.56720984 0.5212456  0.547852\n",
      " 0.51475984 0.519856   0.6319116  0.57223994 0.6108774  0.6755214\n",
      " 0.6153199  0.5748993 ]\n",
      "The rewards are: [0.61000615 0.81034464 0.5562903  0.6763628  0.5323056  0.7359538\n",
      " 0.6767865  0.66381884 0.5232564  0.74147266 0.78730613 0.5439887\n",
      " 0.6968175  0.7225301  0.6239439  0.61272115 0.52678627 0.78323203\n",
      " 0.6139474  0.81178933 0.5242262  0.5565024  0.5410081  0.68164676\n",
      " 0.5075323  0.5878869  0.59328884 0.73831105 0.5348357  0.693118\n",
      " 0.5468415  0.60947615]\n",
      "The rewards are: [0.6350223  0.6315028  0.6557851  0.5191465  0.6091042  0.66046447\n",
      " 0.69567597 0.6285502  0.51852477 0.5624241  0.8195879  0.68339777\n",
      " 0.536233   0.6881229  0.60016    0.6387945  0.5801443  0.815493\n",
      " 0.8068159  0.5098595  0.62068856 0.5651453  0.50238425 0.7064158\n",
      " 0.6322085  0.67766243 0.72844255 0.6522368  0.62908065 0.560217\n",
      " 0.6752024  0.5363639 ]\n",
      "The rewards are: [0.5413474  0.60589427 0.67937076 0.68504816 0.57394344 0.534394\n",
      " 0.5639621  0.5760056  0.63849086 0.7460101  0.7711999  0.741802\n",
      " 0.5653105  0.7321511  0.50872105 0.73834735 0.651766   0.7646332\n",
      " 0.7266345  0.5425124  0.7406915  0.62345153 0.6041396  0.628019\n",
      " 0.609211   0.8295778  0.78554964 0.51338506 0.52758974 0.7376818\n",
      " 0.51835966 0.70999557]\n",
      "The rewards are: [0.7734048  0.62159723 0.68097067 0.50399    0.54614335 0.64739364\n",
      " 0.5252995  0.60957325 0.6774263  0.62352914 0.6396897  0.71311337\n",
      " 0.7322963  0.70431197 0.68865395 0.5494462  0.52716696 0.80307466\n",
      " 0.6965039  0.5202502  0.6542411  0.6689626  0.7044519  0.54382426\n",
      " 0.50035864 0.7961384  0.73240477 0.7486857  0.6937228  0.56908923\n",
      " 0.61217344 0.57743865]\n",
      "The rewards are: [0.59243387 0.6753732  0.62075484 0.52494025 0.5983766  0.56286407\n",
      " 0.63017064 0.54864484 0.8294621  0.6914536  0.53138506 0.700004\n",
      " 0.58491886 0.53129077 0.6445957  0.72195977 0.6395825  0.7182323\n",
      " 0.518897   0.55512834 0.7046679  0.7767897  0.55118096 0.5409373\n",
      " 0.50673765 0.6147008  0.5969385  0.6375173  0.58712745 0.5605067\n",
      " 0.6936955  0.5461423 ]\n",
      "The rewards are: [0.6042137  0.6580779  0.693221   0.6519787  0.6533042  0.52244735\n",
      " 0.65242726 0.5751134  0.61000675 0.64590865 0.7876905  0.67706734\n",
      " 0.6340975  0.6362378  0.670733   0.69218975 0.7029544  0.60739666\n",
      " 0.66474634 0.6508683  0.7065214  0.69389856 0.62673056 0.55835575\n",
      " 0.76781714 0.52059025 0.63265    0.5280907  0.61900926 0.58859503\n",
      " 0.6417365  0.6145124 ]\n",
      "The rewards are: [0.79684734 0.60470897 0.79543513 0.6420507  0.5421902  0.73736227\n",
      " 0.6429188  0.68680793 0.50833184 0.6799938  0.73835874 0.6528461\n",
      " 0.5089618  0.57255614 0.53476804 0.699284   0.76678133 0.5507949\n",
      " 0.74353915 0.52119356 0.7193353  0.6530824  0.571445   0.74940884\n",
      " 0.642056   0.51624966 0.62493765 0.64970255 0.61754966 0.75423795\n",
      " 0.6123691  0.64079016]\n",
      "The rewards are: [0.7406775  0.7438058  0.6988656  0.51840734 0.7490954  0.6325542\n",
      " 0.6534615  0.7660193  0.61846936 0.598878   0.6123146  0.7050095\n",
      " 0.5103044  0.7688243  0.6779864  0.5109377  0.7276365  0.5983258\n",
      " 0.55763805 0.5562736  0.59647703 0.6605132  0.6675076  0.7547578\n",
      " 0.5285377  0.66496986 0.8409353  0.6367966  0.5242794  0.56343496\n",
      " 0.63571495 0.53940856]\n",
      "The rewards are: [0.68050176 0.5679377  0.59628534 0.65463644 0.64896667 0.52363396\n",
      " 0.63237125 0.7210315  0.7922143  0.63753396 0.5687655  0.6889325\n",
      " 0.74624795 0.58911973 0.5451536  0.7528119  0.56003296 0.51098824\n",
      " 0.57805955 0.7338791  0.74112284 0.7037522  0.80203813 0.76906294\n",
      " 0.7312315  0.8271634  0.644364   0.7140297  0.6194879  0.5749773\n",
      " 0.731991   0.6625582 ]\n",
      "The rewards are: [0.51396614 0.57205933 0.7108036  0.52037346 0.6081233  0.84819144\n",
      " 0.520953   0.6645957  0.6545572  0.64398897 0.60872394 0.7312528\n",
      " 0.6298093  0.74504423 0.7754167  0.7590687  0.65069187 0.783159\n",
      " 0.6279254  0.5842208  0.55528224 0.5677829  0.7647298  0.6094131\n",
      " 0.54882383 0.80143386 0.7853899  0.86700976 0.73593944 0.65574074\n",
      " 0.5918303  0.5774749 ]\n",
      "The rewards are: [0.70882106 0.566029   0.5112004  0.5466131  0.5705415  0.6623719\n",
      " 0.62104696 0.76173556 0.5727683  0.7955368  0.6784572  0.6427459\n",
      " 0.56940705 0.6080875  0.7520693  0.7769231  0.75751096 0.8298434\n",
      " 0.51236403 0.67233473 0.6945976  0.5427435  0.6845247  0.8183592\n",
      " 0.7893443  0.87471956 0.5248536  0.60263085 0.67919004 0.78791285\n",
      " 0.68500865 0.6625828 ]\n",
      "The rewards are: [0.6663154  0.67828655 0.60830057 0.59236544 0.54380757 0.59995526\n",
      " 0.52057165 0.6514662  0.5988638  0.7104939  0.661673   0.5638846\n",
      " 0.8246224  0.6059136  0.5557021  0.71913725 0.58917856 0.7305383\n",
      " 0.6298156  0.67750245 0.6510734  0.66751516 0.6646143  0.74289006\n",
      " 0.7442622  0.71079427 0.64911956 0.6453838  0.8155141  0.82434994\n",
      " 0.51660115 0.616743  ]\n",
      "The rewards are: [0.78618634 0.67941564 0.5454534  0.6564771  0.56858    0.7551277\n",
      " 0.71143633 0.770279   0.67648673 0.8097017  0.65998226 0.7194783\n",
      " 0.62923914 0.75094455 0.8190586  0.60615575 0.6971695  0.6379676\n",
      " 0.520925   0.57306933 0.68258715 0.574424   0.7216942  0.74686867\n",
      " 0.6424131  0.7557044  0.6142916  0.73428375 0.5597593  0.7705172\n",
      " 0.52462935 0.7684965 ]\n",
      "The rewards are: [0.5575166  0.62202215 0.6389416  0.5249508  0.6855157  0.7738117\n",
      " 0.64177394 0.8089506  0.5791458  0.6629905  0.50094336 0.6516999\n",
      " 0.72482526 0.6260289  0.6071906  0.5990336  0.7997075  0.57995147\n",
      " 0.63637686 0.52886724 0.51713985 0.74935186 0.6838973  0.5248294\n",
      " 0.82079685 0.6222128  0.7070092  0.52404493 0.5764137  0.72560626\n",
      " 0.68338424 0.6462958 ]\n",
      "The rewards are: [0.678306   0.78189987 0.6640327  0.7373585  0.76519024 0.72433543\n",
      " 0.8066804  0.6340453  0.76304233 0.5435061  0.7219408  0.6585863\n",
      " 0.73951703 0.8225289  0.56510466 0.77596784 0.7490819  0.636717\n",
      " 0.6807189  0.6681258  0.5616611  0.62372625 0.6412868  0.7138815\n",
      " 0.56702167 0.8042353  0.583645   0.5420236  0.53828657 0.6764359\n",
      " 0.66095614 0.63319707]\n",
      "The rewards are: [0.77766323 0.56255496 0.62937874 0.7996951  0.64300203 0.5656364\n",
      " 0.7038437  0.5505543  0.53738093 0.79495686 0.7152373  0.5649917\n",
      " 0.6149475  0.693343   0.5006617  0.5542125  0.57052445 0.6825179\n",
      " 0.76450074 0.69125026 0.73917717 0.83245736 0.5553903  0.7382825\n",
      " 0.553242   0.7600933  0.7526626  0.6503755  0.7348331  0.5917917\n",
      " 0.6794864  0.5918113 ]\n",
      "The rewards are: [0.65691954 0.6119456  0.7616688  0.6647306  0.735232   0.665946\n",
      " 0.5965241  0.69200134 0.7372906  0.68881714 0.6037364  0.6773636\n",
      " 0.858193   0.52629584 0.7284178  0.84384716 0.7567977  0.79723805\n",
      " 0.50034654 0.7275209  0.7430658  0.82246625 0.7278027  0.7515247\n",
      " 0.6842285  0.66679436 0.7283124  0.79752207 0.7184378  0.61731327\n",
      " 0.82481927 0.75067747]\n",
      "The rewards are: [0.7446479  0.5161959  0.7037968  0.7380224  0.5018145  0.55661005\n",
      " 0.76882046 0.5275394  0.73820347 0.72441363 0.64925295 0.6419343\n",
      " 0.6956776  0.67687446 0.5231962  0.7392487  0.7080038  0.72879535\n",
      " 0.74307275 0.6978283  0.662215   0.71874917 0.6280898  0.6464557\n",
      " 0.5662674  0.82478523 0.8290573  0.51060146 0.57727736 0.700737\n",
      " 0.5332073  0.68309593]\n",
      "The rewards are: [0.65607965 0.5941634  0.5684782  0.63774014 0.7067687  0.63029975\n",
      " 0.68116796 0.7386838  0.69131327 0.538484   0.71864825 0.50915116\n",
      " 0.73673356 0.538113   0.7114995  0.72916365 0.73353016 0.7309356\n",
      " 0.5873911  0.7741283  0.525932   0.8253269  0.7116351  0.7202263\n",
      " 0.6004452  0.71921283 0.71809316 0.6695623  0.6329675  0.73690563\n",
      " 0.62822914 0.7429896 ]\n",
      "The rewards are: [0.58556515 0.6723431  0.79592985 0.5251057  0.5302871  0.5641882\n",
      " 0.6435574  0.6364676  0.721843   0.5004601  0.7366982  0.64845324\n",
      " 0.66780424 0.6870508  0.6554832  0.6680768  0.5064616  0.7751948\n",
      " 0.76641077 0.6858638  0.71246785 0.7464997  0.6740528  0.8006443\n",
      " 0.704015   0.6718633  0.65915954 0.72514087 0.83187956 0.5836358\n",
      " 0.52145827 0.840411  ]\n",
      "The rewards are: [0.7494728  0.5108751  0.5678184  0.6109931  0.7173751  0.7077346\n",
      " 0.66539145 0.69707453 0.6481579  0.6685599  0.6075841  0.6961731\n",
      " 0.7668389  0.8418362  0.7580128  0.6515693  0.80684495 0.5200915\n",
      " 0.7215742  0.65885705 0.568444   0.75300133 0.67486244 0.5911451\n",
      " 0.5356626  0.60304785 0.71299833 0.7032294  0.7550489  0.50842184\n",
      " 0.81444377 0.7343734 ]\n",
      "The rewards are: [0.6273829  0.7318142  0.5950005  0.589766   0.6399619  0.76113665\n",
      " 0.64817005 0.6090031  0.68822575 0.69719815 0.59973556 0.63536894\n",
      " 0.6318038  0.80152327 0.69320685 0.61505955 0.7851534  0.5857615\n",
      " 0.6604747  0.62531996 0.6798357  0.6273913  0.6275012  0.67326695\n",
      " 0.8178364  0.5601225  0.6671863  0.6474303  0.61801815 0.557276\n",
      " 0.6034824  0.67055166]\n",
      "The rewards are: [0.703156   0.69901466 0.61240983 0.77186465 0.6091305  0.5845324\n",
      " 0.58999133 0.5809602  0.6317491  0.5003683  0.73818165 0.714491\n",
      " 0.65164626 0.79675347 0.5888995  0.7605221  0.69083506 0.75070864\n",
      " 0.57083625 0.5242608  0.54501545 0.5586142  0.65999293 0.85326105\n",
      " 0.71250194 0.53076893 0.758057   0.50175166 0.6050493  0.6765157\n",
      " 0.76610994 0.5346321 ]\n",
      "The rewards are: [0.7656492  0.60831    0.6187294  0.6806692  0.589954   0.7231996\n",
      " 0.6688649  0.746285   0.6718399  0.7559803  0.5434879  0.67203057\n",
      " 0.5450699  0.710458   0.50847816 0.6071169  0.7554869  0.510419\n",
      " 0.62000763 0.73700935 0.59484184 0.7371478  0.57303315 0.7866472\n",
      " 0.5882245  0.52021384 0.61046505 0.5873469  0.7257529  0.5300157\n",
      " 0.50160927 0.54919404]\n",
      "The rewards are: [0.5980267  0.5779922  0.7618175  0.56136686 0.6689072  0.57906294\n",
      " 0.6198504  0.8008781  0.5675835  0.7568024  0.7099044  0.67721283\n",
      " 0.5003161  0.84971714 0.81416166 0.5580655  0.69137186 0.5822426\n",
      " 0.7472904  0.6001925  0.78449035 0.5048905  0.6654979  0.8349755\n",
      " 0.7584956  0.5571717  0.7916009  0.72905594 0.8075846  0.588562\n",
      " 0.63648164 0.6429277 ]\n",
      "The rewards are: [0.5936112  0.80993587 0.7921917  0.542338   0.64952    0.6670439\n",
      " 0.65174484 0.60957325 0.68833095 0.87616014 0.62153447 0.68746567\n",
      " 0.85685825 0.61494905 0.6975158  0.68180174 0.75134355 0.6053165\n",
      " 0.52771616 0.6671165  0.7228786  0.89032316 0.74635077 0.60903615\n",
      " 0.6420124  0.75404304 0.75465965 0.628597   0.78571975 0.6483563\n",
      " 0.7107075  0.5327947 ]\n",
      "The rewards are: [0.67438275 0.6687242  0.7879777  0.5727352  0.59747773 0.77216\n",
      " 0.80921924 0.7238669  0.78296685 0.6812419  0.73929507 0.54999423\n",
      " 0.6630959  0.833011   0.5129183  0.7986339  0.7081363  0.73613626\n",
      " 0.8117386  0.76396906 0.7236023  0.766584   0.65291035 0.8243597\n",
      " 0.6263619  0.67462665 0.68135154 0.6298731  0.51182216 0.7219527\n",
      " 0.7646883  0.7055985 ]\n",
      "The rewards are: [0.56722647 0.747902   0.50741684 0.56926656 0.75498253 0.7841353\n",
      " 0.6914057  0.57279956 0.518752   0.6399174  0.81379646 0.5145179\n",
      " 0.85468405 0.6108368  0.8317306  0.63495934 0.8383215  0.70138544\n",
      " 0.58982    0.8129834  0.5600307  0.590915   0.5872838  0.76169354\n",
      " 0.61911196 0.6446626  0.6256579  0.53726244 0.769923   0.8394489\n",
      " 0.50412893 0.856258  ]\n",
      "The rewards are: [0.6151301  0.65163296 0.7294512  0.6984724  0.5865515  0.6169798\n",
      " 0.5863227  0.81246567 0.6721672  0.793516   0.6235277  0.73230696\n",
      " 0.69951326 0.7209272  0.6030287  0.5516419  0.600159   0.65296584\n",
      " 0.53310066 0.7500595  0.50365144 0.5646316  0.63330007 0.50097847\n",
      " 0.7352663  0.71371263 0.6873326  0.69464743 0.69870293 0.69073117\n",
      " 0.5352095  0.5496062 ]\n",
      "The rewards are: [0.7450542  0.5718277  0.56472635 0.58692604 0.7012185  0.77768177\n",
      " 0.5233278  0.78359157 0.5219001  0.6675569  0.51448375 0.57802725\n",
      " 0.5375152  0.7601206  0.7743455  0.53086555 0.6960396  0.62134314\n",
      " 0.80456406 0.7462003  0.8254702  0.6611112  0.6869231  0.87358636\n",
      " 0.67879736 0.60283065 0.6792776  0.84900284 0.7715141  0.5971235\n",
      " 0.7585275  0.74024355]\n",
      "The rewards are: [0.5587157  0.6423447  0.69737464 0.61269116 0.88748807 0.71188366\n",
      " 0.86314267 0.5538786  0.73234    0.7940963  0.88695467 0.7694023\n",
      " 0.7106412  0.6863002  0.70632285 0.75210816 0.7541496  0.7030556\n",
      " 0.59390134 0.65573144 0.7134401  0.5278344  0.71057236 0.77941006\n",
      " 0.8550165  0.8728926  0.6877058  0.74343127 0.7695341  0.6264475\n",
      " 0.5316441  0.86125964]\n",
      "The rewards are: [0.74812025 0.651073   0.6426762  0.8450932  0.7627093  0.69977295\n",
      " 0.718866   0.76910806 0.8220028  0.6636987  0.68286157 0.72293675\n",
      " 0.64992696 0.79990953 0.82329106 0.8126733  0.76751953 0.58177805\n",
      " 0.6186509  0.78099    0.7189146  0.6623167  0.54934645 0.567401\n",
      " 0.60151446 0.7195849  0.80490875 0.74179655 0.8380577  0.54769224\n",
      " 0.6987739  0.72284967]\n",
      "The rewards are: [0.7637161  0.80477405 0.59080726 0.85181046 0.6571596  0.7773188\n",
      " 0.56031066 0.7653229  0.61531657 0.7628618  0.7309679  0.80397934\n",
      " 0.58372396 0.68406624 0.5617484  0.55400497 0.7174489  0.75534815\n",
      " 0.59670204 0.7903233  0.8126799  0.6372458  0.8025282  0.80277646\n",
      " 0.7203672  0.6277129  0.78444123 0.56127954 0.69862413 0.7946539\n",
      " 0.6368395  0.7696976 ]\n",
      "The rewards are: [0.58901036 0.7735256  0.7198919  0.9173464  0.5143406  0.80533147\n",
      " 0.75413    0.5672548  0.8399657  0.5058009  0.7584815  0.7947736\n",
      " 0.57698625 0.5255665  0.7144496  0.5924491  0.7769634  0.80438393\n",
      " 0.68931884 0.75828785 0.62067217 0.69675833 0.7856806  0.8144092\n",
      " 0.60939336 0.5665117  0.83801174 0.6778088  0.7811911  0.50984484\n",
      " 0.7633231  0.7107919 ]\n",
      "The rewards are: [0.74664676 0.7544753  0.70837766 0.64755416 0.56352466 0.7830881\n",
      " 0.5102588  0.73994446 0.78073645 0.730226   0.75819385 0.8256976\n",
      " 0.75975907 0.73965466 0.69897777 0.8034946  0.6481812  0.6432644\n",
      " 0.73600113 0.5379079  0.72855705 0.67323965 0.61745936 0.52778155\n",
      " 0.7601644  0.6339325  0.79378265 0.7683118  0.6089407  0.92229104\n",
      " 0.790397   0.84206873]\n",
      "The rewards are: [0.56620723 0.6123752  0.5148119  0.85644585 0.8363833  0.78959566\n",
      " 0.739009   0.8122865  0.7822763  0.64954734 0.6404342  0.65277857\n",
      " 0.5020175  0.81545067 0.83119684 0.50768876 0.6577949  0.7944266\n",
      " 0.63756835 0.8053822  0.6858419  0.69393325 0.5355816  0.8034464\n",
      " 0.8349947  0.8505324  0.7642943  0.6988199  0.6054895  0.8747544\n",
      " 0.6961559  0.7416115 ]\n",
      "The rewards are: [0.59331477 0.8533686  0.8660995  0.6197592  0.73661035 0.7084749\n",
      " 0.635161   0.5986837  0.7073719  0.793633   0.70902944 0.75888646\n",
      " 0.7139969  0.63979715 0.7748477  0.68762803 0.63758063 0.6638916\n",
      " 0.6989414  0.7434189  0.75890964 0.51073104 0.8118055  0.73799884\n",
      " 0.64561486 0.79386634 0.73939955 0.5809612  0.70405716 0.67127043\n",
      " 0.74711853 0.9110634 ]\n",
      "The rewards are: [0.6804118  0.75462925 0.6882669  0.6187922  0.7125368  0.5525618\n",
      " 0.5515059  0.6645077  0.5619983  0.7214895  0.65520585 0.770385\n",
      " 0.79829186 0.764733   0.6064121  0.8104954  0.83852553 0.78605\n",
      " 0.7192711  0.81224185 0.66197497 0.5630489  0.5121294  0.8046457\n",
      " 0.732408   0.6694946  0.53133076 0.503525   0.7428639  0.66463447\n",
      " 0.84912604 0.798595  ]\n",
      "The rewards are: [0.58238333 0.78067493 0.7229087  0.60056233 0.5612786  0.8692261\n",
      " 0.67330426 0.8731282  0.76848876 0.72606176 0.6347923  0.7920195\n",
      " 0.68556094 0.6158203  0.81199324 0.57322216 0.59056014 0.75593203\n",
      " 0.75116134 0.56764615 0.6679454  0.77545595 0.8297995  0.8566115\n",
      " 0.5461056  0.7210463  0.6114145  0.64591223 0.75517297 0.8578367\n",
      " 0.5915396  0.6273185 ]\n",
      "The rewards are: [0.74828655 0.8030393  0.5987124  0.8103664  0.6467274  0.7417186\n",
      " 0.64255446 0.8501418  0.693011   0.5977952  0.7202018  0.7402014\n",
      " 0.8110655  0.6627858  0.59069544 0.56011856 0.5637502  0.5160528\n",
      " 0.55056643 0.7160334  0.71746    0.7805916  0.7514067  0.67784935\n",
      " 0.80802    0.5032177  0.52610964 0.551302   0.521319   0.80849177\n",
      " 0.8170297  0.57590467]\n",
      "The rewards are: [0.7139735  0.796427   0.723276   0.7926883  0.57132304 0.5095262\n",
      " 0.7869188  0.70796776 0.6678228  0.75772184 0.85980684 0.56153715\n",
      " 0.90608567 0.67848593 0.73436683 0.6311765  0.7059523  0.5627398\n",
      " 0.7102048  0.71093655 0.65643305 0.88304985 0.65008605 0.75146693\n",
      " 0.6030524  0.68054426 0.5034222  0.75696456 0.7273077  0.5411697\n",
      " 0.6921768  0.524162  ]\n",
      "The rewards are: [0.8444338  0.7462769  0.86425644 0.6821073  0.50141174 0.8301332\n",
      " 0.74466723 0.84960186 0.7741504  0.7237398  0.5255325  0.7050747\n",
      " 0.6955259  0.7251839  0.6665566  0.73111796 0.785206   0.50024533\n",
      " 0.6690959  0.70940304 0.83981097 0.5027965  0.855272   0.7870615\n",
      " 0.7718425  0.5812866  0.7934753  0.8120092  0.8620483  0.6287429\n",
      " 0.79009813 0.6518286 ]\n",
      "The rewards are: [0.5364693  0.73937863 0.82572395 0.67281485 0.6379705  0.90867436\n",
      " 0.5225879  0.65853    0.8622663  0.8301691  0.80978125 0.9014109\n",
      " 0.7578092  0.83247125 0.8070689  0.5838301  0.6082962  0.653982\n",
      " 0.5285326  0.76427436 0.799296   0.79457724 0.8325684  0.7620936\n",
      " 0.5772736  0.89136845 0.5929308  0.8367081  0.680072   0.64386475\n",
      " 0.8492074  0.5046709 ]\n",
      "The rewards are: [0.7942809  0.56803346 0.59103817 0.7721339  0.8526048  0.6032972\n",
      " 0.66308385 0.68944865 0.9010547  0.867071   0.7275761  0.70845526\n",
      " 0.8390726  0.6505248  0.9385367  0.58634776 0.8984144  0.8278571\n",
      " 0.5537657  0.77968353 0.66488934 0.6466592  0.7704103  0.8345259\n",
      " 0.645695   0.7078104  0.8095429  0.66213673 0.75657    0.75770026\n",
      " 0.7926548  0.67095184]\n",
      "The rewards are: [0.6409707  0.86426073 0.50435275 0.85264134 0.6946485  0.50979054\n",
      " 0.5504723  0.6691394  0.55086523 0.72768164 0.74810296 0.8818033\n",
      " 0.7981383  0.7120622  0.8486956  0.81268847 0.6731106  0.8517817\n",
      " 0.7346211  0.826033   0.78647196 0.65365416 0.8659497  0.6782354\n",
      " 0.5109331  0.5901028  0.516898   0.51378053 0.80643594 0.6496732\n",
      " 0.58472055 0.77331805]\n",
      "The rewards are: [0.93550396 0.7035658  0.50753254 0.5198905  0.71954584 0.5630152\n",
      " 0.72432476 0.8101712  0.5705093  0.61818546 0.6245029  0.7494619\n",
      " 0.8508021  0.7723074  0.91807806 0.8929947  0.6192969  0.8393708\n",
      " 0.54486287 0.68102926 0.9009569  0.70603395 0.92103773 0.5093056\n",
      " 0.84329295 0.8223287  0.87860566 0.74437314 0.67873394 0.71485436\n",
      " 0.6277643  0.52828234]\n",
      "The rewards are: [0.76383924 0.8418946  0.68604463 0.772758   0.6802739  0.7780341\n",
      " 0.5570098  0.7472987  0.55029875 0.6836479  0.56649655 0.61502224\n",
      " 0.60589826 0.61615586 0.83768076 0.84955114 0.92491317 0.74001044\n",
      " 0.55865806 0.51486355 0.6220686  0.776148   0.8370117  0.8580723\n",
      " 0.81826586 0.8394537  0.6387386  0.7653021  0.73144525 0.72911716\n",
      " 0.7907259  0.50406075]\n",
      "The rewards are: [0.7222445  0.63305235 0.7955498  0.77587575 0.73582506 0.5008985\n",
      " 0.6364287  0.7469765  0.60285866 0.74986464 0.74908495 0.8414501\n",
      " 0.620127   0.75213206 0.64887613 0.83173054 0.8132163  0.66707444\n",
      " 0.79168385 0.7367774  0.8295126  0.54559255 0.8395205  0.88201904\n",
      " 0.5228714  0.5646405  0.6279277  0.8184406  0.6792669  0.82096505\n",
      " 0.9270555  0.5789465 ]\n",
      "The rewards are: [0.7981523  0.7401242  0.5826148  0.6023326  0.80642647 0.65651566\n",
      " 0.7074765  0.7684724  0.54266304 0.6997216  0.9338377  0.85687697\n",
      " 0.7178517  0.6483674  0.5037489  0.6816307  0.6015114  0.87291616\n",
      " 0.87160265 0.77024627 0.6968128  0.9447938  0.5312283  0.615374\n",
      " 0.67647904 0.54305863 0.81287324 0.7288483  0.6155678  0.70326513\n",
      " 0.58749145 0.57601464]\n",
      "The rewards are: [0.85034037 0.9089523  0.86862373 0.5389901  0.511032   0.5379942\n",
      " 0.5949257  0.67166203 0.58950645 0.58678776 0.79882026 0.7377356\n",
      " 0.8201157  0.72961634 0.7261059  0.9215575  0.85674816 0.6366743\n",
      " 0.7832872  0.73174196 0.7101428  0.87280196 0.79643935 0.7351403\n",
      " 0.5081553  0.84109026 0.70662355 0.61291105 0.7778166  0.81081474\n",
      " 0.68872875 0.89274466]\n",
      "The rewards are: [0.54254353 0.5997568  0.74797875 0.88860434 0.5072295  0.7111582\n",
      " 0.8009013  0.6522758  0.843791   0.8484007  0.82888263 0.64126724\n",
      " 0.7748994  0.91417474 0.8939679  0.82288    0.7492405  0.5283712\n",
      " 0.63931054 0.77390236 0.71818155 0.7392273  0.7114784  0.5745084\n",
      " 0.78844184 0.5395304  0.56713533 0.7365944  0.61727184 0.87993085\n",
      " 0.6775654  0.6961583 ]\n",
      "The rewards are: [0.5469217  0.85213226 0.52140355 0.78397167 0.85086405 0.72390544\n",
      " 0.6663619  0.8640346  0.7169728  0.5096197  0.6088807  0.6143127\n",
      " 0.6756666  0.70830274 0.7803715  0.82614475 0.6520217  0.6993582\n",
      " 0.6333219  0.53100944 0.7981252  0.5684277  0.59748197 0.52126837\n",
      " 0.63640994 0.60887104 0.87741584 0.58433217 0.569103   0.7836716\n",
      " 0.6849996  0.8065799 ]\n",
      "The rewards are: [0.8003398  0.68401736 0.7379722  0.88943565 0.8632536  0.6739542\n",
      " 0.50404197 0.7966778  0.7547305  0.79645824 0.6765007  0.5608\n",
      " 0.75471175 0.633546   0.67623377 0.6076505  0.5242989  0.5336534\n",
      " 0.67510843 0.7050384  0.6003492  0.74915594 0.77651376 0.68553495\n",
      " 0.88066953 0.5595527  0.5676621  0.6422827  0.8315554  0.78832734\n",
      " 0.56322926 0.7285836 ]\n",
      "The rewards are: [0.7617185  0.83133334 0.76575625 0.70279163 0.6655538  0.69261795\n",
      " 0.54555225 0.7234065  0.79483265 0.6141087  0.86623734 0.8325155\n",
      " 0.8134428  0.8385444  0.5226436  0.7673352  0.9391483  0.8391597\n",
      " 0.651175   0.68519056 0.7744339  0.9145852  0.71882814 0.6932621\n",
      " 0.7808974  0.65909857 0.5133875  0.63174295 0.8436663  0.80238533\n",
      " 0.7421807  0.531872  ]\n",
      "The rewards are: [0.735767   0.87481844 0.90990716 0.8008118  0.7238394  0.7881994\n",
      " 0.6243866  0.7991052  0.836083   0.6897854  0.8073673  0.75203943\n",
      " 0.660271   0.8445851  0.7248056  0.84630746 0.8382007  0.7035375\n",
      " 0.62152845 0.7660249  0.5835807  0.9380822  0.59760493 0.67394656\n",
      " 0.7456832  0.7695365  0.6494257  0.79231167 0.6619332  0.6730051\n",
      " 0.728458   0.64741725]\n",
      "The rewards are: [0.5093658  0.5489294  0.7680319  0.63741064 0.6803988  0.8079149\n",
      " 0.95701295 0.80785495 0.8538748  0.65499014 0.8927318  0.83689195\n",
      " 0.712883   0.8465716  0.7827547  0.8184504  0.5011745  0.6573732\n",
      " 0.53056246 0.842844   0.67144483 0.78082883 0.58257675 0.7363847\n",
      " 0.8852334  0.6628693  0.5467923  0.7562305  0.6152966  0.911422\n",
      " 0.68111604 0.6703747 ]\n",
      "The rewards are: [0.5356231  0.71983355 0.5507669  0.8688107  0.8338802  0.51788247\n",
      " 0.53274465 0.73601425 0.8914145  0.7234656  0.87739486 0.73744506\n",
      " 0.6270067  0.69143677 0.7643522  0.8310374  0.9029273  0.649408\n",
      " 0.8529263  0.75717944 0.6733203  0.76471364 0.8149633  0.731422\n",
      " 0.65766686 0.59440565 0.83401567 0.6483826  0.7186451  0.6925512\n",
      " 0.8190393  0.7551616 ]\n",
      "The rewards are: [0.86586237 0.56924623 0.52039725 0.74445075 0.78201    0.5406553\n",
      " 0.5043101  0.74542516 0.8670066  0.77454513 0.6230993  0.7835377\n",
      " 0.83710504 0.9188424  0.9437624  0.8886812  0.8185642  0.52641684\n",
      " 0.8245022  0.7785164  0.7494601  0.53766    0.60483503 0.9428331\n",
      " 0.6475545  0.68679124 0.69597954 0.6042852  0.52601933 0.69982815\n",
      " 0.933397   0.83537006]\n",
      "The rewards are: [0.57940793 0.89488375 0.8685033  0.8126639  0.73501575 0.86072093\n",
      " 0.84491503 0.8323955  0.5097727  0.85878915 0.7505661  0.84999806\n",
      " 0.735982   0.51630235 0.8399827  0.7719287  0.63733053 0.72613335\n",
      " 0.79466915 0.7150112  0.5775064  0.6779409  0.6235247  0.5269506\n",
      " 0.82622916 0.6111348  0.8789229  0.7024614  0.504512   0.87731683\n",
      " 0.8579386  0.7227903 ]\n",
      "The rewards are: [0.535517   0.70955104 0.6876163  0.90721816 0.75409144 0.55227315\n",
      " 0.7042583  0.7784813  0.6226476  0.8840904  0.88313735 0.6919701\n",
      " 0.7462288  0.6628257  0.8610435  0.77280635 0.7592732  0.886629\n",
      " 0.5923114  0.84161896 0.8312763  0.92860985 0.92916065 0.7448562\n",
      " 0.6271835  0.61619747 0.6094661  0.7861795  0.57843995 0.6436097\n",
      " 0.72772896 0.868703  ]\n",
      "The rewards are: [0.7059221  0.72399366 0.83637065 0.513076   0.895263   0.85669035\n",
      " 0.7408599  0.6860665  0.948658   0.6117452  0.7416038  0.68620795\n",
      " 0.64071053 0.8321413  0.5381621  0.9080705  0.6921896  0.87193865\n",
      " 0.7875858  0.8123111  0.5515089  0.67116904 0.60970473 0.8910403\n",
      " 0.6906424  0.8796716  0.6799698  0.62409604 0.7637922  0.68405503\n",
      " 0.6591617  0.88235044]\n",
      "The rewards are: [0.65524966 0.85745305 0.8463598  0.94804895 0.7190893  0.6005908\n",
      " 0.78569824 0.5678753  0.70793974 0.90149033 0.5280528  0.8635767\n",
      " 0.506431   0.5953723  0.6946049  0.5055127  0.86536086 0.6394025\n",
      " 0.86580265 0.7812444  0.64061505 0.9298202  0.83663535 0.77034366\n",
      " 0.86288667 0.7264312  0.9192958  0.74729997 0.72085005 0.782762\n",
      " 0.82827216 0.7502077 ]\n",
      "The rewards are: [0.7601688  0.65716773 0.7320145  0.9053075  0.63254607 0.8039322\n",
      " 0.7617808  0.7138555  0.51607525 0.696624   0.80736035 0.50293934\n",
      " 0.5549375  0.74663156 0.7645775  0.5054937  0.7619702  0.8290977\n",
      " 0.87330955 0.91280407 0.641932   0.936817   0.66734177 0.58951604\n",
      " 0.8337472  0.67896664 0.8351236  0.7112762  0.78559583 0.57153124\n",
      " 0.77562964 0.7141427 ]\n",
      "The rewards are: [0.81181693 0.8110767  0.6765049  0.7032701  0.5688709  0.8347987\n",
      " 0.6380667  0.8793442  0.7973207  0.8314174  0.8087153  0.7874233\n",
      " 0.8151388  0.77584475 0.7809613  0.65430146 0.8937511  0.9238728\n",
      " 0.6505528  0.67728543 0.63529706 0.6745328  0.68480825 0.76796097\n",
      " 0.803638   0.8173692  0.70951104 0.77145374 0.80613774 0.7185813\n",
      " 0.83357114 0.90551054]\n",
      "The rewards are: [0.78414106 0.81297874 0.6486679  0.7109549  0.7860845  0.67831415\n",
      " 0.7071257  0.5933529  0.7133055  0.912771   0.83835024 0.7701697\n",
      " 0.87061095 0.8289011  0.6639076  0.56313926 0.82150286 0.82378376\n",
      " 0.8591132  0.6502099  0.919171   0.8885457  0.82899797 0.86625206\n",
      " 0.8092794  0.5240844  0.62610984 0.9413028  0.82474303 0.93200415\n",
      " 0.5952209  0.6092194 ]\n",
      "The rewards are: [0.61192966 0.8901924  0.97737235 0.88982254 0.72356254 0.74315995\n",
      " 0.7469466  0.7076165  0.7552965  0.8730722  0.61234236 0.81209826\n",
      " 0.59882057 0.54358524 0.92674917 0.72972363 0.7172811  0.81521696\n",
      " 0.6746477  0.8192378  0.6364872  0.77592427 0.641315   0.74029607\n",
      " 0.9127473  0.6221781  0.7853957  0.9196016  0.6395351  0.5728747\n",
      " 0.7306783  0.5312235 ]\n",
      "The rewards are: [0.64572614 0.6091893  0.5794508  0.8410933  0.53718346 0.5010996\n",
      " 0.5796156  0.65365785 0.5304032  0.5685895  0.6642454  0.6041389\n",
      " 0.67802113 0.56112826 0.57930213 0.6412336  0.87942684 0.9300217\n",
      " 0.9069645  0.84986115 0.8701738  0.9266974  0.9373987  0.9020167\n",
      " 0.81834227 0.78929013 0.7554704  0.52461886 0.8921577  0.8449421\n",
      " 0.9199611  0.66702586]\n",
      "The rewards are: [0.86332893 0.8092056  0.8057704  0.80494773 0.53621787 0.74349296\n",
      " 0.60682744 0.922185   0.6752171  0.7153886  0.75269204 0.74375117\n",
      " 0.6480275  0.8123501  0.5797751  0.6506023  0.87475425 0.9097711\n",
      " 0.84575385 0.6310533  0.91163397 0.5310346  0.60108715 0.78658575\n",
      " 0.74575555 0.66725755 0.5356994  0.83903223 0.6696782  0.66356784\n",
      " 0.5701768  0.67000407]\n",
      "The rewards are: [0.6791978  0.90405226 0.88663423 0.80298835 0.914656   0.592055\n",
      " 0.55926204 0.8407899  0.8828398  0.80108047 0.88676226 0.84798974\n",
      " 0.5316515  0.8320338  0.7487283  0.56169033 0.93744266 0.8026525\n",
      " 0.528701   0.8200585  0.81661665 0.59084904 0.6869532  0.7142113\n",
      " 0.9308747  0.69440293 0.93452066 0.9476384  0.7975818  0.86019176\n",
      " 0.8086343  0.716669  ]\n",
      "The rewards are: [0.7423973  0.78694665 0.80266124 0.72405946 0.694959   0.9369235\n",
      " 0.68316805 0.8938692  0.8206183  0.6814258  0.9350044  0.92598796\n",
      " 0.84775084 0.8727821  0.62453735 0.7830726  0.8298191  0.89346755\n",
      " 0.72991675 0.79334426 0.8554849  0.6141228  0.598693   0.80355686\n",
      " 0.8794334  0.8165269  0.80728465 0.5902273  0.8825479  0.6842311\n",
      " 0.6202472  0.9457237 ]\n",
      "The rewards are: [0.7742748  0.8256507  0.7620567  0.9133836  0.62192094 0.60519624\n",
      " 0.9230184  0.7819225  0.5593809  0.82441485 0.5512201  0.54477423\n",
      " 0.6936577  0.86556405 0.6432003  0.7888852  0.69711477 0.95867527\n",
      " 0.76646644 0.5173107  0.79154444 0.91788703 0.78508085 0.57336706\n",
      " 0.9257593  0.65330493 0.89114046 0.80741745 0.9148552  0.8215556\n",
      " 0.71657044 0.7371408 ]\n",
      "The rewards are: [0.90101147 0.7144184  0.73040956 0.64686376 0.5940476  0.78413373\n",
      " 0.9050319  0.55207354 0.80681026 0.57691723 0.8186595  0.76034844\n",
      " 0.6833234  0.9130722  0.67121214 0.5351118  0.8170925  0.8673461\n",
      " 0.7464393  0.76176906 0.8043416  0.8056231  0.8339427  0.768587\n",
      " 0.54374397 0.610111   0.8014035  0.8770969  0.62360275 0.8715567\n",
      " 0.6703383  0.8196968 ]\n",
      "The rewards are: [0.8851133  0.79643184 0.8730654  0.87284577 0.6741252  0.8329745\n",
      " 0.9061012  0.85855913 0.6151591  0.8230535  0.93334436 0.7434809\n",
      " 0.58527666 0.91055954 0.8992589  0.85307753 0.60265094 0.6736029\n",
      " 0.5385375  0.7100194  0.8320995  0.84054506 0.5146387  0.8450179\n",
      " 0.6539623  0.9126227  0.592026   0.8550396  0.6804085  0.67964494\n",
      " 0.71205825 0.70223135]\n",
      "The rewards are: [0.7559097  0.8574421  0.7335854  0.5600226  0.85179114 0.6914018\n",
      " 0.8256251  0.85870695 0.7691697  0.68964297 0.683543   0.54893655\n",
      " 0.5486666  0.9181129  0.7290122  0.9032518  0.5077235  0.8595181\n",
      " 0.5261394  0.91532224 0.7314195  0.857906   0.70801383 0.9285707\n",
      " 0.8129917  0.6570675  0.5646453  0.6151881  0.76640326 0.7204967\n",
      " 0.57109904 0.85888124]\n",
      "The rewards are: [0.7418681  0.7232071  0.68867767 0.83222556 0.76006293 0.63366187\n",
      " 0.6479693  0.6831688  0.6901706  0.79276603 0.8715829  0.88205725\n",
      " 0.71540695 0.75776196 0.6683458  0.7380853  0.52136856 0.844345\n",
      " 0.5927874  0.79321176 0.5825875  0.85214746 0.7559154  0.5981808\n",
      " 0.7006884  0.8042715  0.68446565 0.70944107 0.64952147 0.52694046\n",
      " 0.5687802  0.8373101 ]\n",
      "The rewards are: [0.84067243 0.9289781  0.51536316 0.8692291  0.75406104 0.8916438\n",
      " 0.74805456 0.5122113  0.6573534  0.64778996 0.7219868  0.51308167\n",
      " 0.7838852  0.95456135 0.5796543  0.51301664 0.6972391  0.7001043\n",
      " 0.7714809  0.8666159  0.7849909  0.8518973  0.9268708  0.7008272\n",
      " 0.8783624  0.71103144 0.8134674  0.6243143  0.7467102  0.52736396\n",
      " 0.50155544 0.84744215]\n",
      "The rewards are: [0.86012584 0.5880398  0.6507212  0.8505136  0.8222097  0.8064592\n",
      " 0.7574531  0.83661324 0.86453766 0.7941919  0.68294245 0.81019163\n",
      " 0.8454187  0.7108537  0.52979976 0.6415597  0.6167774  0.9496136\n",
      " 0.5374097  0.75419474 0.7820667  0.84882784 0.6913917  0.9055684\n",
      " 0.53037125 0.7260244  0.7229274  0.7259093  0.58227736 0.77431357\n",
      " 0.7851975  0.80321324]\n",
      "The rewards are: [0.8910563  0.73804986 0.76050186 0.8323817  0.79801244 0.7676213\n",
      " 0.5588346  0.6989625  0.86737317 0.77708375 0.95325416 0.90977937\n",
      " 0.90673107 0.8871412  0.5080903  0.8763695  0.6970761  0.6125789\n",
      " 0.70575595 0.5733351  0.86605304 0.94371605 0.8414365  0.6165871\n",
      " 0.7063959  0.5035903  0.6570249  0.88948184 0.8263353  0.7384144\n",
      " 0.87937933 0.5162099 ]\n",
      "The rewards are: [0.85833704 0.7197629  0.645716   0.78102773 0.7010804  0.9113732\n",
      " 0.841862   0.74305403 0.65023774 0.57449347 0.81712437 0.82233226\n",
      " 0.8554894  0.6759538  0.7972391  0.6307766  0.60305876 0.5246459\n",
      " 0.6919727  0.8412934  0.6712551  0.6517404  0.7530457  0.76059264\n",
      " 0.64440984 0.89123046 0.7042241  0.529982   0.9142891  0.7798608\n",
      " 0.5213079  0.5319365 ]\n",
      "The rewards are: [0.60726273 0.7142184  0.6155992  0.9378757  0.69754    0.83434004\n",
      " 0.72038406 0.7610193  0.8930729  0.7298747  0.741637   0.69259167\n",
      " 0.8640298  0.79768795 0.6739686  0.61237186 0.6461189  0.827058\n",
      " 0.5396862  0.66132426 0.8864899  0.8950108  0.59799016 0.8624465\n",
      " 0.63276494 0.51002264 0.6336619  0.8980139  0.9213172  0.60692316\n",
      " 0.5565336  0.9471075 ]\n",
      "The rewards are: [0.78356177 0.6887363  0.73352563 0.8969608  0.5816386  0.8901684\n",
      " 0.6110086  0.95451844 0.9584395  0.5194802  0.80605054 0.7843419\n",
      " 0.9176593  0.82057565 0.7836183  0.6034025  0.80539346 0.7611842\n",
      " 0.82156634 0.7787039  0.5296652  0.5405444  0.8027748  0.5119349\n",
      " 0.7922401  0.8164207  0.6110392  0.5614236  0.7795746  0.69633913\n",
      " 0.71381587 0.5510956 ]\n",
      "The rewards are: [0.9042264  0.5170503  0.846543   0.8991738  0.6436858  0.78878087\n",
      " 0.81682634 0.55867976 0.59233516 0.7618376  0.8329982  0.84487224\n",
      " 0.66932184 0.61675227 0.9195977  0.92852265 0.58087194 0.9075484\n",
      " 0.83281696 0.7498022  0.94044304 0.6821095  0.8608347  0.9226727\n",
      " 0.8130502  0.81886923 0.89964753 0.92594635 0.8350189  0.9061098\n",
      " 0.71562046 0.8723448 ]\n",
      "The rewards are: [0.8788717  0.7417363  0.5770807  0.836696   0.6364041  0.6466432\n",
      " 0.81286955 0.63788253 0.8169782  0.7506598  0.78130853 0.66869104\n",
      " 0.8758742  0.75134957 0.92353064 0.5008582  0.7109225  0.7667612\n",
      " 0.7033593  0.92234015 0.8260276  0.77957785 0.64071214 0.5820577\n",
      " 0.5471757  0.50735396 0.97245693 0.55579716 0.6612469  0.89774317\n",
      " 0.87003946 0.5458442 ]\n",
      "The rewards are: [0.73381287 0.5301967  0.7935993  0.8574208  0.5655912  0.5597951\n",
      " 0.6230103  0.73292154 0.8685518  0.8281974  0.8131955  0.8983321\n",
      " 0.8646452  0.9055402  0.6424054  0.9095816  0.8776415  0.56597006\n",
      " 0.7775716  0.5153274  0.75478464 0.8923773  0.8413004  0.6141917\n",
      " 0.86583036 0.51663226 0.6983015  0.72235715 0.8355094  0.84013665\n",
      " 0.8741692  0.8135816 ]\n",
      "The rewards are: [0.5743846  0.7709736  0.8054211  0.8962644  0.7644603  0.5976995\n",
      " 0.9479072  0.8492631  0.8758399  0.6775648  0.91413945 0.73612654\n",
      " 0.7998795  0.5438903  0.8386604  0.66927844 0.80909705 0.5234202\n",
      " 0.94587684 0.91128963 0.97695833 0.7435872  0.7402081  0.74583524\n",
      " 0.7898816  0.50586134 0.58545625 0.6210171  0.88302404 0.627109\n",
      " 0.8309185  0.8408142 ]\n",
      "The rewards are: [0.9457446  0.6817431  0.72992074 0.7883337  0.9294251  0.8675449\n",
      " 0.8331593  0.89372766 0.91746646 0.7195028  0.5560526  0.80063444\n",
      " 0.8222877  0.89123636 0.7908032  0.8254412  0.7416587  0.5795735\n",
      " 0.79267675 0.7556451  0.5610381  0.9015356  0.72704667 0.91495466\n",
      " 0.78710854 0.8815777  0.94123435 0.7783827  0.75719637 0.54368556\n",
      " 0.8432341  0.6501333 ]\n",
      "The rewards are: [0.87324697 0.7388536  0.7054135  0.8644621  0.77336746 0.8019616\n",
      " 0.5188142  0.6715412  0.70282507 0.8787773  0.6688434  0.5884236\n",
      " 0.8639338  0.63680965 0.83523494 0.8440465  0.7652772  0.53051704\n",
      " 0.8785249  0.83068454 0.82199454 0.82238305 0.5875691  0.8635742\n",
      " 0.9452108  0.8552496  0.65102226 0.7843208  0.789461   0.8316192\n",
      " 0.6541307  0.91224   ]\n",
      "The rewards are: [0.8811361  0.52411383 0.8894046  0.78952754 0.8344401  0.7530907\n",
      " 0.89000607 0.9374481  0.8873016  0.5219331  0.8426226  0.9068421\n",
      " 0.86898744 0.6510553  0.67993635 0.733847   0.5043808  0.8845367\n",
      " 0.9158078  0.9273461  0.6888807  0.52019334 0.8429354  0.7966296\n",
      " 0.79087764 0.7879533  0.8444497  0.6141405  0.6247373  0.6240015\n",
      " 0.5068203  0.690652  ]\n",
      "The rewards are: [0.92069817 0.5050111  0.89111894 0.8645373  0.5361187  0.8039745\n",
      " 0.5320916  0.7785894  0.78711987 0.9042803  0.6386336  0.72332025\n",
      " 0.803962   0.91646093 0.5250774  0.781608   0.5278846  0.89196974\n",
      " 0.6089275  0.6568287  0.7964503  0.9067395  0.72199905 0.87235916\n",
      " 0.5867518  0.9229725  0.8877354  0.8779198  0.7656448  0.85950506\n",
      " 0.8058705  0.8409391 ]\n",
      "The rewards are: [0.8771496  0.77589506 0.8129301  0.81459755 0.90381473 0.6332015\n",
      " 0.7214505  0.53806055 0.93642884 0.51646966 0.84959954 0.51489687\n",
      " 0.83723587 0.57562023 0.7408812  0.86753166 0.9134693  0.86127716\n",
      " 0.61749476 0.84671825 0.72584265 0.52938825 0.5291704  0.6234166\n",
      " 0.6610041  0.8051257  0.6715181  0.8553569  0.71554404 0.65793383\n",
      " 0.95947695 0.9153908 ]\n",
      "The rewards are: [0.551363   0.6024045  0.80081624 0.83441496 0.7161013  0.9103966\n",
      " 0.8996364  0.5119045  0.7655753  0.667484   0.83790046 0.8423036\n",
      " 0.8656948  0.6034648  0.50262624 0.80856377 0.6134672  0.69707936\n",
      " 0.88206136 0.60014325 0.78921217 0.8241124  0.83932316 0.90571547\n",
      " 0.7703732  0.8982372  0.9058572  0.828715   0.9155519  0.64142615\n",
      " 0.7593986  0.8647964 ]\n",
      "The rewards are: [0.9225989  0.9165879  0.59623265 0.81980854 0.68598217 0.7346909\n",
      " 0.65097356 0.9243774  0.74694186 0.63153535 0.7614508  0.6720547\n",
      " 0.6440713  0.8590895  0.67969304 0.8905734  0.9355893  0.83000183\n",
      " 0.6760936  0.94515926 0.7355571  0.7296287  0.5492564  0.86702967\n",
      " 0.96108824 0.6365575  0.77428985 0.7854215  0.75168544 0.7106047\n",
      " 0.79739255 0.7895651 ]\n",
      "The rewards are: [0.86012506 0.7641482  0.7506815  0.82994443 0.5344483  0.7534592\n",
      " 0.8295694  0.74420047 0.56967723 0.8719771  0.87146616 0.8702437\n",
      " 0.7882503  0.95026976 0.7937244  0.843379   0.6979861  0.79205614\n",
      " 0.66640496 0.85070854 0.7308188  0.7408811  0.6042852  0.6548734\n",
      " 0.81757045 0.76816    0.84087425 0.5622113  0.7142461  0.7633819\n",
      " 0.90416443 0.8104619 ]\n",
      "The rewards are: [0.6441192  0.86513084 0.92318743 0.77567595 0.8066605  0.80710965\n",
      " 0.9220409  0.787094   0.7918897  0.61721724 0.71338725 0.8056989\n",
      " 0.85903966 0.7714761  0.86223215 0.5736221  0.504068   0.6824199\n",
      " 0.8470935  0.90331143 0.822718   0.6738057  0.7394316  0.9009223\n",
      " 0.8868553  0.9037114  0.7418083  0.6233916  0.738907   0.70755744\n",
      " 0.7167314  0.55177647]\n",
      "The rewards are: [0.71623075 0.50655544 0.7463146  0.81206125 0.8257271  0.9658229\n",
      " 0.7295294  0.90391695 0.50868434 0.6074955  0.8169892  0.886168\n",
      " 0.73482597 0.8910217  0.8770477  0.9146975  0.5998657  0.8970992\n",
      " 0.6708763  0.90278697 0.79791194 0.7003837  0.88941026 0.8910281\n",
      " 0.6115426  0.9295399  0.6062515  0.83324206 0.61548835 0.9177864\n",
      " 0.9345814  0.886759  ]\n",
      "The rewards are: [0.82459503 0.90560764 0.8739363  0.5927312  0.80955356 0.5578803\n",
      " 0.8660185  0.88943976 0.7357489  0.93248624 0.76966035 0.7016993\n",
      " 0.83829534 0.6899096  0.9019713  0.5831413  0.9385333  0.71184903\n",
      " 0.5089614  0.9371516  0.6050525  0.7263475  0.68753695 0.6625608\n",
      " 0.94642866 0.61395884 0.95517397 0.7036633  0.7357283  0.7711519\n",
      " 0.9651086  0.93190014]\n",
      "The rewards are: [0.7253458  0.68079185 0.6506858  0.7718585  0.74845624 0.76486576\n",
      " 0.91448337 0.73572034 0.9244086  0.6880177  0.91976213 0.74546826\n",
      " 0.8502556  0.69384485 0.85453624 0.8790448  0.7773941  0.7770011\n",
      " 0.86320615 0.7739189  0.8730812  0.7611271  0.8135884  0.7262633\n",
      " 0.7315833  0.93982005 0.90726066 0.5494525  0.77777547 0.8324919\n",
      " 0.8068314  0.94434774]\n",
      "The rewards are: [0.703485   0.60194606 0.7897184  0.8135135  0.96664757 0.80081856\n",
      " 0.88184816 0.9462246  0.8169369  0.8115668  0.8284563  0.80303985\n",
      " 0.76134163 0.7599708  0.7876373  0.8279645  0.9263492  0.88717735\n",
      " 0.7417788  0.6177905  0.82678705 0.76257426 0.55789715 0.80860764\n",
      " 0.9643146  0.7994151  0.74732107 0.90443134 0.5025245  0.5095598\n",
      " 0.65189874 0.7915002 ]\n",
      "The rewards are: [0.67730445 0.94268703 0.9122208  0.8727188  0.9409974  0.9241142\n",
      " 0.7324855  0.83125925 0.7693419  0.6265332  0.92152977 0.8581529\n",
      " 0.6430954  0.8194545  0.5386517  0.5214936  0.86412334 0.84563166\n",
      " 0.8836631  0.75810516 0.75916046 0.9633877  0.9139984  0.8876495\n",
      " 0.5795835  0.816306   0.5294104  0.5658896  0.55191284 0.5489843\n",
      " 0.7531171  0.59298635]\n",
      "The rewards are: [0.6243199  0.53450286 0.74524724 0.69102234 0.79304194 0.5646573\n",
      " 0.6147901  0.58636475 0.7366967  0.63139856 0.590786   0.6492677\n",
      " 0.86361724 0.72200376 0.86026585 0.5132882  0.61908704 0.9283344\n",
      " 0.93301314 0.97164243 0.942563   0.9567472  0.9168563  0.855793\n",
      " 0.94214624 0.8367324  0.78198767 0.95701677 0.73471147 0.9507816\n",
      " 0.8994297  0.6337221 ]\n",
      "The rewards are: [0.787168   0.79896605 0.9632387  0.6632871  0.8501029  0.89013875\n",
      " 0.55712795 0.58765036 0.94880414 0.5789751  0.7053937  0.70817673\n",
      " 0.61951876 0.8909344  0.7696847  0.60693663 0.83236355 0.82899594\n",
      " 0.8923698  0.75822383 0.874408   0.7040219  0.92871183 0.8758101\n",
      " 0.70782596 0.7413536  0.7567766  0.8194363  0.884076   0.6918585\n",
      " 0.7792989  0.57150465]\n",
      "The rewards are: [0.5278224  0.92031676 0.5997653  0.81855357 0.79747313 0.5913512\n",
      " 0.7794045  0.8214235  0.8671093  0.5337896  0.87958854 0.91127086\n",
      " 0.8578614  0.9052885  0.508334   0.8142553  0.796146   0.7412073\n",
      " 0.9373827  0.6338558  0.671404   0.7862248  0.8597664  0.94279295\n",
      " 0.6919998  0.7116825  0.93308836 0.9206989  0.69591767 0.882924\n",
      " 0.83069646 0.79978377]\n",
      "The rewards are: [0.7671471  0.8204098  0.5975312  0.8036527  0.74427384 0.6463226\n",
      " 0.5550244  0.6311738  0.92393374 0.89396775 0.7318055  0.79225916\n",
      " 0.5867367  0.86868143 0.807617   0.749955   0.9520919  0.8395393\n",
      " 0.8932529  0.86858803 0.79184353 0.9124372  0.8755262  0.85448\n",
      " 0.95773953 0.8605184  0.73031276 0.8246878  0.8835134  0.8382047\n",
      " 0.7068829  0.6750881 ]\n",
      "The rewards are: [0.89081085 0.7394847  0.8568515  0.93123025 0.64143306 0.57839143\n",
      " 0.7394182  0.5503851  0.93060404 0.87378705 0.680365   0.9621657\n",
      " 0.5778392  0.72216785 0.80067277 0.77816194 0.57461554 0.6775085\n",
      " 0.9631875  0.6738854  0.6523161  0.85186267 0.80395526 0.73049927\n",
      " 0.6800994  0.65818536 0.80955476 0.727401   0.85310733 0.9181724\n",
      " 0.754663   0.76461893]\n",
      "The rewards are: [0.57688314 0.8339881  0.6123222  0.84230036 0.7799366  0.9470857\n",
      " 0.8439915  0.8202241  0.73889893 0.8611039  0.9258097  0.9456879\n",
      " 0.79744864 0.63154197 0.77483565 0.92133    0.9490486  0.5207355\n",
      " 0.6987802  0.9044237  0.52542317 0.92683893 0.5272611  0.8752756\n",
      " 0.87591016 0.84642375 0.89281553 0.6173865  0.9312536  0.5389633\n",
      " 0.88518816 0.6212928 ]\n",
      "The rewards are: [0.86009383 0.87047404 0.83970135 0.84813106 0.73398703 0.9341639\n",
      " 0.8864416  0.929302   0.8807784  0.7284961  0.7882584  0.7181206\n",
      " 0.82396215 0.6320971  0.76068765 0.67782193 0.7861759  0.8103059\n",
      " 0.5814365  0.91502094 0.8147868  0.6383418  0.6719214  0.740734\n",
      " 0.8282238  0.81806827 0.8432047  0.62188697 0.7590843  0.84813917\n",
      " 0.88546455 0.9169442 ]\n",
      "The rewards are: [0.9484317  0.9686393  0.7952073  0.7591069  0.8977515  0.77927256\n",
      " 0.9762105  0.5776306  0.5468178  0.97726804 0.70548135 0.9175491\n",
      " 0.9076591  0.5598343  0.7042242  0.7739972  0.7446089  0.97087586\n",
      " 0.7669722  0.7687372  0.88980204 0.9626759  0.5381505  0.5414146\n",
      " 0.78910667 0.7725071  0.9764057  0.6455212  0.92629665 0.78226244\n",
      " 0.869056   0.73814243]\n",
      "The rewards are: [0.6294486  0.7804917  0.8431947  0.97259164 0.6828882  0.87786204\n",
      " 0.77668387 0.8823623  0.90282226 0.8808334  0.9278949  0.5328834\n",
      " 0.56742007 0.90500057 0.9209251  0.8141772  0.91477525 0.7778094\n",
      " 0.93500286 0.74877495 0.9204074  0.82474536 0.69075274 0.917216\n",
      " 0.893232   0.8757829  0.5806114  0.850073   0.9625889  0.89857864\n",
      " 0.9187706  0.9608781 ]\n",
      "The rewards are: [0.9489335  0.781075   0.64370286 0.73943806 0.5019797  0.9569591\n",
      " 0.51589644 0.84402114 0.9101555  0.5069585  0.918002   0.55126387\n",
      " 0.61196786 0.5186257  0.9131542  0.9701498  0.9450551  0.9628112\n",
      " 0.9562844  0.60293514 0.52911586 0.92683095 0.5447318  0.9253632\n",
      " 0.8353025  0.87426597 0.8753477  0.8512666  0.6223118  0.8244451\n",
      " 0.9331115  0.907991  ]\n",
      "The rewards are: [0.95510554 0.94475275 0.553828   0.9010392  0.8293094  0.90544504\n",
      " 0.63850856 0.9121335  0.61845106 0.73153883 0.62858814 0.8203349\n",
      " 0.8712008  0.7796521  0.7986329  0.882232   0.8978553  0.91759557\n",
      " 0.91286725 0.9172338  0.90973854 0.9078285  0.7931329  0.8218533\n",
      " 0.7359859  0.81332225 0.8341279  0.90300125 0.85836476 0.53841776\n",
      " 0.8722727  0.8916619 ]\n",
      "The rewards are: [0.96570075 0.93152094 0.9068498  0.61317074 0.91253126 0.8958177\n",
      " 0.9618279  0.93450767 0.80194473 0.7232115  0.7648453  0.8493536\n",
      " 0.8937283  0.9591439  0.8607025  0.851215   0.7703392  0.7515367\n",
      " 0.8829613  0.5024102  0.82977796 0.9462144  0.5187368  0.7777561\n",
      " 0.82727677 0.9298002  0.76322585 0.71887016 0.87060255 0.9252804\n",
      " 0.9353661  0.9473027 ]\n",
      "The rewards are: [0.8712495  0.93250996 0.6263554  0.72369707 0.6475328  0.886511\n",
      " 0.780608   0.8095077  0.60617626 0.94663835 0.8620449  0.8482322\n",
      " 0.9078021  0.9769652  0.5983363  0.96813464 0.7757521  0.5653262\n",
      " 0.62329787 0.59402794 0.8702688  0.524885   0.5394673  0.77278703\n",
      " 0.9364721  0.7750086  0.78868663 0.8160456  0.9185486  0.7298471\n",
      " 0.8700144  0.8437916 ]\n",
      "The rewards are: [0.78627086 0.93646026 0.84473354 0.8860578  0.7390249  0.7995487\n",
      " 0.7121983  0.75634986 0.834471   0.85729265 0.8479026  0.96912664\n",
      " 0.914203   0.8781416  0.79657567 0.7718517  0.7841128  0.5581575\n",
      " 0.83699304 0.8098318  0.898633   0.8504114  0.8098897  0.9300365\n",
      " 0.69610393 0.70427865 0.90576154 0.8167153  0.60106266 0.8923631\n",
      " 0.5571212  0.6606133 ]\n",
      "The rewards are: [0.85828596 0.84867907 0.86555487 0.9007144  0.823035   0.9169135\n",
      " 0.8354905  0.53805006 0.7750324  0.90801513 0.8287407  0.6132289\n",
      " 0.8132337  0.8736125  0.98778826 0.9099952  0.6302166  0.56362116\n",
      " 0.9441089  0.907949   0.9154124  0.54354656 0.61522794 0.95392394\n",
      " 0.95775837 0.95113724 0.5215886  0.9392369  0.5127343  0.8281037\n",
      " 0.8767422  0.7504469 ]\n",
      "The rewards are: [0.6613812  0.9587603  0.5799699  0.9070257  0.7262558  0.66727114\n",
      " 0.8543192  0.86203265 0.8705352  0.92262733 0.76108664 0.7074696\n",
      " 0.60253525 0.9403416  0.5356414  0.5669219  0.9111184  0.9655231\n",
      " 0.9185429  0.94553596 0.96668476 0.9254736  0.95605564 0.8490929\n",
      " 0.6480116  0.5165027  0.9239904  0.9361198  0.8876597  0.55965894\n",
      " 0.7887129  0.64554834]\n",
      "The rewards are: [0.844503   0.8173372  0.89913255 0.6028329  0.9333589  0.92260337\n",
      " 0.5103417  0.88385487 0.92109114 0.8881962  0.69088864 0.71046937\n",
      " 0.857887   0.91047496 0.86367166 0.6452243  0.77060556 0.7670968\n",
      " 0.7497497  0.8188586  0.5189462  0.57027054 0.98211825 0.9235531\n",
      " 0.90337914 0.93168694 0.9187072  0.5642708  0.70015    0.7896453\n",
      " 0.96774954 0.8984565 ]\n",
      "The rewards are: [0.80094975 0.7827507  0.78747404 0.95193887 0.655741   0.88956946\n",
      " 0.8799471  0.7022386  0.9392516  0.9044948  0.51432365 0.69848585\n",
      " 0.8783547  0.78106135 0.95796126 0.8692969  0.80818945 0.95237637\n",
      " 0.9235751  0.8775475  0.804516   0.7802726  0.5288132  0.8102375\n",
      " 0.7775397  0.73046136 0.5019354  0.5781367  0.82222134 0.9222142\n",
      " 0.7817343  0.706592  ]\n",
      "The rewards are: [0.9325439  0.8988675  0.8689869  0.8631677  0.74379236 0.94652796\n",
      " 0.8385346  0.66451746 0.9214641  0.9307923  0.9686637  0.9394197\n",
      " 0.695382   0.87510896 0.95319396 0.83758676 0.51647216 0.74713224\n",
      " 0.87766856 0.97220606 0.7156776  0.7785071  0.71579015 0.7919284\n",
      " 0.9256261  0.869647   0.84723485 0.87987524 0.7356469  0.6391857\n",
      " 0.8917564  0.8531705 ]\n",
      "The rewards are: [0.929981   0.9420274  0.93826807 0.96119905 0.67133677 0.8508686\n",
      " 0.7450978  0.7744591  0.8815862  0.83432907 0.878424   0.6244952\n",
      " 0.95167255 0.8691156  0.93529993 0.9474249  0.94194424 0.93997496\n",
      " 0.63243043 0.91753864 0.7786891  0.9451711  0.97057533 0.7461453\n",
      " 0.8138784  0.87964576 0.9275848  0.79489505 0.96736676 0.8875907\n",
      " 0.908262   0.92121905]\n",
      "The rewards are: [0.857982   0.54220444 0.86419696 0.69041735 0.89864516 0.8400074\n",
      " 0.6272061  0.50211513 0.88841224 0.9590455  0.89793813 0.73273265\n",
      " 0.963884   0.7801125  0.6239354  0.8153254  0.51655173 0.9168592\n",
      " 0.8273749  0.82377774 0.95883286 0.7764709  0.95278114 0.82877713\n",
      " 0.6793761  0.7214034  0.89757454 0.60713446 0.66905427 0.87087387\n",
      " 0.8979392  0.5209182 ]\n",
      "The rewards are: [0.9306727  0.9595448  0.82394296 0.54565305 0.81995    0.91323364\n",
      " 0.60952955 0.93066925 0.62124515 0.75761217 0.8660246  0.9659267\n",
      " 0.73848164 0.96996015 0.53446174 0.85141534 0.9102563  0.9748632\n",
      " 0.9746981  0.5291482  0.9095658  0.8397681  0.7132292  0.91531336\n",
      " 0.93885356 0.5015578  0.9300864  0.78892285 0.8322229  0.82101464\n",
      " 0.9720804  0.9541439 ]\n",
      "The rewards are: [0.9152826  0.6324299  0.83980215 0.95011264 0.7095818  0.9168152\n",
      " 0.9249393  0.94783926 0.67976224 0.9616854  0.9512688  0.50294137\n",
      " 0.85788757 0.669077   0.8986898  0.88485867 0.8971127  0.9536358\n",
      " 0.60845613 0.6157251  0.8021989  0.76992756 0.9355313  0.84889394\n",
      " 0.91184306 0.8988019  0.58419347 0.5213913  0.9419118  0.7894567\n",
      " 0.9372781  0.91751605]\n",
      "The rewards are: [0.9144991  0.5145636  0.6594378  0.959032   0.8040532  0.8326704\n",
      " 0.9119478  0.8565328  0.94286066 0.88354486 0.758896   0.6825558\n",
      " 0.8806528  0.7781884  0.9294936  0.6945716  0.7404531  0.679488\n",
      " 0.7667194  0.9536828  0.7267334  0.8533804  0.7261907  0.9522199\n",
      " 0.71639323 0.6231912  0.63880587 0.84324634 0.9140681  0.55949396\n",
      " 0.58785564 0.69854045]\n",
      "The rewards are: [0.76336175 0.55444694 0.68656325 0.9229767  0.9219281  0.9565367\n",
      " 0.5539896  0.9028406  0.8267513  0.87472653 0.92985046 0.94573444\n",
      " 0.96127903 0.92465216 0.8630361  0.9200439  0.97840947 0.57788324\n",
      " 0.86312836 0.676802   0.9290335  0.6571015  0.9142823  0.948754\n",
      " 0.8424266  0.8814781  0.8008618  0.8908848  0.7220909  0.7282426\n",
      " 0.9809202  0.86034244]\n",
      "The rewards are: [0.83348626 0.91575813 0.95200217 0.8733712  0.72206753 0.90794057\n",
      " 0.98908234 0.95954025 0.95772654 0.86112446 0.84630626 0.8155999\n",
      " 0.9555934  0.55202013 0.96175575 0.84021986 0.5186773  0.93492675\n",
      " 0.7532621  0.88338166 0.6432657  0.92935014 0.8487815  0.80443287\n",
      " 0.8669423  0.9188848  0.8996346  0.9481566  0.8009475  0.8092195\n",
      " 0.8966219  0.5278506 ]\n",
      "The rewards are: [0.6155461  0.95929426 0.8394927  0.9103272  0.96367854 0.96143687\n",
      " 0.7813638  0.90294534 0.87298965 0.8260343  0.854002   0.90818304\n",
      " 0.85703516 0.67906255 0.7810108  0.9328805  0.8773204  0.8987058\n",
      " 0.64617866 0.6853817  0.7150973  0.94226366 0.68753606 0.912462\n",
      " 0.7356295  0.7698323  0.959616   0.9629334  0.94164896 0.96033204\n",
      " 0.9767768  0.7010188 ]\n",
      "The rewards are: [0.5690379  0.76268506 0.6856313  0.9683819  0.6243912  0.95617145\n",
      " 0.9532865  0.98303246 0.98742944 0.6508808  0.9493632  0.8726267\n",
      " 0.90087247 0.8546576  0.99221134 0.7218369  0.8456011  0.77934045\n",
      " 0.7042298  0.92033005 0.8614095  0.907206   0.97954684 0.8420709\n",
      " 0.671729   0.6716895  0.7334878  0.7741547  0.7373799  0.9469788\n",
      " 0.9699865  0.95848304]\n",
      "The rewards are: [0.91936994 0.9377831  0.9737457  0.96486384 0.6635756  0.7998926\n",
      " 0.9221252  0.55241805 0.94202656 0.5783303  0.8996444  0.7915157\n",
      " 0.64045405 0.51873684 0.7569561  0.81981796 0.96213007 0.92307353\n",
      " 0.8051565  0.6957103  0.85521877 0.9140765  0.91891885 0.9785388\n",
      " 0.80582076 0.82577586 0.6575375  0.9879616  0.8632598  0.5509292\n",
      " 0.92056924 0.87659883]\n",
      "The rewards are: [0.8748579  0.9174731  0.90690106 0.9254421  0.8689699  0.71663266\n",
      " 0.96787786 0.6908381  0.90478    0.9526289  0.8872271  0.8741507\n",
      " 0.93440294 0.5458372  0.8453276  0.8333216  0.84596676 0.50904995\n",
      " 0.8249227  0.9319728  0.83364403 0.5567069  0.84356713 0.931975\n",
      " 0.8999053  0.6563022  0.97165495 0.8871345  0.7643241  0.96884817\n",
      " 0.64128184 0.7319641 ]\n",
      "The rewards are: [0.73114467 0.9780909  0.93528324 0.959622   0.96620697 0.97688454\n",
      " 0.94372797 0.8705467  0.7356424  0.9193806  0.90698105 0.9603855\n",
      " 0.77200663 0.9349693  0.7551095  0.66378194 0.9258524  0.88873136\n",
      " 0.94272685 0.9404089  0.8280571  0.87947947 0.91813487 0.8545427\n",
      " 0.7625016  0.7886847  0.6138755  0.8752926  0.7823903  0.541675\n",
      " 0.81683445 0.9160494 ]\n",
      "The rewards are: [0.91372055 0.97149175 0.7412913  0.96614575 0.5939707  0.8579268\n",
      " 0.8822033  0.889796   0.6084187  0.8360859  0.8795158  0.96447843\n",
      " 0.56679064 0.9618806  0.691829   0.8977467  0.92378795 0.9054895\n",
      " 0.6055987  0.65579313 0.820998   0.55160254 0.968016   0.91858035\n",
      " 0.58612853 0.78127825 0.884728   0.6719123  0.84199107 0.7086988\n",
      " 0.5526063  0.813185  ]\n",
      "The rewards are: [0.9228767  0.96087766 0.6235141  0.7788395  0.98451704 0.8614446\n",
      " 0.9250484  0.94899577 0.9592384  0.90427387 0.82868356 0.79500157\n",
      " 0.80468875 0.87773883 0.5955564  0.7534287  0.9398925  0.92505664\n",
      " 0.51529706 0.9429549  0.7696055  0.88024    0.9498102  0.8254869\n",
      " 0.8846422  0.75733316 0.8525718  0.9765465  0.81248635 0.558246\n",
      " 0.9019784  0.90174365]\n",
      "The rewards are: [0.8551484  0.8087494  0.78770393 0.9885067  0.9605224  0.8419196\n",
      " 0.93328756 0.8362907  0.5298484  0.8945944  0.7048103  0.6369745\n",
      " 0.9632175  0.83222747 0.92458427 0.9338407  0.5483161  0.69948083\n",
      " 0.7977081  0.9196366  0.71884394 0.69164467 0.6265281  0.5423815\n",
      " 0.95046055 0.9606036  0.91306496 0.8608719  0.73233724 0.7118437\n",
      " 0.80737495 0.61326903]\n",
      "The rewards are: [0.5494587  0.8454667  0.98758405 0.6881959  0.7916974  0.87318474\n",
      " 0.96395785 0.5568241  0.7844694  0.9719285  0.7730724  0.97157854\n",
      " 0.63566405 0.5889442  0.9665541  0.90101635 0.8223527  0.9418253\n",
      " 0.5610199  0.9183213  0.94539213 0.8977261  0.8264793  0.96639574\n",
      " 0.58333474 0.9498729  0.673684   0.9684485  0.63689095 0.77141917\n",
      " 0.8687466  0.9030891 ]\n",
      "The rewards are: [0.92253804 0.98291045 0.94239306 0.91062754 0.6940939  0.7532724\n",
      " 0.8281746  0.8284879  0.9550539  0.70435315 0.6680545  0.9868841\n",
      " 0.9010218  0.92535096 0.787642   0.60838056 0.60255224 0.75660443\n",
      " 0.9713759  0.8741493  0.56337845 0.8404191  0.9229546  0.95724875\n",
      " 0.75368184 0.9366876  0.9384504  0.78285587 0.9427105  0.68443\n",
      " 0.9144813  0.8963537 ]\n",
      "The rewards are: [0.9370773  0.98216736 0.60745525 0.827749   0.86978966 0.6002269\n",
      " 0.7750748  0.9499421  0.8587978  0.73624647 0.642637   0.9687865\n",
      " 0.9497328  0.92687654 0.8129851  0.95250416 0.86227584 0.62431234\n",
      " 0.69500744 0.65430063 0.5726304  0.95062375 0.9316209  0.7191023\n",
      " 0.83860195 0.88627625 0.63155776 0.6522345  0.83943003 0.96609706\n",
      " 0.9449175  0.90399307]\n",
      "The rewards are: [0.8057667  0.8295528  0.86680835 0.90755767 0.7172525  0.9758445\n",
      " 0.8361545  0.83518076 0.6099101  0.9159754  0.86604947 0.9601931\n",
      " 0.9007458  0.5274208  0.91254777 0.55966485 0.939227   0.6001935\n",
      " 0.97432524 0.6259117  0.953982   0.709504   0.74474967 0.5742963\n",
      " 0.7074532  0.7220186  0.8375559  0.92580694 0.6216362  0.9547235\n",
      " 0.9265574  0.9265482 ]\n",
      "The rewards are: [0.9853608  0.66599756 0.9000755  0.8995308  0.7854408  0.8733691\n",
      " 0.9267     0.8969891  0.80442303 0.6074121  0.7177031  0.967504\n",
      " 0.79468936 0.7196972  0.87013423 0.79068565 0.6411392  0.95230186\n",
      " 0.9200676  0.51737225 0.6529675  0.96603787 0.95092523 0.96171975\n",
      " 0.52885604 0.9023686  0.9724001  0.93008274 0.525189   0.97219807\n",
      " 0.6815914  0.953704  ]\n",
      "The rewards are: [0.8724073  0.8134626  0.57485193 0.90579927 0.9669961  0.773024\n",
      " 0.8400344  0.9594039  0.9480693  0.5652652  0.76820767 0.506705\n",
      " 0.8734108  0.89702725 0.8101487  0.93124    0.9263311  0.74222386\n",
      " 0.5891546  0.94989485 0.87779135 0.93483156 0.9025357  0.78782856\n",
      " 0.65092856 0.92453885 0.928932   0.6058528  0.9938431  0.9340209\n",
      " 0.61501086 0.8364995 ]\n",
      "The rewards are: [0.9337925  0.8666245  0.8300671  0.8592341  0.95575845 0.9325363\n",
      " 0.6986663  0.83082545 0.75025237 0.8111739  0.6912605  0.97713953\n",
      " 0.9620378  0.6853432  0.98426086 0.8165954  0.89926726 0.6922112\n",
      " 0.7254621  0.945598   0.83475745 0.7867366  0.96892416 0.820498\n",
      " 0.93993324 0.5988012  0.8537656  0.95957714 0.8334999  0.96671206\n",
      " 0.8314202  0.83308244]\n",
      "The rewards are: [0.85010314 0.9648292  0.93481684 0.58487767 0.80392665 0.90147305\n",
      " 0.9667412  0.84058136 0.67506915 0.6044446  0.9460231  0.8631484\n",
      " 0.9815217  0.88779086 0.7180866  0.97722113 0.97064036 0.7244801\n",
      " 0.9639346  0.9749997  0.7719662  0.715115   0.87605226 0.7768722\n",
      " 0.853532   0.69568276 0.98230195 0.94299495 0.6769823  0.9794534\n",
      " 0.66673875 0.91307795]\n",
      "The rewards are: [0.85107905 0.932445   0.6162339  0.71611375 0.7821568  0.57359964\n",
      " 0.9205751  0.65175605 0.50978273 0.5460247  0.5535806  0.96715164\n",
      " 0.95207834 0.80052304 0.8650543  0.7023741  0.7122834  0.89134765\n",
      " 0.8530582  0.88232565 0.77258193 0.68179363 0.80695546 0.509476\n",
      " 0.93471885 0.610498   0.90511525 0.9413985  0.600862   0.75825524\n",
      " 0.9474163  0.7024389 ]\n",
      "The rewards are: [0.9618666  0.77172446 0.98835844 0.7063511  0.5488353  0.5694802\n",
      " 0.6029561  0.9291424  0.98648703 0.9003134  0.9178584  0.980057\n",
      " 0.67249846 0.9545656  0.8742654  0.92197144 0.8453724  0.9403981\n",
      " 0.84950614 0.94725424 0.9405005  0.8393738  0.8633914  0.9440979\n",
      " 0.62795323 0.9777089  0.67825407 0.80943835 0.7141322  0.97256684\n",
      " 0.98538107 0.8058663 ]\n",
      "The rewards are: [0.9036737  0.7634613  0.7419156  0.9011881  0.69962895 0.69464767\n",
      " 0.9313776  0.9451009  0.88737273 0.67722726 0.906075   0.92325175\n",
      " 0.9311995  0.9724512  0.94513065 0.577467   0.7895015  0.95002913\n",
      " 0.9288467  0.8733361  0.97356963 0.75692403 0.74116826 0.9412424\n",
      " 0.9646155  0.8783114  0.7828999  0.9844647  0.8084736  0.8548909\n",
      " 0.8509461  0.96534073]\n",
      "The rewards are: [0.7563195  0.90746063 0.70395994 0.7442712  0.8384869  0.80811775\n",
      " 0.8748136  0.8454309  0.93294704 0.8522427  0.9779499  0.7798181\n",
      " 0.96159196 0.5356445  0.890933   0.78173536 0.5750702  0.96346164\n",
      " 0.6615958  0.8701018  0.80019397 0.93922853 0.93907464 0.9679436\n",
      " 0.8376834  0.6039738  0.7781033  0.96947306 0.8850299  0.7458932\n",
      " 0.8974178  0.95169   ]\n",
      "The rewards are: [0.9167038  0.95632136 0.953581   0.97302026 0.7544406  0.9266322\n",
      " 0.9521568  0.7771219  0.65912193 0.5063339  0.9567967  0.8594557\n",
      " 0.8623883  0.92997193 0.96836054 0.8219884  0.6532937  0.8070785\n",
      " 0.8588072  0.64869285 0.5868469  0.91021115 0.51635617 0.95797974\n",
      " 0.9281164  0.6244368  0.98260486 0.96009374 0.8646874  0.60781354\n",
      " 0.7992174  0.8391439 ]\n",
      "The rewards are: [0.593383   0.609564   0.9485504  0.85315    0.9392025  0.68539184\n",
      " 0.54966027 0.7428798  0.9412563  0.77069986 0.791347   0.936386\n",
      " 0.9372554  0.9488295  0.95340353 0.90741175 0.9693609  0.578447\n",
      " 0.93639535 0.92679054 0.86851007 0.8710091  0.60215056 0.55310124\n",
      " 0.62323105 0.72488993 0.7492121  0.9874785  0.98336893 0.8786625\n",
      " 0.874288   0.9660139 ]\n",
      "The rewards are: [0.5487408  0.9647089  0.79406023 0.93403757 0.96769565 0.7327155\n",
      " 0.9469966  0.9184535  0.9775261  0.98091036 0.8988802  0.7494497\n",
      " 0.77778333 0.84188217 0.5730012  0.80126804 0.65251714 0.9436383\n",
      " 0.94705343 0.9160154  0.89866054 0.9489934  0.9888981  0.5212218\n",
      " 0.77123624 0.93212724 0.958218   0.84309244 0.99148446 0.91660917\n",
      " 0.66021204 0.97474116]\n",
      "The rewards are: [0.8561104  0.946676   0.6087952  0.71182853 0.5950369  0.6407359\n",
      " 0.88690275 0.79384166 0.66331553 0.88587767 0.7591395  0.6224199\n",
      " 0.5734694  0.84725976 0.9847252  0.92655814 0.9141804  0.5650377\n",
      " 0.7010418  0.8191695  0.8029263  0.5195114  0.94885826 0.98862106\n",
      " 0.6743613  0.82997155 0.91361445 0.7751061  0.97604054 0.69929785\n",
      " 0.92798525 0.73091793]\n",
      "The rewards are: [0.8552184  0.64826304 0.8445334  0.93123585 0.5847683  0.7459268\n",
      " 0.95527303 0.9191904  0.54551566 0.81668496 0.97006804 0.94496185\n",
      " 0.92182386 0.87940884 0.91433483 0.96266747 0.9413219  0.8959059\n",
      " 0.64350986 0.8571527  0.75692177 0.7961963  0.6017872  0.7434041\n",
      " 0.973538   0.8458794  0.8666472  0.94567996 0.7677157  0.96369594\n",
      " 0.97440505 0.7015209 ]\n",
      "The rewards are: [0.628138   0.9463049  0.93091816 0.5975202  0.62880516 0.78748065\n",
      " 0.71689904 0.6900505  0.941024   0.7162409  0.9453429  0.98326266\n",
      " 0.9665041  0.9386125  0.91840273 0.8780529  0.9059595  0.93184\n",
      " 0.84601164 0.7470779  0.59985685 0.590939   0.9053116  0.94355893\n",
      " 0.93805146 0.96429485 0.8065366  0.8920702  0.8903065  0.9190112\n",
      " 0.9059963  0.90325004]\n",
      "The rewards are: [0.9501787  0.8233738  0.8279416  0.5264667  0.63524175 0.64200276\n",
      " 0.9088066  0.8793422  0.8548304  0.85436356 0.9273813  0.7265854\n",
      " 0.57172984 0.78711736 0.96088153 0.5663503  0.9237937  0.5486724\n",
      " 0.636833   0.82315725 0.6983991  0.6165321  0.8735118  0.9365823\n",
      " 0.96968085 0.93535596 0.90717113 0.88224036 0.7743822  0.5563118\n",
      " 0.9443248  0.7721847 ]\n",
      "The rewards are: [0.81052655 0.69298285 0.5562323  0.9223882  0.87715787 0.8124708\n",
      " 0.7115165  0.9423388  0.59983206 0.9160483  0.908262   0.76916754\n",
      " 0.84254694 0.9257214  0.710576   0.9328522  0.9529491  0.76093966\n",
      " 0.9750165  0.78778106 0.5859263  0.94451946 0.9547746  0.8706912\n",
      " 0.94188863 0.89726263 0.5981281  0.64478564 0.9327544  0.9713579\n",
      " 0.9169191  0.6890197 ]\n",
      "The rewards are: [0.7030371  0.98853254 0.9696577  0.8494198  0.93091786 0.96797425\n",
      " 0.9490285  0.935874   0.64115626 0.90826064 0.9160845  0.88501775\n",
      " 0.98826116 0.8749557  0.85861725 0.77931756 0.8089721  0.7870253\n",
      " 0.8353386  0.6803521  0.84399587 0.83516604 0.71889603 0.91581607\n",
      " 0.9701834  0.89406204 0.9736874  0.79987884 0.9674348  0.7594559\n",
      " 0.91270274 0.9340538 ]\n",
      "The rewards are: [0.6963966  0.757979   0.89548653 0.666615   0.6681079  0.8026578\n",
      " 0.9667664  0.96053934 0.7105625  0.95119673 0.84164244 0.9327526\n",
      " 0.5465272  0.5900098  0.7572914  0.96058387 0.97078776 0.7701206\n",
      " 0.90426666 0.8661671  0.61552715 0.9734105  0.94922125 0.6803456\n",
      " 0.61773527 0.8484088  0.6370622  0.84792084 0.8808133  0.89809\n",
      " 0.83703315 0.94476485]\n",
      "The rewards are: [0.9747079  0.91831243 0.71168727 0.92701304 0.8449609  0.92465734\n",
      " 0.9071579  0.97040874 0.9587474  0.9446552  0.85615253 0.605401\n",
      " 0.87040335 0.84624666 0.9318607  0.9661868  0.8806797  0.91183555\n",
      " 0.9416166  0.8002517  0.942717   0.87618047 0.8419579  0.9014562\n",
      " 0.5621052  0.7409898  0.8541615  0.72734994 0.90519065 0.8703429\n",
      " 0.8564556  0.8652167 ]\n",
      "The rewards are: [0.96543115 0.70487523 0.7804783  0.95096385 0.94640326 0.76596\n",
      " 0.91031224 0.95533204 0.9641729  0.6002758  0.63069403 0.9369196\n",
      " 0.7842667  0.9868219  0.98139465 0.8367578  0.9639129  0.634241\n",
      " 0.900185   0.67796934 0.9414133  0.8215401  0.86412334 0.9716077\n",
      " 0.92998916 0.8522925  0.9790244  0.55897534 0.98028666 0.92653114\n",
      " 0.7575847  0.9387735 ]\n",
      "The rewards are: [0.71087253 0.9568911  0.8323436  0.80773884 0.8215783  0.9528239\n",
      " 0.5128915  0.7853241  0.97076553 0.9885251  0.9148644  0.9451587\n",
      " 0.86435336 0.5022566  0.9738671  0.77795553 0.8167173  0.93775535\n",
      " 0.5046731  0.86934686 0.92347676 0.996314   0.7632863  0.91679305\n",
      " 0.88275677 0.9792879  0.9001401  0.9382387  0.6777991  0.73351216\n",
      " 0.93086475 0.7665    ]\n",
      "The rewards are: [0.82542765 0.9428106  0.80626    0.8323807  0.953562   0.97450733\n",
      " 0.84871405 0.8520431  0.6332583  0.98560834 0.9186778  0.9769437\n",
      " 0.9582158  0.58368367 0.8489353  0.9317529  0.9687317  0.84359294\n",
      " 0.7522156  0.88586247 0.87209433 0.5732575  0.6793681  0.9423782\n",
      " 0.88494146 0.50502783 0.8804163  0.9259338  0.9082961  0.77402407\n",
      " 0.94797564 0.97860396]\n",
      "The rewards are: [0.849491   0.82604057 0.5654098  0.9503488  0.95654315 0.94017744\n",
      " 0.9415365  0.7271776  0.5977463  0.980718   0.52005684 0.6083753\n",
      " 0.93953854 0.87639797 0.71335673 0.94140756 0.667062   0.77601165\n",
      " 0.95752066 0.6451446  0.86032504 0.641655   0.9100087  0.711995\n",
      " 0.9835791  0.8628213  0.96807915 0.66634345 0.8719642  0.69268894\n",
      " 0.96649665 0.8142327 ]\n",
      "The rewards are: [0.95679957 0.9110872  0.8550781  0.9483841  0.9519897  0.9341971\n",
      " 0.8796069  0.87008125 0.83484006 0.9854128  0.91610074 0.94022757\n",
      " 0.83343714 0.8948739  0.9299342  0.8427538  0.9296321  0.9523569\n",
      " 0.91111386 0.8615921  0.8187984  0.71346843 0.6392846  0.9769131\n",
      " 0.9372756  0.8671552  0.9426914  0.71617424 0.86764187 0.85589117\n",
      " 0.748781   0.72529584]\n",
      "The rewards are: [0.9815818  0.87781596 0.97994953 0.9205938  0.9784541  0.9607094\n",
      " 0.893527   0.8463343  0.8968252  0.91340286 0.79323626 0.977202\n",
      " 0.5965671  0.9483789  0.8042877  0.947651   0.9660288  0.65179527\n",
      " 0.95393884 0.6783938  0.94136393 0.8813283  0.86668944 0.92552\n",
      " 0.57554233 0.9717339  0.8428736  0.75456053 0.9627089  0.8664139\n",
      " 0.9127047  0.84469026]\n",
      "The rewards are: [0.92125064 0.8245857  0.6524677  0.7324683  0.8295926  0.973592\n",
      " 0.63407356 0.72889733 0.5058829  0.7806735  0.86772776 0.9723219\n",
      " 0.9735667  0.87701905 0.9637423  0.9763242  0.92490345 0.9716187\n",
      " 0.57393724 0.5139396  0.90915215 0.7355848  0.793926   0.7817626\n",
      " 0.85777897 0.9855941  0.9787618  0.96020144 0.9738592  0.8680547\n",
      " 0.9498851  0.9115973 ]\n",
      "The rewards are: [0.9667017  0.88380855 0.9588258  0.98561156 0.9601767  0.7998691\n",
      " 0.92689437 0.9669513  0.8358328  0.98124415 0.956047   0.726473\n",
      " 0.6017325  0.9253133  0.9495685  0.69299394 0.9602958  0.52312094\n",
      " 0.8994561  0.86137766 0.9167973  0.84774905 0.89213616 0.9477204\n",
      " 0.97545797 0.58006394 0.790205   0.8179481  0.96983814 0.7498763\n",
      " 0.86299115 0.8870807 ]\n",
      "The rewards are: [0.68611866 0.9095955  0.86811453 0.68303925 0.9751151  0.8530551\n",
      " 0.9430581  0.60261065 0.91833717 0.60148937 0.78574866 0.95755875\n",
      " 0.65344775 0.6251447  0.98660487 0.72857887 0.65704817 0.687723\n",
      " 0.9350317  0.970079   0.87838185 0.7623852  0.9047729  0.7934221\n",
      " 0.90293777 0.7808377  0.9697939  0.7626874  0.8608607  0.9182377\n",
      " 0.6406158  0.67874   ]\n",
      "The rewards are: [0.97842515 0.6913823  0.6393491  0.6648817  0.69650495 0.9777995\n",
      " 0.98027706 0.72899336 0.89735335 0.90931547 0.97782785 0.9495165\n",
      " 0.9531362  0.75669396 0.899071   0.8816892  0.96660066 0.9632608\n",
      " 0.7078178  0.561761   0.95254105 0.97929126 0.5586564  0.9654772\n",
      " 0.723417   0.7804382  0.74923    0.97536397 0.9129814  0.9510256\n",
      " 0.73284703 0.7500737 ]\n",
      "The rewards are: [0.8877757  0.96986413 0.75301486 0.87034047 0.9903948  0.8357658\n",
      " 0.92699206 0.96543705 0.5305304  0.9749049  0.95070386 0.83282393\n",
      " 0.9570984  0.94881034 0.9471318  0.71588206 0.86274254 0.79052556\n",
      " 0.9398363  0.94201237 0.98339707 0.9011602  0.9856176  0.9810481\n",
      " 0.72160095 0.9496196  0.95280105 0.9027789  0.7438012  0.973476\n",
      " 0.9390313  0.79539156]\n",
      "The rewards are: [0.9789028  0.8922036  0.93256605 0.6698275  0.9444356  0.811016\n",
      " 0.748776   0.8740196  0.90338063 0.6623605  0.78826356 0.9345534\n",
      " 0.89661425 0.9780622  0.9854329  0.892746   0.7969494  0.75321984\n",
      " 0.94198316 0.85115045 0.74089295 0.9780254  0.90426797 0.78555787\n",
      " 0.8315118  0.8051223  0.95593536 0.91604763 0.9656142  0.7026718\n",
      " 0.9749585  0.9674974 ]\n",
      "The rewards are: [0.8925442  0.8895244  0.94244003 0.61016375 0.87854385 0.6893811\n",
      " 0.52099514 0.7544262  0.8476743  0.949187   0.977015   0.8783489\n",
      " 0.86330867 0.54243636 0.77975184 0.86377865 0.5775952  0.98562926\n",
      " 0.93459666 0.8533747  0.9922923  0.954385   0.9790467  0.83642673\n",
      " 0.8175546  0.98900956 0.88061416 0.5566184  0.9336681  0.9069385\n",
      " 0.8741365  0.8734545 ]\n",
      "The rewards are: [0.97753614 0.63574034 0.8118161  0.91336    0.69329965 0.9690411\n",
      " 0.9077848  0.7152907  0.7561418  0.92871    0.86064845 0.779534\n",
      " 0.68200326 0.8728146  0.8853342  0.97989494 0.6652888  0.98293084\n",
      " 0.5105983  0.5958315  0.98068374 0.934277   0.64630634 0.94858\n",
      " 0.95643944 0.68949634 0.92240363 0.92682695 0.5906132  0.9588206\n",
      " 0.9848298  0.97728956]\n",
      "The rewards are: [0.96283054 0.9286868  0.8945561  0.92155504 0.94001466 0.732128\n",
      " 0.68319744 0.8617444  0.79587924 0.8991766  0.8719073  0.95671844\n",
      " 0.85852814 0.81074566 0.9945504  0.9508764  0.8879508  0.94395757\n",
      " 0.94540876 0.8509721  0.8329519  0.96820205 0.9527413  0.9418859\n",
      " 0.94477636 0.96026355 0.66651285 0.82830995 0.8033872  0.97209835\n",
      " 0.8796404  0.6306773 ]\n",
      "The rewards are: [0.9778085  0.6881491  0.6583439  0.9689748  0.94658107 0.9465607\n",
      " 0.92372733 0.9885091  0.59901476 0.80081904 0.95304006 0.66820574\n",
      " 0.852648   0.9621665  0.5112958  0.5049518  0.9813183  0.88021386\n",
      " 0.93748707 0.5411112  0.8537224  0.892122   0.744841   0.73197013\n",
      " 0.92211586 0.9357709  0.86718893 0.87979496 0.8928552  0.72684556\n",
      " 0.57982445 0.92056406]\n",
      "The rewards are: [0.95643824 0.9720978  0.87870055 0.66500086 0.7414488  0.5598998\n",
      " 0.91934466 0.95707124 0.9413106  0.88668025 0.52275324 0.96486115\n",
      " 0.8520802  0.95548034 0.9219571  0.54169244 0.93855864 0.70796907\n",
      " 0.9757047  0.8029704  0.967626   0.8711225  0.990437   0.8243296\n",
      " 0.5663551  0.9745283  0.80924314 0.55639493 0.8447493  0.9788594\n",
      " 0.8312147  0.93593043]\n",
      "The rewards are: [0.7617142  0.9544316  0.8350666  0.9822097  0.9623528  0.6033623\n",
      " 0.9013596  0.5665373  0.93915695 0.8524734  0.83778733 0.5188543\n",
      " 0.96318895 0.88921726 0.6574881  0.98580766 0.9790133  0.8981457\n",
      " 0.90989304 0.68508285 0.86935204 0.96036094 0.9240052  0.9113512\n",
      " 0.9303724  0.9054601  0.9195327  0.8436009  0.94692874 0.95718753\n",
      " 0.93327636 0.7457894 ]\n",
      "The rewards are: [0.82447    0.95444167 0.82610047 0.6368729  0.9397592  0.94079965\n",
      " 0.6883458  0.7931554  0.82272834 0.79328394 0.53509766 0.939446\n",
      " 0.9335765  0.60915494 0.89204067 0.79695714 0.7661622  0.8100886\n",
      " 0.850478   0.93541646 0.5746084  0.941265   0.9382085  0.62176514\n",
      " 0.8989996  0.980456   0.85492283 0.9844875  0.7059086  0.78422487\n",
      " 0.94805384 0.9460932 ]\n",
      "The rewards are: [0.9807586  0.9427221  0.81683844 0.9277312  0.931984   0.64253736\n",
      " 0.56165195 0.93879867 0.9744769  0.68600154 0.9508723  0.5735485\n",
      " 0.94111806 0.83513695 0.9131353  0.9769587  0.9737023  0.80215085\n",
      " 0.7191513  0.82086384 0.86910063 0.96101946 0.8831367  0.63629115\n",
      " 0.9847696  0.6403498  0.9632363  0.80698234 0.70851046 0.83346874\n",
      " 0.9439542  0.60868937]\n",
      "The rewards are: [0.80271816 0.99137974 0.8616758  0.6717702  0.7937652  0.9822744\n",
      " 0.82667226 0.97213846 0.9945115  0.7503544  0.9800592  0.90931576\n",
      " 0.70308733 0.99576074 0.9204454  0.8670397  0.89777696 0.871649\n",
      " 0.9157139  0.82565415 0.722014   0.8359594  0.8678178  0.98563564\n",
      " 0.8580398  0.94837177 0.98432064 0.98585343 0.9293409  0.9919338\n",
      " 0.93066114 0.8840087 ]\n",
      "The rewards are: [0.68659955 0.67361605 0.87740827 0.9451109  0.8502391  0.7760752\n",
      " 0.87904394 0.97374356 0.66213125 0.9086522  0.90221596 0.97035134\n",
      " 0.92114156 0.8038025  0.73227036 0.95876104 0.86876893 0.93606204\n",
      " 0.9364487  0.82238996 0.9260895  0.8678813  0.9041242  0.7592381\n",
      " 0.95874494 0.9472794  0.9874598  0.9375954  0.9262891  0.9708529\n",
      " 0.96685725 0.96730465]\n",
      "The rewards are: [0.6139509  0.76239    0.795973   0.94863546 0.94396275 0.90136206\n",
      " 0.9678987  0.91793925 0.9736311  0.9527123  0.97605205 0.97110695\n",
      " 0.7483999  0.85273904 0.93349755 0.95410395 0.9274846  0.5853876\n",
      " 0.96790844 0.9736183  0.8801276  0.944759   0.83077806 0.8209626\n",
      " 0.96211827 0.9443723  0.952123   0.60590506 0.6421141  0.5345877\n",
      " 0.5493469  0.9393965 ]\n",
      "The rewards are: [0.8275528  0.9294277  0.6773471  0.98851484 0.9519991  0.7689036\n",
      " 0.5752139  0.9133798  0.8763361  0.9273781  0.5135291  0.950287\n",
      " 0.90847135 0.93742055 0.8169937  0.7559938  0.6540334  0.97913206\n",
      " 0.9139653  0.81280386 0.9196211  0.86796904 0.9675574  0.9469344\n",
      " 0.9152356  0.8444978  0.93935204 0.9558776  0.62569654 0.9503234\n",
      " 0.898743   0.9671492 ]\n",
      "The rewards are: [0.84266824 0.6696428  0.97958446 0.8722207  0.62974954 0.9602242\n",
      " 0.9756792  0.911121   0.87847894 0.52642137 0.8923659  0.8380614\n",
      " 0.9349124  0.6818985  0.77652043 0.9373633  0.9444463  0.86958635\n",
      " 0.9106155  0.82474226 0.9734817  0.9235339  0.95383793 0.598477\n",
      " 0.9576884  0.51536745 0.8316785  0.9295703  0.77295    0.9447129\n",
      " 0.9152773  0.9130782 ]\n",
      "The rewards are: [0.731698   0.8929596  0.54119647 0.57247365 0.9349011  0.97188324\n",
      " 0.6843337  0.75574046 0.531299   0.89123976 0.96679485 0.93941915\n",
      " 0.8182635  0.7251189  0.9556158  0.87366533 0.96881247 0.5886426\n",
      " 0.7345018  0.89318866 0.9638451  0.9425709  0.592654   0.7792651\n",
      " 0.733337   0.79236186 0.9857196  0.93835306 0.6492418  0.72898436\n",
      " 0.963836   0.9344331 ]\n",
      "The rewards are: [0.97073406 0.51436967 0.9393963  0.9608246  0.9562578  0.93705475\n",
      " 0.84937024 0.9250393  0.68025404 0.89788043 0.505978   0.9650393\n",
      " 0.9862525  0.6041408  0.8074716  0.98164237 0.7204701  0.72835594\n",
      " 0.9954556  0.95245594 0.865001   0.8066327  0.9396013  0.8046426\n",
      " 0.9266158  0.98639953 0.9540633  0.92177624 0.86171114 0.9239541\n",
      " 0.9055993  0.9687155 ]\n",
      "The rewards are: [0.90279764 0.94457597 0.9641868  0.67874795 0.97046095 0.9489178\n",
      " 0.88014424 0.9221109  0.6147566  0.94508207 0.9122575  0.9698561\n",
      " 0.87629926 0.56004155 0.9830495  0.9364813  0.9299738  0.9797791\n",
      " 0.9778     0.9392908  0.64642507 0.9305835  0.97878826 0.9664276\n",
      " 0.8794586  0.65901566 0.83715457 0.90364695 0.931483   0.9525327\n",
      " 0.9022925  0.9596203 ]\n",
      "The rewards are: [0.8760604  0.88714933 0.9055489  0.9392093  0.80905044 0.9836289\n",
      " 0.80084974 0.5220943  0.88061064 0.9418589  0.76005316 0.50115705\n",
      " 0.63668126 0.7134659  0.8914809  0.9846699  0.9536052  0.8787833\n",
      " 0.9867421  0.5674924  0.85156316 0.6754     0.68497384 0.96898144\n",
      " 0.97158694 0.8615019  0.8886655  0.72014976 0.9703377  0.84465414\n",
      " 0.9513311  0.9146437 ]\n",
      "The rewards are: [0.90104854 0.7393544  0.72660756 0.8264395  0.76263964 0.60928446\n",
      " 0.9630558  0.52336705 0.7556385  0.9593107  0.70669353 0.63924354\n",
      " 0.8892492  0.97104776 0.6675046  0.97085583 0.8467233  0.8540337\n",
      " 0.9230188  0.587141   0.9629458  0.99433124 0.6039074  0.9296713\n",
      " 0.9507581  0.92318773 0.9741407  0.96547323 0.7439467  0.7031005\n",
      " 0.980609   0.9606597 ]\n",
      "The rewards are: [0.8002663  0.9487973  0.94595563 0.96832496 0.9631296  0.96709734\n",
      " 0.80494314 0.93263006 0.94776195 0.97882676 0.630952   0.905265\n",
      " 0.96058124 0.8569927  0.9165254  0.76063913 0.9901086  0.9086566\n",
      " 0.9352128  0.7343168  0.96718216 0.941614   0.92937607 0.9367491\n",
      " 0.87964946 0.69251466 0.5448498  0.9670528  0.97477686 0.8331415\n",
      " 0.76756555 0.87689763]\n",
      "The rewards are: [0.81626815 0.9474351  0.9486466  0.82298183 0.7372313  0.9690251\n",
      " 0.8771371  0.9903944  0.6922776  0.9442628  0.5099553  0.5970847\n",
      " 0.7632409  0.76670784 0.9918622  0.9906104  0.69380945 0.9590287\n",
      " 0.918824   0.9860547  0.96408105 0.8161564  0.989061   0.7446899\n",
      " 0.96987724 0.9571882  0.96652335 0.98716563 0.6283408  0.95203114\n",
      " 0.9883946  0.90899307]\n",
      "The rewards are: [0.96397036 0.92668486 0.97875845 0.9265344  0.6373281  0.5571655\n",
      " 0.9279872  0.97764176 0.97801834 0.95445246 0.6354691  0.9898393\n",
      " 0.9661874  0.86579967 0.9730191  0.9815848  0.665669   0.8136256\n",
      " 0.79538226 0.80177665 0.6830106  0.955732   0.9805079  0.8749935\n",
      " 0.6652873  0.52127993 0.96428007 0.9833982  0.6732736  0.9692304\n",
      " 0.8385021  0.8868858 ]\n",
      "The rewards are: [0.973526   0.7968779  0.77362394 0.84729826 0.98508507 0.99637884\n",
      " 0.9752778  0.93422604 0.9569414  0.6715672  0.91895264 0.86619383\n",
      " 0.7778767  0.9427358  0.8950021  0.97471625 0.97477925 0.85222876\n",
      " 0.9524091  0.88830256 0.9608279  0.8886256  0.9217752  0.82318264\n",
      " 0.8433898  0.9785565  0.7921173  0.89702785 0.942811   0.98062426\n",
      " 0.91529816 0.95320994]\n",
      "The rewards are: [0.6175484  0.9589544  0.74400073 0.6356983  0.97259045 0.75041\n",
      " 0.9765171  0.9101239  0.96566206 0.9605883  0.80176914 0.94968677\n",
      " 0.86747634 0.8425844  0.97442394 0.96608424 0.5745142  0.7155431\n",
      " 0.9095791  0.9002452  0.8732296  0.8228417  0.61774063 0.7497995\n",
      " 0.73396313 0.7345473  0.7581522  0.70073366 0.9590291  0.9634871\n",
      " 0.9579973  0.9369568 ]\n",
      "The rewards are: [0.9720567  0.96044135 0.8806942  0.96298736 0.9319985  0.9534247\n",
      " 0.9464608  0.6338176  0.9915155  0.9204609  0.8589188  0.9266119\n",
      " 0.9818341  0.9524675  0.8403226  0.95243865 0.95459855 0.9797309\n",
      " 0.87213457 0.96950746 0.9505913  0.98599315 0.9569098  0.5190497\n",
      " 0.9850891  0.931517   0.8528011  0.9481602  0.7979103  0.78382146\n",
      " 0.90401626 0.97867763]\n",
      "The rewards are: [0.79468936 0.5389872  0.9116451  0.8852621  0.5006677  0.897816\n",
      " 0.87428415 0.9721333  0.95151484 0.8969352  0.9892799  0.9246537\n",
      " 0.95412683 0.9770619  0.90042454 0.9011525  0.5932364  0.8289737\n",
      " 0.8701832  0.9159826  0.98736274 0.789316   0.5206062  0.8666825\n",
      " 0.995854   0.7441966  0.7954837  0.96619654 0.9680054  0.54939497\n",
      " 0.9030696  0.9959073 ]\n",
      "The rewards are: [0.99717677 0.742423   0.90887064 0.97776115 0.6346955  0.9809044\n",
      " 0.85589445 0.9359248  0.91866654 0.9380267  0.9114684  0.91762996\n",
      " 0.85581326 0.91656387 0.8875859  0.7886145  0.8843816  0.92872643\n",
      " 0.888827   0.95707214 0.9427508  0.7148223  0.86455184 0.5290759\n",
      " 0.69351393 0.8626541  0.76580864 0.9929194  0.9702307  0.9802325\n",
      " 0.73973817 0.54743576]\n",
      "The rewards are: [0.9557634  0.9718274  0.6711852  0.8009259  0.9762206  0.8886167\n",
      " 0.7956466  0.9938367  0.9461776  0.8771267  0.9538792  0.8791623\n",
      " 0.91592306 0.99047196 0.72190773 0.9515131  0.6504494  0.6842651\n",
      " 0.80640274 0.89523923 0.8865175  0.98539937 0.8171022  0.7288322\n",
      " 0.581037   0.9823531  0.90422183 0.8716407  0.8480709  0.825178\n",
      " 0.9845078  0.9797753 ]\n",
      "The rewards are: [0.86907405 0.9692471  0.87925637 0.9890865  0.5872411  0.9783326\n",
      " 0.89760125 0.9951865  0.95873654 0.9436492  0.7667061  0.99690443\n",
      " 0.5280561  0.6293099  0.9873956  0.7423165  0.98315954 0.98606884\n",
      " 0.8485037  0.98974204 0.7748129  0.92908776 0.505572   0.98216677\n",
      " 0.9192848  0.87665945 0.9985526  0.82496154 0.9874765  0.82231724\n",
      " 0.58471674 0.92176276]\n",
      "The rewards are: [0.9625555  0.95667994 0.7738535  0.90631276 0.90055656 0.8958508\n",
      " 0.90394855 0.9085962  0.97448844 0.9728526  0.647483   0.98696727\n",
      " 0.9873104  0.844754   0.94042534 0.77786773 0.97564566 0.72700596\n",
      " 0.94402117 0.5081078  0.97763366 0.6861737  0.96778095 0.8898094\n",
      " 0.9786581  0.859653   0.78574246 0.620763   0.74242145 0.95387816\n",
      " 0.86454684 0.978277  ]\n",
      "The rewards are: [0.90771514 0.9511017  0.76245487 0.5699291  0.91844046 0.82787734\n",
      " 0.91399884 0.96674347 0.9897718  0.6404021  0.82400334 0.97111195\n",
      " 0.94556934 0.697374   0.8291913  0.8740367  0.97005355 0.87008536\n",
      " 0.9918242  0.9227387  0.7272079  0.6043467  0.60268956 0.93893474\n",
      " 0.7829119  0.79842764 0.9559746  0.7252181  0.96305645 0.73009604\n",
      " 0.8564031  0.53508425]\n",
      "The rewards are: [0.54049176 0.98214346 0.5739567  0.85602355 0.57673174 0.9655835\n",
      " 0.60332614 0.8715618  0.9682178  0.94849724 0.9628188  0.9043102\n",
      " 0.9124763  0.5151252  0.9127079  0.96333873 0.93389064 0.9567824\n",
      " 0.90898246 0.8165146  0.9879401  0.9504735  0.86615276 0.77231085\n",
      " 0.7696407  0.8770307  0.61258656 0.9089408  0.5887742  0.98156977\n",
      " 0.8861167  0.7257312 ]\n",
      "The rewards are: [0.7687246  0.9964406  0.9036617  0.8424082  0.93957853 0.9824583\n",
      " 0.8504441  0.93761176 0.9031547  0.72739166 0.9252113  0.96886843\n",
      " 0.9666868  0.77396095 0.99714535 0.6330719  0.9330265  0.75036097\n",
      " 0.96197593 0.81236225 0.68776274 0.8143103  0.5478954  0.9423222\n",
      " 0.98333436 0.84991175 0.63128275 0.93603164 0.7543392  0.9248148\n",
      " 0.6047939  0.9746047 ]\n",
      "The rewards are: [0.9648376  0.8499161  0.8311772  0.9566265  0.960367   0.9729978\n",
      " 0.9612411  0.9922501  0.93502474 0.7544249  0.91251045 0.96904737\n",
      " 0.86851925 0.9758839  0.89649385 0.5232699  0.9473529  0.99213094\n",
      " 0.93623245 0.8322757  0.82087934 0.6456962  0.93910646 0.98289454\n",
      " 0.88155353 0.990387   0.9490909  0.7510027  0.89427936 0.93451965\n",
      " 0.9834678  0.9488147 ]\n",
      "The rewards are: [0.95224166 0.9647091  0.83350444 0.9202469  0.9668874  0.8775705\n",
      " 0.52071637 0.712858   0.8324573  0.89690644 0.83707917 0.9274502\n",
      " 0.9387935  0.9611841  0.98397785 0.948426   0.54131573 0.89402145\n",
      " 0.97994643 0.86004305 0.8923038  0.53346604 0.865511   0.9229486\n",
      " 0.8457818  0.95954925 0.75984377 0.9549711  0.8088076  0.7842213\n",
      " 0.9500901  0.6866761 ]\n",
      "The rewards are: [0.9050059  0.82154644 0.6598619  0.59117246 0.9573626  0.9614353\n",
      " 0.95727843 0.78334004 0.9137651  0.51305544 0.76500493 0.59903026\n",
      " 0.96131516 0.98262227 0.98077446 0.9526953  0.94432056 0.95836073\n",
      " 0.991774   0.7671975  0.83936876 0.98229766 0.959579   0.95376277\n",
      " 0.8051753  0.897113   0.60514516 0.97880757 0.96821755 0.95215213\n",
      " 0.9715488  0.68817455]\n",
      "The rewards are: [0.8961167  0.9662417  0.84842134 0.9758976  0.9253666  0.91304696\n",
      " 0.991097   0.99229795 0.6483822  0.6895021  0.888304   0.9879946\n",
      " 0.7125999  0.9005671  0.8885657  0.95431066 0.96080977 0.885554\n",
      " 0.73982996 0.9640767  0.6069344  0.85912913 0.5355299  0.70004934\n",
      " 0.9880513  0.9852136  0.9692068  0.9282749  0.9691832  0.7684468\n",
      " 0.5234647  0.7578068 ]\n",
      "The rewards are: [0.5339514  0.8938311  0.56383365 0.8620623  0.64470696 0.9364723\n",
      " 0.95320326 0.62872493 0.66071695 0.7218029  0.76470184 0.9453329\n",
      " 0.80582803 0.96709085 0.98507303 0.9388231  0.96720725 0.9515809\n",
      " 0.8641576  0.85562164 0.96538967 0.60261196 0.59379554 0.537244\n",
      " 0.5393455  0.98923993 0.95338243 0.9903081  0.6854429  0.6709236\n",
      " 0.7853518  0.977541  ]\n",
      "The rewards are: [0.9292117  0.8427575  0.9898233  0.9198622  0.92928743 0.51121944\n",
      " 0.6211409  0.8941222  0.8884103  0.8881043  0.9487489  0.82801306\n",
      " 0.7852688  0.86337185 0.6833975  0.7947455  0.9885125  0.817786\n",
      " 0.9784638  0.98711395 0.89062625 0.87683403 0.9452647  0.81088245\n",
      " 0.60711527 0.9507404  0.9813079  0.94247615 0.96404904 0.94683206\n",
      " 0.56211126 0.983643  ]\n",
      "The rewards are: [0.74690753 0.9203492  0.80299795 0.6263818  0.9875378  0.6323209\n",
      " 0.97247833 0.91224754 0.7065007  0.97297883 0.800144   0.70462435\n",
      " 0.93449545 0.5606324  0.9523635  0.77884066 0.97708863 0.7449091\n",
      " 0.95585793 0.71626246 0.97938156 0.92545027 0.92503726 0.983039\n",
      " 0.96035194 0.99533033 0.88765144 0.9652277  0.9796978  0.7777907\n",
      " 0.73627174 0.85826445]\n",
      "The rewards are: [0.9914528  0.89341855 0.92331654 0.826805   0.84967214 0.7209746\n",
      " 0.687251   0.9712521  0.71696293 0.8643895  0.9328964  0.9904722\n",
      " 0.90127754 0.960222   0.9688502  0.97959316 0.7466053  0.7680158\n",
      " 0.95320076 0.98386097 0.8708662  0.9732998  0.9813265  0.64563584\n",
      " 0.9128273  0.96791613 0.89569515 0.9966568  0.83753073 0.8364138\n",
      " 0.79484934 0.96251976]\n",
      "The rewards are: [0.9539092  0.87270254 0.9562176  0.65883505 0.9296072  0.5719719\n",
      " 0.86342657 0.9293915  0.90499395 0.9481832  0.9298774  0.7978236\n",
      " 0.9719224  0.9595195  0.956138   0.99175304 0.98072535 0.95223236\n",
      " 0.82992494 0.92553145 0.87913215 0.6399877  0.9679887  0.60199755\n",
      " 0.5408984  0.9001428  0.512632   0.7348428  0.8943709  0.6248963\n",
      " 0.8703712  0.88695383]\n",
      "The rewards are: [0.949986   0.9528089  0.6568979  0.98604715 0.8100951  0.90667063\n",
      " 0.803424   0.92895204 0.93627936 0.806589   0.7864503  0.9846917\n",
      " 0.9606678  0.5149161  0.66404927 0.6375852  0.97790945 0.5854687\n",
      " 0.95824957 0.71637344 0.88826746 0.977486   0.9874055  0.5817422\n",
      " 0.88745874 0.99092054 0.9650743  0.882205   0.5164898  0.973304\n",
      " 0.94212526 0.9800632 ]\n",
      "The rewards are: [0.990754   0.8902372  0.91113544 0.64214575 0.7605182  0.9892319\n",
      " 0.9954181  0.78187186 0.9511927  0.5747008  0.94025224 0.98609227\n",
      " 0.6973722  0.964057   0.6281579  0.96250474 0.9754515  0.87659013\n",
      " 0.83443385 0.97060275 0.91487694 0.9732491  0.63855165 0.7458679\n",
      " 0.55327827 0.87847567 0.97861415 0.94957626 0.9830677  0.86462843\n",
      " 0.92890215 0.63517207]\n",
      "The rewards are: [0.9190049  0.99332494 0.9673505  0.6386128  0.9777843  0.8920442\n",
      " 0.9936546  0.649616   0.9683741  0.7080636  0.94018966 0.6675474\n",
      " 0.7767556  0.8796325  0.53158337 0.98502153 0.9835118  0.5133034\n",
      " 0.7027038  0.8960369  0.6985777  0.9355879  0.9670643  0.9590557\n",
      " 0.9484822  0.9811602  0.63332635 0.9606084  0.6763321  0.9372565\n",
      " 0.7756664  0.94127077]\n",
      "The rewards are: [0.80483055 0.98596406 0.9227515  0.98752034 0.5264379  0.89747286\n",
      " 0.9741434  0.544467   0.82688755 0.8459142  0.96488965 0.67731595\n",
      " 0.94701266 0.97907275 0.9311448  0.884056   0.9593594  0.93056726\n",
      " 0.6160479  0.96871847 0.70731086 0.97598195 0.9029999  0.9524716\n",
      " 0.95435774 0.5942944  0.6868585  0.95333    0.8444806  0.8995265\n",
      " 0.9920419  0.9647829 ]\n",
      "The rewards are: [0.97162163 0.97197986 0.6618317  0.9612366  0.97902966 0.89518076\n",
      " 0.98423105 0.8944757  0.76954395 0.85677415 0.98417073 0.909082\n",
      " 0.9640723  0.9711058  0.6016533  0.9963899  0.7926416  0.8325142\n",
      " 0.968076   0.96511567 0.94919634 0.78479445 0.9849177  0.98188776\n",
      " 0.96100867 0.9196783  0.92874175 0.859379   0.5228731  0.9949909\n",
      " 0.8730903  0.9721543 ]\n",
      "The rewards are: [0.81355035 0.9388107  0.97815806 0.9126167  0.95895267 0.9692788\n",
      " 0.9806433  0.6436573  0.931111   0.53924644 0.88147295 0.85289234\n",
      " 0.963016   0.9109612  0.8374716  0.9469869  0.81879133 0.81958306\n",
      " 0.913275   0.54143846 0.69369304 0.94020325 0.9871617  0.8218922\n",
      " 0.8899718  0.9602909  0.9739146  0.8762654  0.97537136 0.61211985\n",
      " 0.9536547  0.94520986]\n",
      "The rewards are: [0.5793929  0.5247036  0.9737008  0.5481658  0.9400903  0.96319073\n",
      " 0.9482112  0.8966659  0.8084687  0.61128926 0.9885467  0.96041244\n",
      " 0.96142244 0.5796517  0.6336324  0.9704137  0.6503285  0.57836944\n",
      " 0.9723007  0.99331504 0.7154276  0.8056156  0.9096381  0.51480156\n",
      " 0.703598   0.97064453 0.8648601  0.90693116 0.9707063  0.5318014\n",
      " 0.5910739  0.5739403 ]\n",
      "The rewards are: [0.9923815  0.9931149  0.894327   0.94677293 0.96587855 0.52963865\n",
      " 0.93537575 0.9631578  0.50027204 0.9895957  0.7072937  0.7230413\n",
      " 0.98540086 0.8009686  0.9646123  0.95020056 0.56013304 0.5336681\n",
      " 0.97340405 0.9777405  0.82467484 0.7767276  0.9845841  0.98174554\n",
      " 0.8696479  0.71357256 0.67130655 0.9795864  0.8885395  0.54756653\n",
      " 0.83723086 0.79262453]\n",
      "The rewards are: [0.96934277 0.9751371  0.9668437  0.59826267 0.9749017  0.964799\n",
      " 0.98799545 0.94002485 0.84553987 0.92278    0.8559823  0.6148158\n",
      " 0.5263015  0.8632853  0.96053547 0.9877055  0.979957   0.9494403\n",
      " 0.9556993  0.9179891  0.92406005 0.6199273  0.94146484 0.9509121\n",
      " 0.7856278  0.99663866 0.57401395 0.9242659  0.95539063 0.9279274\n",
      " 0.9056356  0.8469338 ]\n",
      "The rewards are: [0.9901702  0.9497314  0.7375106  0.72253656 0.97926074 0.8839049\n",
      " 0.6368306  0.9281151  0.9316271  0.96171135 0.9785769  0.984899\n",
      " 0.79742014 0.99549955 0.6658014  0.93437296 0.8477963  0.9914881\n",
      " 0.9666825  0.97545075 0.9139126  0.6893896  0.95881563 0.9719468\n",
      " 0.98776287 0.97488993 0.9415474  0.8770596  0.9437527  0.5092162\n",
      " 0.5698248  0.5121339 ]\n",
      "The rewards are: [0.9813302  0.644069   0.72241324 0.9023783  0.9876581  0.92639554\n",
      " 0.6739465  0.9904901  0.5453809  0.867258   0.8881848  0.8867559\n",
      " 0.9837467  0.94382405 0.87685806 0.6514632  0.72270685 0.9627206\n",
      " 0.9750524  0.8672537  0.7805942  0.9618707  0.99305665 0.90503585\n",
      " 0.9714589  0.886436   0.75527453 0.8694361  0.92793095 0.91305304\n",
      " 0.97654    0.98802465]\n",
      "The rewards are: [0.9223374  0.534707   0.7332328  0.922994   0.66530466 0.8920551\n",
      " 0.9691938  0.9755332  0.592399   0.5076449  0.87699217 0.9121661\n",
      " 0.6231536  0.75213623 0.9625054  0.98330194 0.9549699  0.8994208\n",
      " 0.96933794 0.9716779  0.9833145  0.92897326 0.94497126 0.9839189\n",
      " 0.78408474 0.94741064 0.9284196  0.8698688  0.9344551  0.89919555\n",
      " 0.9406332  0.7963948 ]\n",
      "The rewards are: [0.9842982  0.97634184 0.990507   0.8544727  0.53508276 0.97323143\n",
      " 0.51335645 0.5833275  0.6916484  0.7662169  0.9272179  0.9583343\n",
      " 0.988451   0.9320353  0.6389252  0.98793787 0.9813705  0.9335488\n",
      " 0.5052221  0.96216756 0.9660801  0.515293   0.8494404  0.992413\n",
      " 0.97757494 0.92833894 0.9118415  0.8731688  0.9966474  0.69135165\n",
      " 0.9858644  0.8897308 ]\n",
      "The rewards are: [0.8473418  0.93233246 0.64774126 0.96159494 0.88346183 0.9825928\n",
      " 0.8131528  0.94051725 0.91450447 0.9629924  0.6369372  0.97700274\n",
      " 0.9645769  0.97486067 0.9876128  0.9151889  0.99327713 0.90451765\n",
      " 0.6097418  0.81680965 0.9920872  0.9221449  0.7092351  0.9742623\n",
      " 0.8359664  0.93205565 0.95637816 0.52309763 0.97242314 0.8269403\n",
      " 0.95641613 0.9145683 ]\n",
      "The rewards are: [0.9581361  0.9534128  0.8309426  0.81010497 0.95278925 0.733878\n",
      " 0.62953275 0.9214147  0.83279574 0.904702   0.9603217  0.833122\n",
      " 0.8325427  0.9924212  0.9428059  0.9942906  0.92754036 0.829386\n",
      " 0.64261127 0.8462658  0.7362706  0.9794438  0.9773372  0.8827406\n",
      " 0.9442912  0.86796045 0.912581   0.8901739  0.97273624 0.98643434\n",
      " 0.98942685 0.95365536]\n",
      "The rewards are: [0.9547492  0.5266719  0.9562056  0.9725175  0.97442734 0.9859725\n",
      " 0.8284451  0.9742916  0.9766049  0.90185803 0.96822095 0.9785669\n",
      " 0.8016869  0.9419798  0.9856206  0.7485292  0.6721371  0.8991067\n",
      " 0.9674713  0.97252333 0.7816916  0.8411436  0.9417296  0.56834227\n",
      " 0.9573414  0.82284504 0.7169936  0.55035853 0.7864079  0.82484406\n",
      " 0.8880042  0.64354193]\n",
      "The rewards are: [0.6211999  0.9854596  0.94196427 0.5960294  0.86716205 0.9785575\n",
      " 0.83462906 0.9307256  0.97856253 0.5134583  0.9370499  0.9782954\n",
      " 0.8499684  0.8150796  0.8813622  0.99091244 0.9477295  0.95136774\n",
      " 0.8685234  0.60362697 0.9093643  0.9952136  0.95549935 0.9747137\n",
      " 0.60415596 0.9842085  0.9210267  0.98542064 0.811747   0.8020063\n",
      " 0.5798282  0.9357437 ]\n",
      "The rewards are: [0.6868512  0.7522447  0.9746981  0.95848423 0.9820354  0.9177841\n",
      " 0.96442884 0.9721244  0.94941634 0.90333116 0.9571668  0.8523243\n",
      " 0.9799136  0.9768585  0.6651249  0.9539396  0.8709737  0.9883995\n",
      " 0.7282486  0.9757017  0.9582633  0.72218335 0.9971123  0.8917833\n",
      " 0.88183933 0.73102427 0.6996737  0.9097173  0.9584111  0.8950776\n",
      " 0.95617616 0.9155724 ]\n",
      "The rewards are: [0.9432171  0.99300003 0.9813225  0.9847889  0.6053044  0.9461178\n",
      " 0.8957793  0.85174143 0.7157689  0.7238881  0.96385217 0.9595496\n",
      " 0.9045009  0.88191813 0.9688843  0.8773221  0.9489862  0.8967072\n",
      " 0.98676866 0.86491835 0.9557917  0.9158053  0.94620556 0.98368996\n",
      " 0.9248673  0.9905573  0.95652515 0.98988616 0.98493713 0.74732924\n",
      " 0.9573982  0.9637338 ]\n",
      "The rewards are: [0.9570383  0.97708845 0.9848224  0.9749672  0.98242366 0.8488798\n",
      " 0.9852926  0.88917184 0.99829024 0.96426237 0.9218423  0.6050716\n",
      " 0.5914763  0.8318512  0.5135757  0.9453329  0.98274577 0.95390934\n",
      " 0.9732377  0.98093283 0.79037565 0.59767866 0.5987824  0.752449\n",
      " 0.90020114 0.8469218  0.8295053  0.98597646 0.9630004  0.7900643\n",
      " 0.55584633 0.8933515 ]\n",
      "The rewards are: [0.7951578  0.9846593  0.9640169  0.9428719  0.97802025 0.5600181\n",
      " 0.9664106  0.91466606 0.9125793  0.78847116 0.8802585  0.9660999\n",
      " 0.9944936  0.97285277 0.9913954  0.85799134 0.93896496 0.90574664\n",
      " 0.99410737 0.64809453 0.9856523  0.9801768  0.5984199  0.9896701\n",
      " 0.98702955 0.61414015 0.8319901  0.8421816  0.96096087 0.9913394\n",
      " 0.9803218  0.916483  ]\n",
      "The rewards are: [0.9294465  0.82613266 0.9328203  0.7586559  0.96390426 0.9725229\n",
      " 0.8737136  0.9890097  0.8876782  0.8444036  0.99008405 0.64814043\n",
      " 0.7376141  0.77747667 0.94967204 0.943218   0.9929529  0.98194593\n",
      " 0.9896959  0.8137157  0.9785776  0.52736455 0.8257305  0.9399782\n",
      " 0.89335567 0.95070946 0.9468267  0.95577013 0.9875238  0.8683606\n",
      " 0.8208693  0.94851017]\n",
      "The rewards are: [0.7627648  0.7195708  0.9597371  0.9573357  0.9577627  0.8109068\n",
      " 0.99423414 0.533988   0.97070056 0.9476202  0.96674556 0.9082528\n",
      " 0.91934234 0.9913556  0.94559026 0.9669585  0.82938653 0.99188095\n",
      " 0.99359024 0.8270365  0.58196235 0.6165077  0.9680063  0.9938653\n",
      " 0.87887406 0.9710146  0.92534727 0.96579474 0.92782265 0.98250717\n",
      " 0.737737   0.89419806]\n",
      "The rewards are: [0.85071266 0.62302905 0.96358657 0.97450846 0.98178273 0.51685643\n",
      " 0.5415036  0.936338   0.9521508  0.9503651  0.9678382  0.97664464\n",
      " 0.9266912  0.9695691  0.9916359  0.7493084  0.9710381  0.8431935\n",
      " 0.9754843  0.98283845 0.53414613 0.8087988  0.86064845 0.6121902\n",
      " 0.8102397  0.9027931  0.994645   0.9928141  0.87524116 0.99402076\n",
      " 0.95165724 0.9767556 ]\n",
      "The rewards are: [0.7884206  0.79213244 0.8751308  0.6636814  0.87469786 0.91291136\n",
      " 0.5325289  0.9938251  0.99099004 0.97445244 0.9628505  0.96475464\n",
      " 0.5993352  0.93459636 0.94048023 0.6934033  0.9844379  0.91273177\n",
      " 0.990131   0.8854271  0.975361   0.9296449  0.6367892  0.915726\n",
      " 0.8996007  0.6751748  0.9600944  0.93743354 0.9122826  0.98078394\n",
      " 0.78446114 0.8883828 ]\n",
      "The rewards are: [0.9707071  0.51110554 0.88467914 0.94612426 0.7889137  0.96138376\n",
      " 0.9297515  0.94642067 0.7026494  0.99209845 0.98366493 0.5779864\n",
      " 0.9480155  0.99151295 0.9983199  0.99619436 0.72167504 0.77069044\n",
      " 0.95761526 0.9783594  0.5302976  0.66030985 0.5911506  0.97325706\n",
      " 0.6875767  0.795048   0.87569726 0.97234094 0.7756972  0.9887744\n",
      " 0.9181857  0.97943866]\n",
      "The rewards are: [0.98871183 0.94638115 0.9773028  0.9090717  0.97686917 0.97450304\n",
      " 0.996872   0.81228256 0.9064155  0.9600544  0.9439717  0.95378685\n",
      " 0.6336895  0.9045748  0.967934   0.9382889  0.7565585  0.95319694\n",
      " 0.97440684 0.77322555 0.5708349  0.9246543  0.7209274  0.9911622\n",
      " 0.8397495  0.94966465 0.5570777  0.9669357  0.9894476  0.9743697\n",
      " 0.9155924  0.95619184]\n",
      "The rewards are: [0.9574797  0.9470149  0.8103073  0.72159195 0.99324846 0.65928096\n",
      " 0.8042521  0.6375411  0.8738458  0.995481   0.660993   0.51234764\n",
      " 0.983133   0.7773395  0.9552613  0.68947583 0.95507187 0.9871088\n",
      " 0.9957004  0.58524495 0.99426585 0.9894497  0.92580163 0.87065333\n",
      " 0.9351132  0.8252516  0.945892   0.82377875 0.9759982  0.9622611\n",
      " 0.91367626 0.9569982 ]\n",
      "The rewards are: [0.8167178  0.9364423  0.87600684 0.94076735 0.9983382  0.86962223\n",
      " 0.95821065 0.86834073 0.92585474 0.94248855 0.9725965  0.9610682\n",
      " 0.7940075  0.9654862  0.99630713 0.85408556 0.50712794 0.95726305\n",
      " 0.75907224 0.98864657 0.9881605  0.98196936 0.91281307 0.8298982\n",
      " 0.9238707  0.6010093  0.9747217  0.7673103  0.59374166 0.9545003\n",
      " 0.64786685 0.78001475]\n",
      "The rewards are: [0.94749564 0.75827855 0.9693838  0.7085099  0.97502553 0.98562557\n",
      " 0.65225565 0.8825536  0.7349694  0.68445694 0.7921993  0.93074375\n",
      " 0.9940348  0.9975744  0.9238117  0.9774225  0.5269986  0.5221212\n",
      " 0.98220736 0.9915141  0.97919536 0.6013763  0.649625   0.9925687\n",
      " 0.7824964  0.87472534 0.8951819  0.9229857  0.807039   0.94622594\n",
      " 0.9395465  0.8938258 ]\n",
      "The rewards are: [0.73767346 0.78253525 0.98560786 0.9699101  0.67540896 0.86252576\n",
      " 0.78369653 0.9196447  0.98250556 0.9560287  0.8256569  0.7762755\n",
      " 0.9468465  0.93673414 0.9296911  0.8907868  0.89490926 0.9758411\n",
      " 0.7512084  0.9636797  0.93492967 0.98697996 0.55223894 0.9723912\n",
      " 0.9485736  0.87187016 0.6777849  0.7449704  0.5381306  0.7648944\n",
      " 0.99280643 0.9545905 ]\n",
      "The rewards are: [0.9702452  0.9767596  0.99229676 0.8506126  0.5475794  0.97164303\n",
      " 0.61719006 0.96901065 0.9565424  0.9702056  0.8115093  0.72230977\n",
      " 0.9642944  0.781992   0.9830747  0.8642479  0.9631883  0.8352225\n",
      " 0.975801   0.9413296  0.91235393 0.9836717  0.6456285  0.9921578\n",
      " 0.9924784  0.991478   0.8128961  0.9823751  0.9080998  0.8196508\n",
      " 0.97271913 0.97302985]\n",
      "The rewards are: [0.9434466  0.9709344  0.9719213  0.83525354 0.8112713  0.7775986\n",
      " 0.97696316 0.99846786 0.97850287 0.65035015 0.7013185  0.76339215\n",
      " 0.8992514  0.9784758  0.99346715 0.99470997 0.87551624 0.8597418\n",
      " 0.9375418  0.9716817  0.8859399  0.8860072  0.9086532  0.98708564\n",
      " 0.99654347 0.9710551  0.9566002  0.6794347  0.97424614 0.9747423\n",
      " 0.9866257  0.94954187]\n",
      "The rewards are: [0.8873688  0.96608824 0.9607817  0.8221045  0.8369913  0.68679446\n",
      " 0.9880327  0.95846146 0.9720104  0.7478973  0.9868346  0.7809424\n",
      " 0.8635032  0.98771274 0.9797814  0.9903714  0.8062447  0.9873885\n",
      " 0.88857156 0.76001704 0.98838615 0.98578227 0.5817663  0.9845917\n",
      " 0.9577572  0.95420325 0.9678987  0.71265286 0.9578569  0.8070894\n",
      " 0.63643396 0.9614315 ]\n",
      "The rewards are: [0.99781704 0.85549843 0.9461359  0.7383072  0.950888   0.6479292\n",
      " 0.8347706  0.9691458  0.5879024  0.9914302  0.8965458  0.7157979\n",
      " 0.95398307 0.9768553  0.9006968  0.99134934 0.9619767  0.9125202\n",
      " 0.97281826 0.91924936 0.7525817  0.9059964  0.73218393 0.94740266\n",
      " 0.87556344 0.7686365  0.97914207 0.56074107 0.9439011  0.57661295\n",
      " 0.7786524  0.6850224 ]\n",
      "The rewards are: [0.9142299  0.96965235 0.7918939  0.96353376 0.9874466  0.9376997\n",
      " 0.89089984 0.97551167 0.8872366  0.97010493 0.92895126 0.9289527\n",
      " 0.9861742  0.9561418  0.734858   0.9962942  0.6983149  0.9389973\n",
      " 0.7240307  0.6222803  0.98887306 0.97566706 0.935792   0.89499295\n",
      " 0.9819302  0.9524331  0.5685543  0.99166954 0.92918247 0.97335637\n",
      " 0.6858451  0.8208146 ]\n",
      "The rewards are: [0.6041546  0.98479766 0.6584301  0.98540133 0.99243486 0.8060716\n",
      " 0.9882969  0.9560355  0.940425   0.89545375 0.9025293  0.96696603\n",
      " 0.97943854 0.9787594  0.7486879  0.9810006  0.93100226 0.7747243\n",
      " 0.9482745  0.8234179  0.9871371  0.53332794 0.8756034  0.9694595\n",
      " 0.9570484  0.97107947 0.96087885 0.9953258  0.6104687  0.90920097\n",
      " 0.99073833 0.9664395 ]\n",
      "The rewards are: [0.6507655  0.8320093  0.9448299  0.9815424  0.93622535 0.9188246\n",
      " 0.8303501  0.8336082  0.9819219  0.98413104 0.940803   0.93938863\n",
      " 0.5402512  0.6760189  0.9740612  0.98976934 0.684076   0.9889206\n",
      " 0.80825317 0.98709714 0.99035126 0.99146515 0.63245565 0.9850368\n",
      " 0.97949284 0.8211171  0.96102625 0.9854005  0.98850495 0.98436916\n",
      " 0.90510935 0.997797  ]\n",
      "The rewards are: [0.9847046  0.9814688  0.9640684  0.8264193  0.933732   0.9716106\n",
      " 0.9718179  0.9901731  0.9784816  0.5739429  0.88712895 0.96072555\n",
      " 0.98998487 0.9887637  0.8634236  0.9306025  0.88531953 0.9830997\n",
      " 0.7734058  0.81402314 0.92481697 0.9278393  0.95473826 0.9628504\n",
      " 0.8072236  0.9615763  0.9177668  0.8100068  0.9864769  0.97981775\n",
      " 0.9699459  0.66967845]\n",
      "The rewards are: [0.9952625  0.949886   0.8803379  0.84951746 0.81631595 0.9726723\n",
      " 0.90861243 0.87427294 0.98612    0.64782107 0.93878824 0.7510604\n",
      " 0.90990746 0.94369197 0.96025205 0.92749214 0.9910846  0.9703166\n",
      " 0.9299851  0.8993005  0.9889237  0.5340503  0.95063955 0.9553244\n",
      " 0.9906323  0.910352   0.9912736  0.95785797 0.651017   0.9803656\n",
      " 0.8013115  0.9954922 ]\n",
      "The rewards are: [0.9284868  0.87207365 0.9956418  0.71465296 0.96316296 0.9867178\n",
      " 0.9860534  0.7026674  0.86975735 0.75352585 0.6396153  0.99560106\n",
      " 0.9943593  0.9496683  0.9367596  0.94422954 0.6652451  0.9866463\n",
      " 0.9933401  0.9971328  0.9976453  0.9087651  0.98131806 0.98680824\n",
      " 0.98484904 0.9808367  0.9573095  0.9848465  0.9909984  0.9512381\n",
      " 0.9887183  0.98324215]\n",
      "The rewards are: [0.9905749  0.8791301  0.91667366 0.8771132  0.95363975 0.9788072\n",
      " 0.9415889  0.9748811  0.7618524  0.7615536  0.84222835 0.9427064\n",
      " 0.88992363 0.8841822  0.8398695  0.9242714  0.9181561  0.9852743\n",
      " 0.5496634  0.99654007 0.97535294 0.88105357 0.97881955 0.79606664\n",
      " 0.95262086 0.90409076 0.9563306  0.7022754  0.8770324  0.9973041\n",
      " 0.98049164 0.8099228 ]\n",
      "The rewards are: [0.8860466  0.9633364  0.90606207 0.865257   0.9729762  0.89355075\n",
      " 0.96443105 0.989814   0.99643743 0.90354943 0.9884072  0.93011206\n",
      " 0.98713744 0.97984916 0.995814   0.97337556 0.82291985 0.61997694\n",
      " 0.634175   0.89934945 0.99186057 0.99361575 0.9823299  0.99513537\n",
      " 0.9197271  0.86118335 0.9853306  0.9437928  0.8143698  0.88706046\n",
      " 0.99363154 0.9841554 ]\n",
      "The rewards are: [0.68216074 0.985827   0.96558464 0.979043   0.9847423  0.75254035\n",
      " 0.8857641  0.99520785 0.99179184 0.63186073 0.96468705 0.8881916\n",
      " 0.9899464  0.8690382  0.9786441  0.9701007  0.87813395 0.95165235\n",
      " 0.98926115 0.90374565 0.97838485 0.70066565 0.9821035  0.9792747\n",
      " 0.5271307  0.8776413  0.90862197 0.9200323  0.86904365 0.9256345\n",
      " 0.9457125  0.842691  ]\n",
      "The rewards are: [0.967202   0.99055487 0.70775855 0.97889805 0.97909683 0.99347925\n",
      " 0.85214686 0.9887792  0.9929234  0.7367788  0.9902582  0.90966225\n",
      " 0.86533344 0.60266536 0.9918888  0.98848253 0.9917197  0.9940553\n",
      " 0.7017839  0.9863186  0.93700266 0.97097003 0.67589885 0.98509336\n",
      " 0.54279095 0.98342496 0.88278025 0.7653669  0.7402014  0.9493917\n",
      " 0.9272385  0.7863508 ]\n",
      "The rewards are: [0.92426205 0.98994267 0.6716728  0.9793762  0.91967285 0.9669757\n",
      " 0.99296147 0.97816247 0.9193683  0.9945775  0.989661   0.9899871\n",
      " 0.9953988  0.8203564  0.746268   0.53036326 0.9905551  0.9915903\n",
      " 0.9914124  0.9930865  0.765373   0.6745928  0.52556705 0.97538245\n",
      " 0.90652657 0.79814094 0.9748556  0.85035366 0.95437217 0.9901966\n",
      " 0.63496375 0.8247993 ]\n",
      "The rewards are: [0.97672105 0.92918706 0.79622805 0.96984845 0.9301385  0.9912431\n",
      " 0.9620569  0.9623984  0.9818756  0.9770009  0.7771442  0.98378223\n",
      " 0.96496814 0.9685361  0.9263086  0.6745521  0.8592269  0.66297776\n",
      " 0.5851333  0.9743707  0.6362602  0.9823397  0.9749203  0.87257653\n",
      " 0.96805054 0.97763664 0.8710377  0.7894937  0.9915469  0.9175338\n",
      " 0.9057744  0.6500483 ]\n",
      "The rewards are: [0.96554106 0.9758715  0.50019425 0.9764746  0.96730965 0.9626608\n",
      " 0.9953768  0.98169464 0.94381183 0.97565585 0.9109444  0.9303014\n",
      " 0.80720544 0.8015824  0.8050367  0.6105737  0.9009752  0.91942936\n",
      " 0.9000346  0.8136668  0.8264831  0.88020474 0.89123845 0.9854106\n",
      " 0.95406044 0.99519676 0.8670263  0.9858555  0.95082164 0.9551931\n",
      " 0.5043209  0.8568665 ]\n",
      "The rewards are: [0.9820863  0.9848354  0.6301525  0.97358227 0.6469982  0.9805878\n",
      " 0.8085486  0.5231297  0.98624563 0.9745481  0.9642436  0.7835494\n",
      " 0.9947744  0.9776618  0.7137718  0.6395384  0.95120215 0.8582854\n",
      " 0.9864391  0.9670805  0.8877415  0.9556009  0.96353954 0.8166222\n",
      " 0.66970813 0.64896095 0.9687312  0.9043478  0.93827957 0.9821494\n",
      " 0.98306364 0.9244169 ]\n",
      "The rewards are: [0.6165887  0.99150074 0.9939056  0.9166986  0.9354586  0.69457024\n",
      " 0.80907923 0.9866324  0.607222   0.9138945  0.9723626  0.9892112\n",
      " 0.9946485  0.8143185  0.91898346 0.69886965 0.5635995  0.98279417\n",
      " 0.74883944 0.96430725 0.52108115 0.99209565 0.94971085 0.9260016\n",
      " 0.9750626  0.5480971  0.83775306 0.80345404 0.9840963  0.9453073\n",
      " 0.938643   0.99831486]\n",
      "The rewards are: [0.70707655 0.98395705 0.5042481  0.9767055  0.96191096 0.8888386\n",
      " 0.88450015 0.8616782  0.9808533  0.6549083  0.98273486 0.57103544\n",
      " 0.6456895  0.99138933 0.99225265 0.78316194 0.7490251  0.61216605\n",
      " 0.99098504 0.9482518  0.5064126  0.79712564 0.8605881  0.9821768\n",
      " 0.9666054  0.9569326  0.97683835 0.94616723 0.97359496 0.995256\n",
      " 0.9768579  0.91937107]\n",
      "The rewards are: [0.99233973 0.93525827 0.5164278  0.97858024 0.9182314  0.96070755\n",
      " 0.5842146  0.88240546 0.99332494 0.75813144 0.9692871  0.9620509\n",
      " 0.9530739  0.98611856 0.9771542  0.7485305  0.9736275  0.84771675\n",
      " 0.9974343  0.98422307 0.8772738  0.65735537 0.55485547 0.8611965\n",
      " 0.9665316  0.59991825 0.98970187 0.9851638  0.9347904  0.9444025\n",
      " 0.9699856  0.9700052 ]\n",
      "The rewards are: [0.9957658  0.9943585  0.97909045 0.7383336  0.98366976 0.68416876\n",
      " 0.98879063 0.9142933  0.9580591  0.7534884  0.5124989  0.9669347\n",
      " 0.5243963  0.9920589  0.9739498  0.9084833  0.8779715  0.5960939\n",
      " 0.9954977  0.7824002  0.9913077  0.5326275  0.98695534 0.94044554\n",
      " 0.9773054  0.9083413  0.97979444 0.9784545  0.9945069  0.8919172\n",
      " 0.80200183 0.9784252 ]\n",
      "The rewards are: [0.8915722  0.918437   0.9931416  0.9750602  0.9214653  0.97392786\n",
      " 0.8661364  0.9822373  0.8385114  0.99219257 0.8013545  0.96756965\n",
      " 0.97057533 0.86961716 0.92234033 0.9780393  0.7958826  0.96357775\n",
      " 0.94662285 0.5983953  0.9132994  0.90914303 0.9811988  0.92718345\n",
      " 0.98742956 0.76286095 0.77038765 0.98188746 0.6101122  0.99723285\n",
      " 0.97063655 0.950279  ]\n",
      "The rewards are: [0.98668253 0.9768794  0.6287677  0.88438654 0.96633977 0.99628437\n",
      " 0.5533865  0.9855542  0.76575214 0.7221099  0.88985634 0.97141266\n",
      " 0.57776564 0.99971396 0.9957883  0.6259245  0.9832902  0.6694864\n",
      " 0.9791124  0.8928581  0.98515934 0.9927651  0.71045995 0.99224573\n",
      " 0.9982375  0.9416258  0.8591836  0.78180146 0.95636934 0.868049\n",
      " 0.9134385  0.98374003]\n",
      "The rewards are: [0.85560524 0.6187468  0.87659764 0.98704094 0.793205   0.9652165\n",
      " 0.99716216 0.896482   0.8750791  0.9947916  0.988735   0.8782455\n",
      " 0.8781528  0.7651152  0.77668667 0.9558465  0.9926634  0.5614069\n",
      " 0.9819919  0.97331965 0.9767122  0.8303128  0.9879353  0.72147906\n",
      " 0.9622827  0.9519595  0.97586346 0.9708955  0.9390123  0.93481\n",
      " 0.9529906  0.9718785 ]\n",
      "The rewards are: [0.790534   0.6507754  0.9366019  0.839815   0.9505417  0.8797076\n",
      " 0.76064116 0.9642098  0.99868315 0.83676887 0.9870083  0.92256767\n",
      " 0.7573112  0.99441564 0.8125767  0.96566755 0.7658155  0.8949501\n",
      " 0.79247516 0.9843619  0.9062081  0.83503145 0.90502757 0.9608102\n",
      " 0.9809199  0.99235314 0.9872667  0.9831738  0.9227186  0.93671596\n",
      " 0.9255568  0.98094577]\n",
      "The rewards are: [0.8984725  0.9852551  0.9811338  0.9675757  0.5197133  0.98028743\n",
      " 0.82026666 0.6221335  0.76804084 0.88963425 0.96658117 0.96714526\n",
      " 0.9407166  0.9120609  0.93998224 0.7168067  0.58055747 0.6571052\n",
      " 0.689502   0.98773885 0.8252773  0.9648433  0.9780853  0.9644078\n",
      " 0.6006497  0.9772709  0.9598795  0.99798894 0.99362284 0.93889487\n",
      " 0.9772509  0.98016447]\n",
      "The rewards are: [0.6203364  0.9341355  0.97490454 0.98302543 0.94675404 0.9864493\n",
      " 0.9677439  0.528572   0.65056455 0.85092956 0.8937798  0.9777206\n",
      " 0.69356555 0.7506031  0.5780849  0.6672036  0.81520766 0.9021446\n",
      " 0.9911026  0.9910778  0.9069401  0.8034335  0.9943293  0.97545093\n",
      " 0.9860713  0.62289685 0.88457084 0.79295003 0.87847805 0.9318669\n",
      " 0.9988992  0.8123285 ]\n",
      "The rewards are: [0.90721726 0.9889909  0.92425185 0.98623127 0.89252937 0.8795679\n",
      " 0.8741307  0.83429587 0.7214057  0.9708426  0.8846298  0.6658153\n",
      " 0.86101013 0.9829122  0.8971226  0.6777705  0.8431416  0.9880723\n",
      " 0.9876165  0.99236614 0.5324064  0.75365496 0.9848585  0.86906743\n",
      " 0.9784396  0.86856055 0.9558724  0.67240155 0.98569983 0.8893484\n",
      " 0.907923   0.99762744]\n",
      "The rewards are: [0.9985178  0.6506218  0.96961    0.6776137  0.9976162  0.83296907\n",
      " 0.7900714  0.974441   0.8428442  0.95473224 0.9041769  0.75366676\n",
      " 0.9779783  0.99176955 0.88629043 0.83499414 0.8343746  0.55750525\n",
      " 0.6710964  0.98304904 0.5339746  0.9153005  0.66460717 0.99155957\n",
      " 0.66241884 0.7741369  0.8569387  0.7484333  0.78078985 0.9953069\n",
      " 0.9841861  0.78816783]\n",
      "The rewards are: [0.81071913 0.88110363 0.76969665 0.9322474  0.9629257  0.949848\n",
      " 0.6396518  0.96791416 0.8716484  0.9947942  0.9918692  0.8414249\n",
      " 0.8597245  0.89273554 0.93981737 0.75158334 0.9464218  0.9783771\n",
      " 0.9460715  0.7042837  0.99321944 0.856737   0.57215905 0.68593466\n",
      " 0.82543284 0.84919643 0.58228725 0.7807217  0.9675789  0.9100111\n",
      " 0.5231508  0.586111  ]\n",
      "The rewards are: [0.9697971  0.66827595 0.9988127  0.957998   0.7529641  0.65600127\n",
      " 0.95676357 0.9954745  0.9854129  0.937233   0.60846674 0.86042506\n",
      " 0.74548805 0.9785628  0.8962336  0.9200412  0.9550157  0.8890056\n",
      " 0.9027652  0.76421297 0.9958319  0.6729898  0.99613637 0.92079467\n",
      " 0.9687691  0.6068424  0.5614029  0.973553   0.7343273  0.9765688\n",
      " 0.58504885 0.9564896 ]\n",
      "The rewards are: [0.96270454 0.98538184 0.8422059  0.9505342  0.9667959  0.98923886\n",
      " 0.9636413  0.7184864  0.90376204 0.9859794  0.9940653  0.5968276\n",
      " 0.89865994 0.7936632  0.8787843  0.9922438  0.6459378  0.8401947\n",
      " 0.9732574  0.97895616 0.5013931  0.9617112  0.9862834  0.5992538\n",
      " 0.96643865 0.81112725 0.8121026  0.92537147 0.9856328  0.54828966\n",
      " 0.8369709  0.90622604]\n",
      "The rewards are: [0.9849786  0.96325296 0.8149032  0.98512137 0.97963536 0.70364386\n",
      " 0.81144994 0.9876473  0.96502763 0.990846   0.9893867  0.8551056\n",
      " 0.95362216 0.97650117 0.92846996 0.9385636  0.94436336 0.85547584\n",
      " 0.8859645  0.9849534  0.96871567 0.97259563 0.98279876 0.5877356\n",
      " 0.9905021  0.9548829  0.88940006 0.76616365 0.81972337 0.9949468\n",
      " 0.83834386 0.9426189 ]\n",
      "The rewards are: [0.99779934 0.7391784  0.75822234 0.99666363 0.9816359  0.99156624\n",
      " 0.54300493 0.91725963 0.9954809  0.98792124 0.9587685  0.8198316\n",
      " 0.6002517  0.8183835  0.96613085 0.9959359  0.9958897  0.9895113\n",
      " 0.9510748  0.9330894  0.97708    0.98428094 0.9554554  0.9745876\n",
      " 0.9954131  0.904804   0.97943497 0.89340067 0.99031794 0.9575407\n",
      " 0.75465465 0.9713098 ]\n",
      "The rewards are: [0.916597   0.97951365 0.9349574  0.6304763  0.97651106 0.972518\n",
      " 0.549221   0.85868436 0.99085    0.96202105 0.5876246  0.9756414\n",
      " 0.98173404 0.92762136 0.8726194  0.739604   0.60042834 0.972484\n",
      " 0.6655264  0.99389344 0.8897012  0.7070119  0.8566292  0.7653645\n",
      " 0.9965342  0.8674796  0.8810792  0.99145764 0.9663603  0.9349299\n",
      " 0.8579426  0.9860221 ]\n",
      "The rewards are: [0.99071044 0.9915001  0.654641   0.87316567 0.9886439  0.98702455\n",
      " 0.960603   0.9954485  0.9627925  0.99198455 0.74164724 0.71906316\n",
      " 0.9533493  0.9266729  0.92138004 0.8555943  0.9146907  0.938642\n",
      " 0.9795156  0.5570103  0.9871565  0.9928825  0.99526596 0.7255632\n",
      " 0.7684099  0.77932644 0.7359124  0.9863892  0.87243223 0.97025865\n",
      " 0.95877254 0.7359124 ]\n",
      "The rewards are: [0.99240065 0.9769305  0.99535584 0.977762   0.70386064 0.9968554\n",
      " 0.98920715 0.86047065 0.989239   0.95359355 0.97702074 0.9908077\n",
      " 0.94887775 0.9976494  0.995899   0.9892972  0.9800597  0.7355504\n",
      " 0.9965293  0.6595253  0.9949137  0.99919575 0.92099047 0.9795975\n",
      " 0.5117225  0.96585864 0.98144126 0.9521661  0.96675926 0.7039086\n",
      " 0.9002788  0.9490008 ]\n",
      "The rewards are: [0.9346493  0.9673235  0.89400244 0.96847993 0.8779187  0.96210116\n",
      " 0.9929878  0.6807642  0.8781375  0.55385107 0.9082585  0.9984219\n",
      " 0.5620515  0.9885301  0.94884586 0.82931113 0.61373174 0.9789038\n",
      " 0.9234799  0.64909506 0.9793433  0.62323374 0.88965607 0.95549613\n",
      " 0.9498016  0.785832   0.90953404 0.9434304  0.94384104 0.7538371\n",
      " 0.57426584 0.9850386 ]\n",
      "The rewards are: [0.99622536 0.8989116  0.5332519  0.9598357  0.99122894 0.9630903\n",
      " 0.6725626  0.9823334  0.9868879  0.993747   0.9962853  0.99348795\n",
      " 0.8911081  0.8097731  0.8270272  0.78789973 0.91128194 0.95287347\n",
      " 0.88679624 0.9621013  0.97160023 0.96878874 0.9479823  0.76747024\n",
      " 0.9640306  0.9117198  0.94362414 0.99711895 0.9809544  0.952391\n",
      " 0.56651986 0.9475484 ]\n",
      "The rewards are: [0.78587246 0.9855138  0.97915053 0.93997514 0.86723214 0.8173779\n",
      " 0.98657113 0.9666902  0.97201985 0.91232353 0.73047006 0.63830614\n",
      " 0.9959979  0.8388942  0.9411826  0.99189395 0.9837588  0.9887262\n",
      " 0.99019194 0.9884775  0.9870926  0.91616416 0.9814045  0.97564757\n",
      " 0.9801502  0.97431695 0.99808455 0.7146615  0.97769076 0.9869617\n",
      " 0.98967046 0.5568486 ]\n",
      "The rewards are: [0.99618113 0.85864615 0.93135417 0.9747912  0.9861602  0.8897739\n",
      " 0.9138979  0.87212694 0.995978   0.98941606 0.5856302  0.98970896\n",
      " 0.8402638  0.511108   0.6834215  0.8291856  0.9713608  0.73865473\n",
      " 0.66394365 0.7985711  0.99928695 0.9985607  0.7174787  0.52085584\n",
      " 0.98977125 0.82227653 0.65511554 0.88865    0.97320676 0.9857281\n",
      " 0.74043673 0.94325817]\n",
      "The rewards are: [0.5938903  0.9278528  0.9127531  0.98806494 0.60546684 0.76468724\n",
      " 0.5419503  0.5552628  0.93980646 0.8150126  0.92368644 0.5441862\n",
      " 0.75483704 0.99150777 0.8410943  0.97750455 0.97533745 0.9914522\n",
      " 0.5815008  0.9950518  0.9849145  0.598199   0.92621195 0.99253947\n",
      " 0.84267867 0.66010463 0.9820609  0.8673556  0.5254523  0.9577026\n",
      " 0.8501712  0.95198166]\n",
      "The rewards are: [0.85692984 0.8968647  0.9185982  0.9499504  0.97305614 0.9693136\n",
      " 0.86898303 0.94650096 0.9926165  0.9466991  0.9826032  0.98101705\n",
      " 0.99023193 0.9752235  0.9808352  0.85193366 0.9839802  0.9094151\n",
      " 0.99086654 0.98931366 0.89608467 0.92999583 0.76888764 0.7638787\n",
      " 0.9583852  0.85959154 0.54046726 0.99845517 0.9726553  0.5957171\n",
      " 0.9708793  0.91617876]\n",
      "The rewards are: [0.993606   0.8925439  0.79872817 0.96021277 0.62048113 0.98555785\n",
      " 0.9371866  0.92599803 0.88374674 0.8666383  0.9464326  0.95967585\n",
      " 0.94236374 0.98683083 0.9983576  0.7886262  0.98817354 0.9344788\n",
      " 0.9896318  0.9697556  0.92214465 0.98640627 0.9468337  0.58959734\n",
      " 0.9678094  0.98129165 0.973245   0.87907296 0.69978315 0.87127644\n",
      " 0.889248   0.9903287 ]\n",
      "The rewards are: [0.9922339  0.9755838  0.9507498  0.92940223 0.97769105 0.5948393\n",
      " 0.98604673 0.9802642  0.9398692  0.9074787  0.7390441  0.99578995\n",
      " 0.98517716 0.80296975 0.52045673 0.99794275 0.98704094 0.99431676\n",
      " 0.81347877 0.9514914  0.9438631  0.7085685  0.62154806 0.5586215\n",
      " 0.97607964 0.9451911  0.6307768  0.90656    0.9941492  0.9309153\n",
      " 0.816218   0.9177652 ]\n",
      "The rewards are: [0.5694777  0.8581828  0.7996068  0.8069672  0.98272896 0.6847379\n",
      " 0.99228364 0.95481455 0.87598276 0.7519396  0.9181838  0.96348983\n",
      " 0.7756532  0.7879219  0.74093777 0.9653805  0.9808024  0.91076934\n",
      " 0.97402555 0.9778921  0.94142956 0.9849834  0.9969863  0.9462119\n",
      " 0.9426021  0.9763173  0.99305516 0.9442813  0.8681946  0.9005362\n",
      " 0.913088   0.9217151 ]\n",
      "The rewards are: [0.958577   0.7601206  0.9987218  0.86413336 0.87365663 0.55734766\n",
      " 0.6581315  0.99395543 0.79263854 0.93196213 0.9901202  0.9977387\n",
      " 0.9169896  0.79403424 0.8736807  0.7931002  0.8290884  0.96620375\n",
      " 0.85103035 0.97770554 0.981042   0.97839373 0.8929986  0.8706863\n",
      " 0.81424683 0.9519395  0.905802   0.64717174 0.971307   0.98011017\n",
      " 0.96812195 0.92027545]\n",
      "The rewards are: [0.9426546  0.9843704  0.94601136 0.93001616 0.9614413  0.9384729\n",
      " 0.98249316 0.9891474  0.67393905 0.8775105  0.9550087  0.97381413\n",
      " 0.9596755  0.6664248  0.953601   0.9485861  0.9461116  0.5037679\n",
      " 0.9607536  0.9774097  0.9407695  0.63325727 0.9893721  0.9806819\n",
      " 0.70350575 0.95259327 0.98342127 0.85029316 0.9755231  0.9812309\n",
      " 0.79428923 0.98272485]\n",
      "The rewards are: [0.79432225 0.97940606 0.9988943  0.97311515 0.7206382  0.82247263\n",
      " 0.9377005  0.9838701  0.8987502  0.97925687 0.9169766  0.9722148\n",
      " 0.9745575  0.64239496 0.9264812  0.7133471  0.92182016 0.9719865\n",
      " 0.9965406  0.934937   0.61205477 0.8397965  0.9893645  0.8374531\n",
      " 0.9928214  0.98942727 0.77604437 0.9865414  0.9316361  0.97779125\n",
      " 0.9970829  0.6997563 ]\n",
      "The rewards are: [0.987626   0.5796551  0.53799886 0.9997482  0.8364291  0.9966\n",
      " 0.91109794 0.990488   0.94742674 0.8390487  0.6514007  0.99264914\n",
      " 0.9897949  0.95154905 0.88698506 0.99935263 0.9952296  0.94547725\n",
      " 0.9834167  0.9215499  0.997017   0.82533616 0.94334114 0.99614453\n",
      " 0.80578256 0.9978143  0.82365537 0.82239103 0.9846102  0.9498714\n",
      " 0.98945415 0.8408716 ]\n",
      "The rewards are: [0.9813571  0.525484   0.9794319  0.90986776 0.99389887 0.9871947\n",
      " 0.96997035 0.95109767 0.99249095 0.9861944  0.98793924 0.90468776\n",
      " 0.98920083 0.8597443  0.9784056  0.9833988  0.5903495  0.7579093\n",
      " 0.97681755 0.99713767 0.97524726 0.9645606  0.98076814 0.99832326\n",
      " 0.95518035 0.9432862  0.9382348  0.99167526 0.78291655 0.894971\n",
      " 0.853524   0.9743712 ]\n",
      "The rewards are: [0.9560153  0.9964497  0.87315047 0.5342539  0.9576074  0.96107715\n",
      " 0.8650231  0.9933339  0.909124   0.96673554 0.99171054 0.9137382\n",
      " 0.9708124  0.9901957  0.9738989  0.9264395  0.7559962  0.9685422\n",
      " 0.9915565  0.71038043 0.9551386  0.9885378  0.9866318  0.96402\n",
      " 0.89904445 0.99001807 0.9954496  0.74143255 0.59543663 0.5549885\n",
      " 0.93429416 0.99691236]\n",
      "The rewards are: [0.99001163 0.99322987 0.535661   0.9881742  0.9606987  0.9103817\n",
      " 0.982621   0.98625594 0.9612377  0.68622214 0.91267574 0.9794082\n",
      " 0.8057979  0.93101925 0.952845   0.964903   0.6466051  0.94428515\n",
      " 0.9939466  0.7311762  0.96554416 0.97518027 0.90918547 0.987695\n",
      " 0.604498   0.9889424  0.9941948  0.9883609  0.94364524 0.9124247\n",
      " 0.91593057 0.9784801 ]\n",
      "The rewards are: [0.8512118  0.9386743  0.9876368  0.8540581  0.93369156 0.5014172\n",
      " 0.99007636 0.98712826 0.9935822  0.9582465  0.98281187 0.82095295\n",
      " 0.98236775 0.98240465 0.95081466 0.9567498  0.9836061  0.99429375\n",
      " 0.9826066  0.99223536 0.95478934 0.9969344  0.6831428  0.97201407\n",
      " 0.82167923 0.84547055 0.91866755 0.54359233 0.9495753  0.9756771\n",
      " 0.9869638  0.97145283]\n",
      "The rewards are: [0.9690579  0.98918813 0.96388406 0.9863464  0.9817806  0.8708872\n",
      " 0.94466776 0.991919   0.9552944  0.97709846 0.9451108  0.9848305\n",
      " 0.7942995  0.9934803  0.9922449  0.9936103  0.985166   0.93702495\n",
      " 0.8008383  0.6646473  0.92627865 0.95901775 0.9439929  0.99300826\n",
      " 0.996046   0.9618229  0.81379384 0.94178015 0.88042516 0.99510694\n",
      " 0.98468834 0.65839946]\n",
      "The rewards are: [0.98613733 0.9963941  0.9873198  0.9211176  0.94707865 0.7785001\n",
      " 0.9457721  0.6692604  0.6276945  0.9643262  0.6057223  0.59484607\n",
      " 0.96418756 0.75770795 0.8141684  0.9133659  0.9236535  0.7950617\n",
      " 0.7283996  0.9687608  0.99067056 0.7160696  0.9304609  0.99897987\n",
      " 0.991731   0.76999956 0.70877117 0.75610095 0.94610095 0.89755803\n",
      " 0.7366819  0.9967212 ]\n",
      "The rewards are: [0.97588253 0.99067116 0.7368517  0.67479235 0.52394027 0.89225256\n",
      " 0.8524559  0.90871865 0.97472286 0.9811333  0.95854807 0.6725085\n",
      " 0.8070186  0.9613614  0.93100846 0.9221643  0.8606367  0.99940956\n",
      " 0.9468376  0.99211544 0.93632555 0.95444775 0.9957486  0.6115728\n",
      " 0.9207023  0.7963386  0.9831026  0.82579464 0.9755611  0.9796255\n",
      " 0.8591973  0.9803711 ]\n",
      "The rewards are: [0.85696673 0.8508252  0.82482046 0.95685476 0.8298868  0.9741277\n",
      " 0.9714137  0.8962525  0.9954867  0.98780304 0.8061264  0.870642\n",
      " 0.8447323  0.6722224  0.6600214  0.99716336 0.99808997 0.9794756\n",
      " 0.6032634  0.99904555 0.9494359  0.9872277  0.99032915 0.8464757\n",
      " 0.78755623 0.89628583 0.83855855 0.7088748  0.9645216  0.8861618\n",
      " 0.6196402  0.8763124 ]\n",
      "The rewards are: [0.9836639  0.69827497 0.95127904 0.7899886  0.88310564 0.74406046\n",
      " 0.97036946 0.8590471  0.7767835  0.9884216  0.97997206 0.9110809\n",
      " 0.96277905 0.81290966 0.8022423  0.99785054 0.99110657 0.87962323\n",
      " 0.88460124 0.98985076 0.99675506 0.990013   0.63093424 0.9758818\n",
      " 0.9172094  0.9943756  0.9230201  0.8900121  0.94937205 0.9382078\n",
      " 0.9447056  0.9777209 ]\n",
      "The rewards are: [0.9982443  0.54588646 0.939357   0.9393119  0.9968374  0.8004756\n",
      " 0.77074724 0.9881571  0.9702939  0.8809999  0.9426996  0.9739696\n",
      " 0.989944   0.98121625 0.9767695  0.7118876  0.984329   0.98988813\n",
      " 0.9292012  0.98493654 0.9317166  0.9754716  0.53924423 0.6324013\n",
      " 0.99802953 0.99371755 0.9952058  0.97462964 0.9752793  0.95135826\n",
      " 0.5423362  0.8502999 ]\n",
      "The rewards are: [0.9567857  0.99527717 0.9784272  0.9938976  0.5909375  0.9931068\n",
      " 0.9863923  0.9617827  0.57742256 0.94164366 0.81703854 0.9666299\n",
      " 0.99597126 0.7545903  0.7831601  0.70790154 0.8611709  0.9383874\n",
      " 0.9816379  0.7150165  0.8402989  0.65876955 0.96314627 0.9049817\n",
      " 0.9928807  0.9942325  0.96517354 0.7841586  0.89990515 0.76517504\n",
      " 0.97284174 0.9608882 ]\n",
      "The rewards are: [0.8330493  0.98845357 0.9647293  0.9735339  0.99608624 0.91804546\n",
      " 0.94613457 0.8137765  0.9980159  0.83338946 0.93530494 0.9955771\n",
      " 0.7179708  0.91920453 0.9770652  0.9944653  0.887371   0.888555\n",
      " 0.5320329  0.99561584 0.9654354  0.85790616 0.9928316  0.69467056\n",
      " 0.8689869  0.97647923 0.98252493 0.97873634 0.9674311  0.9953903\n",
      " 0.5371149  0.6095615 ]\n",
      "The rewards are: [0.694242   0.7275904  0.9488808  0.899602   0.57850814 0.52543217\n",
      " 0.95271945 0.99782795 0.6838796  0.930714   0.699216   0.96336406\n",
      " 0.97597003 0.9768496  0.9267987  0.9502437  0.90285933 0.9013596\n",
      " 0.9893544  0.9736386  0.98055845 0.9200659  0.99223655 0.9768941\n",
      " 0.96073604 0.98741466 0.9477469  0.9678523  0.993331   0.917393\n",
      " 0.6770684  0.8773183 ]\n",
      "The rewards are: [0.9890114  0.9967474  0.6829206  0.8890745  0.9869599  0.66381216\n",
      " 0.90340346 0.848532   0.8952233  0.8926978  0.9623166  0.85305303\n",
      " 0.81393826 0.96492964 0.98371166 0.99707866 0.98648596 0.8190438\n",
      " 0.987344   0.78772175 0.9138345  0.87347525 0.941152   0.81688064\n",
      " 0.99405956 0.9841738  0.77215517 0.83337337 0.6797897  0.80299085\n",
      " 0.9117189  0.9803506 ]\n",
      "The rewards are: [0.8806368  0.8987888  0.891611   0.89803916 0.5500024  0.77882737\n",
      " 0.8404564  0.65455294 0.88596696 0.9037178  0.98688865 0.5546123\n",
      " 0.5427901  0.99427336 0.7146094  0.9418041  0.9600042  0.5264123\n",
      " 0.9839039  0.89965576 0.81291705 0.9737554  0.7971939  0.8518666\n",
      " 0.98732275 0.85948414 0.9954596  0.8984391  0.8975827  0.9971169\n",
      " 0.9885748  0.60366255]\n",
      "The rewards are: [0.8972077  0.82529926 0.90036464 0.9906908  0.92087936 0.98705006\n",
      " 0.97143835 0.9490767  0.99225336 0.99130684 0.93990535 0.97393733\n",
      " 0.93226117 0.96815634 0.86775947 0.96599513 0.89989734 0.79958576\n",
      " 0.9133551  0.9930211  0.9868232  0.9572259  0.55084205 0.72348344\n",
      " 0.7643617  0.97632265 0.8893569  0.90466654 0.7060874  0.9821447\n",
      " 0.9414845  0.68285793]\n",
      "The rewards are: [0.9938886  0.9636102  0.98482805 0.9782848  0.96842635 0.5542255\n",
      " 0.9646619  0.9123186  0.99502075 0.9700403  0.51805174 0.5825957\n",
      " 0.9701341  0.9920324  0.98588306 0.8784173  0.86762625 0.8680015\n",
      " 0.97742164 0.9904512  0.9955206  0.84490865 0.9872915  0.9182881\n",
      " 0.9911594  0.9864987  0.5470218  0.79523796 0.8909712  0.933506\n",
      " 0.9975924  0.80963993]\n",
      "The rewards are: [0.9522209  0.98602283 0.92678756 0.9425314  0.99623716 0.79651105\n",
      " 0.8268543  0.9374861  0.9612115  0.9294327  0.93233865 0.7843332\n",
      " 0.9744503  0.9800551  0.85518926 0.99084747 0.99269706 0.9766025\n",
      " 0.98687    0.7637273  0.9414308  0.8543206  0.9900512  0.5277177\n",
      " 0.9304686  0.8626737  0.8099534  0.95113164 0.8348319  0.99247944\n",
      " 0.98318934 0.99875915]\n",
      "The rewards are: [0.9580759  0.99696976 0.5143183  0.8431603  0.51472044 0.6046184\n",
      " 0.9739023  0.91152215 0.998705   0.845241   0.96144503 0.9953607\n",
      " 0.9957302  0.6889538  0.9555279  0.9924374  0.98337483 0.9937255\n",
      " 0.9562023  0.99960786 0.8539064  0.58877933 0.9122966  0.87966174\n",
      " 0.9376502  0.9574965  0.9942378  0.9753297  0.9634197  0.9882107\n",
      " 0.9650523  0.9624936 ]\n",
      "The rewards are: [0.9900553  0.9703236  0.97797203 0.8258886  0.9925303  0.8538161\n",
      " 0.9741432  0.91863024 0.9855363  0.8888339  0.9323659  0.9535902\n",
      " 0.9808065  0.96235204 0.54009855 0.98833084 0.9521316  0.97538495\n",
      " 0.9890838  0.9136939  0.93324274 0.8996924  0.9539514  0.7282396\n",
      " 0.96772176 0.9627084  0.9879671  0.98925763 0.99562573 0.99495184\n",
      " 0.9887671  0.9785615 ]\n",
      "The rewards are: [0.9933342  0.975957   0.9864819  0.9920144  0.7496146  0.7816232\n",
      " 0.93962085 0.6563485  0.9356185  0.9574727  0.98201454 0.9685934\n",
      " 0.9902884  0.94319105 0.9696251  0.9701558  0.97863597 0.99558085\n",
      " 0.914817   0.98988694 0.8599148  0.9961134  0.9733192  0.9951821\n",
      " 0.5495803  0.69175184 0.50826544 0.98304236 0.86281884 0.80118895\n",
      " 0.91228664 0.9990909 ]\n",
      "The rewards are: [0.99305737 0.91797894 0.9824546  0.70477897 0.62023157 0.55417323\n",
      " 0.9853698  0.9892051  0.98927104 0.9840476  0.95318854 0.8691547\n",
      " 0.9981559  0.69994587 0.9994399  0.9380317  0.991918   0.96337366\n",
      " 0.6682582  0.99890053 0.50666374 0.6451068  0.9857013  0.95962113\n",
      " 0.5810534  0.9745891  0.99690443 0.5182505  0.8120687  0.9878879\n",
      " 0.89002657 0.95739895]\n",
      "The rewards are: [0.6820346  0.7417504  0.86126727 0.6172573  0.9770017  0.73706603\n",
      " 0.8075248  0.88600504 0.8094906  0.93355274 0.9410764  0.97560674\n",
      " 0.80578053 0.92741716 0.9952932  0.9384725  0.96912676 0.8649253\n",
      " 0.75394624 0.9969311  0.8483503  0.7388151  0.9736082  0.8479928\n",
      " 0.9626715  0.99219185 0.9580759  0.82428885 0.9929061  0.99235606\n",
      " 0.9552776  0.8853134 ]\n",
      "The rewards are: [0.9641066  0.8654918  0.9735908  0.9721041  0.83081996 0.9891644\n",
      " 0.8417652  0.89266884 0.88755584 0.98534214 0.9806034  0.8975549\n",
      " 0.5710965  0.9684155  0.98938274 0.9718802  0.81103176 0.8074411\n",
      " 0.9973513  0.9896651  0.6431514  0.96432865 0.7911121  0.8776352\n",
      " 0.9888736  0.90962934 0.9885993  0.98772454 0.9687854  0.6900794\n",
      " 0.993816   0.9759346 ]\n",
      "The rewards are: [0.9015255  0.9860621  0.9915019  0.99172467 0.5195709  0.51509005\n",
      " 0.99751556 0.9963462  0.9984206  0.73814434 0.990927   0.9101449\n",
      " 0.56759346 0.989116   0.99568653 0.9918561  0.9744624  0.97797364\n",
      " 0.99517536 0.9531509  0.9835437  0.9782244  0.8466177  0.97305614\n",
      " 0.9661509  0.9960079  0.98917997 0.58803827 0.5196302  0.998176\n",
      " 0.9676068  0.99136645]\n",
      "The rewards are: [0.88330424 0.988458   0.8721123  0.9983577  0.8213058  0.95507675\n",
      " 0.8098235  0.9837283  0.55101824 0.6363027  0.9536136  0.9871646\n",
      " 0.89056325 0.98730206 0.7822239  0.9403691  0.9788294  0.9861042\n",
      " 0.9670069  0.9166123  0.853224   0.99696034 0.7285699  0.630797\n",
      " 0.9911237  0.55912924 0.9579676  0.9857686  0.9554258  0.977626\n",
      " 0.9215678  0.904937  ]\n",
      "The rewards are: [0.9729988  0.745494   0.9179988  0.9609585  0.56346214 0.9637348\n",
      " 0.5751673  0.98017293 0.8581747  0.98318017 0.9298561  0.99839324\n",
      " 0.79330695 0.98672754 0.9871344  0.7343238  0.6528103  0.9824948\n",
      " 0.5144161  0.9800495  0.9750012  0.9895475  0.9761523  0.9205573\n",
      " 0.6882649  0.5908315  0.7484888  0.9956254  0.99456406 0.79911464\n",
      " 0.9718159  0.96395874]\n",
      "The rewards are: [0.8822688  0.981201   0.99219817 0.5895641  0.87615067 0.99110305\n",
      " 0.508074   0.5079681  0.7391508  0.71362567 0.98004705 0.9727356\n",
      " 0.6813701  0.98498607 0.90761536 0.9867622  0.73289543 0.776868\n",
      " 0.9903673  0.5417318  0.99480706 0.5527906  0.97178066 0.9850358\n",
      " 0.52135825 0.897082   0.99664354 0.9375498  0.89205456 0.96026325\n",
      " 0.9971486  0.9805038 ]\n",
      "The rewards are: [0.9261454  0.981233   0.99742967 0.93746245 0.96626985 0.6401709\n",
      " 0.97838074 0.6901957  0.90425986 0.9958949  0.9892737  0.9783785\n",
      " 0.99800974 0.93773395 0.8404553  0.95513254 0.7017805  0.5568306\n",
      " 0.9660538  0.9879227  0.9879149  0.7815127  0.98905027 0.97887784\n",
      " 0.97184855 0.9307256  0.9897692  0.9666873  0.60768414 0.5650311\n",
      " 0.71813715 0.56569797]\n",
      "The rewards are: [0.99286073 0.9944601  0.8861064  0.9736352  0.9586609  0.983727\n",
      " 0.95996094 0.5101228  0.980605   0.61326075 0.96460587 0.8909233\n",
      " 0.8103305  0.9847801  0.9546699  0.98297256 0.99065584 0.96221226\n",
      " 0.9966137  0.5720093  0.9856566  0.9894183  0.99826604 0.9546815\n",
      " 0.8732042  0.9983235  0.935445   0.94478136 0.93187195 0.9876643\n",
      " 0.98742527 0.9714685 ]\n",
      "The rewards are: [0.9878229  0.9965647  0.93596566 0.99444264 0.9699286  0.62192273\n",
      " 0.7953537  0.9746279  0.9387714  0.93048555 0.9544786  0.9597663\n",
      " 0.8992179  0.91992897 0.9708364  0.9944127  0.99094325 0.94391996\n",
      " 0.99106336 0.8318607  0.81212014 0.97459745 0.99659854 0.9811428\n",
      " 0.9917985  0.99541384 0.5925359  0.94502765 0.96879804 0.97187054\n",
      " 0.9698961  0.9019099 ]\n",
      "The rewards are: [0.99709153 0.91088194 0.677661   0.9763575  0.9391914  0.7757855\n",
      " 0.7200751  0.9919728  0.9837065  0.97212976 0.8799578  0.9866258\n",
      " 0.96443874 0.959987   0.9667753  0.99403363 0.9825587  0.9852395\n",
      " 0.9143729  0.99689    0.9859563  0.986167   0.6119889  0.8726216\n",
      " 0.993662   0.9869955  0.99173635 0.7319903  0.7749684  0.9753577\n",
      " 0.9963566  0.98964536]\n",
      "The rewards are: [0.8396159  0.61228853 0.9484229  0.9742125  0.9782376  0.9956235\n",
      " 0.98819727 0.99069375 0.99239165 0.8431034  0.9351669  0.99705267\n",
      " 0.98192054 0.9083487  0.98968107 0.7244899  0.87318945 0.97554535\n",
      " 0.72953045 0.89332724 0.9850043  0.894547   0.98180157 0.897054\n",
      " 0.98256344 0.6858583  0.86738795 0.9919526  0.9974854  0.9935427\n",
      " 0.9691218  0.90560204]\n",
      "The rewards are: [0.99198335 0.9922347  0.9977963  0.85389227 0.74103147 0.9944178\n",
      " 0.9773422  0.9031256  0.98019344 0.8049596  0.932328   0.93625563\n",
      " 0.5303194  0.99762076 0.8768601  0.8864876  0.9929309  0.9806192\n",
      " 0.7334724  0.69112647 0.682943   0.99508154 0.95264566 0.8831955\n",
      " 0.96889246 0.9831911  0.98515946 0.9795832  0.93962866 0.98198676\n",
      " 0.98650616 0.9474736 ]\n",
      "The rewards are: [0.6150878  0.9751967  0.964762   0.9714562  0.98117685 0.6809214\n",
      " 0.90161085 0.7617325  0.97781014 0.8438879  0.99174917 0.9813659\n",
      " 0.6938497  0.9170741  0.9981042  0.99276793 0.9817509  0.7657334\n",
      " 0.5032264  0.8216843  0.98672444 0.86804014 0.9958905  0.7720468\n",
      " 0.94006914 0.9762724  0.86770445 0.9652734  0.98701304 0.98827726\n",
      " 0.93388104 0.59442383]\n",
      "The rewards are: [0.98913926 0.9760251  0.9785792  0.9149039  0.93575466 0.967817\n",
      " 0.87191916 0.9944746  0.9927725  0.9340699  0.7632025  0.6472864\n",
      " 0.9841458  0.9703139  0.9989675  0.7984921  0.9870142  0.9941035\n",
      " 0.99162954 0.79909235 0.9927256  0.96871984 0.78760844 0.9860465\n",
      " 0.9527003  0.98767126 0.9373558  0.85038143 0.9899955  0.99640393\n",
      " 0.6543407  0.97468704]\n",
      "The rewards are: [0.9831867  0.9530231  0.89782953 0.92806214 0.5725842  0.6321948\n",
      " 0.90970826 0.9594009  0.9615011  0.77236015 0.79416686 0.9989635\n",
      " 0.96393484 0.95995885 0.9912246  0.5655672  0.962508   0.5843586\n",
      " 0.9796036  0.9969312  0.9798201  0.95023197 0.9742749  0.5582632\n",
      " 0.998033   0.90308815 0.5486062  0.95343995 0.5644979  0.9354875\n",
      " 0.98646104 0.9295993 ]\n",
      "The rewards are: [0.95786786 0.9830514  0.5569564  0.9686062  0.8987266  0.9912425\n",
      " 0.76282257 0.76617813 0.996258   0.9269406  0.99089897 0.9750431\n",
      " 0.8993745  0.996201   0.9758044  0.9852887  0.9533143  0.9644533\n",
      " 0.9826066  0.95830333 0.99449676 0.9521035  0.9125393  0.5401986\n",
      " 0.84613043 0.9977794  0.909912   0.9911793  0.89283377 0.8592027\n",
      " 0.9979861  0.98981524]\n",
      "The rewards are: [0.5096873  0.99186045 0.9740053  0.7971591  0.9259312  0.99405307\n",
      " 0.9393796  0.9923658  0.9902082  0.81998277 0.769155   0.94369173\n",
      " 0.98231    0.9840267  0.95254016 0.76124376 0.97357506 0.9970796\n",
      " 0.9935541  0.95370924 0.9902711  0.9712531  0.87061375 0.73374426\n",
      " 0.98139787 0.92964584 0.8103737  0.96806717 0.96250254 0.90952045\n",
      " 0.8368332  0.7663374 ]\n",
      "The rewards are: [0.86059135 0.95043015 0.9780568  0.98876685 0.9576192  0.98589087\n",
      " 0.99494284 0.9803218  0.98704565 0.83193547 0.9729327  0.88088787\n",
      " 0.99090827 0.90190244 0.993929   0.9894057  0.9613961  0.98385483\n",
      " 0.99144214 0.9708406  0.848542   0.99272525 0.9795451  0.9544748\n",
      " 0.8793801  0.97910655 0.99821055 0.8255234  0.97555    0.9802766\n",
      " 0.984365   0.8908924 ]\n",
      "The rewards are: [0.99719363 0.98492646 0.7708289  0.9979533  0.53424424 0.9832851\n",
      " 0.99728036 0.86805516 0.978488   0.997412   0.9605465  0.9210865\n",
      " 0.97952914 0.99398077 0.9976071  0.99003863 0.74915415 0.62448955\n",
      " 0.97081137 0.98679745 0.99685234 0.9944976  0.9838378  0.8866339\n",
      " 0.9069044  0.64673436 0.9664766  0.9903949  0.9875448  0.9443569\n",
      " 0.70612127 0.9475269 ]\n",
      "The rewards are: [0.9689398  0.91562647 0.9849672  0.9984842  0.9992611  0.9809806\n",
      " 0.98257726 0.98879963 0.96133155 0.9744193  0.9711245  0.9726618\n",
      " 0.5383665  0.99237084 0.95007753 0.6890929  0.59206694 0.98706156\n",
      " 0.8356669  0.7127542  0.89156854 0.9549255  0.74803275 0.9612675\n",
      " 0.8015069  0.7168409  0.9808791  0.7726782  0.99307996 0.9945852\n",
      " 0.965243   0.9359082 ]\n",
      "The rewards are: [0.97710323 0.93104434 0.9952931  0.9618207  0.5040607  0.9730348\n",
      " 0.9979259  0.9102699  0.9758931  0.6667296  0.9183715  0.9630381\n",
      " 0.9726052  0.8200209  0.9923574  0.9378239  0.89316696 0.98129624\n",
      " 0.9679091  0.8968111  0.95017856 0.998781   0.9312895  0.9468826\n",
      " 0.96470994 0.9788536  0.9902659  0.9805101  0.9016373  0.9783996\n",
      " 0.9874784  0.66275007]\n",
      "The rewards are: [0.90120983 0.9626921  0.9943726  0.96927285 0.9963911  0.9547219\n",
      " 0.99530196 0.9875038  0.99282277 0.93868244 0.99892837 0.9887398\n",
      " 0.99601007 0.667062   0.57268023 0.9813067  0.9897956  0.9386966\n",
      " 0.970266   0.94127035 0.97640073 0.8555471  0.9996557  0.95288783\n",
      " 0.98555726 0.98467505 0.9761999  0.94632286 0.98210335 0.5040192\n",
      " 0.98838824 0.9895035 ]\n",
      "The rewards are: [0.9823949  0.91863537 0.86832154 0.98361117 0.95718527 0.53327185\n",
      " 0.9291682  0.6103193  0.9727102  0.7422963  0.9849177  0.98511237\n",
      " 0.9902844  0.98857564 0.96176547 0.62606955 0.95404166 0.9961062\n",
      " 0.98729193 0.97349113 0.99263376 0.7653279  0.7302991  0.92461956\n",
      " 0.9419426  0.8892352  0.6781731  0.7117345  0.62069553 0.9644127\n",
      " 0.9866725  0.98664445]\n",
      "The rewards are: [0.9487564  0.85079294 0.6639445  0.92686886 0.68670624 0.84074914\n",
      " 0.95797527 0.9418112  0.74888295 0.9727377  0.5505912  0.7692256\n",
      " 0.96043134 0.9915325  0.99510986 0.7474809  0.96285176 0.9745746\n",
      " 0.88617265 0.986681   0.89828527 0.9842138  0.80621165 0.84225905\n",
      " 0.99391586 0.89000833 0.81507504 0.9398072  0.9876458  0.7183795\n",
      " 0.9331904  0.99399793]\n",
      "The rewards are: [0.69268376 0.905842   0.9688995  0.9804951  0.96953356 0.99505794\n",
      " 0.95410883 0.911424   0.9901888  0.96539867 0.93028855 0.9918583\n",
      " 0.93156815 0.87771815 0.94619757 0.99338865 0.99315566 0.9375945\n",
      " 0.9597184  0.9979931  0.9960759  0.9305841  0.99167764 0.99498993\n",
      " 0.9843799  0.74931324 0.96258616 0.93900156 0.98578393 0.98107713\n",
      " 0.68947256 0.95607895]\n",
      "The rewards are: [0.8449535  0.9689078  0.6611973  0.99381775 0.9691432  0.9822334\n",
      " 0.6470736  0.8110458  0.8558592  0.94802547 0.9917789  0.8088519\n",
      " 0.9315936  0.96899104 0.99196506 0.96203536 0.68435633 0.9907285\n",
      " 0.96110237 0.93497837 0.9893651  0.5941988  0.6936504  0.98742396\n",
      " 0.9806378  0.99237293 0.93692374 0.9362344  0.9427421  0.9990339\n",
      " 0.9154764  0.57896   ]\n",
      "The rewards are: [0.9856312  0.99942625 0.5766017  0.99690884 0.983413   0.9837335\n",
      " 0.6547528  0.9268035  0.99616927 0.99111277 0.87080157 0.92691773\n",
      " 0.8084058  0.9704195  0.9919768  0.9887932  0.9867639  0.944318\n",
      " 0.9503156  0.987929   0.56025517 0.9932904  0.74170053 0.7748768\n",
      " 0.7968814  0.9927918  0.859194   0.945658   0.9816907  0.985817\n",
      " 0.68124044 0.9669613 ]\n",
      "The rewards are: [0.9941565  0.9439257  0.75836176 0.65544266 0.93034345 0.7763566\n",
      " 0.99556893 0.9754901  0.76703054 0.98683274 0.97582847 0.944769\n",
      " 0.5537172  0.98009413 0.86181897 0.9218961  0.8576114  0.91994584\n",
      " 0.9898059  0.78918564 0.77265716 0.89879465 0.9892887  0.9921008\n",
      " 0.9595906  0.974944   0.99203086 0.9836782  0.9523305  0.99007285\n",
      " 0.9911588  0.88621694]\n",
      "The rewards are: [0.57405436 0.99221426 0.9990502  0.9046361  0.9965571  0.8601173\n",
      " 0.84461063 0.76554394 0.5022505  0.9969145  0.9863951  0.57882416\n",
      " 0.9996617  0.98641104 0.9708574  0.8322831  0.63457304 0.99829394\n",
      " 0.99527955 0.99265975 0.9905335  0.9670177  0.99364215 0.96064913\n",
      " 0.88519156 0.85016805 0.94912523 0.98943275 0.5172775  0.9729673\n",
      " 0.9616588  0.96242625]\n",
      "The rewards are: [0.9924499  0.96547157 0.90883785 0.9527692  0.9021584  0.98717564\n",
      " 0.9841411  0.9151519  0.9704     0.93186873 0.97089773 0.9833439\n",
      " 0.9819933  0.8330284  0.958223   0.9791166  0.9761203  0.9923354\n",
      " 0.95437264 0.948267   0.99537426 0.99665135 0.5943897  0.93894416\n",
      " 0.91990477 0.94082046 0.5410135  0.97539675 0.99134856 0.7264301\n",
      " 0.59236044 0.97931194]\n",
      "The rewards are: [0.9763861  0.87940544 0.99164915 0.963526   0.86921483 0.983063\n",
      " 0.9246275  0.9760573  0.69374126 0.94551635 0.99095273 0.9974256\n",
      " 0.6827951  0.8862179  0.9912083  0.92358166 0.9660444  0.99712783\n",
      " 0.9389286  0.9771912  0.9676761  0.96816146 0.938925   0.9717648\n",
      " 0.9831081  0.78913045 0.973175   0.9843605  0.7283104  0.7585578\n",
      " 0.6563512  0.9887783 ]\n",
      "The rewards are: [0.84581286 0.9781844  0.985857   0.7641191  0.9527463  0.98195285\n",
      " 0.9520487  0.85684186 0.7631677  0.9235119  0.8606765  0.98742723\n",
      " 0.98793983 0.7538999  0.88561136 0.971631   0.9162449  0.5806738\n",
      " 0.971989   0.99430853 0.6569417  0.9430559  0.9878681  0.90633047\n",
      " 0.5645747  0.988359   0.88255566 0.86968297 0.96225256 0.99011505\n",
      " 0.5197922  0.99185795]\n",
      "The rewards are: [0.98980075 0.9573122  0.96408933 0.9890675  0.97165626 0.60410845\n",
      " 0.7415884  0.9984617  0.9888958  0.9830882  0.9868976  0.79871774\n",
      " 0.91979283 0.99470985 0.9446903  0.6554213  0.9802408  0.9525919\n",
      " 0.9973035  0.96282005 0.99455017 0.8585254  0.9830934  0.97256595\n",
      " 0.9944284  0.98931587 0.69615704 0.9665717  0.9382159  0.9545542\n",
      " 0.8532716  0.98847383]\n",
      "The rewards are: [0.9352128  0.9888009  0.9438067  0.9956708  0.7057325  0.96706825\n",
      " 0.9745079  0.9094104  0.98722166 0.83429056 0.72452885 0.98929906\n",
      " 0.86369693 0.92056215 0.989622   0.68567383 0.7276396  0.8578738\n",
      " 0.9615128  0.98008037 0.9982595  0.98304063 0.98114645 0.979575\n",
      " 0.98113567 0.9908708  0.99882275 0.8626919  0.9791068  0.9970362\n",
      " 0.9974377  0.9764683 ]\n",
      "The rewards are: [0.9892791  0.74925405 0.8597934  0.5089487  0.6499664  0.7626666\n",
      " 0.83744377 0.9479543  0.99064964 0.74559623 0.9719295  0.997837\n",
      " 0.8178233  0.9893918  0.7152357  0.53767955 0.91073394 0.7606653\n",
      " 0.95357966 0.9452062  0.984971   0.9995473  0.7986296  0.96129555\n",
      " 0.9877987  0.87790024 0.9107988  0.88079834 0.9421858  0.83752704\n",
      " 0.99764735 0.72595584]\n",
      "The rewards are: [0.9707517  0.61755484 0.99056786 0.9976266  0.92033875 0.9240513\n",
      " 0.9870864  0.64228773 0.96142465 0.75278646 0.99917006 0.9620907\n",
      " 0.92434883 0.99410605 0.88089544 0.9974679  0.9966273  0.6787176\n",
      " 0.9836332  0.97725827 0.8547363  0.95582044 0.5793282  0.52066797\n",
      " 0.892797   0.9517873  0.94064677 0.95095295 0.99270403 0.988901\n",
      " 0.9987669  0.9861479 ]\n",
      "The rewards are: [0.8190777  0.88399065 0.97378606 0.8715399  0.9675877  0.8741431\n",
      " 0.980809   0.96808463 0.99703133 0.98269695 0.880045   0.99597627\n",
      " 0.7618221  0.6363205  0.9824818  0.9388797  0.92642426 0.9977731\n",
      " 0.6588276  0.7920383  0.97507054 0.95393795 0.9900712  0.99416274\n",
      " 0.9891929  0.81596303 0.9983101  0.98583317 0.9946042  0.5126906\n",
      " 0.7520087  0.98243135]\n",
      "The rewards are: [0.81738526 0.99877805 0.84570706 0.8900545  0.8589128  0.89370847\n",
      " 0.9955481  0.9681281  0.99031806 0.82685876 0.90514314 0.8020042\n",
      " 0.6576923  0.99219537 0.99324566 0.98423    0.8238427  0.8049635\n",
      " 0.9947319  0.9503445  0.8889121  0.99043405 0.7968593  0.9153811\n",
      " 0.5764204  0.98931026 0.96687794 0.97618777 0.9946101  0.90512013\n",
      " 0.94036937 0.9995466 ]\n",
      "The rewards are: [0.92996925 0.82453376 0.81732863 0.9482771  0.9871974  0.9884272\n",
      " 0.9333487  0.90624726 0.80157715 0.987298   0.99625766 0.9921744\n",
      " 0.9899158  0.6455036  0.7617225  0.98243713 0.99798584 0.9081347\n",
      " 0.9496769  0.98053956 0.989066   0.97026217 0.78479666 0.9713454\n",
      " 0.99365    0.9635704  0.6580524  0.98405325 0.9366645  0.6986883\n",
      " 0.9785507  0.96291256]\n",
      "The rewards are: [0.8551633  0.9535305  0.9873237  0.9933206  0.9793285  0.53589165\n",
      " 0.9427065  0.84497315 0.987716   0.62428135 0.990573   0.7413847\n",
      " 0.9358034  0.8967743  0.6267278  0.99394953 0.97722226 0.7689862\n",
      " 0.8626221  0.982228   0.997059   0.9473149  0.7345473  0.835375\n",
      " 0.63712245 0.8444186  0.5238738  0.94192976 0.9402204  0.9705411\n",
      " 0.6937857  0.9785129 ]\n",
      "The rewards are: [0.98803467 0.9164095  0.9385815  0.9994332  0.9156879  0.9872612\n",
      " 0.9560089  0.9781014  0.9145667  0.84962    0.8481299  0.96234804\n",
      " 0.70029134 0.5341432  0.76756275 0.57526004 0.9476522  0.9963715\n",
      " 0.99007845 0.76817656 0.64219075 0.9545817  0.9972492  0.96530414\n",
      " 0.93941146 0.9494542  0.89126337 0.9244123  0.986628   0.86711836\n",
      " 0.9139882  0.9774566 ]\n",
      "The rewards are: [0.995195   0.97660404 0.9929997  0.99593276 0.9931605  0.9929462\n",
      " 0.9772157  0.99709094 0.8538398  0.99893135 0.8910711  0.9510709\n",
      " 0.9773771  0.8363951  0.9211736  0.9940057  0.63147646 0.9857767\n",
      " 0.9748121  0.97474664 0.9290492  0.997686   0.99339664 0.9310114\n",
      " 0.7567421  0.90400445 0.5574603  0.9902874  0.9082152  0.985399\n",
      " 0.9466897  0.962088  ]\n",
      "The rewards are: [0.894974   0.9814388  0.97595084 0.9963349  0.8757716  0.98730254\n",
      " 0.8810185  0.64824355 0.94267106 0.9956728  0.530252   0.9942584\n",
      " 0.9748274  0.9119595  0.70733374 0.78193593 0.99452764 0.98927885\n",
      " 0.96171045 0.9527476  0.90392494 0.9948225  0.97362995 0.9981913\n",
      " 0.99689555 0.9450448  0.7235871  0.9787067  0.9865736  0.9424172\n",
      " 0.99683857 0.98890543]\n",
      "The rewards are: [0.9450562  0.9902569  0.990542   0.86438227 0.72269374 0.95187545\n",
      " 0.95538175 0.50506413 0.96732426 0.9105299  0.9945608  0.9863295\n",
      " 0.99592495 0.96381843 0.98419964 0.9919675  0.9063342  0.88161767\n",
      " 0.8167609  0.9961338  0.82311714 0.9990644  0.9870854  0.9396573\n",
      " 0.8199896  0.96661013 0.9909791  0.9851377  0.94013286 0.8738437\n",
      " 0.79428685 0.93166673]\n",
      "The rewards are: [0.9078265  0.8765919  0.9730376  0.83052665 0.7100479  0.8682171\n",
      " 0.8176612  0.9214769  0.97910106 0.984233   0.9874281  0.5609716\n",
      " 0.6833781  0.99896765 0.9881765  0.98054594 0.99183756 0.9696637\n",
      " 0.9940566  0.99318165 0.998312   0.9758237  0.79417366 0.8657009\n",
      " 0.9979809  0.97557235 0.9987815  0.9994661  0.8414584  0.7691885\n",
      " 0.95523924 0.5994449 ]\n",
      "The rewards are: [0.9642824  0.96505684 0.98343974 0.74977773 0.96822774 0.92564\n",
      " 0.99093163 0.9797372  0.9726743  0.995624   0.9110845  0.6170201\n",
      " 0.9245634  0.5785805  0.88253    0.98703396 0.98231536 0.99347925\n",
      " 0.92965996 0.9732901  0.9937177  0.9596858  0.6816447  0.9685416\n",
      " 0.9869391  0.98599374 0.9944904  0.7747999  0.69275165 0.8588426\n",
      " 0.86867356 0.9782615 ]\n",
      "The rewards are: [0.8228627  0.9639114  0.93288964 0.99839056 0.9718461  0.90318733\n",
      " 0.95771235 0.97154266 0.9781179  0.97334146 0.84090847 0.9680217\n",
      " 0.77952605 0.96507305 0.77350366 0.99007565 0.9879539  0.99785787\n",
      " 0.9760602  0.9939948  0.9993332  0.9995974  0.91587186 0.94976676\n",
      " 0.9878564  0.9934356  0.6678777  0.89101523 0.8865202  0.9940627\n",
      " 0.982545   0.9970853 ]\n",
      "The rewards are: [0.88801837 0.72870636 0.7951269  0.99054796 0.99533314 0.99619424\n",
      " 0.9906899  0.8512577  0.92123437 0.9871875  0.9447122  0.9958525\n",
      " 0.99689734 0.91232663 0.94165826 0.99447614 0.9605962  0.73067003\n",
      " 0.99945146 0.9927906  0.9637926  0.9735801  0.98416626 0.8143885\n",
      " 0.9946108  0.94492024 0.8108253  0.99095166 0.9803074  0.90232533\n",
      " 0.95210373 0.991137  ]\n",
      "The rewards are: [0.987783   0.9872158  0.9923692  0.910425   0.7675191  0.9936347\n",
      " 0.93730146 0.98918706 0.9992028  0.9985915  0.8985458  0.9853394\n",
      " 0.9640225  0.62882    0.96186024 0.5407959  0.98762506 0.53136307\n",
      " 0.581858   0.84665936 0.78074557 0.9876494  0.9870918  0.9768486\n",
      " 0.9006722  0.98519725 0.9413013  0.9756034  0.8190691  0.9726668\n",
      " 0.9747567  0.986273  ]\n",
      "The rewards are: [0.9222447  0.88040304 0.90501475 0.9694006  0.98306954 0.99547666\n",
      " 0.98760986 0.9739906  0.94962054 0.509777   0.96794474 0.98007923\n",
      " 0.99652654 0.98801035 0.93312705 0.98708993 0.95412534 0.9962232\n",
      " 0.75589395 0.95483345 0.92639536 0.85896534 0.9789786  0.9254598\n",
      " 0.994441   0.97942674 0.699011   0.95648676 0.8643496  0.94140154\n",
      " 0.906564   0.9973048 ]\n",
      "The rewards are: [0.97499895 0.6659078  0.9534959  0.9974452  0.99570066 0.96497047\n",
      " 0.9955745  0.6174808  0.76774067 0.994392   0.5931316  0.7738594\n",
      " 0.9933222  0.9831624  0.7762322  0.6121196  0.97154003 0.9843126\n",
      " 0.9874356  0.8123683  0.9948908  0.5346477  0.99237144 0.9830626\n",
      " 0.9743937  0.8124632  0.79021347 0.5359935  0.9649281  0.99045557\n",
      " 0.8812499  0.93634164]\n",
      "The rewards are: [0.99245477 0.9117621  0.93546987 0.879272   0.73482126 0.98754126\n",
      " 0.9933537  0.98967665 0.83468884 0.99921405 0.9858198  0.9961808\n",
      " 0.98913294 0.99516666 0.50235337 0.804035   0.81764704 0.6306961\n",
      " 0.99789447 0.82877403 0.56412625 0.9989685  0.56400836 0.95967263\n",
      " 0.7578994  0.9972613  0.9629595  0.9932667  0.98225135 0.9429933\n",
      " 0.99719256 0.9866052 ]\n",
      "The rewards are: [0.9981742  0.93979275 0.99657494 0.9880228  0.99491656 0.9040717\n",
      " 0.8935627  0.7887504  0.91516036 0.7942546  0.971782   0.95208323\n",
      " 0.8643411  0.9971169  0.54076016 0.99430877 0.9175858  0.98810005\n",
      " 0.9768058  0.9520721  0.9923414  0.82078135 0.9598521  0.99208575\n",
      " 0.9875244  0.9301245  0.98241985 0.93310225 0.70446825 0.99668545\n",
      " 0.879938   0.9712352 ]\n",
      "The rewards are: [0.54429525 0.9946197  0.9578034  0.8567101  0.8873199  0.93428844\n",
      " 0.99201304 0.93578553 0.854395   0.61501414 0.5069798  0.77655685\n",
      " 0.62098354 0.9218281  0.9590406  0.65743804 0.9870396  0.84753346\n",
      " 0.98520225 0.9480382  0.98468506 0.9920311  0.99431396 0.97546333\n",
      " 0.60628945 0.9693745  0.78173214 0.9811291  0.9957474  0.9776242\n",
      " 0.9905212  0.97629875]\n",
      "The rewards are: [0.97106093 0.5038473  0.9627097  0.99787056 0.9848029  0.9811576\n",
      " 0.84995663 0.5191475  0.9955041  0.97022027 0.99082726 0.98778874\n",
      " 0.988607   0.91273296 0.64946467 0.9632038  0.64617616 0.99877375\n",
      " 0.8804744  0.7949943  0.5219097  0.9543058  0.9581986  0.9974293\n",
      " 0.98984444 0.9580527  0.54496247 0.9958967  0.53901756 0.90829456\n",
      " 0.55380625 0.87923646]\n",
      "The rewards are: [0.9856354  0.8647413  0.87863123 0.6090175  0.9954184  0.99544513\n",
      " 0.99161327 0.5304716  0.7393031  0.9824165  0.81651795 0.9285358\n",
      " 0.9787177  0.8382849  0.9838843  0.9536856  0.9732624  0.8397493\n",
      " 0.99557376 0.97559017 0.9797473  0.9873865  0.9988286  0.68261874\n",
      " 0.97938436 0.89201605 0.9556346  0.9931115  0.96090496 0.9985298\n",
      " 0.92398983 0.9279226 ]\n",
      "The rewards are: [0.5241774  0.99857116 0.98867536 0.99790645 0.9866899  0.9956892\n",
      " 0.9863891  0.55687505 0.8547002  0.99770975 0.9668396  0.8497676\n",
      " 0.9860453  0.9923923  0.95860934 0.98331267 0.5002853  0.99785256\n",
      " 0.9961992  0.97729295 0.63054997 0.6682769  0.99439114 0.80148834\n",
      " 0.95327127 0.535846   0.8061674  0.7145813  0.9716945  0.926019\n",
      " 0.9972415  0.7458371 ]\n",
      "The rewards are: [0.97733235 0.9835207  0.9949196  0.6233883  0.9500441  0.9771494\n",
      " 0.9970739  0.98628706 0.9913618  0.6842899  0.9913606  0.9979498\n",
      " 0.7938867  0.9681409  0.5313843  0.7022047  0.99808794 0.9045218\n",
      " 0.50536776 0.99499017 0.96079403 0.9868249  0.9906295  0.99408215\n",
      " 0.9790117  0.95914155 0.997357   0.88915277 0.97594756 0.9257217\n",
      " 0.52414685 0.96417266]\n",
      "The rewards are: [0.998941   0.9910568  0.99635726 0.9934255  0.96246874 0.97855604\n",
      " 0.8972678  0.59912074 0.83102274 0.998204   0.91902554 0.9817139\n",
      " 0.8909871  0.98835117 0.90695506 0.99730265 0.9751374  0.9879507\n",
      " 0.99161315 0.9328329  0.8694122  0.98479384 0.9989453  0.7650684\n",
      " 0.69781613 0.9850476  0.95613736 0.99601716 0.95422345 0.94480157\n",
      " 0.99953926 0.8772426 ]\n",
      "The rewards are: [0.9264722  0.79542947 0.9548758  0.91294056 0.70263386 0.99470466\n",
      " 0.80663836 0.9950971  0.99858594 0.9873554  0.87546396 0.8907978\n",
      " 0.98271793 0.9928844  0.7010302  0.9731424  0.63726526 0.9932018\n",
      " 0.95303375 0.5471669  0.9355216  0.9949739  0.86590654 0.9828096\n",
      " 0.95119774 0.6079149  0.946888   0.95721227 0.95778    0.99580187\n",
      " 0.9409611  0.88806033]\n",
      "The rewards are: [0.9839715  0.9868563  0.99548906 0.8844318  0.94889903 0.9609008\n",
      " 0.9605504  0.9964798  0.9968548  0.82043386 0.88994694 0.96892035\n",
      " 0.98863333 0.9480342  0.58663875 0.9974644  0.99926454 0.9566856\n",
      " 0.96989566 0.98394245 0.9865892  0.9891635  0.96184105 0.9497229\n",
      " 0.9482836  0.99269694 0.9937564  0.96780425 0.97041    0.96995944\n",
      " 0.9860481  0.98295456]\n",
      "The rewards are: [0.97860533 0.948289   0.9537098  0.9780026  0.8775798  0.98252136\n",
      " 0.9973387  0.9934982  0.6973565  0.9854768  0.99397475 0.9400213\n",
      " 0.9767284  0.9966221  0.9854446  0.9800382  0.9498482  0.8130667\n",
      " 0.9908599  0.99363023 0.95085704 0.7070434  0.99450654 0.82590777\n",
      " 0.995769   0.7628315  0.9791499  0.9803964  0.99443936 0.979782\n",
      " 0.9800371  0.9963043 ]\n",
      "The rewards are: [0.9972312  0.6814855  0.98836994 0.8764366  0.9350978  0.989139\n",
      " 0.87979436 0.9939737  0.9000516  0.8775832  0.9541568  0.9910787\n",
      " 0.9435437  0.96635187 0.8602234  0.98547363 0.99417996 0.58398074\n",
      " 0.83564705 0.98507094 0.76782537 0.9904011  0.9880614  0.993149\n",
      " 0.9602139  0.7910252  0.9806066  0.96958375 0.89265925 0.95365673\n",
      " 0.97485006 0.997004  ]\n",
      "The rewards are: [0.9753743  0.9449091  0.9888786  0.9957918  0.9789893  0.9747977\n",
      " 0.9392725  0.9670045  0.9774844  0.9752035  0.9908964  0.78583616\n",
      " 0.9364092  0.9216299  0.9284846  0.7496693  0.54504913 0.99298686\n",
      " 0.9738037  0.93521976 0.97725725 0.9197555  0.8155553  0.9648393\n",
      " 0.9921821  0.99902713 0.98834383 0.9720773  0.8922431  0.95650446\n",
      " 0.95139116 0.9906791 ]\n",
      "The rewards are: [0.6198575  0.9740831  0.73087645 0.8229658  0.6200355  0.957337\n",
      " 0.8093834  0.99355435 0.9370305  0.813848   0.99529254 0.8152256\n",
      " 0.85787606 0.787955   0.98491967 0.6159932  0.97275937 0.9807765\n",
      " 0.9210994  0.9143738  0.9875004  0.7224704  0.9207992  0.98964816\n",
      " 0.94658756 0.9618569  0.94477594 0.99275994 0.94203067 0.7530562\n",
      " 0.93038255 0.99272424]\n",
      "The rewards are: [0.7731436  0.7932584  0.92772436 0.99661046 0.9962185  0.8376198\n",
      " 0.95872307 0.9904942  0.99944824 0.9509904  0.6504221  0.99920076\n",
      " 0.6143187  0.9599625  0.9886763  0.70945096 0.99788195 0.9987184\n",
      " 0.83120126 0.8661342  0.9327924  0.7916669  0.9435977  0.92454666\n",
      " 0.96961796 0.85554826 0.6979892  0.8669746  0.8724369  0.98386556\n",
      " 0.9918493  0.9798004 ]\n",
      "The rewards are: [0.978312   0.98364025 0.720465   0.9959566  0.6907466  0.9929838\n",
      " 0.98778486 0.9935191  0.9941875  0.96652424 0.92860717 0.99656016\n",
      " 0.99131304 0.8654278  0.89557356 0.9891533  0.99260396 0.7466932\n",
      " 0.9936261  0.8639687  0.99594975 0.9988914  0.9955407  0.9880833\n",
      " 0.997551   0.98527133 0.9922795  0.99854326 0.9970975  0.99208856\n",
      " 0.99437076 0.9035327 ]\n",
      "The rewards are: [0.99261534 0.9965913  0.9903751  0.6700326  0.91730565 0.9963027\n",
      " 0.56579113 0.7085927  0.96308786 0.9908922  0.97112095 0.9997521\n",
      " 0.8935436  0.9835169  0.96569186 0.7287007  0.93060195 0.9885206\n",
      " 0.65914184 0.90436584 0.9969404  0.88898826 0.99445385 0.980082\n",
      " 0.9905133  0.95357937 0.98355156 0.7494325  0.97618836 0.9568445\n",
      " 0.9716573  0.98861676]\n",
      "The rewards are: [0.95732576 0.99888164 0.9981298  0.7254882  0.9714451  0.9928745\n",
      " 0.99460876 0.9629676  0.95588297 0.9640652  0.94318    0.92339736\n",
      " 0.7389358  0.99419326 0.97810704 0.982668   0.9889787  0.9940584\n",
      " 0.826787   0.98739064 0.8508339  0.9935336  0.82890046 0.95225906\n",
      " 0.98340696 0.9975101  0.99545926 0.99149936 0.9519293  0.99787736\n",
      " 0.9741202  0.99915266]\n",
      "The rewards are: [0.9390031  0.59941864 0.9810145  0.99837095 0.9941829  0.9917597\n",
      " 0.99486464 0.87635267 0.94856125 0.9545097  0.9948     0.9949515\n",
      " 0.9742674  0.97432774 0.98243666 0.98686314 0.9257297  0.9881791\n",
      " 0.95064884 0.92065024 0.988644   0.93150526 0.6585048  0.80005664\n",
      " 0.88735294 0.7588742  0.6749602  0.6399291  0.7639891  0.96465164\n",
      " 0.9908897  0.96044606]\n",
      "The rewards are: [0.9517206  0.9970024  0.9538108  0.78782    0.9843158  0.96594894\n",
      " 0.9201666  0.9131886  0.7720002  0.93000543 0.8658477  0.9915758\n",
      " 0.9923969  0.8053606  0.93300927 0.9868499  0.905392   0.97419465\n",
      " 0.7994772  0.76010925 0.9164029  0.9928911  0.9868199  0.94891673\n",
      " 0.9965965  0.8046062  0.9949744  0.97592145 0.99573225 0.9940078\n",
      " 0.8434562  0.57464194]\n",
      "The rewards are: [0.97536975 0.90177476 0.82623607 0.98319995 0.923468   0.9340436\n",
      " 0.8022499  0.8369207  0.9844082  0.9961726  0.9948673  0.5332703\n",
      " 0.86886317 0.97843516 0.8411423  0.87586194 0.99492395 0.9528533\n",
      " 0.8823807  0.9843969  0.99328125 0.9926063  0.83661926 0.71838844\n",
      " 0.83300704 0.75981563 0.79603267 0.79409266 0.9273636  0.89919525\n",
      " 0.99409926 0.95539826]\n",
      "The rewards are: [0.5164304  0.99603456 0.6617424  0.64901716 0.988701   0.99648726\n",
      " 0.9110888  0.9379313  0.9981694  0.9956909  0.9080973  0.64130646\n",
      " 0.97126323 0.98403615 0.99541855 0.57011634 0.84461635 0.95025945\n",
      " 0.9739516  0.98827446 0.9834014  0.9823017  0.82822907 0.98326886\n",
      " 0.9721229  0.7802851  0.98889416 0.9867513  0.9997881  0.9956813\n",
      " 0.8896211  0.80415004]\n",
      "The rewards are: [0.884645   0.98476994 0.5292275  0.6251942  0.99644333 0.9678321\n",
      " 0.9872017  0.9321879  0.99137455 0.99342537 0.9350323  0.9852142\n",
      " 0.9826376  0.684233   0.9865085  0.81979877 0.8716074  0.9867466\n",
      " 0.79775655 0.9851951  0.5273116  0.9984432  0.99300945 0.88592756\n",
      " 0.998769   0.9931005  0.99273795 0.9951558  0.9333582  0.79989964\n",
      " 0.8941893  0.97363347]\n",
      "The rewards are: [0.86006147 0.9861594  0.96448773 0.6970148  0.95463145 0.9126201\n",
      " 0.96697646 0.7181342  0.9869379  0.9210903  0.7818452  0.78630126\n",
      " 0.9860935  0.98230505 0.89554554 0.9677298  0.98515517 0.8771676\n",
      " 0.9994042  0.9905563  0.9737529  0.9527966  0.9921383  0.9504233\n",
      " 0.9635508  0.9904636  0.896563   0.7907751  0.9533222  0.9856135\n",
      " 0.9833376  0.9513905 ]\n",
      "The rewards are: [0.996051   0.99821115 0.9757106  0.679483   0.9943732  0.9896039\n",
      " 0.5699053  0.98006356 0.9384231  0.99674267 0.8212894  0.99865806\n",
      " 0.96361434 0.9644046  0.7989222  0.99329364 0.9585852  0.9846154\n",
      " 0.938663   0.991968   0.98751825 0.89718586 0.98967266 0.9959841\n",
      " 0.90677804 0.982271   0.98567563 0.97348547 0.94643563 0.87509096\n",
      " 0.9584147  0.5597517 ]\n",
      "The rewards are: [0.99888605 0.9043635  0.98746556 0.98310584 0.55771446 0.9915583\n",
      " 0.908151   0.5081648  0.99458045 0.9694947  0.95222205 0.9674608\n",
      " 0.8467765  0.99656576 0.96953535 0.624059   0.7146308  0.9201241\n",
      " 0.99463356 0.76741654 0.9648212  0.99468493 0.9908478  0.955411\n",
      " 0.93524873 0.9957404  0.9418363  0.9886276  0.9938737  0.98206294\n",
      " 0.96156526 0.9837196 ]\n",
      "The rewards are: [0.994632   0.73714095 0.9711594  0.9609502  0.87863505 0.9885113\n",
      " 0.98666245 0.9898461  0.93666923 0.78042704 0.9311443  0.9871853\n",
      " 0.7001408  0.9445277  0.9592157  0.9993247  0.97173136 0.9966589\n",
      " 0.9682493  0.7700835  0.86095244 0.57553357 0.51476586 0.9745472\n",
      " 0.85022974 0.97344196 0.9983871  0.7942983  0.9717818  0.99343055\n",
      " 0.994101   0.9410036 ]\n",
      "The rewards are: [0.63160306 0.9791836  0.8892886  0.7516624  0.8338918  0.99291515\n",
      " 0.88419384 0.97452646 0.98631024 0.991247   0.99130636 0.98775685\n",
      " 0.9868881  0.63766426 0.976163   0.9476226  0.9864725  0.82734907\n",
      " 0.9463111  0.97865444 0.75351375 0.7114395  0.9947436  0.98620474\n",
      " 0.9449282  0.7795318  0.5067764  0.984854   0.8733945  0.63024163\n",
      " 0.9947536  0.97500175]\n",
      "The rewards are: [0.86616224 0.6418722  0.98816735 0.9635234  0.53895086 0.8719335\n",
      " 0.99861324 0.9366509  0.842587   0.9799385  0.95294315 0.9870608\n",
      " 0.8443571  0.9918976  0.99742055 0.91880524 0.99940145 0.9904891\n",
      " 0.9750635  0.9872652  0.99570763 0.98426324 0.61300325 0.5441513\n",
      " 0.9330825  0.9738883  0.7672924  0.91521597 0.998538   0.71810645\n",
      " 0.96375704 0.9789104 ]\n",
      "The rewards are: [0.9951627  0.9705658  0.97939533 0.6570548  0.9827853  0.9814404\n",
      " 0.99281365 0.954905   0.98932356 0.9893349  0.9328249  0.9831812\n",
      " 0.9717642  0.9771549  0.9885118  0.9804205  0.66667557 0.7340884\n",
      " 0.9676999  0.94213957 0.9333669  0.9809687  0.88972366 0.9689866\n",
      " 0.7541646  0.9195211  0.9799151  0.9017353  0.98907745 0.9968964\n",
      " 0.9813818  0.98588866]\n",
      "The rewards are: [0.98561263 0.87902826 0.9870843  0.9591783  0.5105114  0.9022659\n",
      " 0.96391433 0.98696125 0.99778724 0.9946355  0.6342203  0.99727446\n",
      " 0.7750292  0.7057096  0.75270087 0.6036749  0.9674969  0.98700005\n",
      " 0.7488066  0.99276924 0.9639531  0.9974663  0.9807928  0.5336961\n",
      " 0.9437061  0.99170285 0.52966225 0.95766336 0.93788266 0.9437134\n",
      " 0.995852   0.90109414]\n",
      "The rewards are: [0.9893435  0.99668854 0.98002625 0.9925615  0.9441438  0.9985461\n",
      " 0.63569504 0.9964619  0.9786679  0.97945213 0.828726   0.92630094\n",
      " 0.9109873  0.948462   0.99340963 0.98552173 0.9857901  0.9895955\n",
      " 0.9960998  0.89285344 0.9178368  0.993168   0.9641044  0.9346794\n",
      " 0.9558365  0.92917794 0.991396   0.8908845  0.8749756  0.99633384\n",
      " 0.97908825 0.99918073]\n",
      "The rewards are: [0.9996928  0.9459901  0.98636055 0.99354833 0.9156848  0.9185141\n",
      " 0.8447389  0.96414065 0.97444916 0.92451304 0.96420383 0.97898096\n",
      " 0.5553224  0.9919669  0.9852506  0.77056    0.5314352  0.71777105\n",
      " 0.9962542  0.9224941  0.97836655 0.9986308  0.668994   0.9231983\n",
      " 0.9859432  0.9752728  0.7926495  0.99617565 0.9987692  0.9957997\n",
      " 0.8159344  0.8786354 ]\n",
      "The rewards are: [0.78406954 0.87444466 0.9541859  0.9736179  0.99303705 0.9865797\n",
      " 0.9858041  0.99342126 0.9466289  0.8387241  0.9845382  0.9742545\n",
      " 0.722926   0.8552038  0.99758375 0.84820014 0.93001574 0.99008524\n",
      " 0.50742453 0.97346354 0.89327806 0.99889684 0.9906156  0.9998511\n",
      " 0.9618722  0.98303795 0.96888506 0.9747472  0.99546576 0.97298604\n",
      " 0.7186222  0.9406333 ]\n",
      "The rewards are: [0.99775034 0.8992669  0.9800537  0.9911883  0.95981514 0.9823646\n",
      " 0.9447716  0.9803218  0.99750227 0.99075764 0.53963524 0.88158053\n",
      " 0.9765038  0.68076473 0.8678129  0.99082774 0.98481894 0.99163413\n",
      " 0.98038656 0.7345883  0.9974366  0.99598527 0.9896281  0.98898494\n",
      " 0.96726906 0.9462489  0.9348526  0.96503884 0.5324516  0.9985012\n",
      " 0.99743277 0.9935616 ]\n",
      "The rewards are: [0.98594344 0.7383806  0.977883   0.98502827 0.9865891  0.9871351\n",
      " 0.9745238  0.9758985  0.9976247  0.7780934  0.99589336 0.9865057\n",
      " 0.99712175 0.85328376 0.9588425  0.97363484 0.5605086  0.548899\n",
      " 0.99739647 0.9927971  0.9136135  0.97877055 0.9907198  0.80210936\n",
      " 0.9525337  0.99756193 0.98488784 0.9972097  0.97049034 0.9617807\n",
      " 0.9955915  0.900393  ]\n",
      "The rewards are: [0.99646324 0.6018428  0.9930506  0.99256355 0.9958061  0.9365232\n",
      " 0.99253285 0.99441296 0.8510397  0.9895549  0.7700401  0.99662364\n",
      " 0.98128235 0.9892579  0.98516154 0.60403067 0.98841465 0.98129153\n",
      " 0.9967777  0.9296717  0.98671603 0.6553863  0.71162134 0.925601\n",
      " 0.9992048  0.9980421  0.9981768  0.8274081  0.7730377  0.97996855\n",
      " 0.7948707  0.9917523 ]\n",
      "The rewards are: [0.9958151  0.99822825 0.87844914 0.8617456  0.98838544 0.9976821\n",
      " 0.9783652  0.9204579  0.9744622  0.8099115  0.99503005 0.84107095\n",
      " 0.9671496  0.948203   0.97919947 0.9930494  0.9832356  0.9757581\n",
      " 0.8826234  0.9562673  0.9287069  0.9648666  0.99532974 0.9661171\n",
      " 0.9934542  0.6238408  0.8788397  0.9992405  0.987023   0.89025354\n",
      " 0.96355814 0.9915258 ]\n",
      "The rewards are: [0.98415226 0.97378683 0.9874434  0.95889497 0.9957146  0.99384344\n",
      " 0.7566766  0.99269414 0.9838508  0.9364468  0.9556143  0.9909338\n",
      " 0.99601233 0.9323506  0.98791236 0.9844281  0.5326357  0.9972428\n",
      " 0.84451574 0.98329145 0.9914048  0.9494215  0.99846363 0.91088325\n",
      " 0.78907657 0.9943598  0.9828844  0.9105472  0.9856448  0.99833786\n",
      " 0.99897087 0.9796466 ]\n",
      "The rewards are: [0.61028904 0.87420666 0.97775614 0.9301895  0.99194825 0.99699426\n",
      " 0.98265195 0.99803036 0.90132445 0.97722584 0.9957904  0.9791951\n",
      " 0.9916568  0.997517   0.9955231  0.9912531  0.9719648  0.9974746\n",
      " 0.96094173 0.95640737 0.9892047  0.564006   0.82503873 0.9602771\n",
      " 0.99538994 0.9876879  0.99649245 0.9944132  0.971809   0.8015127\n",
      " 0.9887572  0.82585156]\n",
      "The rewards are: [0.97782624 0.9147177  0.665172   0.8431909  0.9463425  0.99698204\n",
      " 0.6144074  0.6660162  0.964712   0.9735256  0.9485963  0.87891215\n",
      " 0.87514627 0.9943982  0.9936911  0.9996087  0.9153542  0.9995326\n",
      " 0.59155166 0.9561368  0.5836354  0.9928895  0.9952792  0.9531464\n",
      " 0.98766696 0.99006724 0.99724716 0.9692449  0.99582976 0.99802315\n",
      " 0.8315189  0.9236309 ]\n",
      "The rewards are: [0.92726845 0.85022324 0.8456033  0.96260494 0.6972409  0.5685334\n",
      " 0.8936865  0.9187899  0.9483855  0.99805415 0.8065918  0.94510984\n",
      " 0.9883935  0.8677569  0.9741649  0.99908566 0.9082342  0.9974613\n",
      " 0.61909735 0.59373134 0.96399266 0.986053   0.9922733  0.9947996\n",
      " 0.9933409  0.9191751  0.74302065 0.9872019  0.6659416  0.9547202\n",
      " 0.9523995  0.99150485]\n",
      "The rewards are: [0.99871683 0.6236755  0.996363   0.6696148  0.97487324 0.9949846\n",
      " 0.86095965 0.999196   0.9193361  0.97410226 0.9863338  0.88850737\n",
      " 0.9892876  0.9945702  0.95125014 0.95633805 0.99925584 0.98652333\n",
      " 0.996402   0.7910615  0.99796665 0.97602034 0.5389129  0.9501931\n",
      " 0.9977228  0.8817057  0.9890948  0.9921325  0.996259   0.7702653\n",
      " 0.9905551  0.99823546]\n",
      "The rewards are: [0.9771912  0.6332933  0.9891166  0.99789786 0.9948512  0.9600565\n",
      " 0.99064726 0.9863919  0.94136244 0.94758445 0.9983486  0.5029405\n",
      " 0.99246913 0.9902906  0.9700621  0.9420723  0.9914465  0.97973275\n",
      " 0.6593634  0.7702676  0.9544131  0.9888236  0.7708286  0.9968298\n",
      " 0.962185   0.8384807  0.68662125 0.95641357 0.70733535 0.9968971\n",
      " 0.99446833 0.8828019 ]\n",
      "The rewards are: [0.97096753 0.98472613 0.97481924 0.970279   0.9689454  0.9993137\n",
      " 0.5752978  0.95258397 0.9934604  0.9217748  0.5292666  0.9507554\n",
      " 0.8449033  0.99768543 0.82711077 0.9991534  0.98354995 0.9880712\n",
      " 0.99578047 0.846734   0.9090696  0.97808707 0.9939505  0.5338581\n",
      " 0.6648594  0.9933733  0.9851328  0.9450599  0.5592509  0.9455404\n",
      " 0.9922131  0.9960763 ]\n",
      "The rewards are: [0.9608069  0.99923205 0.7228601  0.9976617  0.9938408  0.92747694\n",
      " 0.87477565 0.98237693 0.99736917 0.98468935 0.82568926 0.8864801\n",
      " 0.91550815 0.9933415  0.73213863 0.69187564 0.9900643  0.99509144\n",
      " 0.99338466 0.9793323  0.7380708  0.852904   0.9825784  0.7779355\n",
      " 0.96372926 0.8679638  0.949708   0.98774976 0.9836526  0.6613949\n",
      " 0.6816579  0.9471974 ]\n",
      "The rewards are: [0.97754717 0.9954809  0.8839843  0.7059988  0.98252743 0.8879755\n",
      " 0.9882036  0.74304986 0.9864928  0.9841027  0.98349774 0.978296\n",
      " 0.5204253  0.99764365 0.9970675  0.9995208  0.99643975 0.930124\n",
      " 0.99483454 0.998667   0.90905917 0.7470204  0.99319565 0.9891501\n",
      " 0.96003836 0.9910028  0.58777374 0.5908523  0.99472964 0.68096316\n",
      " 0.97342074 0.9946679 ]\n",
      "The rewards are: [0.8451469  0.9154406  0.6561816  0.9559217  0.9862006  0.9856172\n",
      " 0.9621582  0.9977276  0.77902824 0.9848246  0.8929543  0.7775972\n",
      " 0.9966576  0.98092765 0.98845637 0.8172849  0.9807958  0.99810743\n",
      " 0.987666   0.8283961  0.7610122  0.86793435 0.89735615 0.71510243\n",
      " 0.9812123  0.9902119  0.996212   0.98753625 0.6734402  0.9954341\n",
      " 0.9167543  0.9936185 ]\n",
      "The rewards are: [0.90574735 0.7475493  0.99290234 0.835275   0.9944537  0.6165581\n",
      " 0.99807125 0.9971528  0.68075204 0.6367352  0.9623794  0.98891824\n",
      " 0.93309706 0.99066556 0.99927765 0.9959478  0.99520147 0.9712256\n",
      " 0.90499115 0.83337396 0.9918839  0.7059971  0.946119   0.93743235\n",
      " 0.9359443  0.945328   0.9885972  0.7913576  0.9883796  0.9898408\n",
      " 0.9842169  0.9955995 ]\n",
      "The rewards are: [0.9649912  0.99894124 0.98744035 0.6742617  0.99831665 0.99400204\n",
      " 0.9999007  0.98492014 0.83527553 0.9980038  0.99070615 0.9930754\n",
      " 0.99706084 0.7967727  0.997068   0.9841903  0.9922661  0.9405716\n",
      " 0.9887782  0.8520848  0.9630418  0.8831088  0.93030155 0.97897035\n",
      " 0.66200364 0.9418381  0.79553306 0.9890941  0.9794831  0.6483434\n",
      " 0.98257935 0.97262156]\n",
      "The rewards are: [0.96507907 0.99798787 0.93761784 0.99772054 0.989297   0.73085755\n",
      " 0.9954991  0.989251   0.99787724 0.98575264 0.9997813  0.6721861\n",
      " 0.88761926 0.9489847  0.97643334 0.99970764 0.98291653 0.935585\n",
      " 0.78921264 0.99179596 0.90131104 0.91647685 0.9611846  0.93290883\n",
      " 0.9956189  0.99799526 0.9896986  0.9658383  0.7764639  0.97852147\n",
      " 0.99627316 0.58122694]\n",
      "The rewards are: [0.987346   0.9978879  0.98612624 0.96016103 0.99975187 0.9741521\n",
      " 0.9961637  0.94344294 0.9854885  0.97208697 0.7366605  0.94148713\n",
      " 0.9006956  0.9870336  0.9878092  0.9517586  0.9114651  0.98034316\n",
      " 0.99754614 0.92215043 0.9988576  0.97105163 0.9822933  0.88549036\n",
      " 0.9796363  0.9988569  0.9800913  0.9913611  0.9931757  0.67919433\n",
      " 0.51869166 0.9956672 ]\n",
      "The rewards are: [0.9316901  0.8355814  0.9767254  0.9945235  0.9937099  0.9759108\n",
      " 0.94779944 0.8395966  0.7772734  0.7718555  0.9177915  0.993178\n",
      " 0.99889874 0.67883784 0.98870754 0.99654984 0.980232   0.78904146\n",
      " 0.86372983 0.71892476 0.9927129  0.98314387 0.99934775 0.99645716\n",
      " 0.9736259  0.7089201  0.89048856 0.9957438  0.98513734 0.81939775\n",
      " 0.7408999  0.9874844 ]\n",
      "The rewards are: [0.98421836 0.9971425  0.5885604  0.9548178  0.99645364 0.9653329\n",
      " 0.9922442  0.99777585 0.5010823  0.9921985  0.99851495 0.89218044\n",
      " 0.9949309  0.9888164  0.86976546 0.98749965 0.9474059  0.8645123\n",
      " 0.77063    0.70349807 0.993979   0.9905855  0.9807273  0.70351034\n",
      " 0.93314993 0.99337935 0.582115   0.9566399  0.84985846 0.8731124\n",
      " 0.9783186  0.649208  ]\n",
      "The rewards are: [0.9571088  0.9731267  0.6127802  0.9474814  0.9719962  0.9922463\n",
      " 0.99810636 0.9692377  0.9600265  0.9942602  0.9958835  0.9933563\n",
      " 0.9812664  0.5111274  0.91783136 0.98590314 0.9818595  0.99693525\n",
      " 0.86368847 0.99139047 0.76824313 0.9888699  0.9857721  0.8886068\n",
      " 0.9922219  0.9995838  0.5424722  0.96173704 0.8860121  0.9856107\n",
      " 0.9961349  0.52886444]\n",
      "The rewards are: [0.994293   0.99825424 0.75056857 0.99283653 0.9953679  0.9009043\n",
      " 0.9947635  0.9248644  0.9564498  0.9913863  0.99979895 0.9947667\n",
      " 0.8973609  0.985727   0.60514957 0.6616408  0.9574152  0.99650985\n",
      " 0.9356809  0.9831504  0.98543906 0.9492195  0.9774973  0.5801704\n",
      " 0.96615446 0.8586682  0.9977894  0.9988218  0.95494115 0.99752766\n",
      " 0.98173517 0.9905296 ]\n",
      "The rewards are: [0.908677   0.9234145  0.83986795 0.98502964 0.98919326 0.930555\n",
      " 0.9773425  0.9979255  0.8081711  0.7942654  0.99432725 0.6335594\n",
      " 0.965155   0.99906665 0.89860886 0.9962464  0.99859256 0.79595\n",
      " 0.991882   0.98525846 0.9910691  0.9090721  0.92527336 0.9723956\n",
      " 0.9793698  0.9989498  0.9956624  0.95913446 0.9982553  0.835241\n",
      " 0.9613071  0.9963523 ]\n",
      "The rewards are: [0.8772149  0.8326635  0.9779614  0.6237306  0.5600673  0.98827374\n",
      " 0.99377924 0.9803966  0.9395293  0.5030024  0.5976542  0.95534104\n",
      " 0.9954417  0.99703395 0.95333344 0.97498566 0.9578746  0.5216769\n",
      " 0.99858    0.98329216 0.9565782  0.9479524  0.99502254 0.9701412\n",
      " 0.98650265 0.99950457 0.9983191  0.9803741  0.809744   0.99807835\n",
      " 0.75530416 0.9995977 ]\n",
      "The rewards are: [0.9949944  0.9905256  0.9724711  0.96895427 0.9816388  0.5313809\n",
      " 0.70966464 0.9930942  0.7493316  0.9870443  0.94359386 0.98669004\n",
      " 0.99774134 0.9989893  0.9969754  0.9956909  0.95068085 0.97056645\n",
      " 0.9974285  0.97537166 0.9571525  0.98473454 0.9289211  0.9915044\n",
      " 0.96845955 0.9977186  0.9771896  0.99843115 0.9890009  0.99547005\n",
      " 0.9828896  0.9197568 ]\n",
      "The rewards are: [0.99066275 0.8625364  0.5781585  0.9815201  0.5079032  0.9727006\n",
      " 0.8708805  0.96672976 0.9961255  0.9424414  0.97255343 0.98717195\n",
      " 0.84956807 0.99619234 0.958641   0.6582016  0.9907898  0.81739926\n",
      " 0.987783   0.9842833  0.9981864  0.9284491  0.96057045 0.83567476\n",
      " 0.99201375 0.9271002  0.99090356 0.9959675  0.98687845 0.94291687\n",
      " 0.9527252  0.98592013]\n",
      "The rewards are: [0.974243   0.7587913  0.9987257  0.929614   0.9905129  0.7788162\n",
      " 0.9924589  0.99456173 0.99591655 0.9460381  0.9317148  0.9943453\n",
      " 0.99731135 0.9522878  0.9975109  0.9929543  0.84120345 0.9908897\n",
      " 0.98313546 0.99727494 0.9973239  0.9986779  0.5897804  0.9569532\n",
      " 0.93812186 0.9740528  0.9951397  0.99573946 0.98657227 0.98059833\n",
      " 0.9736439  0.6543831 ]\n",
      "The rewards are: [0.9769206  0.9891165  0.64850056 0.998781   0.9338873  0.9948143\n",
      " 0.9248009  0.9915488  0.95761436 0.9464149  0.9946097  0.8670324\n",
      " 0.9258729  0.7939349  0.9940732  0.99624324 0.9872049  0.97700626\n",
      " 0.9921983  0.82987756 0.9842567  0.7227976  0.92696583 0.9275152\n",
      " 0.98830974 0.88465255 0.9765968  0.91727406 0.99749136 0.9982216\n",
      " 0.5863359  0.960389  ]\n",
      "The rewards are: [0.9429712  0.98961407 0.99836403 0.8789222  0.98782116 0.9114636\n",
      " 0.9423796  0.98085254 0.8950433  0.6848068  0.9603993  0.9790536\n",
      " 0.9938379  0.9965145  0.51252717 0.9942801  0.9473902  0.8977657\n",
      " 0.98939884 0.9800617  0.69542974 0.5534819  0.97353303 0.9600606\n",
      " 0.74577695 0.9887989  0.9826066  0.99721754 0.92741346 0.6869532\n",
      " 0.59119326 0.93648726]\n",
      "The rewards are: [0.7774408  0.79617923 0.84481573 0.9677618  0.988724   0.99725515\n",
      " 0.9934651  0.70742613 0.6052876  0.7535308  0.9953237  0.98645043\n",
      " 0.91617316 0.9931659  0.99434435 0.95513546 0.9923382  0.97617155\n",
      " 0.99530077 0.85570353 0.99761885 0.90248877 0.90985024 0.99799144\n",
      " 0.9338248  0.93958116 0.62906575 0.99199706 0.55982554 0.979066\n",
      " 0.9663104  0.9677522 ]\n",
      "The rewards are: [0.9863848  0.6652459  0.9193346  0.9703836  0.98664135 0.9940057\n",
      " 0.99531037 0.9504073  0.98504436 0.9974004  0.9545867  0.663943\n",
      " 0.8944583  0.99914634 0.82388633 0.9975752  0.7116321  0.62008375\n",
      " 0.99056256 0.80558187 0.99712497 0.93336016 0.9095226  0.9426118\n",
      " 0.9935499  0.68018764 0.97032344 0.98593706 0.9650906  0.9883808\n",
      " 0.9532729  0.9995466 ]\n",
      "The rewards are: [0.9202178  0.9628034  0.9855392  0.9718778  0.98877966 0.9965502\n",
      " 0.73593074 0.9665713  0.9898615  0.80802697 0.595271   0.99735886\n",
      " 0.6470424  0.98184574 0.94977784 0.89343643 0.995691   0.9971841\n",
      " 0.9207118  0.9962923  0.7172207  0.81499213 0.9959726  0.92011696\n",
      " 0.99107647 0.98071265 0.8035736  0.59011924 0.99421906 0.94620746\n",
      " 0.9786744  0.9687122 ]\n",
      "The rewards are: [0.9823169  0.8721312  0.96134776 0.9337663  0.942717   0.80115736\n",
      " 0.57931465 0.9966049  0.9864725  0.6795057  0.9992575  0.8578138\n",
      " 0.98883575 0.9774278  0.9934628  0.8948239  0.9890598  0.9800046\n",
      " 0.52547824 0.9955478  0.8640055  0.7262733  0.9935448  0.99307126\n",
      " 0.99887043 0.88553274 0.72461146 0.9977428  0.98323894 0.9495033\n",
      " 0.93767107 0.9923211 ]\n",
      "The rewards are: [0.52438    0.9950708  0.853771   0.995155   0.5466899  0.9045688\n",
      " 0.99672616 0.9956644  0.9887998  0.7953632  0.95739895 0.7365782\n",
      " 0.9972627  0.9578899  0.9508485  0.9693516  0.6402554  0.97771865\n",
      " 0.96524626 0.9960181  0.9997459  0.9844589  0.74006635 0.9957623\n",
      " 0.9941261  0.98317313 0.8539923  0.99543613 0.83131963 0.9152211\n",
      " 0.99408156 0.9112315 ]\n",
      "The rewards are: [0.8123302  0.87549824 0.9961876  0.9193672  0.9804638  0.99144757\n",
      " 0.9897578  0.94963723 0.97770214 0.93266684 0.6479702  0.9891732\n",
      " 0.9912708  0.9941825  0.9504639  0.9989814  0.97769266 0.98834455\n",
      " 0.9685318  0.995187   0.9372301  0.9870912  0.9867929  0.97914404\n",
      " 0.7383468  0.8417127  0.9160185  0.9845271  0.99723226 0.6325115\n",
      " 0.54887056 0.97593564]\n",
      "The rewards are: [0.9881976  0.74307257 0.9902018  0.94085544 0.6341942  0.9997452\n",
      " 0.99164504 0.9916168  0.67376196 0.9872493  0.9833235  0.9876944\n",
      " 0.8565823  0.71321386 0.9469306  0.9190562  0.96529037 0.9662194\n",
      " 0.6354616  0.9638543  0.8868506  0.70226777 0.9978631  0.99756455\n",
      " 0.99109346 0.99446154 0.99889815 0.99160004 0.97621673 0.599785\n",
      " 0.9471927  0.9955556 ]\n",
      "The rewards are: [0.98418045 0.9124615  0.99799037 0.9978969  0.9986785  0.99892104\n",
      " 0.8160234  0.9693542  0.99384177 0.98550004 0.9613523  0.9073565\n",
      " 0.9515295  0.98840415 0.68460983 0.9982358  0.9881849  0.61239064\n",
      " 0.8917237  0.5162955  0.6670208  0.940553   0.99384034 0.96593815\n",
      " 0.96697414 0.9829008  0.9535986  0.99939597 0.6297318  0.7906461\n",
      " 0.9970657  0.97629607]\n",
      "The rewards are: [0.8254534  0.99737215 0.606108   0.9213254  0.9962441  0.8075031\n",
      " 0.96222985 0.9919869  0.9987225  0.97253394 0.99934286 0.9793017\n",
      " 0.9867041  0.7357828  0.99577457 0.59924006 0.9974795  0.7511748\n",
      " 0.78330827 0.7127958  0.52125657 0.99604094 0.99536103 0.9871573\n",
      " 0.5943993  0.9917874  0.98547757 0.5248104  0.97336483 0.95964825\n",
      " 0.9664099  0.99665135]\n",
      "The rewards are: [0.997396   0.95066726 0.97972304 0.98894984 0.9858714  0.9782835\n",
      " 0.7195888  0.95436645 0.9758444  0.7195887  0.8934867  0.604974\n",
      " 0.5124984  0.8607133  0.9979266  0.9107473  0.94089675 0.7664285\n",
      " 0.97667015 0.9905911  0.9347282  0.9942789  0.6815664  0.9685024\n",
      " 0.9870396  0.9667268  0.96235454 0.9678046  0.9431229  0.951143\n",
      " 0.9143341  0.99413896]\n",
      "The rewards are: [0.9765686  0.9910512  0.96648115 0.73216265 0.9919464  0.9132948\n",
      " 0.8144144  0.90894115 0.9606657  0.9471316  0.9612626  0.88813335\n",
      " 0.98003644 0.95788574 0.9936098  0.9350257  0.99073434 0.8380534\n",
      " 0.9930227  0.9687987  0.9654397  0.9927289  0.51263547 0.9956092\n",
      " 0.9723407  0.9995449  0.9795466  0.9967438  0.96860665 0.7228478\n",
      " 0.99115294 0.98932195]\n",
      "The rewards are: [0.9856295  0.8238195  0.9932012  0.88827926 0.99319285 0.9876265\n",
      " 0.9428683  0.9645247  0.98116666 0.9992206  0.8733741  0.98345655\n",
      " 0.9790733  0.96717024 0.7525598  0.99657637 0.92069614 0.7335872\n",
      " 0.98897773 0.98489517 0.917628   0.99473566 0.9616169  0.99880946\n",
      " 0.9592872  0.99418736 0.68855286 0.9810869  0.9592371  0.8774344\n",
      " 0.99398744 0.55170035]\n",
      "The rewards are: [0.9948454  0.75429946 0.994169   0.9976846  0.92612433 0.9274292\n",
      " 0.8989612  0.9929685  0.97953653 0.98423725 0.6405792  0.996262\n",
      " 0.9890898  0.9213161  0.98250455 0.57880306 0.97571045 0.88785344\n",
      " 0.98989946 0.9009498  0.9914102  0.9775634  0.8836349  0.7927666\n",
      " 0.95900416 0.80742425 0.94403213 0.9975249  0.9969291  0.96683663\n",
      " 0.8849311  0.9987626 ]\n",
      "The rewards are: [0.8118286  0.9933635  0.99651766 0.97071123 0.96587867 0.9974738\n",
      " 0.9028952  0.9968176  0.9758567  0.84601265 0.6794654  0.9954822\n",
      " 0.8114019  0.96272755 0.99054855 0.9894321  0.9750186  0.9907375\n",
      " 0.90048474 0.9853697  0.8840389  0.98528093 0.9853586  0.98744476\n",
      " 0.7375888  0.99957913 0.89941597 0.96026003 0.99745995 0.9706782\n",
      " 0.99626875 0.96787095]\n",
      "The rewards are: [0.7873524  0.99306995 0.90814143 0.97296125 0.95229524 0.98293346\n",
      " 0.64310175 0.9930005  0.8888795  0.53338295 0.997001   0.89797455\n",
      " 0.886397   0.79825306 0.9335916  0.9898045  0.9285263  0.87670547\n",
      " 0.9962218  0.99930346 0.9935714  0.9900519  0.9440874  0.9910636\n",
      " 0.8375194  0.896663   0.51359636 0.80646783 0.5851475  0.9083755\n",
      " 0.98570377 0.9979608 ]\n",
      "The rewards are: [0.9975497  0.99564505 0.84665835 0.98983616 0.98693186 0.5243331\n",
      " 0.75161713 0.9874936  0.9868122  0.9992441  0.99813914 0.8055986\n",
      " 0.9979892  0.9848549  0.9598237  0.96594894 0.99655765 0.98673266\n",
      " 0.99801874 0.96382165 0.9610744  0.76391244 0.9948832  0.5933438\n",
      " 0.8393398  0.9420816  0.96715975 0.9527927  0.9792043  0.99685705\n",
      " 0.9995722  0.9979322 ]\n",
      "The rewards are: [0.9069047  0.99623436 0.984444   0.7731115  0.99424404 0.99103045\n",
      " 0.92902786 0.98705715 0.9409195  0.9319549  0.9689388  0.9748039\n",
      " 0.99207485 0.9914454  0.9455996  0.87370765 0.9183625  0.96474075\n",
      " 0.99957436 0.9989178  0.96267265 0.99268264 0.7610225  0.99329513\n",
      " 0.98974353 0.9792556  0.8742331  0.64962614 0.7496159  0.9786612\n",
      " 0.9934098  0.8454958 ]\n",
      "The rewards are: [0.99862075 0.96402454 0.98770034 0.99509084 0.6036947  0.9908426\n",
      " 0.9696928  0.98754185 0.99785125 0.85797083 0.84812343 0.9905094\n",
      " 0.5316711  0.71668214 0.98549694 0.9128843  0.7027336  0.7199089\n",
      " 0.5312611  0.99093294 0.9568444  0.93716145 0.98593765 0.9914437\n",
      " 0.8161926  0.9951379  0.96045893 0.84185916 0.9816275  0.98975676\n",
      " 0.9726228  0.9604906 ]\n",
      "The rewards are: [0.9830908  0.96871895 0.98365235 0.99427587 0.98450166 0.50054777\n",
      " 0.97641194 0.7249665  0.9742061  0.95369685 0.9738017  0.98369664\n",
      " 0.9980482  0.9973514  0.9854735  0.8446667  0.9911246  0.99105316\n",
      " 0.997552   0.9814167  0.87590456 0.8549566  0.8983272  0.9985537\n",
      " 0.9973158  0.9798591  0.9981939  0.79027045 0.92940253 0.6009862\n",
      " 0.9949763  0.9897433 ]\n",
      "The rewards are: [0.9947983  0.974979   0.66085476 0.99628276 0.97490704 0.98039573\n",
      " 0.93756837 0.9909373  0.988318   0.9800789  0.9953635  0.8417676\n",
      " 0.8669717  0.99857664 0.9908921  0.99961996 0.9156278  0.9952276\n",
      " 0.9968882  0.99393106 0.9994355  0.9773089  0.99382174 0.9845685\n",
      " 0.9945793  0.9374441  0.9808668  0.9670811  0.99456406 0.9862578\n",
      " 0.7621383  0.97836304]\n",
      "The rewards are: [0.9980788  0.85316515 0.9635152  0.6184026  0.9932134  0.9451828\n",
      " 0.8307413  0.752322   0.9989593  0.83056974 0.9966217  0.9317761\n",
      " 0.9994412  0.954782   0.7616768  0.9443773  0.8338614  0.6146297\n",
      " 0.91523844 0.994645   0.93018824 0.9528626  0.9958574  0.98635894\n",
      " 0.8944771  0.99900454 0.89422107 0.70460105 0.9962565  0.9676443\n",
      " 0.9847535  0.9831634 ]\n",
      "The rewards are: [0.9938491  0.9961719  0.6605739  0.7229048  0.9981375  0.98823136\n",
      " 0.89587617 0.9238343  0.9589089  0.9969779  0.9181676  0.93698746\n",
      " 0.9715388  0.98778546 0.8758677  0.5265424  0.8819865  0.97899616\n",
      " 0.9975126  0.8696166  0.9675318  0.96723735 0.9713877  0.88615835\n",
      " 0.69081223 0.9674268  0.9190592  0.9859013  0.9687591  0.9948655\n",
      " 0.99858105 0.99312043]\n",
      "The rewards are: [0.90727437 0.9401394  0.9759468  0.99122506 0.95772326 0.9991767\n",
      " 0.7234794  0.9773582  0.90386933 0.9107087  0.98941666 0.9997538\n",
      " 0.9970059  0.9843127  0.97757226 0.839436   0.98461807 0.9942544\n",
      " 0.994909   0.9964191  0.9569293  0.98503774 0.98255205 0.98787284\n",
      " 0.6895389  0.79434764 0.9989497  0.9484498  0.98055434 0.9826403\n",
      " 0.998061   0.7840721 ]\n",
      "The rewards are: [0.9642349  0.9900011  0.98646694 0.79680634 0.9956346  0.9879996\n",
      " 0.57509387 0.8720032  0.9864719  0.99016094 0.99663603 0.9723389\n",
      " 0.965691   0.9906267  0.9988514  0.9922718  0.8914434  0.98335624\n",
      " 0.9330509  0.9442587  0.98693454 0.9982857  0.97788596 0.9153688\n",
      " 0.9918936  0.9914794  0.99078596 0.5455373  0.99538815 0.9587184\n",
      " 0.9659638  0.863746  ]\n",
      "The rewards are: [0.9990588  0.9386616  0.8513152  0.97598696 0.95036507 0.9983163\n",
      " 0.9941414  0.8804183  0.9228626  0.99360424 0.97548205 0.94560665\n",
      " 0.7569114  0.9843279  0.9979583  0.945625   0.9735594  0.99553055\n",
      " 0.9949207  0.8409064  0.9183013  0.69981915 0.7315577  0.9831234\n",
      " 0.9732967  0.9585713  0.98981184 0.9958748  0.9993333  0.9835293\n",
      " 0.8687132  0.9565476 ]\n",
      "The rewards are: [0.886795   0.9812841  0.9966331  0.6555098  0.89784575 0.9509685\n",
      " 0.9860319  0.97855717 0.9361725  0.9960078  0.78366506 0.56221825\n",
      " 0.9915837  0.9930489  0.8732125  0.9978362  0.99855834 0.96981186\n",
      " 0.9890659  0.9938047  0.995971   0.8982422  0.9993272  0.91353893\n",
      " 0.9917067  0.6705658  0.8696263  0.98460984 0.7652429  0.88014966\n",
      " 0.96908915 0.8015275 ]\n",
      "The rewards are: [0.9773917  0.9903348  0.9891635  0.6630623  0.9968363  0.998949\n",
      " 0.9914977  0.99534094 0.6571214  0.5974367  0.9976749  0.9905716\n",
      " 0.93405837 0.7348932  0.954078   0.57402533 0.8034728  0.99613416\n",
      " 0.86584103 0.99036354 0.7772069  0.8358784  0.59074    0.99009645\n",
      " 0.9554943  0.9904552  0.81555605 0.9965209  0.9958331  0.9893482\n",
      " 0.9798636  0.9571787 ]\n",
      "The rewards are: [0.8323895  0.9983747  0.9254405  0.9911408  0.9991321  0.9613392\n",
      " 0.9611062  0.79769653 0.98921645 0.84024566 0.99460125 0.7922318\n",
      " 0.97445655 0.9842905  0.9586113  0.9892793  0.7235154  0.5100295\n",
      " 0.9907087  0.71819746 0.747258   0.98260224 0.98333144 0.91731286\n",
      " 0.9968753  0.99249154 0.9968362  0.9929755  0.9984498  0.9896421\n",
      " 0.9015999  0.9993098 ]\n",
      "The rewards are: [0.99125504 0.9035176  0.73652524 0.8085296  0.9777759  0.9906376\n",
      " 0.78793305 0.7648013  0.99361426 0.87961197 0.88904905 0.97562057\n",
      " 0.92217875 0.95985514 0.9423414  0.991751   0.9955788  0.60175824\n",
      " 0.9526591  0.9751775  0.5711257  0.99949    0.9984372  0.9680855\n",
      " 0.9456145  0.98700094 0.8956523  0.9922077  0.9961404  0.9927608\n",
      " 0.9626302  0.98930347]\n",
      "The rewards are: [0.9992704  0.99960726 0.86208    0.9941111  0.7969728  0.98313427\n",
      " 0.9925442  0.73383754 0.5272586  0.9984408  0.593731   0.87586063\n",
      " 0.9768315  0.7840747  0.9183888  0.9926267  0.9550589  0.8152262\n",
      " 0.9879261  0.9862477  0.9981206  0.8647081  0.9971048  0.9988619\n",
      " 0.6130612  0.9877951  0.9906131  0.99155325 0.988846   0.8430136\n",
      " 0.98887223 0.99688643]\n",
      "The rewards are: [0.9966001  0.9921205  0.9589341  0.9885357  0.9836007  0.9801964\n",
      " 0.90598094 0.8892612  0.9818308  0.9901697  0.9841568  0.9416856\n",
      " 0.7292741  0.8463062  0.7250545  0.9594415  0.774297   0.9993124\n",
      " 0.9108608  0.9904544  0.99920386 0.5278192  0.9877507  0.9967925\n",
      " 0.9338419  0.7446916  0.69017    0.73228914 0.9880574  0.99836046\n",
      " 0.99143654 0.99296427]\n",
      "The rewards are: [0.7821235  0.9991258  0.8931336  0.74877924 0.9726954  0.972551\n",
      " 0.98876053 0.9981509  0.84553945 0.9992705  0.960735   0.9980677\n",
      " 0.9186323  0.98906904 0.94662434 0.9984022  0.99122393 0.99804246\n",
      " 0.9867682  0.98946023 0.9470136  0.9478878  0.98268753 0.9300635\n",
      " 0.99013853 0.98104596 0.93326813 0.68019354 0.98717123 0.8738991\n",
      " 0.98240906 0.9981517 ]\n",
      "The rewards are: [0.73808545 0.9976858  0.988567   0.74720985 0.983114   0.99866676\n",
      " 0.95562094 0.8981041  0.98057646 0.9934089  0.9989988  0.99784184\n",
      " 0.99534684 0.99004155 0.9896143  0.98163855 0.92869353 0.9626433\n",
      " 0.9717914  0.9774957  0.61187685 0.86183846 0.7704327  0.69221085\n",
      " 0.99028367 0.99639064 0.9927125  0.9766857  0.993152   0.5515921\n",
      " 0.99012774 0.941763  ]\n",
      "The rewards are: [0.9951315  0.99306893 0.98360026 0.80958325 0.97550553 0.96327156\n",
      " 0.99567693 0.99301684 0.772727   0.99922013 0.98836434 0.9848609\n",
      " 0.9953092  0.9909967  0.93923336 0.9981085  0.9723503  0.9883581\n",
      " 0.9556329  0.94225    0.99180675 0.9645858  0.9933351  0.9984748\n",
      " 0.99446094 0.99485886 0.95350724 0.8792799  0.96650076 0.9935434\n",
      " 0.9969741  0.88261986]\n",
      "The rewards are: [0.9648569  0.96720093 0.97919697 0.9285662  0.97146344 0.9746018\n",
      " 0.9915053  0.9971943  0.998543   0.9962792  0.6843049  0.9909305\n",
      " 0.9867756  0.9308339  0.75396115 0.916597   0.9990915  0.8955261\n",
      " 0.9335551  0.98967135 0.9948218  0.8866515  0.91342497 0.98927605\n",
      " 0.9920656  0.99605113 0.9953992  0.9810307  0.96637136 0.89149845\n",
      " 0.99523735 0.99834406]\n",
      "The rewards are: [0.9969735  0.98926604 0.90944904 0.65702647 0.8848235  0.9853216\n",
      " 0.9463648  0.9778592  0.98943245 0.90290636 0.8025139  0.9824981\n",
      " 0.9335715  0.9890731  0.98765194 0.9960483  0.89589804 0.9483827\n",
      " 0.9987206  0.90960604 0.9499987  0.99691224 0.8113509  0.7894359\n",
      " 0.9943362  0.99837303 0.9613771  0.9857757  0.8986413  0.9911773\n",
      " 0.9578024  0.9927268 ]\n",
      "The rewards are: [0.9976937  0.92284405 0.9912918  0.70710593 0.990864   0.7342797\n",
      " 0.9901362  0.9967025  0.99804413 0.9924378  0.60134286 0.96260405\n",
      " 0.995236   0.9878576  0.524172   0.9883117  0.9367144  0.9980508\n",
      " 0.8260172  0.99854267 0.713068   0.9961844  0.9896568  0.9976937\n",
      " 0.8371297  0.9938446  0.98487604 0.99070543 0.8250723  0.9994815\n",
      " 0.86151433 0.9931051 ]\n",
      "The rewards are: [0.9914801  0.99810874 0.9874587  0.9790749  0.9703936  0.9880612\n",
      " 0.95927507 0.99407566 0.94035196 0.9167209  0.8739171  0.9964534\n",
      " 0.90851736 0.9801835  0.6772534  0.99379575 0.8290064  0.9982535\n",
      " 0.98482764 0.99907744 0.9574386  0.96729183 0.99967146 0.9981858\n",
      " 0.84206563 0.99075127 0.89137423 0.6543125  0.9784877  0.66828024\n",
      " 0.99328023 0.99669075]\n",
      "The rewards are: [0.9478798  0.9978114  0.9958187  0.9980229  0.90875083 0.9997749\n",
      " 0.8433551  0.98401135 0.9304795  0.99759525 0.99074465 0.6239817\n",
      " 0.99221545 0.98455864 0.9967758  0.92359287 0.98917705 0.97923\n",
      " 0.9903502  0.9718603  0.70710456 0.98249614 0.9961572  0.90316564\n",
      " 0.87162846 0.9973646  0.9949104  0.7367077  0.908899   0.8984457\n",
      " 0.86626244 0.9011647 ]\n",
      "The rewards are: [0.99945694 0.93672127 0.56949574 0.5070332  0.99322766 0.98904026\n",
      " 0.89911675 0.9977316  0.9257099  0.9773142  0.93823195 0.9714149\n",
      " 0.985989   0.76191443 0.99643373 0.9749547  0.9670329  0.977\n",
      " 0.9864802  0.92758226 0.8035383  0.9877273  0.7955651  0.99798125\n",
      " 0.99625045 0.98206055 0.8676167  0.99833447 0.9605445  0.9736641\n",
      " 0.9958026  0.998988  ]\n",
      "The rewards are: [0.9964887  0.54258513 0.8711306  0.94844455 0.8773629  0.9862536\n",
      " 0.9946742  0.99002975 0.9931465  0.9952814  0.64802575 0.9120907\n",
      " 0.9730182  0.80608433 0.8844417  0.6979633  0.89082813 0.9818579\n",
      " 0.99372286 0.89352775 0.98343086 0.90958345 0.9863164  0.6189432\n",
      " 0.96578693 0.97704095 0.8227979  0.99847513 0.99388254 0.8482036\n",
      " 0.99134517 0.97848755]\n",
      "The rewards are: [0.9550949  0.9989441  0.990694   0.8665995  0.70751846 0.9985145\n",
      " 0.9767526  0.6277795  0.976398   0.8813312  0.9835343  0.73965514\n",
      " 0.978205   0.98304856 0.9983015  0.9577348  0.9903758  0.67284805\n",
      " 0.99875534 0.8967582  0.99947363 0.8825074  0.90113366 0.7477179\n",
      " 0.82000583 0.7047622  0.9978064  0.8732343  0.58797735 0.9961119\n",
      " 0.9304056  0.9990006 ]\n",
      "The rewards are: [0.96542025 0.99255943 0.9929571  0.9924022  0.95426387 0.97540057\n",
      " 0.9724813  0.9959065  0.99524033 0.9876061  0.97988874 0.99692386\n",
      " 0.89139044 0.997088   0.9375424  0.50337255 0.9879062  0.9164409\n",
      " 0.9995303  0.98784864 0.99676526 0.9916005  0.9964265  0.9956038\n",
      " 0.9408739  0.9597382  0.99865216 0.578447   0.9991536  0.98204446\n",
      " 0.9863797  0.92074335]\n",
      "The rewards are: [0.8282416  0.98593175 0.9931757  0.6882263  0.97512335 0.99240947\n",
      " 0.81214267 0.6532077  0.9776494  0.94395286 0.9997234  0.99820185\n",
      " 0.94787014 0.99318975 0.92362905 0.8924696  0.9915319  0.9357138\n",
      " 0.99854386 0.9845099  0.9963883  0.99304366 0.98641807 0.9916202\n",
      " 0.93538004 0.99515426 0.94607246 0.9989681  0.99400973 0.9881727\n",
      " 0.99079084 0.99930954]\n",
      "The rewards are: [0.9985884  0.98363435 0.9870363  0.96138895 0.99788755 0.9983499\n",
      " 0.99386096 0.97148347 0.99020517 0.9928703  0.9781804  0.924097\n",
      " 0.866905   0.91134846 0.86064476 0.9998847  0.99830437 0.993626\n",
      " 0.8311209  0.9728218  0.7627974  0.9898039  0.99948287 0.92073613\n",
      " 0.988497   0.96927065 0.9914415  0.81484526 0.9317611  0.91254574\n",
      " 0.7820318  0.98868924]\n",
      "The rewards are: [0.5493639  0.7940416  0.9996213  0.9976793  0.97867304 0.9597383\n",
      " 0.9938751  0.75940377 0.90491724 0.9991843  0.9562711  0.99432325\n",
      " 0.8207318  0.9478851  0.98199064 0.99672925 0.93356144 0.8217794\n",
      " 0.96814394 0.85056454 0.9880112  0.95234275 0.99565375 0.9919593\n",
      " 0.9847652  0.9955265  0.9551475  0.83062357 0.94324726 0.98574615\n",
      " 0.6522896  0.5803004 ]\n",
      "The rewards are: [0.6234572  0.98444206 0.56555134 0.9057785  0.96586    0.6741865\n",
      " 0.9975249  0.9958508  0.9957377  0.65093565 0.9988726  0.9892636\n",
      " 0.91804755 0.9970798  0.98225063 0.8623221  0.98966646 0.9943403\n",
      " 0.6910795  0.99047977 0.7362446  0.5315449  0.96523994 0.9822114\n",
      " 0.9972687  0.89413995 0.9990729  0.57108766 0.9336629  0.97450227\n",
      " 0.91370714 0.94954723]\n",
      "The rewards are: [0.9847017  0.6077449  0.56668097 0.9851332  0.9747456  0.9800315\n",
      " 0.98705715 0.98393863 0.99704283 0.81352204 0.9983279  0.9842279\n",
      " 0.9757176  0.9932921  0.7123304  0.99241513 0.9899249  0.99564916\n",
      " 0.98911804 0.9754901  0.869773   0.93284786 0.9278714  0.99869436\n",
      " 0.98495364 0.9873584  0.9967834  0.9746651  0.9997985  0.9818355\n",
      " 0.9910924  0.8087237 ]\n",
      "The rewards are: [0.6947724  0.9902942  0.6789678  0.9893197  0.9578383  0.9994764\n",
      " 0.990444   0.5180533  0.7104891  0.93297225 0.7310963  0.93562907\n",
      " 0.6583272  0.9897069  0.9560583  0.89415795 0.6581168  0.99125695\n",
      " 0.9838754  0.7105818  0.9933476  0.99155915 0.96341264 0.9201503\n",
      " 0.6705554  0.9899642  0.99862003 0.99149233 0.98620516 0.944261\n",
      " 0.9972377  0.9771444 ]\n",
      "The rewards are: [0.98019695 0.97906256 0.99943715 0.9959019  0.8001487  0.9956846\n",
      " 0.9969036  0.96701515 0.9902166  0.98328674 0.97458386 0.9577598\n",
      " 0.9789755  0.9981104  0.61932087 0.99553055 0.9719704  0.6192682\n",
      " 0.9884001  0.9259269  0.98721087 0.9965467  0.9982906  0.8848963\n",
      " 0.69207644 0.99821365 0.9880007  0.93911296 0.96067375 0.94487\n",
      " 0.9924694  0.55369675]\n",
      "The rewards are: [0.9897522  0.8360356  0.7309608  0.95917314 0.9954699  0.9937168\n",
      " 0.94636804 0.99154824 0.9976538  0.9572094  0.96074986 0.96828\n",
      " 0.99923575 0.58961254 0.53446424 0.99284655 0.95311046 0.80428606\n",
      " 0.8892054  0.961631   0.99828714 0.9958462  0.9946189  0.85088575\n",
      " 0.99221003 0.9914179  0.98384136 0.9977202  0.75531864 0.9993523\n",
      " 0.9969784  0.5752595 ]\n",
      "The rewards are: [0.5496643  0.98067254 0.97870135 0.79008394 0.9963715  0.99970585\n",
      " 0.74184895 0.9701052  0.9971107  0.5464679  0.9947739  0.9995111\n",
      " 0.96529025 0.99050516 0.9935923  0.82750386 0.9913306  0.98929846\n",
      " 0.97983164 0.9897774  0.69164264 0.9742904  0.5918924  0.9869757\n",
      " 0.89901066 0.9969863  0.9688492  0.9979672  0.94293284 0.97872263\n",
      " 0.9780694  0.91152453]\n",
      "The rewards are: [0.9588765  0.9839467  0.9918498  0.95406795 0.97760856 0.9976326\n",
      " 0.9718168  0.9872788  0.965115   0.82143164 0.97078115 0.99832016\n",
      " 0.9984086  0.96321946 0.9972696  0.9647786  0.9995963  0.9632236\n",
      " 0.5949115  0.5760833  0.9972499  0.99266785 0.92949194 0.74170494\n",
      " 0.54763407 0.976383   0.86246884 0.9914397  0.991703   0.53608453\n",
      " 0.99896264 0.6074685 ]\n",
      "The rewards are: [0.7244804  0.99957675 0.96323186 0.99289626 0.9770544  0.9335273\n",
      " 0.99858665 0.98716056 0.9952819  0.8679058  0.840008   0.98411363\n",
      " 0.9763425  0.98385066 0.9688338  0.6717537  0.91100776 0.99790645\n",
      " 0.9883349  0.97832835 0.5981263  0.9897585  0.5601012  0.97840333\n",
      " 0.933462   0.99547666 0.8602661  0.7047487  0.7266045  0.92847425\n",
      " 0.99835783 0.99269134]\n",
      "The rewards are: [0.9907418  0.9032518  0.98857415 0.7029165  0.5563544  0.9859184\n",
      " 0.99209654 0.9308282  0.54526556 0.9982664  0.99515224 0.88940024\n",
      " 0.97873366 0.99805164 0.58952117 0.99596655 0.9262778  0.9996984\n",
      " 0.976488   0.96238196 0.56724036 0.9992874  0.9599952  0.93482614\n",
      " 0.95454043 0.9982527  0.97814196 0.81128    0.99565953 0.8248992\n",
      " 0.80219007 0.90331864]\n",
      "The rewards are: [0.99905974 0.98255056 0.9953206  0.866028   0.9739333  0.9943211\n",
      " 0.93558747 0.99875104 0.97365487 0.88359964 0.9995944  0.98873085\n",
      " 0.99299556 0.98726904 0.9995877  0.9977429  0.8908513  0.99010265\n",
      " 0.5946134  0.981499   0.9892119  0.97602206 0.9997054  0.6354632\n",
      " 0.989781   0.99585587 0.9993117  0.9955102  0.6981689  0.993113\n",
      " 0.9801664  0.99638355]\n",
      "The rewards are: [0.8231722  0.99771225 0.7138999  0.9935401  0.9916945  0.998809\n",
      " 0.50628245 0.9575424  0.9958406  0.9868614  0.96254    0.91115206\n",
      " 0.9248096  0.96626675 0.99897075 0.9946339  0.9478883  0.96434504\n",
      " 0.9875107  0.8922176  0.9978472  0.98154575 0.99459547 0.84024787\n",
      " 0.87240595 0.869889   0.99789196 0.7814129  0.9924843  0.9919179\n",
      " 0.5452525  0.8761308 ]\n",
      "The rewards are: [0.99175805 0.99561137 0.9989876  0.9927545  0.9992555  0.99270225\n",
      " 0.9934969  0.9331182  0.9750872  0.99737394 0.994584   0.99574727\n",
      " 0.99284935 0.9809691  0.91609144 0.95973283 0.82191545 0.7610862\n",
      " 0.9804735  0.9562808  0.98088616 0.84981894 0.98495793 0.6603132\n",
      " 0.98480475 0.9995982  0.9893441  0.6279829  0.9957158  0.9286208\n",
      " 0.9903771  0.91981196]\n",
      "The rewards are: [0.9848946  0.5776901  0.9467352  0.5754997  0.9978027  0.99055195\n",
      " 0.993745   0.9441579  0.99911624 0.99217695 0.9300896  0.7755853\n",
      " 0.6661857  0.63581043 0.9102526  0.99591404 0.9001806  0.97335774\n",
      " 0.9973328  0.6472391  0.9988054  0.89787257 0.98954576 0.979345\n",
      " 0.52463084 0.95721465 0.9984396  0.90157956 0.86305577 0.99833006\n",
      " 0.9918223  0.51989037]\n",
      "The rewards are: [0.9993931  0.9252553  0.9227993  0.9927038  0.97740734 0.99025893\n",
      " 0.99792117 0.9998161  0.7966335  0.86454356 0.8599037  0.9448202\n",
      " 0.78304315 0.9872083  0.9964169  0.9987633  0.999741   0.99505925\n",
      " 0.99705493 0.95051104 0.9765304  0.99678063 0.88813627 0.9993672\n",
      " 0.911292   0.93192303 0.9615482  0.9205829  0.8402254  0.99875164\n",
      " 0.89351594 0.9893021 ]\n",
      "The rewards are: [0.7845779  0.99452823 0.99861944 0.9123671  0.99745315 0.99813336\n",
      " 0.99574137 0.9352562  0.9948714  0.98610175 0.99571997 0.99778265\n",
      " 0.5410497  0.99916065 0.96246606 0.7524717  0.6091696  0.9852958\n",
      " 0.99601483 0.5827933  0.90241987 0.96270514 0.91590357 0.98894846\n",
      " 0.94824094 0.9781636  0.99819463 0.96077806 0.996591   0.98241884\n",
      " 0.96624446 0.84965336]\n",
      "The rewards are: [0.98948354 0.9314946  0.58790547 0.9822459  0.8867608  0.6609434\n",
      " 0.98903733 0.97951084 0.97904223 0.9836379  0.95214826 0.9935638\n",
      " 0.96117514 0.99351126 0.927144   0.9976713  0.96563697 0.96380025\n",
      " 0.9943777  0.84380805 0.9980665  0.99683595 0.93403256 0.9916505\n",
      " 0.55937105 0.99197245 0.9932382  0.71338576 0.987375   0.9966428\n",
      " 0.78285015 0.98767406]\n",
      "The rewards are: [0.97846484 0.9919154  0.9988741  0.9983968  0.9935296  0.9996164\n",
      " 0.93434685 0.9943455  0.8264357  0.89094245 0.9512029  0.9960504\n",
      " 0.8733738  0.7109984  0.99035513 0.99839634 0.9592341  0.98686206\n",
      " 0.99657744 0.9997665  0.6359513  0.8354946  0.89474857 0.9959545\n",
      " 0.9667891  0.9360795  0.998672   0.99521    0.9223657  0.9792363\n",
      " 0.99300086 0.8122921 ]\n",
      "The rewards are: [0.9989612  0.8924911  0.9720143  0.9707252  0.8324605  0.98642737\n",
      " 0.9978877  0.50507355 0.988246   0.6718032  0.90978676 0.9991054\n",
      " 0.99623173 0.97429097 0.978381   0.99913603 0.97632617 0.99683017\n",
      " 0.88020355 0.9994411  0.99550974 0.9469438  0.55398077 0.8747066\n",
      " 0.9700824  0.97706634 0.995376   0.90114486 0.9904394  0.99504364\n",
      " 0.9457708  0.97729665]\n",
      "The rewards are: [0.9907504  0.9983145  0.98763835 0.92805475 0.9887449  0.96925664\n",
      " 0.9987078  0.9439379  0.9556558  0.9985304  0.87458605 0.9948021\n",
      " 0.99851173 0.9929387  0.9843568  0.99447423 0.9977239  0.80122554\n",
      " 0.88380724 0.9735014  0.97075677 0.9998122  0.69434005 0.99789447\n",
      " 0.9937773  0.7952116  0.9967169  0.90433735 0.9837532  0.5564905\n",
      " 0.96538126 0.99933416]\n",
      "The rewards are: [0.99859375 0.7989744  0.93168694 0.99953246 0.9965623  0.9842551\n",
      " 0.9630483  0.99931526 0.95075655 0.92210126 0.97303265 0.94294477\n",
      " 0.93095994 0.94301885 0.9946896  0.992589   0.99695206 0.9989517\n",
      " 0.97757703 0.8837311  0.98980135 0.9234043  0.99835795 0.98830205\n",
      " 0.9981572  0.8284477  0.5114429  0.9950964  0.51824903 0.96894526\n",
      " 0.877187   0.70072985]\n",
      "The rewards are: [0.9944495  0.96782804 0.9966988  0.9312361  0.8629498  0.97354996\n",
      " 0.9869288  0.9983499  0.76676553 0.87959224 0.9741337  0.99910635\n",
      " 0.98036927 0.91155654 0.9486652  0.9920041  0.97519284 0.99144685\n",
      " 0.90075624 0.996396   0.68733424 0.9988219  0.8010398  0.8385358\n",
      " 0.9931593  0.98927015 0.9988053  0.9575328  0.91146284 0.5018308\n",
      " 0.9128077  0.90232587]\n",
      "The rewards are: [0.99953806 0.99656063 0.7514535  0.92771596 0.98118836 0.94845134\n",
      " 0.61624604 0.98270535 0.94434816 0.5733118  0.9098757  0.9911532\n",
      " 0.73881686 0.992698   0.7742992  0.64024043 0.9818559  0.9998797\n",
      " 0.99787307 0.99455607 0.9872915  0.99905735 0.96344715 0.99686277\n",
      " 0.9722286  0.8564789  0.99786407 0.9847823  0.90318054 0.90358\n",
      " 0.9207328  0.8190659 ]\n",
      "The rewards are: [0.8747605  0.99843496 0.8514459  0.50992584 0.95858335 0.99608034\n",
      " 0.9858677  0.8753492  0.9958288  0.975964   0.87417567 0.98436546\n",
      " 0.99293727 0.99451643 0.8942324  0.6855749  0.59257776 0.9709485\n",
      " 0.9978715  0.9953194  0.9911876  0.62186825 0.67458105 0.99620855\n",
      " 0.98489296 0.997378   0.9868933  0.61515087 0.9784718  0.8798329\n",
      " 0.887968   0.9926307 ]\n",
      "The rewards are: [0.85746926 0.9939241  0.65012676 0.9929838  0.6605076  0.97905356\n",
      " 0.9991134  0.973913   0.99658513 0.8174138  0.9845673  0.98912084\n",
      " 0.8563604  0.70814806 0.9943304  0.9942736  0.9769308  0.88821226\n",
      " 0.7412211  0.9971529  0.85531765 0.9392725  0.9845249  0.99958974\n",
      " 0.83494127 0.9929109  0.9534925  0.7228683  0.98433304 0.92821383\n",
      " 0.9837338  0.98312044]\n",
      "The rewards are: [0.9933564  0.75611705 0.7408428  0.9915079  0.9989538  0.9996774\n",
      " 0.99391645 0.9881529  0.93336326 0.85356265 0.80201983 0.99948174\n",
      " 0.51084745 0.9352987  0.9623079  0.9858935  0.9879412  0.8371066\n",
      " 0.6747211  0.9891516  0.9504157  0.55623406 0.7618444  0.79039234\n",
      " 0.5881876  0.963174   0.9854554  0.9883618  0.86387676 0.9980155\n",
      " 0.99948955 0.9988803 ]\n",
      "The rewards are: [0.9732474  0.99293584 0.99287635 0.99139833 0.8708511  0.6494835\n",
      " 0.9676645  0.90283585 0.9070181  0.9594398  0.9859801  0.99584407\n",
      " 0.97435117 0.9896588  0.99698526 0.9949837  0.97775626 0.80413634\n",
      " 0.978457   0.75131553 0.99752694 0.98512775 0.9958164  0.91955155\n",
      " 0.9968098  0.98774487 0.9905743  0.9878489  0.9977901  0.961982\n",
      " 0.9510304  0.9947713 ]\n",
      "The rewards are: [0.99175596 0.78787965 0.99884903 0.9937697  0.98713326 0.9900383\n",
      " 0.9984097  0.9994228  0.9262014  0.9963882  0.97849107 0.9978846\n",
      " 0.9503201  0.9989003  0.76927215 0.9444847  0.7805395  0.93482256\n",
      " 0.7310101  0.88881004 0.9884643  0.98097575 0.98409384 0.9718112\n",
      " 0.9333991  0.9821547  0.98668647 0.9995615  0.9972485  0.96898645\n",
      " 0.94013053 0.6266318 ]\n",
      "The rewards are: [0.9985185  0.9791068  0.9898727  0.830043   0.9122629  0.82083935\n",
      " 0.983499   0.9938579  0.99598616 0.9677816  0.9932463  0.9078071\n",
      " 0.99649435 0.99437064 0.89598334 0.99723345 0.9738424  0.9980228\n",
      " 0.9861837  0.971501   0.7557333  0.99580765 0.9997743  0.9932422\n",
      " 0.99443924 0.99640936 0.99815565 0.6061838  0.8541214  0.8068622\n",
      " 0.9983204  0.90759367]\n",
      "The rewards are: [0.99100566 0.9983564  0.9991903  0.9923085  0.89156663 0.9940988\n",
      " 0.9942357  0.89234793 0.95224595 0.9974685  0.9978746  0.9091672\n",
      " 0.9985788  0.84382594 0.99261403 0.9985757  0.9621463  0.7860416\n",
      " 0.88958645 0.99013674 0.99102354 0.99694854 0.9864073  0.98609734\n",
      " 0.99861884 0.9899156  0.7599944  0.9983347  0.9937325  0.9981729\n",
      " 0.9826471  0.82339305]\n",
      "The rewards are: [0.9769696  0.8836661  0.9281461  0.9941717  0.77690655 0.97950375\n",
      " 0.8742505  0.9316215  0.9883129  0.98015565 0.9953696  0.8034678\n",
      " 0.83566123 0.9817615  0.9955095  0.99837387 0.9989324  0.9949615\n",
      " 0.9623686  0.99513394 0.9973053  0.9862428  0.9503997  0.59009296\n",
      " 0.9978289  0.9901737  0.5254289  0.6879595  0.9963404  0.99440706\n",
      " 0.97900224 0.99775547]\n",
      "The rewards are: [0.9969266  0.6882451  0.79591393 0.94926345 0.9968079  0.9856948\n",
      " 0.5368129  0.9545727  0.98179585 0.64890534 0.9985942  0.9599649\n",
      " 0.73674697 0.9998386  0.9966028  0.9816767  0.9278993  0.9850403\n",
      " 0.9368798  0.8411118  0.58384186 0.9930032  0.6571065  0.9928082\n",
      " 0.9937773  0.9934523  0.9954992  0.9957871  0.99922085 0.715581\n",
      " 0.7092805  0.69614863]\n",
      "The rewards are: [0.93566865 0.86923957 0.9890863  0.5697831  0.98374444 0.9988273\n",
      " 0.991779   0.86513746 0.9900041  0.64565283 0.98404574 0.99000084\n",
      " 0.99395704 0.9997298  0.99674726 0.9986357  0.9842956  0.91832554\n",
      " 0.9991448  0.97251385 0.6248599  0.9977755  0.968119   0.98162353\n",
      " 0.9378167  0.9997123  0.78631675 0.978742   0.91048324 0.72129214\n",
      " 0.9741168  0.98228604]\n",
      "The rewards are: [0.9905088  0.9981254  0.996163   0.73783624 0.992717   0.9771727\n",
      " 0.99643457 0.99083054 0.9955872  0.99505913 0.9877863  0.9959857\n",
      " 0.9498752  0.9848061  0.9706692  0.9992286  0.857622   0.90534663\n",
      " 0.8948236  0.9207567  0.5940028  0.9787016  0.9269561  0.5709189\n",
      " 0.9734542  0.86368996 0.79644525 0.87171197 0.99830353 0.9996234\n",
      " 0.94326335 0.9926139 ]\n",
      "The rewards are: [0.93974316 0.96266556 0.9997627  0.87865037 0.86986786 0.97883725\n",
      " 0.8952298  0.6431291  0.9898357  0.9971781  0.99419594 0.9965544\n",
      " 0.9018112  0.9814803  0.96909755 0.978742   0.9652426  0.97082335\n",
      " 0.9993469  0.9983228  0.96143526 0.95786583 0.93392277 0.84518504\n",
      " 0.9994287  0.9930929  0.9896034  0.8134379  0.9977913  0.99772924\n",
      " 0.9689869  0.98538893]\n",
      "The rewards are: [0.9066716  0.99978286 0.65837735 0.99014    0.9767845  0.9944851\n",
      " 0.9718322  0.89840937 0.9913428  0.81484497 0.99860376 0.9937453\n",
      " 0.7022099  0.9947509  0.9257905  0.8897694  0.8867968  0.85868615\n",
      " 0.9754007  0.9212628  0.99286157 0.62833303 0.6030368  0.98946583\n",
      " 0.9935201  0.9931409  0.99766135 0.9182838  0.9985499  0.94184\n",
      " 0.9845893  0.96427375]\n",
      "The rewards are: [0.9983182  0.5792798  0.94862765 0.9575938  0.9975752  0.9928576\n",
      " 0.83762103 0.7532709  0.99537224 0.94615847 0.87979907 0.9955947\n",
      " 0.8728612  0.81306815 0.8603904  0.9951219  0.9462979  0.96072626\n",
      " 0.97252244 0.95595104 0.9917231  0.9167629  0.89417183 0.7405526\n",
      " 0.99889684 0.8378155  0.98686826 0.9755072  0.99116933 0.9774302\n",
      " 0.84335047 0.9072781 ]\n",
      "The rewards are: [0.63030684 0.9789589  0.85277617 0.96649474 0.9976399  0.98102266\n",
      " 0.6913195  0.87668896 0.5916712  0.988988   0.98934746 0.9898157\n",
      " 0.98286045 0.98934096 0.50084174 0.98245883 0.6908867  0.9931891\n",
      " 0.99433005 0.98740375 0.98424214 0.81391    0.9759292  0.99860543\n",
      " 0.60436964 0.7320216  0.95202506 0.8482304  0.9984314  0.905851\n",
      " 0.68954396 0.98750895]\n",
      "The rewards are: [0.99869365 0.94409734 0.95313436 0.97256774 0.96492654 0.9711844\n",
      " 0.7173674  0.9830273  0.97626376 0.9788275  0.99498874 0.9582749\n",
      " 0.95257944 0.96365523 0.9938306  0.9640737  0.9962578  0.9947018\n",
      " 0.8869119  0.9993243  0.9984676  0.8714165  0.98327327 0.9900866\n",
      " 0.99948007 0.94853765 0.99452376 0.94830227 0.91204375 0.9949373\n",
      " 0.9989473  0.84857786]\n",
      "The rewards are: [0.9967097  0.99400723 0.99232703 0.9962011  0.99626535 0.9803011\n",
      " 0.6508273  0.99629503 0.7552078  0.97072655 0.9975732  0.93603677\n",
      " 0.9936841  0.81603533 0.98894775 0.9975479  0.9980038  0.9228963\n",
      " 0.9876046  0.99529266 0.9612661  0.99914145 0.9978582  0.989135\n",
      " 0.98752755 0.7122326  0.6558758  0.94949794 0.99508214 0.71147877\n",
      " 0.99704903 0.9929448 ]\n",
      "The rewards are: [0.99905354 0.97831696 0.99838495 0.9757857  0.8235615  0.9446618\n",
      " 0.927286   0.9365165  0.61798406 0.8976457  0.9083878  0.9997223\n",
      " 0.73217225 0.99756765 0.86785066 0.83413154 0.63208455 0.9902344\n",
      " 0.91328114 0.9970187  0.95691687 0.99949145 0.9966017  0.8770945\n",
      " 0.99816716 0.9979684  0.9831064  0.97593325 0.8023058  0.98832804\n",
      " 0.99101794 0.9673145 ]\n",
      "The rewards are: [0.58826977 0.66392756 0.99622995 0.99329317 0.9721104  0.82712394\n",
      " 0.9545069  0.9971929  0.994136   0.9898415  0.8991706  0.96346784\n",
      " 0.9976419  0.9909147  0.92270213 0.975869   0.97617006 0.9944137\n",
      " 0.9905992  0.9577141  0.7971119  0.83343995 0.9846836  0.9950943\n",
      " 0.9947673  0.9933102  0.98529065 0.5189368  0.98868793 0.9386709\n",
      " 0.98879683 0.90064377]\n",
      "The rewards are: [0.77083564 0.7934145  0.8769838  0.795713   0.97690225 0.68513924\n",
      " 0.9875732  0.98676807 0.6738895  0.95085025 0.519757   0.99227905\n",
      " 0.99209034 0.99280363 0.9918629  0.99379104 0.5734046  0.9900939\n",
      " 0.9944344  0.9878941  0.9501474  0.9960517  0.99993634 0.6369537\n",
      " 0.7631479  0.9851221  0.9992186  0.9414461  0.99570674 0.9933782\n",
      " 0.9613897  0.9795813 ]\n",
      "The rewards are: [0.98351824 0.9926708  0.8779416  0.9961366  0.8322355  0.9968644\n",
      " 0.89239126 0.99877805 0.99361515 0.9983543  0.9486408  0.7972786\n",
      " 0.9848232  0.99139214 0.99590516 0.99691147 0.51790476 0.97100765\n",
      " 0.9911466  0.9489181  0.8822431  0.75791466 0.6270574  0.99984896\n",
      " 0.9215228  0.9686692  0.99358314 0.9969825  0.98712105 0.9369923\n",
      " 0.999835   0.56515914]\n",
      "The rewards are: [0.9973955  0.9920907  0.9849569  0.99670357 0.97300184 0.8953808\n",
      " 0.77981675 0.88065577 0.94088405 0.9939839  0.8610647  0.84671885\n",
      " 0.99823725 0.8268935  0.9895483  0.82355696 0.96441656 0.52880263\n",
      " 0.9989851  0.80168957 0.96086204 0.99918824 0.99926764 0.9937354\n",
      " 0.99424016 0.99797374 0.99702436 0.99620026 0.9995629  0.99178857\n",
      " 0.9930674  0.5881148 ]\n",
      "The rewards are: [0.83994037 0.98799497 0.9871351  0.974377   0.9643783  0.99924433\n",
      " 0.98803794 0.8652324  0.9952354  0.9908708  0.78363645 0.9781991\n",
      " 0.9733051  0.99786025 0.9791012  0.96939385 0.9988141  0.9891478\n",
      " 0.7665154  0.9996754  0.89371675 0.9804183  0.7983691  0.9992478\n",
      " 0.9866768  0.9962451  0.9827838  0.99929273 0.99762434 0.9649129\n",
      " 0.90288794 0.95436037]\n",
      "The rewards are: [0.9954608  0.9388437  0.78779733 0.92918885 0.9932319  0.83083916\n",
      " 0.9955146  0.9883083  0.99800473 0.99944633 0.9786219  0.9989641\n",
      " 0.9981939  0.99726367 0.9435649  0.9813643  0.962287   0.9905634\n",
      " 0.9526726  0.9853967  0.9901416  0.660743   0.90730625 0.98060703\n",
      " 0.9771837  0.8803978  0.9981206  0.81060046 0.9977946  0.89171183\n",
      " 0.99278015 0.9852851 ]\n",
      "The rewards are: [0.9642099  0.97830087 0.9629308  0.9966732  0.9986363  0.97069925\n",
      " 0.9903943  0.8790433  0.9886497  0.99234575 0.9924406  0.51311594\n",
      " 0.91676855 0.975377   0.6990954  0.99861145 0.96963453 0.9685338\n",
      " 0.99683446 0.90200716 0.9916225  0.8742347  0.726622   0.99598265\n",
      " 0.9927511  0.9840747  0.9207885  0.9828212  0.99427927 0.76591086\n",
      " 0.9904174  0.98995286]\n",
      "The rewards are: [0.96901065 0.9967278  0.94519997 0.9950045  0.97914976 0.95183104\n",
      " 0.8759491  0.9939079  0.97793716 0.98888296 0.98972195 0.9972645\n",
      " 0.65653765 0.9932759  0.993238   0.9917012  0.790671   0.70689756\n",
      " 0.98164076 0.9953028  0.8472032  0.99854183 0.5769654  0.9732285\n",
      " 0.95744145 0.9871585  0.9921063  0.95069593 0.9920312  0.5677413\n",
      " 0.9219743  0.9643841 ]\n",
      "The rewards are: [0.9718982  0.7337537  0.9818449  0.9892663  0.9140851  0.50593215\n",
      " 0.9986206  0.99849176 0.9988167  0.9580731  0.9873815  0.9720829\n",
      " 0.9859443  0.99671656 0.586477   0.9925345  0.9858517  0.9915548\n",
      " 0.9937359  0.9541845  0.9969618  0.90426433 0.99817324 0.858636\n",
      " 0.6039836  0.98795563 0.59940904 0.5796202  0.98523074 0.68943715\n",
      " 0.6745744  0.83418137]\n",
      "The rewards are: [0.8739095  0.9988502  0.9647999  0.9997181  0.979807   0.9966271\n",
      " 0.9914425  0.99912626 0.8825393  0.9604139  0.53982955 0.7964075\n",
      " 0.9844699  0.9487681  0.9990252  0.80060136 0.99608696 0.9818512\n",
      " 0.9853969  0.9630871  0.8930058  0.6670184  0.76735556 0.9205287\n",
      " 0.9245953  0.9769767  0.8275755  0.9972537  0.9994949  0.6915457\n",
      " 0.9962923  0.9511315 ]\n",
      "The rewards are: [0.9941918  0.993522   0.97636807 0.9528312  0.99006724 0.94848317\n",
      " 0.65168095 0.99915004 0.8792578  0.7871146  0.739717   0.9884367\n",
      " 0.9322165  0.9986732  0.67730665 0.90920895 0.98695624 0.9973049\n",
      " 0.9984366  0.8651565  0.9176676  0.95094866 0.7294736  0.9030071\n",
      " 0.9861513  0.9888621  0.7104287  0.992124   0.66075677 0.6912124\n",
      " 0.8732481  0.9976497 ]\n",
      "The rewards are: [0.9883583  0.84675986 0.9582761  0.97496676 0.9899602  0.99450135\n",
      " 0.94164735 0.9978271  0.999241   0.98117113 0.9025252  0.88782316\n",
      " 0.8037938  0.99585354 0.95474935 0.51389825 0.9920149  0.9977481\n",
      " 0.97672105 0.99831367 0.9848801  0.96401244 0.8207915  0.9568177\n",
      " 0.9796969  0.9729591  0.92090255 0.9972205  0.95822376 0.9318087\n",
      " 0.9925476  0.9808297 ]\n",
      "The rewards are: [0.8412376  0.99623543 0.98116565 0.99369264 0.9508385  0.96212286\n",
      " 0.5405765  0.9874644  0.9976997  0.9240747  0.99993455 0.93498504\n",
      " 0.59652925 0.7411597  0.99834824 0.9949431  0.9991036  0.99768186\n",
      " 0.8267914  0.7461936  0.80186385 0.9975763  0.89917177 0.98422736\n",
      " 0.99560815 0.9344326  0.9992042  0.99972147 0.9238319  0.9938007\n",
      " 0.9938041  0.97473776]\n",
      "The rewards are: [0.9987658  0.9533481  0.50798947 0.55845904 0.9715039  0.9504922\n",
      " 0.9898857  0.9653185  0.9481053  0.9975672  0.9959382  0.89020807\n",
      " 0.9992378  0.9939381  0.97555304 0.98978806 0.9243845  0.98687905\n",
      " 0.76214594 0.821872   0.99304706 0.99568874 0.9688028  0.88465804\n",
      " 0.98347175 0.99648523 0.99645436 0.78803533 0.95451945 0.9957391\n",
      " 0.96660954 0.91352105]\n",
      "The rewards are: [0.9694623  0.9810029  0.9954541  0.607753   0.95362955 0.9872082\n",
      " 0.84783095 0.74424434 0.9616186  0.99816906 0.91403574 0.55157316\n",
      " 0.9623164  0.9982399  0.5732215  0.9996816  0.9204361  0.9881131\n",
      " 0.99985313 0.71764135 0.5903433  0.95251226 0.90003586 0.99936324\n",
      " 0.9975896  0.987237   0.96857095 0.71827435 0.67322624 0.99645764\n",
      " 0.99794215 0.81113994]\n",
      "The rewards are: [0.9792642  0.94542396 0.98728555 0.97707486 0.92513645 0.6446424\n",
      " 0.9900271  0.9667172  0.98721063 0.9862605  0.99556977 0.78631717\n",
      " 0.9973538  0.7016991  0.9536893  0.95982283 0.98931164 0.998543\n",
      " 0.960051   0.79228604 0.6685649  0.99626225 0.9996309  0.9755966\n",
      " 0.86003035 0.97674745 0.9714333  0.9854407  0.9930767  0.96489364\n",
      " 0.9980344  0.9849916 ]\n",
      "The rewards are: [0.9167102  0.53564775 0.99366015 0.93883824 0.6381165  0.9959681\n",
      " 0.9556844  0.58299345 0.99906486 0.9980539  0.91966397 0.9315734\n",
      " 0.96850115 0.93330234 0.9944015  0.99941325 0.9963654  0.8404589\n",
      " 0.88078225 0.7505057  0.59836364 0.83492976 0.78922266 0.9731907\n",
      " 0.9289805  0.9818747  0.9973838  0.634071   0.98272103 0.9477794\n",
      " 0.985783   0.97363764]\n",
      "The rewards are: [0.9417927  0.8996266  0.99801636 0.99890983 0.5152549  0.97048867\n",
      " 0.9987072  0.9969963  0.99879956 0.9924413  0.994695   0.9884017\n",
      " 0.7034718  0.9472491  0.97817755 0.99987996 0.6318107  0.9924017\n",
      " 0.99814034 0.9299113  0.9969078  0.9939845  0.99412775 0.9551934\n",
      " 0.9798028  0.999859   0.7305955  0.98714113 0.8666947  0.64302576\n",
      " 0.92952394 0.9918407 ]\n",
      "The rewards are: [0.9706113  0.9704635  0.9966286  0.99632615 0.96771514 0.9875167\n",
      " 0.9989743  0.7781757  0.9993844  0.93061143 0.9723904  0.9738539\n",
      " 0.9535387  0.85305107 0.81328905 0.99907947 0.9995055  0.95958966\n",
      " 0.9998741  0.994451   0.921007   0.8245601  0.9961867  0.9478247\n",
      " 0.6696529  0.99960107 0.8406707  0.99879503 0.9977617  0.6784701\n",
      " 0.99392974 0.9962985 ]\n",
      "The rewards are: [0.9908879  0.9980568  0.99361527 0.9982432  0.97932386 0.97604513\n",
      " 0.9895293  0.97865033 0.911384   0.99939597 0.9139968  0.9544521\n",
      " 0.9860299  0.91500616 0.92786473 0.99979204 0.992922   0.99457437\n",
      " 0.94258684 0.9956665  0.98325896 0.99810284 0.98491067 0.954448\n",
      " 0.9381163  0.9981108  0.98060924 0.9311795  0.9924247  0.97175807\n",
      " 0.98018634 0.9641778 ]\n",
      "The rewards are: [0.7380753  0.9739905  0.9911758  0.99847597 0.94226885 0.91712743\n",
      " 0.9970497  0.99047005 0.99730825 0.5913004  0.9743062  0.99980706\n",
      " 0.9420348  0.9958675  0.99611014 0.9970086  0.9945102  0.98549217\n",
      " 0.66499853 0.99739444 0.9986659  0.99154234 0.81652325 0.83378536\n",
      " 0.9950589  0.7672037  0.99628747 0.98795706 0.6173029  0.95047593\n",
      " 0.7006135  0.99412894]\n",
      "The rewards are: [0.9386878  0.791539   0.5085953  0.98875856 0.5897339  0.9397557\n",
      " 0.9932488  0.97464764 0.99822265 0.94753844 0.8088428  0.9254633\n",
      " 0.9945075  0.988677   0.9866166  0.97885305 0.9980724  0.7895585\n",
      " 0.83239156 0.98384005 0.99050456 0.90610784 0.9910129  0.67695546\n",
      " 0.9968309  0.8796997  0.6752072  0.99325293 0.9660357  0.9974995\n",
      " 0.98456913 0.98657054]\n",
      "The rewards are: [0.9990845  0.89919287 0.995288   0.9887462  0.98731565 0.99418986\n",
      " 0.6299891  0.77393466 0.9957612  0.8224475  0.9417873  0.99706465\n",
      " 0.55035263 0.9082905  0.5679565  0.9901523  0.9988727  0.9410214\n",
      " 0.9968008  0.72685635 0.99958485 0.995246   0.9914603  0.85650384\n",
      " 0.9845558  0.995598   0.9906536  0.96012837 0.8422195  0.9898364\n",
      " 0.9985707  0.9896862 ]\n",
      "The rewards are: [0.9949881  0.9614297  0.9984485  0.99985445 0.62898064 0.98913646\n",
      " 0.8393671  0.9442814  0.93770295 0.6725107  0.5201706  0.98933697\n",
      " 0.6254808  0.94883883 0.99850404 0.63825345 0.99550277 0.9929263\n",
      " 0.99827266 0.8721895  0.9911815  0.8800235  0.99081576 0.9462241\n",
      " 0.7922099  0.9820358  0.9993741  0.9924737  0.98126626 0.97789294\n",
      " 0.9709306  0.98306584]\n",
      "The rewards are: [0.99737453 0.97423846 0.7044407  0.9987404  0.5201992  0.98833454\n",
      " 0.99688333 0.95402247 0.8935755  0.9496311  0.9800711  0.94003236\n",
      " 0.99691594 0.89358455 0.9947062  0.9967187  0.97935265 0.7223565\n",
      " 0.7222142  0.6655832  0.85336787 0.92524743 0.99883837 0.99665475\n",
      " 0.85142666 0.83987445 0.85463804 0.97625196 0.9939937  0.72688663\n",
      " 0.99979216 0.99850035]\n",
      "The rewards are: [0.9699523  0.9745992  0.9961051  0.9967152  0.9983506  0.9553471\n",
      " 0.99409145 0.99323046 0.9938793  0.9712658  0.7513807  0.9941439\n",
      " 0.9876188  0.97205794 0.9931426  0.9589079  0.97370726 0.9913053\n",
      " 0.8194328  0.99869365 0.8984847  0.9536817  0.8289597  0.9963142\n",
      " 0.90705246 0.9885554  0.9958691  0.98008025 0.7317902  0.9360874\n",
      " 0.9908489  0.9409109 ]\n",
      "The rewards are: [0.69985914 0.99096256 0.5535726  0.8720089  0.98633367 0.8943897\n",
      " 0.9307548  0.99916005 0.99162924 0.9685865  0.8021719  0.9768336\n",
      " 0.9759502  0.9492921  0.9879738  0.97909784 0.99122566 0.98311263\n",
      " 0.9290463  0.9733891  0.9943164  0.99414563 0.9869272  0.791256\n",
      " 0.9464436  0.99878603 0.9988274  0.9954411  0.66960996 0.6826248\n",
      " 0.99042434 0.9844589 ]\n",
      "The rewards are: [0.99912804 0.9361781  0.96485573 0.99724567 0.98787165 0.93046486\n",
      " 0.74537194 0.99928087 0.9656325  0.98195004 0.7183306  0.99450856\n",
      " 0.994609   0.5341772  0.86743873 0.82375497 0.9967147  0.9465738\n",
      " 0.997482   0.65364283 0.99453133 0.9540307  0.87628776 0.9838305\n",
      " 0.9464058  0.7871344  0.66650677 0.9979114  0.9766102  0.99201137\n",
      " 0.9874794  0.8998634 ]\n",
      "The rewards are: [0.98087054 0.9986833  0.8962749  0.9929617  0.9699119  0.9529621\n",
      " 0.98353267 0.99797446 0.99567103 0.98878735 0.88204074 0.99832577\n",
      " 0.99300754 0.76720047 0.9817255  0.91014045 0.65420926 0.83407784\n",
      " 0.9866963  0.999772   0.9987116  0.9965475  0.9934229  0.8356164\n",
      " 0.9988888  0.8381944  0.998955   0.99774545 0.9637964  0.8735593\n",
      " 0.9919069  0.57892543]\n",
      "The rewards are: [0.98976    0.9792322  0.9967265  0.95595104 0.9875937  0.59218067\n",
      " 0.9908578  0.9941142  0.99704224 0.98015666 0.94930613 0.9977458\n",
      " 0.9709269  0.9132771  0.9986557  0.9808915  0.9939604  0.9948472\n",
      " 0.86314094 0.5642633  0.97747165 0.99828964 0.95239276 0.88543016\n",
      " 0.9938583  0.86948586 0.9740683  0.9725494  0.89868695 0.9774345\n",
      " 0.9963037  0.82340676]\n",
      "The rewards are: [0.89870906 0.6885088  0.994655   0.99802077 0.9930462  0.8846417\n",
      " 0.99706465 0.9686072  0.9985719  0.9437969  0.9957066  0.9862068\n",
      " 0.9976847  0.53567326 0.99970216 0.94033295 0.9622156  0.9915828\n",
      " 0.79779816 0.98789704 0.99876654 0.6788683  0.99982125 0.57432055\n",
      " 0.92543966 0.9867763  0.9942526  0.7947893  0.97089136 0.99933124\n",
      " 0.95031077 0.99683785]\n",
      "The rewards are: [0.9794134  0.5614685  0.99565613 0.51200986 0.94271785 0.9998053\n",
      " 0.61149293 0.99799323 0.7809106  0.9994733  0.99949145 0.90760505\n",
      " 0.9687039  0.98232883 0.98067427 0.9174579  0.99460286 0.86812097\n",
      " 0.82818794 0.88323104 0.9519793  0.71591526 0.98471236 0.9590465\n",
      " 0.9983327  0.8516156  0.92855567 0.9774893  0.8792447  0.9371359\n",
      " 0.9804745  0.9026662 ]\n",
      "The rewards are: [0.9941433  0.9888881  0.8870044  0.80615664 0.8257642  0.9497727\n",
      " 0.94194996 0.9877274  0.8910798  0.89411837 0.98196316 0.6755873\n",
      " 0.99057114 0.87807435 0.99811816 0.9892005  0.95418316 0.9919391\n",
      " 0.9971048  0.8070114  0.9936792  0.9886169  0.9707863  0.9937138\n",
      " 0.99374783 0.99683493 0.9998839  0.9690618  0.96204424 0.99977714\n",
      " 0.8864555  0.88363886]\n",
      "The rewards are: [0.8517508  0.9950237  0.9987772  0.9851296  0.90723455 0.997591\n",
      " 0.6571543  0.99795014 0.8857036  0.9133766  0.9672839  0.6859054\n",
      " 0.9781098  0.55593175 0.9507694  0.98996466 0.9748785  0.99321246\n",
      " 0.99617505 0.53688365 0.9449902  0.9843172  0.92082673 0.99182117\n",
      " 0.99852693 0.9738893  0.891622   0.99561346 0.7245447  0.9979081\n",
      " 0.99183685 0.9804332 ]\n",
      "The rewards are: [0.9996501  0.932128   0.9996755  0.9620798  0.60378987 0.9981335\n",
      " 0.9961696  0.9656266  0.6761652  0.9968321  0.5924884  0.89862734\n",
      " 0.85168487 0.99513274 0.9860129  0.5716233  0.99729985 0.9811996\n",
      " 0.8323957  0.9939704  0.9897739  0.9676298  0.9988105  0.99697435\n",
      " 0.8413105  0.9966234  0.9952179  0.7804616  0.8734578  0.98352045\n",
      " 0.97728693 0.99617517]\n",
      "The rewards are: [0.96198565 0.68919164 0.89189434 0.9914227  0.9787482  0.95503193\n",
      " 0.58704084 0.99934846 0.99378043 0.63393795 0.8909782  0.98944455\n",
      " 0.84901494 0.997063   0.9289819  0.6634163  0.99861634 0.9862996\n",
      " 0.97217596 0.9737853  0.9891887  0.93633044 0.9970228  0.99515885\n",
      " 0.8756777  0.9824285  0.9461293  0.92630094 0.9978271  0.9346132\n",
      " 0.9952319  0.9974375 ]\n",
      "The rewards are: [0.9984127  0.755824   0.99507207 0.98172265 0.99873847 0.99279433\n",
      " 0.8434191  0.9995517  0.939004   0.99530447 0.9996884  0.9970126\n",
      " 0.9970457  0.97175545 0.9760607  0.9760786  0.9981775  0.98882383\n",
      " 0.9989729  0.89432675 0.9559963  0.8285866  0.5297102  0.9677815\n",
      " 0.5752339  0.9631667  0.9216488  0.9989441  0.9893393  0.9976981\n",
      " 0.99105364 0.9886867 ]\n",
      "The rewards are: [0.97027326 0.9758768  0.50917166 0.5808611  0.9816582  0.84434676\n",
      " 0.94812095 0.9098212  0.96918136 0.99936324 0.9967372  0.95935434\n",
      " 0.8987275  0.9635115  0.98741674 0.9988765  0.99932873 0.98883176\n",
      " 0.99366534 0.992979   0.6959144  0.9969915  0.9658956  0.9366167\n",
      " 0.99552214 0.8932634  0.99211955 0.90264404 0.97471976 0.98782504\n",
      " 0.99934    0.6418975 ]\n",
      "The rewards are: [0.98667556 0.99252594 0.99044853 0.8810831  0.98770356 0.8635427\n",
      " 0.9718641  0.67321026 0.96978396 0.98951054 0.99437743 0.7386113\n",
      " 0.8843819  0.9971917  0.7559748  0.9968927  0.55399895 0.9649354\n",
      " 0.9865737  0.5337182  0.9687498  0.9982999  0.6327303  0.98519576\n",
      " 0.9496081  0.997601   0.7160797  0.7097011  0.99995816 0.99789375\n",
      " 0.9948068  0.99711454]\n",
      "The rewards are: [0.99601537 0.97060555 0.9850749  0.99774796 0.7718245  0.93690467\n",
      " 0.9666281  0.99647933 0.9889831  0.8733776  0.9911692  0.98987365\n",
      " 0.9945192  0.9984415  0.98790205 0.99793303 0.99619544 0.9995491\n",
      " 0.90513635 0.73629314 0.996799   0.8193373  0.9848636  0.95341486\n",
      " 0.87864    0.99294657 0.61048526 0.7893757  0.9916387  0.9905471\n",
      " 0.9910081  0.99855787]\n",
      "The rewards are: [0.86834663 0.9914445  0.9921765  0.9947411  0.979548   0.9966599\n",
      " 0.9937237  0.83232117 0.99821174 0.9988285  0.76230997 0.99336857\n",
      " 0.9897787  0.99479634 0.8953602  0.9890631  0.98169714 0.98295873\n",
      " 0.831464   0.506544   0.5496461  0.9986156  0.99566597 0.9825454\n",
      " 0.96629643 0.99724674 0.9906158  0.9944149  0.9787394  0.96764004\n",
      " 0.997834   0.99566853]\n",
      "The rewards are: [0.9990232  0.98587286 0.9967913  0.86781985 0.995928   0.96924925\n",
      " 0.60224545 0.97714007 0.86723715 0.9970186  0.98905075 0.99763143\n",
      " 0.92992955 0.9954652  0.98503774 0.71014917 0.9387071  0.7704786\n",
      " 0.9448017  0.9926392  0.9531025  0.987023   0.99537766 0.9735155\n",
      " 0.9922552  0.9595636  0.748266   0.99964726 0.99576    0.9708693\n",
      " 0.9999715  0.8682919 ]\n",
      "The rewards are: [0.9815671  0.9962536  0.99489284 0.70183206 0.9928469  0.9834399\n",
      " 0.8907598  0.9826545  0.5690014  0.61708236 0.9271897  0.9982856\n",
      " 0.94024444 0.96911556 0.99119663 0.90720356 0.98832124 0.7692773\n",
      " 0.99955934 0.5852881  0.99556327 0.99783677 0.9852836  0.9943328\n",
      " 0.9775169  0.97148556 0.99690527 0.802156   0.9996648  0.9862825\n",
      " 0.8730433  0.98164326]\n",
      "The rewards are: [0.9977355  0.9975073  0.561577   0.9974482  0.98988265 0.98198456\n",
      " 0.95067114 0.9906522  0.9959318  0.9825529  0.62979    0.5074414\n",
      " 0.96146023 0.987538   0.9818361  0.99536777 0.95897293 0.9982735\n",
      " 0.9777144  0.6546816  0.9827193  0.9929155  0.9924615  0.9938207\n",
      " 0.9691159  0.8400535  0.99162465 0.84283036 0.943071   0.9779323\n",
      " 0.99228036 0.99660885]\n",
      "The rewards are: [0.99353206 0.86228424 0.9669161  0.97997653 0.99905866 0.73998934\n",
      " 0.9980926  0.99243116 0.9844364  0.9508316  0.93454796 0.98346543\n",
      " 0.99083066 0.8436593  0.9898164  0.9972928  0.8268991  0.9912894\n",
      " 0.990092   0.7641004  0.9823173  0.94001466 0.99939597 0.98731834\n",
      " 0.99881566 0.9450695  0.99139166 0.98400015 0.97668684 0.86512744\n",
      " 0.9909156  0.99507433]\n",
      "The rewards are: [0.9919116  0.9921187  0.6156801  0.7875892  0.9839315  0.993725\n",
      " 0.6068437  0.9856903  0.9907787  0.99164116 0.9985247  0.9483412\n",
      " 0.9974408  0.9988372  0.99054796 0.9624698  0.9978873  0.98042446\n",
      " 0.99097776 0.98142564 0.9931503  0.984303   0.9529108  0.99036425\n",
      " 0.9957632  0.99418986 0.7541412  0.9834284  0.54578274 0.78347063\n",
      " 0.9986683  0.9987888 ]\n",
      "The rewards are: [0.9991805  0.97640944 0.771512   0.99063385 0.9002275  0.999635\n",
      " 0.9124486  0.99058443 0.98025376 0.9971801  0.9699902  0.8302761\n",
      " 0.98762393 0.87716466 0.715493   0.9518898  0.86097133 0.9496817\n",
      " 0.7760991  0.8649816  0.9816374  0.99883646 0.99555606 0.99420375\n",
      " 0.98880637 0.9991315  0.8204323  0.9868513  0.99978155 0.867959\n",
      " 0.987002   0.95479304]\n",
      "The rewards are: [0.9974491  0.9980678  0.9901175  0.99539447 0.9914449  0.98761845\n",
      " 0.9576643  0.9786613  0.91362095 0.95521766 0.9983777  0.6476008\n",
      " 0.9595475  0.9599864  0.992759   0.9975776  0.99803454 0.999406\n",
      " 0.9685288  0.9854381  0.6141071  0.9539615  0.9814439  0.546118\n",
      " 0.9469779  0.999302   0.98898834 0.9985638  0.6512188  0.99484974\n",
      " 0.6462661  0.94667965]\n",
      "The rewards are: [0.97633874 0.999255   0.92787653 0.8366275  0.7806406  0.74652016\n",
      " 0.9347656  0.99887353 0.97539914 0.8576597  0.99426526 0.9617571\n",
      " 0.7389862  0.60382295 0.9517913  0.6258664  0.9901832  0.99061674\n",
      " 0.997095   0.980631   0.981237   0.7789804  0.99879104 0.9937356\n",
      " 0.9979001  0.9542634  0.5736678  0.9966299  0.54838556 0.99407804\n",
      " 0.9999113  0.8304411 ]\n",
      "The rewards are: [0.88615966 0.97254467 0.7356173  0.99763703 0.9566505  0.9951963\n",
      " 0.9989415  0.79089683 0.96377856 0.9844679  0.98718065 0.9915718\n",
      " 0.5501445  0.9984937  0.9992649  0.88672626 0.8917269  0.9617559\n",
      " 0.9972128  0.99930334 0.99532086 0.9919308  0.98299444 0.99599755\n",
      " 0.9979221  0.9814062  0.99787426 0.8761943  0.96807915 0.9414859\n",
      " 0.9633207  0.786496  ]\n",
      "The rewards are: [0.99990404 0.9974112  0.99539363 0.9920238  0.89886016 0.9943857\n",
      " 0.9818287  0.99822205 0.7289688  0.98141056 0.94990915 0.9562789\n",
      " 0.99703836 0.99980694 0.9231743  0.9961635  0.94056386 0.99729365\n",
      " 0.98679256 0.9886142  0.96929425 0.8146823  0.9952147  0.9966827\n",
      " 0.54057026 0.99327576 0.98990977 0.99763155 0.85148466 0.6563535\n",
      " 0.99230474 0.8117022 ]\n",
      "The rewards are: [0.9728265  0.97505647 0.7827747  0.987079   0.96469706 0.92607665\n",
      " 0.726991   0.9725044  0.9894482  0.95782834 0.9371159  0.62325925\n",
      " 0.99431336 0.99971634 0.9641645  0.9894713  0.9995857  0.91646874\n",
      " 0.7615573  0.6374675  0.812825   0.9807765  0.994062   0.99800164\n",
      " 0.96227497 0.9959622  0.7585056  0.95682204 0.98487085 0.99896777\n",
      " 0.9849823  0.9999567 ]\n",
      "The rewards are: [0.9025397  0.9997142  0.9914249  0.9803683  0.9803162  0.9670619\n",
      " 0.9904385  0.99673307 0.94474256 0.99884295 0.99399674 0.9867618\n",
      " 0.9995228  0.87054247 0.557087   0.6504877  0.96879894 0.98622966\n",
      " 0.7120851  0.9943492  0.86866874 0.8761567  0.85917866 0.9818365\n",
      " 0.9301535  0.98645675 0.9957209  0.9813731  0.8113131  0.9961641\n",
      " 0.980357   0.9909361 ]\n",
      "The rewards are: [0.9896143  0.898287   0.91956    0.99880993 0.9943997  0.92872643\n",
      " 0.999479   0.98020923 0.9993266  0.9002875  0.9394138  0.9940095\n",
      " 0.99558014 0.98624045 0.9597816  0.9305866  0.64492846 0.95282537\n",
      " 0.8892302  0.99876344 0.9847883  0.9547417  0.99811566 0.9918311\n",
      " 0.9990988  0.9996848  0.9647585  0.99082863 0.9119731  0.80135024\n",
      " 0.99369884 0.85236657]\n",
      "The rewards are: [0.9564527  0.5321642  0.9984964  0.9999553  0.9765464  0.7996911\n",
      " 0.93190664 0.99223423 0.7950126  0.99327785 0.9922396  0.9157445\n",
      " 0.9983365  0.97649777 0.9461555  0.9934109  0.9979819  0.99982363\n",
      " 0.9735955  0.9978522  0.972831   0.9960461  0.9815655  0.62886024\n",
      " 0.87630737 0.9696657  0.9903106  0.98621064 0.98676884 0.9995809\n",
      " 0.65671897 0.9996246 ]\n",
      "The rewards are: [0.99462235 0.99046224 0.67897695 0.93599886 0.9225695  0.9829541\n",
      " 0.70116144 0.9956381  0.98160064 0.9930768  0.97071886 0.9864356\n",
      " 0.9982772  0.99533963 0.5756017  0.5990597  0.66184413 0.9424626\n",
      " 0.8715879  0.99500126 0.9937309  0.98244435 0.9842473  0.8909499\n",
      " 0.9069681  0.9640488  0.99693596 0.9190417  0.9898914  0.9914254\n",
      " 0.95793617 0.97476065]\n",
      "The rewards are: [0.98481834 0.99365366 0.9572235  0.8490552  0.9881781  0.99662113\n",
      " 0.9517219  0.91031045 0.9957618  0.8294057  0.95286924 0.9198973\n",
      " 0.99623615 0.70220804 0.9857972  0.991401   0.99914443 0.9734561\n",
      " 0.976034   0.99483734 0.96115136 0.99624157 0.99870217 0.9116232\n",
      " 0.99603695 0.9793991  0.9987155  0.9480063  0.9880322  0.99832684\n",
      " 0.9960865  0.89668363]\n",
      "The rewards are: [0.99478626 0.9992472  0.9959996  0.8073319  0.977733   0.9992162\n",
      " 0.99945134 0.6470001  0.9574164  0.9938023  0.99945444 0.97479445\n",
      " 0.98531204 0.9968748  0.9994524  0.9938233  0.89211744 0.61262304\n",
      " 0.992011   0.99198854 0.76572573 0.99034405 0.99967873 0.99075586\n",
      " 0.98705924 0.9978649  0.9862984  0.9890781  0.9975241  0.99804366\n",
      " 0.5859533  0.97729844]\n",
      "The rewards are: [0.9622007  0.8279144  0.9627959  0.9136494  0.86582834 0.93554133\n",
      " 0.9262908  0.50429803 0.9965321  0.921448   0.9915826  0.80724424\n",
      " 0.9763116  0.93407434 0.9968021  0.95814264 0.9286215  0.9873317\n",
      " 0.9440991  0.99642855 0.98878795 0.9978459  0.9928543  0.8494049\n",
      " 0.99850523 0.99003696 0.99786747 0.9909638  0.6272581  0.97759366\n",
      " 0.91906667 0.9961856 ]\n",
      "The rewards are: [0.99241203 0.99926764 0.9961659  0.99919003 0.78842324 0.99838257\n",
      " 0.92360973 0.53630835 0.999226   0.8866419  0.9837096  0.5450243\n",
      " 0.9924988  0.9959203  0.8326435  0.8922206  0.9983425  0.54554445\n",
      " 0.9671709  0.88588226 0.9974591  0.9930582  0.99000436 0.9998305\n",
      " 0.8476004  0.9673372  0.997122   0.99811804 0.99801934 0.9486743\n",
      " 0.93134224 0.9962746 ]\n",
      "The rewards are: [0.71796197 0.964144   0.9960568  0.7979805  0.9898739  0.99636614\n",
      " 0.9967525  0.986597   0.99064386 0.97286826 0.804018   0.9996686\n",
      " 0.9437238  0.84819585 0.99590886 0.9893729  0.9962303  0.9962335\n",
      " 0.9755751  0.84039307 0.996082   0.98518    0.69649607 0.99414647\n",
      " 0.9974515  0.9988655  0.999298   0.83390665 0.9854739  0.989691\n",
      " 0.8385762  0.99819106]\n",
      "The rewards are: [0.99509037 0.99691135 0.99694926 0.99548954 0.99871457 0.9660989\n",
      " 0.9838161  0.9908432  0.99236804 0.9399365  0.996915   0.9367025\n",
      " 0.8771257  0.666244   0.93049854 0.96663773 0.78081155 0.7178824\n",
      " 0.9964477  0.79855883 0.7838838  0.91709566 0.9943545  0.99716586\n",
      " 0.9922671  0.6975473  0.55322605 0.737779   0.9734654  0.9542129\n",
      " 0.97152406 0.98587245]\n",
      "The rewards are: [0.9871695  0.99620974 0.9969733  0.98030245 0.9997619  0.6762741\n",
      " 0.89138305 0.9839384  0.5091108  0.988649   0.9913272  0.9871141\n",
      " 0.61416847 0.991797   0.9986511  0.9983559  0.8015652  0.90679574\n",
      " 0.98781824 0.99969554 0.99653864 0.7806522  0.9908125  0.9842057\n",
      " 0.9447067  0.9854761  0.64285356 0.7286923  0.81304395 0.93342733\n",
      " 0.99971074 0.8865996 ]\n",
      "The rewards are: [0.8394249  0.9974201  0.9600385  0.9859264  0.9965744  0.77729183\n",
      " 0.7683671  0.993246   0.99058425 0.9908137  0.95850724 0.9417728\n",
      " 0.98507243 0.99489033 0.9318222  0.98290426 0.9996294  0.9995529\n",
      " 0.9025885  0.90502363 0.95932806 0.9873403  0.98774207 0.9240126\n",
      " 0.59413534 0.97853696 0.9572956  0.9541063  0.99941957 0.997752\n",
      " 0.6699925  0.967996  ]\n",
      "The rewards are: [0.98825586 0.9931924  0.9981254  0.9782512  0.539042   0.9917481\n",
      " 0.99663734 0.994232   0.99728644 0.99709237 0.98627836 0.9954852\n",
      " 0.99966586 0.99726665 0.8035281  0.8797227  0.8310858  0.6752301\n",
      " 0.9965138  0.997995   0.99898106 0.9399451  0.99886394 0.9853453\n",
      " 0.9948238  0.9996896  0.8096939  0.9486871  0.9147898  0.9801789\n",
      " 0.9712657  0.93086696]\n",
      "The rewards are: [0.8147639  0.9977366  0.9859483  0.63626224 0.9928718  0.9906014\n",
      " 0.98075074 0.9950322  0.9713571  0.8012303  0.61623216 0.9998914\n",
      " 0.99754566 0.89844733 0.96624357 0.99313736 0.8711424  0.99541265\n",
      " 0.81787884 0.63835454 0.99918264 0.99751484 0.9667654  0.99965036\n",
      " 0.7677517  0.9861442  0.99757665 0.6185996  0.88869697 0.9998977\n",
      " 0.65748835 0.9915353 ]\n",
      "The rewards are: [0.99873227 0.9896002  0.9936679  0.5607741  0.99482936 0.9815336\n",
      " 0.9494992  0.9331298  0.997482   0.9949641  0.7840011  0.996828\n",
      " 0.9985061  0.9251256  0.9415633  0.99247736 0.97210354 0.9639027\n",
      " 0.85570997 0.9935267  0.9975304  0.9993742  0.97320694 0.9965887\n",
      " 0.952221   0.985691   0.5139318  0.9967379  0.9699866  0.99012226\n",
      " 0.79325396 0.9800427 ]\n",
      "The rewards are: [0.9558503  0.7494744  0.75391597 0.9937298  0.7922745  0.9748821\n",
      " 0.9987047  0.90361035 0.9463488  0.90124243 0.9977307  0.96329415\n",
      " 0.98196596 0.5794713  0.970966   0.93643904 0.62491065 0.9771732\n",
      " 0.9957344  0.9973157  0.8118002  0.99780303 0.9909567  0.9981172\n",
      " 0.97901505 0.6882218  0.9555527  0.9322856  0.99193454 0.9984113\n",
      " 0.99391717 0.9276468 ]\n",
      "The rewards are: [0.97607285 0.84177136 0.8440269  0.9810049  0.98673743 0.9028099\n",
      " 0.7400481  0.99773705 0.9930969  0.99821043 0.9989698  0.9879717\n",
      " 0.8216617  0.9995334  0.9871464  0.8250822  0.51023287 0.9975668\n",
      " 0.9950971  0.9995147  0.9884481  0.9972715  0.9935213  0.6769313\n",
      " 0.9623795  0.5972255  0.99907446 0.99849796 0.99611783 0.9968765\n",
      " 0.9888489  0.60124904]\n",
      "The rewards are: [0.9770159  0.99126536 0.9962829  0.72186166 0.9958093  0.9857005\n",
      " 0.9656164  0.77270555 0.99008477 0.9987986  0.7850562  0.9983039\n",
      " 0.666931   0.9934824  0.9811911  0.9820576  0.7312209  0.9694607\n",
      " 0.9728397  0.9946307  0.89244944 0.98028517 0.9995146  0.98697376\n",
      " 0.9945912  0.9357992  0.9991678  0.9824119  0.9995881  0.9825021\n",
      " 0.9979373  0.94724154]\n",
      "The rewards are: [0.9450477  0.99944764 0.99240196 0.99560285 0.97452706 0.9921747\n",
      " 0.99931765 0.994586   0.99539316 0.9971445  0.9853116  0.8523216\n",
      " 0.98827493 0.719028   0.6213322  0.9977889  0.8124456  0.99639255\n",
      " 0.99509263 0.9576977  0.99633574 0.9451675  0.94570166 0.92873174\n",
      " 0.9820977  0.9995278  0.9988869  0.9768827  0.73334324 0.99833363\n",
      " 0.9836795  0.993214  ]\n",
      "The rewards are: [0.8222876  0.71616703 0.93372947 0.9113784  0.95524824 0.9642228\n",
      " 0.92494345 0.9962668  0.9116558  0.81145585 0.99764544 0.9975732\n",
      " 0.8296301  0.9924872  0.91147983 0.9771928  0.9614236  0.9985876\n",
      " 0.9988098  0.8733243  0.9925835  0.9959395  0.9200849  0.99347585\n",
      " 0.99463886 0.9861822  0.997256   0.8697921  0.9324821  0.97633386\n",
      " 0.99058914 0.8731432 ]\n",
      "The rewards are: [0.99129444 0.81475645 0.9917092  0.99230826 0.98854524 0.8950492\n",
      " 0.99803525 0.983101   0.9906144  0.9988085  0.99832076 0.9871954\n",
      " 0.9432133  0.9932087  0.72073287 0.64557195 0.99776983 0.9920317\n",
      " 0.9290995  0.9574032  0.7509054  0.90468955 0.98459977 0.9920094\n",
      " 0.97694767 0.89885217 0.9980996  0.96037436 0.7072898  0.99958545\n",
      " 0.9954407  0.8069343 ]\n",
      "The rewards are: [0.99001724 0.99983406 0.9635713  0.9990669  0.8274623  0.97757703\n",
      " 0.99075633 0.9157709  0.6058292  0.7262774  0.6253637  0.82877713\n",
      " 0.9932147  0.9666772  0.9995844  0.95380694 0.96879375 0.9917857\n",
      " 0.9950264  0.77474135 0.5491478  0.9879502  0.99711406 0.9974366\n",
      " 0.9970874  0.99870014 0.8102114  0.9889836  0.8458746  0.9980392\n",
      " 0.9045786  0.9993592 ]\n",
      "The rewards are: [0.7053213  0.9923982  0.9775327  0.98497456 0.9976138  0.99813926\n",
      " 0.93168503 0.90034384 0.98656845 0.8374024  0.99912614 0.95833796\n",
      " 0.99262637 0.9976305  0.99665266 0.8206892  0.9721324  0.99164623\n",
      " 0.8434969  0.9989322  0.99957305 0.9835481  0.9935335  0.99212205\n",
      " 0.99923694 0.9985709  0.98959106 0.91145194 0.9553483  0.99117774\n",
      " 0.97741675 0.99761933]\n",
      "The rewards are: [0.9810585  0.9234732  0.9806276  0.83093065 0.95209986 0.9971776\n",
      " 0.7953629  0.98678255 0.8904952  0.9982638  0.9968983  0.98462033\n",
      " 0.90719527 0.99230605 0.9993993  0.988896   0.73021674 0.9148409\n",
      " 0.9549416  0.99258596 0.99709177 0.99451196 0.84004146 0.9587969\n",
      " 0.9869099  0.9958158  0.98065335 0.99629563 0.99954826 0.8406769\n",
      " 0.9745286  0.9586805 ]\n",
      "The rewards are: [0.99854386 0.994191   0.99886346 0.99082994 0.9993351  0.99458647\n",
      " 0.9901322  0.9985171  0.9770899  0.99794894 0.63424027 0.8862154\n",
      " 0.9945228  0.8820338  0.83693373 0.9962591  0.8901719  0.62129956\n",
      " 0.9814524  0.9997557  0.9586069  0.9913844  0.75809956 0.5988489\n",
      " 0.9969013  0.99837506 0.9981329  0.99430037 0.7859391  0.98889893\n",
      " 0.70934755 0.9715611 ]\n",
      "The rewards are: [0.9992964  0.9870809  0.99956316 0.83631706 0.95107186 0.98553014\n",
      " 0.9996674  0.5339979  0.99318576 0.92920715 0.54885215 0.99699736\n",
      " 0.9842254  0.999561   0.9983594  0.9976432  0.94638425 0.97009516\n",
      " 0.99940264 0.9606752  0.99878484 0.9461059  0.98166466 0.7636258\n",
      " 0.99860436 0.9968923  0.9944944  0.9820665  0.9232401  0.99856794\n",
      " 0.99079657 0.97901493]\n",
      "The rewards are: [0.9980001  0.826847   0.9511781  0.8667805  0.9760887  0.9988061\n",
      " 0.9952644  0.96908474 0.99686486 0.9992887  0.9782533  0.9827556\n",
      " 0.97872967 0.519294   0.999003   0.98097515 0.9809146  0.9705847\n",
      " 0.7929007  0.95446056 0.927715   0.98691434 0.9961688  0.9859416\n",
      " 0.9957872  0.98308253 0.9839865  0.5293104  0.60136384 0.52800447\n",
      " 0.96196425 0.61439127]\n",
      "The rewards are: [0.9435758  0.9989951  0.9786199  0.95475954 0.9967674  0.9411224\n",
      " 0.8901894  0.9697673  0.6965436  0.85194385 0.91661215 0.890806\n",
      " 0.985844   0.7033453  0.9996476  0.99403316 0.9919991  0.66606873\n",
      " 0.99962044 0.99877816 0.9140342  0.8358784  0.9989372  0.9021849\n",
      " 0.9985239  0.53058463 0.9466554  0.88482547 0.9939084  0.99777883\n",
      " 0.8321593  0.99628013]\n",
      "The rewards are: [0.74589306 0.8949583  0.99490875 0.8436928  0.6216248  0.96943027\n",
      " 0.99611664 0.9972384  0.98640406 0.9581967  0.97256356 0.9929375\n",
      " 0.91143143 0.9966737  0.9696134  0.9447376  0.9897565  0.96840703\n",
      " 0.9646824  0.9608727  0.98021966 0.99732804 0.989956   0.988064\n",
      " 0.9947647  0.9971027  0.827212   0.9932777  0.9889021  0.9838215\n",
      " 0.9722253  0.58588207]\n",
      "The rewards are: [0.9925053  0.9959876  0.96391034 0.96009475 0.9972933  0.85783654\n",
      " 0.9823668  0.9867661  0.7557605  0.9973911  0.9904253  0.9680815\n",
      " 0.9600307  0.96368176 0.95852005 0.93122923 0.99120164 0.92718726\n",
      " 0.9316719  0.7836309  0.920415   0.94459796 0.9763441  0.99143714\n",
      " 0.9960681  0.9679942  0.9870252  0.9765926  0.9975956  0.9872931\n",
      " 0.9986885  0.65050256]\n",
      "The rewards are: [0.8084838  0.6797489  0.98592794 0.83458    0.9980743  0.9990752\n",
      " 0.9900821  0.9863559  0.77071935 0.94746125 0.984141   0.9972429\n",
      " 0.99558663 0.80472755 0.99493486 0.997326   0.7017417  0.9979151\n",
      " 0.99917847 0.9987607  0.9416851  0.99447304 0.98831195 0.9998054\n",
      " 0.9793911  0.5452583  0.9482687  0.74333197 0.98089087 0.77159756\n",
      " 0.98574126 0.9938838 ]\n",
      "The rewards are: [0.99892884 0.99988425 0.9765128  0.98028964 0.99682045 0.863111\n",
      " 0.99149305 0.9881043  0.99963605 0.99995744 0.9935634  0.56802624\n",
      " 0.998912   0.98965186 0.7828362  0.99430496 0.9900671  0.9429746\n",
      " 0.99062866 0.9724001  0.84858507 0.9661341  0.99257576 0.98401964\n",
      " 0.99799585 0.9680454  0.9924954  0.8766028  0.93898803 0.9152754\n",
      " 0.99163157 0.99285406]\n",
      "The rewards are: [0.99952114 0.9980313  0.9994229  0.9987722  0.863602   0.7412053\n",
      " 0.9907177  0.5409144  0.98494947 0.94775116 0.64096826 0.699737\n",
      " 0.99552155 0.99610424 0.9982627  0.99721414 0.9996406  0.9963296\n",
      " 0.9576352  0.52819014 0.5069229  0.98778594 0.9957203  0.9669968\n",
      " 0.50213104 0.5912949  0.9941222  0.99983203 0.9855456  0.99317014\n",
      " 0.99311996 0.8050551 ]\n",
      "The rewards are: [0.84022415 0.9880856  0.9975879  0.9701769  0.99851125 0.92689764\n",
      " 0.99448293 0.76510686 0.99963105 0.94259787 0.99893993 0.58572733\n",
      " 0.97915727 0.863791   0.899104   0.99710864 0.9966768  0.6960579\n",
      " 0.9968652  0.9979164  0.9900006  0.99714583 0.9715272  0.9962962\n",
      " 0.99448943 0.9585503  0.9942801  0.98018026 0.99742126 0.88326466\n",
      " 0.6605939  0.8584789 ]\n",
      "The rewards are: [0.9909679  0.99769884 0.9969138  0.98649174 0.9989411  0.97432035\n",
      " 0.949355   0.6194566  0.99275666 0.9813463  0.99853456 0.8010793\n",
      " 0.92370456 0.9900856  0.99854493 0.92129666 0.8595133  0.84211963\n",
      " 0.93791705 0.96265715 0.97572166 0.7086025  0.99601066 0.9965622\n",
      " 0.89943457 0.99619186 0.9995592  0.9797738  0.9907156  0.97355723\n",
      " 0.99507445 0.998348  ]\n",
      "The rewards are: [0.99452424 0.93621945 0.9971788  0.96675926 0.6931399  0.99773836\n",
      " 0.99233913 0.9979601  0.8808205  0.99948716 0.88602626 0.9807725\n",
      " 0.99724424 0.99876726 0.61407983 0.97408235 0.5084745  0.9613124\n",
      " 0.75148237 0.9783537  0.6568776  0.5748803  0.95856243 0.918938\n",
      " 0.9516408  0.9962108  0.9535645  0.993619   0.97967726 0.99404186\n",
      " 0.9880718  0.9425168 ]\n",
      "The rewards are: [0.99500895 0.9802269  0.9357526  0.9946031  0.83216435 0.9995802\n",
      " 0.9753857  0.9992111  0.9839103  0.98194534 0.97195995 0.99981695\n",
      " 0.9805013  0.9912511  0.9927436  0.88312757 0.99703074 0.9928543\n",
      " 0.9838488  0.9746232  0.9890266  0.93463063 0.9774506  0.9996644\n",
      " 0.9995701  0.9922464  0.956803   0.9934681  0.96074957 0.81484467\n",
      " 0.9974597  0.99253184]\n",
      "The rewards are: [0.99695146 0.99899894 0.99417394 0.9946359  0.99770796 0.98950946\n",
      " 0.9629695  0.98706055 0.98052716 0.9820847  0.99993    0.99420494\n",
      " 0.9967085  0.99470735 0.99383813 0.97513175 0.9986307  0.98421913\n",
      " 0.7197957  0.9856053  0.8828634  0.8178993  0.8683657  0.99807113\n",
      " 0.9941421  0.9898705  0.9244394  0.5391739  0.97343856 0.94525695\n",
      " 0.9480749  0.9647472 ]\n",
      "The rewards are: [0.9998386  0.9969092  0.9993247  0.6386822  0.99937016 0.9987545\n",
      " 0.99490875 0.9740785  0.93848985 0.9999434  0.998103   0.9995546\n",
      " 0.99703515 0.98580486 0.99709165 0.9994318  0.9891103  0.74962693\n",
      " 0.9981091  0.99998164 0.99920964 0.98286945 0.6796757  0.9858898\n",
      " 0.98139185 0.95070446 0.6288756  0.7591494  0.97629285 0.538807\n",
      " 0.9059149  0.9964045 ]\n",
      "The rewards are: [0.9958401  0.91439587 0.90172076 0.761209   0.7080064  0.74227756\n",
      " 0.998458   0.91841424 0.98782164 0.99988425 0.73100305 0.9994991\n",
      " 0.5102574  0.9880342  0.6538406  0.9907636  0.9992417  0.97674143\n",
      " 0.9802756  0.6737188  0.7902415  0.9971011  0.91203076 0.9763495\n",
      " 0.98290426 0.9968004  0.74583393 0.7243698  0.98894227 0.99013454\n",
      " 0.9971445  0.9972025 ]\n",
      "The rewards are: [0.7538006  0.9989982  0.9946278  0.9785978  0.6377631  0.7817754\n",
      " 0.9772585  0.98370314 0.9606918  0.9732044  0.9909697  0.9989736\n",
      " 0.84471995 0.93897057 0.99706155 0.94465965 0.99947506 0.9932996\n",
      " 0.9928658  0.97756904 0.6614577  0.98389834 0.991041   0.992957\n",
      " 0.98695743 0.72840035 0.998059   0.99527633 0.9998184  0.9509784\n",
      " 0.99736136 0.99179137]\n",
      "The rewards are: [0.996689   0.7663336  0.98904455 0.9372301  0.99665976 0.9926455\n",
      " 0.99855167 0.9990626  0.6576614  0.62493557 0.69427556 0.99326116\n",
      " 0.9866262  0.98742    0.97338504 0.9434738  0.99655175 0.979729\n",
      " 0.97467756 0.9089858  0.9430249  0.9375599  0.9954998  0.9975546\n",
      " 0.9970222  0.99754447 0.97407126 0.9689892  0.9912141  0.99715424\n",
      " 0.9510476  0.9971831 ]\n",
      "The rewards are: [0.99854183 0.996088   0.9886121  0.9993297  0.97537845 0.98267347\n",
      " 0.98782676 0.9980977  0.9795814  0.87273693 0.964816   0.98568904\n",
      " 0.9927085  0.9978163  0.9905488  0.99626005 0.99878544 0.9517624\n",
      " 0.9911108  0.9651568  0.9965107  0.8939283  0.99963176 0.9860314\n",
      " 0.86865675 0.9959644  0.99310136 0.997638   0.99818283 0.845601\n",
      " 0.9930385  0.9726477 ]\n",
      "The rewards are: [0.9975303  0.99682117 0.9975891  0.98745733 0.58535725 0.9871121\n",
      " 0.9897815  0.72145337 0.58182204 0.9836536  0.9977894  0.50388885\n",
      " 0.99828464 0.9963973  0.92850095 0.9906219  0.8922088  0.99102414\n",
      " 0.7638553  0.9869571  0.99935454 0.9527794  0.95982504 0.9992619\n",
      " 0.99486804 0.9916078  0.9781658  0.9964843  0.9625554  0.9874176\n",
      " 0.9918749  0.9980165 ]\n",
      "The rewards are: [0.77402043 0.99733114 0.9004343  0.93695325 0.9988752  0.9660668\n",
      " 0.99649423 0.99934405 0.9901737  0.9966799  0.95735854 0.9864785\n",
      " 0.9902541  0.99124664 0.97631866 0.9993844  0.9907004  0.9953301\n",
      " 0.99553657 0.7360489  0.99904937 0.86045986 0.99448    0.9604019\n",
      " 0.99705756 0.9982382  0.9991849  0.9718087  0.99877506 0.89897853\n",
      " 0.9738894  0.9825165 ]\n",
      "The rewards are: [0.5604917  0.99406767 0.9870481  0.9815507  0.8142044  0.5273674\n",
      " 0.98329043 0.95339525 0.97451967 0.9198077  0.96310824 0.9710428\n",
      " 0.99807715 0.99293035 0.9958627  0.9431764  0.99917656 0.989085\n",
      " 0.9158635  0.98323536 0.99004465 0.99176437 0.6552992  0.99947745\n",
      " 0.9912714  0.98921305 0.98412263 0.8834731  0.9944871  0.98068917\n",
      " 0.9778071  0.94812834]\n",
      "The rewards are: [0.9659029  0.99928564 0.7603292  0.98758477 0.9948179  0.97712314\n",
      " 0.9308055  0.56947964 0.9687544  0.97668266 0.99855953 0.9950537\n",
      " 0.9991025  0.9545834  0.9953302  0.98747    0.9965031  0.99895585\n",
      " 0.9972109  0.9442476  0.9964496  0.8555919  0.9996581  0.997244\n",
      " 0.9586375  0.9994222  0.9971323  0.9992293  0.9996501  0.9615511\n",
      " 0.9601553  0.9887555 ]\n",
      "The rewards are: [0.99972636 0.980393   0.9883697  0.83949775 0.9856748  0.7576936\n",
      " 0.9995042  0.99360955 0.99236226 0.9858072  0.992117   0.9964862\n",
      " 0.99438006 0.9632757  0.99635077 0.96730566 0.98142505 0.9005028\n",
      " 0.9897445  0.99790937 0.9984231  0.9844322  0.605442   0.9737988\n",
      " 0.98567885 0.99466854 0.9912293  0.99897987 0.9943996  0.9942767\n",
      " 0.9956607  0.830451  ]\n",
      "The rewards are: [0.5492275  0.7507346  0.97573054 0.8029659  0.72996855 0.61485785\n",
      " 0.9974989  0.9634808  0.997198   0.99006045 0.9994413  0.96206266\n",
      " 0.89928764 0.99340194 0.9935662  0.96018785 0.92419595 0.9996836\n",
      " 0.99972945 0.96502477 0.998898   0.9982343  0.9949586  0.97322637\n",
      " 0.9662158  0.98780096 0.9955857  0.95744693 0.9736075  0.9892147\n",
      " 0.9649613  0.9910806 ]\n",
      "The rewards are: [0.922059   0.9999449  0.89221174 0.5981894  0.99513465 0.53819066\n",
      " 0.99903584 0.99069804 0.9983972  0.5198059  0.93569493 0.8166334\n",
      " 0.64523    0.55722815 0.60867107 0.9285964  0.98303115 0.9975815\n",
      " 0.845976   0.9989882  0.9997216  0.9723461  0.93030554 0.9934689\n",
      " 0.993494   0.99939096 0.969948   0.9655485  0.9969639  0.98125994\n",
      " 0.9247564  0.9499245 ]\n",
      "The rewards are: [0.98038095 0.60492754 0.99384403 0.88190454 0.99864584 0.60218936\n",
      " 0.9124622  0.95510143 0.9967163  0.9967464  0.9277769  0.99895644\n",
      " 0.9516828  0.9931126  0.98873    0.9995421  0.54694957 0.9355578\n",
      " 0.793478   0.9988367  0.99198496 0.9987993  0.9845232  0.9430925\n",
      " 0.99983656 0.9995813  0.98059905 0.7566285  0.9419793  0.9956\n",
      " 0.97658646 0.99163216]\n",
      "The rewards are: [0.676878   0.9859946  0.9969688  0.9960206  0.97411954 0.98941493\n",
      " 0.99895895 0.99785835 0.9816522  0.86080706 0.77679837 0.9975206\n",
      " 0.99992704 0.9970055  0.698336   0.99752575 0.99729806 0.9739639\n",
      " 0.92782176 0.9491354  0.9888086  0.61017996 0.8970194  0.92780185\n",
      " 0.5492453  0.99646324 0.99897754 0.90665257 0.9939936  0.90372044\n",
      " 0.9929461  0.9872089 ]\n",
      "The rewards are: [0.9476249  0.9884244  0.9320541  0.998035   0.8175989  0.9951001\n",
      " 0.99888414 0.75431734 0.96815914 0.9873124  0.62734306 0.9978295\n",
      " 0.99890363 0.99408495 0.9326126  0.9974485  0.9633862  0.9975961\n",
      " 0.85382074 0.516457   0.9898295  0.9953561  0.96326214 0.982418\n",
      " 0.9965178  0.9801383  0.6371102  0.99816567 0.99958736 0.97210634\n",
      " 0.99863344 0.9910945 ]\n",
      "The rewards are: [0.9996966  0.90566635 0.9023912  0.93558997 0.9675735  0.8984965\n",
      " 0.9919252  0.73005533 0.9974999  0.9700963  0.98339427 0.8699624\n",
      " 0.96158576 0.8296856  0.9976998  0.9940708  0.99428743 0.9985185\n",
      " 0.89277285 0.97100645 0.98573303 0.9854939  0.9987103  0.94723326\n",
      " 0.98740375 0.66174436 0.9904373  0.8854299  0.999699   0.6420569\n",
      " 0.9986708  0.9880094 ]\n",
      "The rewards are: [0.99642026 0.89879274 0.99903995 0.9966086  0.9963882  0.9936335\n",
      " 0.9965533  0.97354364 0.9882554  0.9560176  0.7897203  0.9689474\n",
      " 0.68422306 0.9978104  0.71144086 0.9918543  0.99668187 0.9542853\n",
      " 0.96915317 0.99035877 0.9848798  0.8734814  0.9916433  0.99921095\n",
      " 0.9872136  0.9852614  0.9336376  0.9983393  0.9745419  0.99795747\n",
      " 0.9930456  0.9334795 ]\n",
      "The rewards are: [0.8832546  0.9984957  0.9646298  0.99908555 0.988293   0.97494626\n",
      " 0.9868059  0.99203074 0.986054   0.9931552  0.9947907  0.99132615\n",
      " 0.9616933  0.995275   0.8881675  0.983235   0.95094043 0.9710835\n",
      " 0.9957918  0.9373313  0.7809024  0.99697626 0.9893295  0.99580586\n",
      " 0.99650747 0.9996983  0.93259424 0.9457998  0.951649   0.9982728\n",
      " 0.7244659  0.54079473]\n",
      "The rewards are: [0.99679    0.9702663  0.9810275  0.7701905  0.9970521  0.9956228\n",
      " 0.9637884  0.9953955  0.9924474  0.9992561  0.9691204  0.99417603\n",
      " 0.9933743  0.99750036 0.996472   0.8798834  0.99778616 0.99791914\n",
      " 0.94296646 0.9960699  0.9946741  0.93886024 0.938705   0.97951365\n",
      " 0.9903509  0.954577   0.9927429  0.9909136  0.9920845  0.99648076\n",
      " 0.9497058  0.97472066]\n",
      "The rewards are: [0.9955521  0.63497615 0.9954087  0.93621385 0.99404055 0.9939908\n",
      " 0.96848786 0.9976369  0.9907453  0.9080411  0.9901366  0.99194556\n",
      " 0.99568886 0.9634935  0.5147643  0.9843225  0.9835992  0.9928853\n",
      " 0.9546611  0.991659   0.96885395 0.99879766 0.9642303  0.9948553\n",
      " 0.9213008  0.9988091  0.9851687  0.9969483  0.9128193  0.9976604\n",
      " 0.99098235 0.5638006 ]\n",
      "The rewards are: [0.8672089  0.7680969  0.97594756 0.79432565 0.7581698  0.58482987\n",
      " 0.99971277 0.959321   0.99931145 0.99723583 0.8793031  0.79506564\n",
      " 0.89212    0.8732133  0.9776921  0.96267563 0.9996377  0.99656194\n",
      " 0.9672606  0.9997873  0.96741706 0.8254027  0.99655044 0.9316418\n",
      " 0.9835706  0.9510044  0.99646217 0.9967488  0.8812717  0.9935045\n",
      " 0.95237106 0.9980709 ]\n",
      "The rewards are: [0.94119704 0.9780582  0.9654151  0.9981476  0.99283314 0.9990565\n",
      " 0.998741   0.9997663  0.8622056  0.96247745 0.9370021  0.9934808\n",
      " 0.9941636  0.9512645  0.81828326 0.99909663 0.97881913 0.98146915\n",
      " 0.9956071  0.99669915 0.9996118  0.98650116 0.9988955  0.97736007\n",
      " 0.9961034  0.998936   0.99392915 0.9461386  0.96608436 0.97891515\n",
      " 0.99200785 0.98961264]\n",
      "The rewards are: [0.9954331  0.999923   0.9999294  0.97386    0.99413234 0.97177213\n",
      " 0.68015933 0.9972645  0.9957553  0.9974312  0.9993736  0.99431944\n",
      " 0.9913913  0.99992716 0.9932696  0.91233504 0.8864538  0.99654895\n",
      " 0.9184406  0.94553834 0.99395627 0.9994018  0.99693716 0.6811634\n",
      " 0.997334   0.968239   0.9613331  0.9985936  0.98942006 0.9984113\n",
      " 0.9978898  0.9987577 ]\n",
      "The rewards are: [0.9979825  0.9926267  0.99797195 0.8252402  0.92592376 0.9967415\n",
      " 0.98526716 0.9958162  0.97872776 0.83726054 0.99541384 0.9925787\n",
      " 0.99381727 0.68251246 0.7964714  0.98762065 0.9944167  0.99414825\n",
      " 0.9927522  0.9646632  0.9929512  0.7915306  0.9247075  0.7954786\n",
      " 0.8108474  0.97324187 0.9989103  0.95973414 0.9988073  0.570706\n",
      " 0.9793097  0.630475  ]\n",
      "The rewards are: [0.9934645  0.979988   0.9980227  0.9966535  0.99917275 0.9913708\n",
      " 0.9493796  0.813657   0.9989581  0.9712937  0.9924355  0.9998896\n",
      " 0.503314   0.9996043  0.9993333  0.99836725 0.9571972  0.923247\n",
      " 0.98716575 0.9938186  0.9979651  0.99625695 0.99824655 0.9072321\n",
      " 0.9860778  0.8038685  0.99421763 0.99991524 0.54384065 0.99289775\n",
      " 0.9956986  0.946384  ]\n",
      "The rewards are: [0.99123645 0.9982944  0.9778246  0.9723045  0.6791331  0.99284756\n",
      " 0.9917251  0.99730057 0.99633515 0.9904564  0.99773896 0.9948966\n",
      " 0.94138044 0.9506177  0.98896575 0.9904631  0.71818936 0.99476296\n",
      " 0.9874988  0.9995844  0.9746244  0.99882597 0.9973525  0.99155605\n",
      " 0.99947983 0.9839588  0.9920317  0.9928322  0.8138214  0.9951905\n",
      " 0.99040204 0.96758044]\n",
      "The rewards are: [0.9842614  0.96412635 0.98622024 0.84491307 0.9946932  0.9663054\n",
      " 0.99191874 0.99938357 0.98687637 0.9994203  0.98704904 0.98947096\n",
      " 0.93851024 0.9927146  0.9941468  0.9952545  0.9761016  0.9686441\n",
      " 0.91113454 0.99670225 0.57247764 0.9192881  0.986053   0.97560805\n",
      " 0.9360699  0.9986518  0.99780816 0.943969   0.9943347  0.974916\n",
      " 0.8889337  0.9904304 ]\n",
      "The rewards are: [0.9790958  0.9781004  0.9984548  0.9891425  0.950954   0.992355\n",
      " 0.98207676 0.5176946  0.99849284 0.98461056 0.99834836 0.9973556\n",
      " 0.99548066 0.9567317  0.9908742  0.54216254 0.96922314 0.9976019\n",
      " 0.9983254  0.9850583  0.9963462  0.65824133 0.98637646 0.930645\n",
      " 0.99562305 0.92382836 0.510578   0.9940534  0.9880041  0.9234912\n",
      " 0.9806306  0.91719925]\n",
      "The rewards are: [0.51346356 0.9987268  0.7424664  0.9631685  0.9618225  0.9139823\n",
      " 0.9995111  0.8977892  0.71048504 0.8815643  0.9947594  0.99907047\n",
      " 0.98870206 0.9898852  0.9998598  0.9990872  0.6839519  0.63838077\n",
      " 0.897008   0.9754828  0.9989729  0.88518006 0.9952887  0.9733786\n",
      " 0.9187037  0.99341524 0.89820445 0.9922387  0.9929507  0.9949793\n",
      " 0.9961046  0.9930704 ]\n",
      "The rewards are: [0.9383023  0.9778936  0.7016514  0.5844379  0.5772948  0.9998528\n",
      " 0.97160983 0.99990416 0.963831   0.9898141  0.9780677  0.885442\n",
      " 0.99718875 0.9851231  0.8760167  0.9964504  0.7195318  0.9149747\n",
      " 0.970713   0.8666058  0.99663025 0.9969248  0.9934629  0.53344554\n",
      " 0.9916198  0.689313   0.7933425  0.93798184 0.9944745  0.9108123\n",
      " 0.9506063  0.9083936 ]\n",
      "The rewards are: [0.9978835  0.993747   0.99900824 0.86277026 0.9929436  0.99253666\n",
      " 0.8411244  0.9950511  0.8651303  0.9973533  0.8017319  0.92409927\n",
      " 0.9458539  0.88661945 0.8223686  0.99805546 0.97338164 0.8598925\n",
      " 0.9866862  0.9885815  0.88662654 0.99829584 0.9981336  0.9962631\n",
      " 0.9868461  0.9967964  0.96496904 0.9890219  0.99906975 0.9992335\n",
      " 0.9949426  0.9663417 ]\n",
      "The rewards are: [0.9099211  0.9989058  0.95361686 0.9965789  0.9993166  0.9863538\n",
      " 0.9944279  0.9725063  0.7934277  0.969942   0.99237776 0.97864383\n",
      " 0.9464497  0.90323305 0.95511436 0.8678847  0.97623605 0.9943445\n",
      " 0.992312   0.9993624  0.98913795 0.9957237  0.9981542  0.999474\n",
      " 0.989092   0.7050881  0.9748316  0.6700448  0.998453   0.99592614\n",
      " 0.56712276 0.9800862 ]\n",
      "The rewards are: [0.99772424 0.99909496 0.97978365 0.9738844  0.9605037  0.9673798\n",
      " 0.89068353 0.9951669  0.95907974 0.9567067  0.6247932  0.9903349\n",
      " 0.99146724 0.99372756 0.90963453 0.9689941  0.9969999  0.9926045\n",
      " 0.9924021  0.8919344  0.6063511  0.96693647 0.9970246  0.99141425\n",
      " 0.9961951  0.99411184 0.928148   0.6262094  0.9980089  0.98097163\n",
      " 0.8984637  0.9984282 ]\n",
      "The rewards are: [0.8750788  0.9789175  0.99778545 0.96397436 0.99659073 0.9725892\n",
      " 0.8936319  0.9725726  0.9968983  0.94628423 0.9872842  0.92328525\n",
      " 0.9770206  0.99708647 0.9987445  0.87977415 0.9735902  0.9998072\n",
      " 0.99834    0.995612   0.93675834 0.9996507  0.986304   0.9231483\n",
      " 0.99366534 0.94361424 0.99852175 0.9806465  0.9057627  0.9836015\n",
      " 0.99061686 0.998906  ]\n",
      "The rewards are: [0.8933526  0.83407253 0.99700004 0.9996232  0.993185   0.97165406\n",
      " 0.92074144 0.97493047 0.9247877  0.9992423  0.58878595 0.9972554\n",
      " 0.99706024 0.6787393  0.99989474 0.5534644  0.9922019  0.87286294\n",
      " 0.9105791  0.9987167  0.9821269  0.9614326  0.9979734  0.7212144\n",
      " 0.9785212  0.5905738  0.86690176 0.9956169  0.97101724 0.99189913\n",
      " 0.692052   0.8807363 ]\n",
      "The rewards are: [0.62316465 0.96361136 0.8814592  0.94552577 0.998684   0.99596584\n",
      " 0.5353199  0.9826758  0.98418    0.9838291  0.99574125 0.8669265\n",
      " 0.87170845 0.9948967  0.99575317 0.9302845  0.998444   0.95092416\n",
      " 0.6995255  0.9330043  0.9917086  0.9245189  0.9993994  0.99795306\n",
      " 0.85439837 0.9928108  0.9858606  0.8256457  0.9683552  0.9231854\n",
      " 0.72787106 0.9933135 ]\n",
      "The rewards are: [0.976586   0.9928631  0.996858   0.98975337 0.6060047  0.996438\n",
      " 0.9991328  0.95349926 0.99793565 0.9994332  0.86615175 0.8380012\n",
      " 0.854447   0.6039418  0.9995022  0.9956038  0.99637055 0.9998492\n",
      " 0.97896    0.9984491  0.7976094  0.98128945 0.9994531  0.99977463\n",
      " 0.9879242  0.6699827  0.9990244  0.98240846 0.9848298  0.66245073\n",
      " 0.99639785 0.5860087 ]\n",
      "The rewards are: [0.96974677 0.9925783  0.9531281  0.99062866 0.99683493 0.99715436\n",
      " 0.9786294  0.99661934 0.99566627 0.9781145  0.6372669  0.9938538\n",
      " 0.9898958  0.99502486 0.99684    0.99207    0.9976432  0.9990441\n",
      " 0.9989293  0.9856878  0.82316494 0.63341993 0.9903312  0.99410194\n",
      " 0.76554626 0.9911499  0.9892163  0.5083185  0.9947462  0.9980205\n",
      " 0.8592524  0.982213  ]\n",
      "The rewards are: [0.99914896 0.97538596 0.96897817 0.9985518  0.89545506 0.9451285\n",
      " 0.9964056  0.6865949  0.9939166  0.68951494 0.9963689  0.99424887\n",
      " 0.8706474  0.9604019  0.8405689  0.9719639  0.99876714 0.9960806\n",
      " 0.62172467 0.997437   0.99109846 0.9878029  0.9974388  0.95635355\n",
      " 0.86241233 0.8799877  0.9964514  0.9982135  0.9930413  0.9828583\n",
      " 0.9959518  0.9908607 ]\n",
      "The rewards are: [0.94328964 0.98497516 0.7355699  0.99316347 0.9977678  0.94901735\n",
      " 0.91418755 0.88565433 0.6277534  0.97419864 0.67020714 0.9081535\n",
      " 0.99951744 0.9655836  0.93045807 0.73433495 0.9709637  0.94854116\n",
      " 0.9986266  0.98951626 0.92931205 0.9945412  0.9580237  0.96347225\n",
      " 0.99900085 0.7466432  0.9228355  0.77137667 0.9725232  0.84949994\n",
      " 0.99866545 0.87900954]\n",
      "The rewards are: [0.97855055 0.87335336 0.99394554 0.80560774 0.9895419  0.866886\n",
      " 0.9986185  0.99705625 0.99455845 0.99718803 0.98184216 0.9840406\n",
      " 0.8962227  0.9453219  0.9986663  0.7212619  0.9919376  0.9984049\n",
      " 0.9077576  0.9927113  0.99835    0.96367866 0.9929015  0.83933413\n",
      " 0.95407325 0.7570553  0.9981511  0.99628925 0.7604172  0.9785171\n",
      " 0.9383012  0.9794224 ]\n",
      "The rewards are: [0.89164114 0.99498016 0.55877405 0.7323063  0.98423845 0.98901784\n",
      " 0.74677515 0.9997806  0.9874927  0.60286236 0.99689096 0.9934307\n",
      " 0.6739139  0.8343482  0.9253929  0.9983449  0.99159896 0.97448\n",
      " 0.98835015 0.9979603  0.89778227 0.87787956 0.98095316 0.8486752\n",
      " 0.9877891  0.9603527  0.9928067  0.99648935 0.9722581  0.5882681\n",
      " 0.990559   0.9926167 ]\n",
      "The rewards are: [0.8848008  0.9716493  0.9719396  0.9803295  0.99981934 0.99880517\n",
      " 0.855026   0.94348466 0.8072922  0.97472614 0.8071883  0.9983297\n",
      " 0.9870717  0.99731404 0.99769115 0.98848814 0.9859357  0.92812455\n",
      " 0.5668792  0.9751291  0.9582255  0.6411064  0.99992085 0.97898257\n",
      " 0.9546884  0.99982136 0.9926111  0.99760395 0.9930068  0.9986162\n",
      " 0.99337256 0.9980831 ]\n",
      "The rewards are: [0.9630357  0.6188574  0.80263424 0.9956327  0.9965767  0.9390291\n",
      " 0.9878379  0.9876347  0.99928826 0.9985677  0.99656844 0.95003825\n",
      " 0.98845404 0.99819523 0.99843484 0.94949704 0.9227055  0.94122905\n",
      " 0.9937056  0.99965334 0.9965114  0.9964301  0.7243974  0.8966282\n",
      " 0.8802191  0.9241489  0.9876896  0.6323839  0.99311924 0.8366973\n",
      " 0.75994533 0.73193324]\n",
      "The rewards are: [0.9872257  0.9604309  0.65841234 0.8701153  0.9976816  0.81353325\n",
      " 0.99964666 0.9508548  0.8827902  0.9714612  0.9649863  0.96328825\n",
      " 0.5766554  0.9525542  0.86001724 0.991126   0.99840933 0.95637095\n",
      " 0.93523425 0.989994   0.99249154 0.9833682  0.9706442  0.55652523\n",
      " 0.9830136  0.9980058  0.9998789  0.97920084 0.81123555 0.9998441\n",
      " 0.97621095 0.6515158 ]\n",
      "The rewards are: [0.99751955 0.9991725  0.90358835 0.9956665  0.8586371  0.7883367\n",
      " 0.7749449  0.5625794  0.9918399  0.9477575  0.99422616 0.9759961\n",
      " 0.9987669  0.96585953 0.9985763  0.9817046  0.8606068  0.98052937\n",
      " 0.98731714 0.94023097 0.9783095  0.9402292  0.93363875 0.98855644\n",
      " 0.9950814  0.99314636 0.99120843 0.9954751  0.6457233  0.9313573\n",
      " 0.80685085 0.9791387 ]\n",
      "The rewards are: [0.9905371  0.9856205  0.9985593  0.9326595  0.8912864  0.86402804\n",
      " 0.9441818  0.9948612  0.9943428  0.9993279  0.9982284  0.93738335\n",
      " 0.9962584  0.62094414 0.99889237 0.9117466  0.96829545 0.9373387\n",
      " 0.98353493 0.96106863 0.9897709  0.60679644 0.99058986 0.9423991\n",
      " 0.9353152  0.99780995 0.9614358  0.93576634 0.9845806  0.98977697\n",
      " 0.8305495  0.99851674]\n",
      "The rewards are: [0.9995894  0.99835396 0.96122336 0.9944871  0.99743587 0.7474675\n",
      " 0.98469836 0.6160792  0.9996112  0.9774829  0.9753004  0.9999454\n",
      " 0.9942398  0.5609458  0.7258975  0.9695878  0.997212   0.79561824\n",
      " 0.9333512  0.94988614 0.54549164 0.98785734 0.99937963 0.95984757\n",
      " 0.9629489  0.9921015  0.9982047  0.5415594  0.79114985 0.99044436\n",
      " 0.98936033 0.99934846]\n",
      "The rewards are: [0.99713683 0.999311   0.98575217 0.9935122  0.9353756  0.99380714\n",
      " 0.99698466 0.9750089  0.9838785  0.99883705 0.99544275 0.996573\n",
      " 0.99094087 0.99698037 0.98372227 0.92280436 0.99835134 0.89325225\n",
      " 0.983142   0.99521625 0.93488145 0.98762846 0.8332497  0.90799266\n",
      " 0.98468864 0.5705567  0.99886644 0.647968   0.98747176 0.93034744\n",
      " 0.997159   0.9390374 ]\n",
      "The rewards are: [0.9449411  0.9995372  0.9980324  0.9972806  0.9257032  0.9962171\n",
      " 0.99938846 0.9924476  0.9932253  0.9158247  0.9890048  0.99960274\n",
      " 0.9164864  0.9970099  0.9980573  0.98588693 0.9231184  0.9697131\n",
      " 0.53434634 0.92816234 0.5825491  0.9571387  0.68438566 0.97614765\n",
      " 0.99857676 0.88669723 0.9520903  0.99883133 0.9950606  0.97095317\n",
      " 0.9987532  0.9980141 ]\n",
      "The rewards are: [0.7825347  0.9052861  0.9967533  0.995001   0.9777099  0.9274831\n",
      " 0.9907871  0.9926594  0.99891496 0.9464023  0.9404402  0.9772435\n",
      " 0.84402674 0.9926818  0.65951526 0.9868618  0.9921531  0.9985917\n",
      " 0.99976    0.9823465  0.99831486 0.9877555  0.99847215 0.99197596\n",
      " 0.96878135 0.99953103 0.7753162  0.7210659  0.9991524  0.99690825\n",
      " 0.9893995  0.8076451 ]\n",
      "The rewards are: [0.9960246  0.98208594 0.9978315  0.89892817 0.98238623 0.9598391\n",
      " 0.99965763 0.99698883 0.9607627  0.99161303 0.9976019  0.64000076\n",
      " 0.9669211  0.87798613 0.98439276 0.9814524  0.9992908  0.99767226\n",
      " 0.9991806  0.99591357 0.99935335 0.94267017 0.9922198  0.8032694\n",
      " 0.60962915 0.99058926 0.5273003  0.98198205 0.98974544 0.99936086\n",
      " 0.9629972  0.95456755]\n",
      "The rewards are: [0.86456895 0.84662586 0.99832493 0.9549654  0.9999052  0.8969444\n",
      " 0.9979613  0.97629696 0.9567494  0.87416726 0.93051183 0.99257255\n",
      " 0.9998241  0.99570125 0.9966139  0.970705   0.9988612  0.9981019\n",
      " 0.96475685 0.80307513 0.6942406  0.9964904  0.99891555 0.99984944\n",
      " 0.99914    0.99183744 0.9935276  0.9950635  0.99906546 0.91827434\n",
      " 0.6059647  0.9974474 ]\n",
      "The rewards are: [0.96078056 0.9819016  0.9925904  0.995135   0.9948295  0.938662\n",
      " 0.9640542  0.9182999  0.94898766 0.9925289  0.98644024 0.986736\n",
      " 0.9609163  0.99823976 0.81091064 0.77666897 0.9983596  0.7638384\n",
      " 0.9186381  0.9956072  0.9905205  0.99340194 0.8788076  0.98714614\n",
      " 0.9925143  0.68441474 0.8251524  0.61167306 0.9995183  0.97287524\n",
      " 0.9978751  0.9961196 ]\n",
      "The rewards are: [0.91506004 0.9958786  0.94580007 0.9894637  0.901373   0.99881124\n",
      " 0.99996245 0.9127692  0.9974644  0.944666   0.9474145  0.9879622\n",
      " 0.9884228  0.998958   0.9819504  0.91494477 0.9984829  0.7267515\n",
      " 0.9701782  0.99949694 0.5901301  0.9966595  0.99457586 0.9943421\n",
      " 0.9946239  0.8520263  0.8370074  0.9881599  0.9757785  0.85059\n",
      " 0.5851411  0.9971827 ]\n",
      "The rewards are: [0.9596195  0.9494628  0.9958832  0.99901044 0.9974126  0.9991708\n",
      " 0.92162585 0.9944634  0.99805367 0.99368334 0.9942259  0.99967206\n",
      " 0.84680414 0.564047   0.9955179  0.9287694  0.8885322  0.9991179\n",
      " 0.91151243 0.9990414  0.9985306  0.99870205 0.99789137 0.841711\n",
      " 0.69009495 0.99456894 0.5267313  0.9962614  0.9579966  0.99577457\n",
      " 0.9965467  0.99060667]\n",
      "The rewards are: [0.9153604  0.9223925  0.99928325 0.9622165  0.98849213 0.99480313\n",
      " 0.9968635  0.97634596 0.5660585  0.8478194  0.9990932  0.9576601\n",
      " 0.9759957  0.99595886 0.9989442  0.99459946 0.99550074 0.99786586\n",
      " 0.983863   0.97812647 0.97117686 0.9974892  0.80093193 0.9960425\n",
      " 0.9726743  0.9378805  0.80844516 0.99917895 0.99963796 0.84492373\n",
      " 0.9850462  0.9943581 ]\n",
      "The rewards are: [0.83132476 0.5611392  0.96282756 0.98279184 0.99707377 0.9957865\n",
      " 0.983529   0.9914254  0.8620696  0.99366075 0.99288094 0.53175\n",
      " 0.88969445 0.9719824  0.99862015 0.9480675  0.9194975  0.8571531\n",
      " 0.61942875 0.8728351  0.9951373  0.9309625  0.7249541  0.99971324\n",
      " 0.9823669  0.9948413  0.99686724 0.9366493  0.92894137 0.9499293\n",
      " 0.99490416 0.9992555 ]\n",
      "The rewards are: [0.7985394  0.9756335  0.9753677  0.9925022  0.98229975 0.8439233\n",
      " 0.9626745  0.87572366 0.9821315  0.97039694 0.99657094 0.8239352\n",
      " 0.9912991  0.7534078  0.9826806  0.9779132  0.99937856 0.51792926\n",
      " 0.99909866 0.54839826 0.9826565  0.66476846 0.8278927  0.73774815\n",
      " 0.6929167  0.98701316 0.7063621  0.98070335 0.9733377  0.9934476\n",
      " 0.9429425  0.99946946]\n",
      "The rewards are: [0.998038   0.8826069  0.9805783  0.95774686 0.93116724 0.9995974\n",
      " 0.9967608  0.948598   0.9855629  0.92450196 0.9313164  0.7931278\n",
      " 0.99947745 0.9781058  0.8925543  0.86210525 0.99271    0.9996933\n",
      " 0.89699024 0.99915063 0.97735524 0.9370173  0.99841285 0.99626595\n",
      " 0.99270827 0.99855524 0.97619116 0.7644813  0.8903411  0.87812096\n",
      " 0.99529666 0.9620924 ]\n",
      "The rewards are: [0.9766797  0.81796724 0.6711271  0.7413287  0.99345464 0.99800056\n",
      " 0.9993507  0.9969188  0.78204536 0.89728934 0.9278514  0.9415366\n",
      " 0.97331387 0.99216604 0.9991959  0.99760026 0.99547887 0.98144203\n",
      " 0.9977877  0.78543144 0.9981951  0.94966024 0.69246924 0.9129208\n",
      " 0.9222958  0.99814427 0.56114984 0.8990476  0.9673061  0.91672826\n",
      " 0.9814038  0.99912673]\n",
      "The rewards are: [0.999456   0.57632303 0.9980077  0.9915554  0.9938793  0.99377835\n",
      " 0.9994123  0.9971636  0.9929442  0.9763505  0.9974648  0.9995394\n",
      " 0.9767364  0.9887117  0.5249261  0.9981294  0.998418   0.8379585\n",
      " 0.99049103 0.8840987  0.98804295 0.9959967  0.9983224  0.88961005\n",
      " 0.9996511  0.9850145  0.9985415  0.65877813 0.9948532  0.8473772\n",
      " 0.90433043 0.95071703]\n",
      "The rewards are: [0.9955361  0.6201456  0.937663   0.9625357  0.94939387 0.85294837\n",
      " 0.9731164  0.99559844 0.8798897  0.99777204 0.99514455 0.9975567\n",
      " 0.9983369  0.99160284 0.99063885 0.99971277 0.9973448  0.9695664\n",
      " 0.89147335 0.9870984  0.96999145 0.891228   0.9714693  0.9426988\n",
      " 0.9098965  0.9870328  0.9142573  0.9993311  0.99677664 0.92524666\n",
      " 0.9968725  0.9876901 ]\n",
      "The rewards are: [0.9969433  0.73220336 0.9782225  0.8907541  0.99845934 0.9612778\n",
      " 0.9921788  0.9702138  0.9890939  0.99237144 0.9805371  0.7539162\n",
      " 0.9816627  0.9847209  0.84882474 0.996874   0.9988894  0.83869517\n",
      " 0.993845   0.9987392  0.99915814 0.9996691  0.9989666  0.9951126\n",
      " 0.9747934  0.9979214  0.59355634 0.995624   0.53235686 0.9999107\n",
      " 0.9933501  0.96050334]\n",
      "The rewards are: [0.9836963  0.99897087 0.94342726 0.9782137  0.9796892  0.9755501\n",
      " 0.9993011  0.91606104 0.96808237 0.95036227 0.8846529  0.9940578\n",
      " 0.718523   0.88491774 0.9355402  0.772208   0.9271924  0.9968161\n",
      " 0.99487853 0.88705933 0.91844106 0.9098927  0.96834433 0.9480131\n",
      " 0.99076253 0.9989035  0.9960771  0.9947496  0.9450362  0.99923086\n",
      " 0.99014974 0.99785656]\n",
      "The rewards are: [0.97105116 0.9935967  0.992892   0.9803612  0.9926266  0.9952663\n",
      " 0.99512094 0.9949409  0.94192713 0.9677852  0.99927396 0.99321574\n",
      " 0.97939426 0.66391253 0.99469745 0.9980228  0.99173427 0.77495813\n",
      " 0.9986665  0.997045   0.99904686 0.999271   0.9995431  0.992147\n",
      " 0.9792378  0.6162923  0.89480597 0.9936134  0.99807954 0.997546\n",
      " 0.9937164  0.9994198 ]\n",
      "The rewards are: [0.995307   0.993379   0.99166906 0.997086   0.9993382  0.9983601\n",
      " 0.99749017 0.9955244  0.52222836 0.984405   0.96985525 0.79111034\n",
      " 0.9709947  0.8479003  0.91321516 0.68422455 0.9450871  0.99230254\n",
      " 0.98035365 0.9194448  0.9716655  0.97121555 0.99880695 0.9906861\n",
      " 0.9698627  0.54185516 0.69203234 0.57348865 0.74950176 0.9624418\n",
      " 0.9993056  0.99199295]\n",
      "The rewards are: [0.9986866  0.99203193 0.82026476 0.85631454 0.9915379  0.81786346\n",
      " 0.985437   0.9979367  0.96038634 0.9904131  0.89257574 0.9992349\n",
      " 0.9811412  0.9821308  0.92721075 0.8658773  0.993458   0.8967862\n",
      " 0.9986547  0.55339223 0.88733786 0.9893947  0.9934134  0.9718014\n",
      " 0.9566384  0.99738187 0.98127306 0.9973756  0.9916619  0.99940586\n",
      " 0.96790993 0.99234915]\n",
      "The rewards are: [0.7464288  0.9996532  0.66185665 0.9470206  0.8701571  0.988902\n",
      " 0.9913201  0.9846549  0.63210964 0.9995772  0.9975541  0.9983937\n",
      " 0.5731961  0.9966815  0.9935703  0.99412185 0.99251246 0.9994223\n",
      " 0.99723756 0.9759538  0.9988555  0.96648574 0.99928254 0.87919927\n",
      " 0.9986104  0.99544525 0.9354274  0.7412674  0.99835324 0.97132754\n",
      " 0.8981202  0.9967733 ]\n",
      "The rewards are: [0.9997868  0.96806437 0.55839825 0.9997693  0.9430453  0.9980868\n",
      " 0.99533737 0.9965107  0.99076873 0.9987412  0.99560285 0.7237873\n",
      " 0.573458   0.9988495  0.90868604 0.9940473  0.66175723 0.99761045\n",
      " 0.52455455 0.99484754 0.9933664  0.99825996 0.9921829  0.997059\n",
      " 0.9993855  0.9982374  0.9553085  0.96692073 0.99624807 0.9800408\n",
      " 0.8911451  0.71401936]\n",
      "The rewards are: [0.5114543  0.9846667  0.8864863  0.9986203  0.99964523 0.91666406\n",
      " 0.90259755 0.9979328  0.7626026  0.9949603  0.8955983  0.8682194\n",
      " 0.9997004  0.92085886 0.9723932  0.9872525  0.999663   0.9751374\n",
      " 0.989056   0.999899   0.9101123  0.98331004 0.88919103 0.91918546\n",
      " 0.99874145 0.9997603  0.9846772  0.9793788  0.9012207  0.9651238\n",
      " 0.99274033 0.8222145 ]\n",
      "The rewards are: [0.99315345 0.9997509  0.9989988  0.97691137 0.99099815 0.9769612\n",
      " 0.97527474 0.96807355 0.9854584  0.8129391  0.97493774 0.9951768\n",
      " 0.9817966  0.9920638  0.9969078  0.5830858  0.9991792  0.635127\n",
      " 0.9751506  0.9989134  0.99691236 0.97841156 0.7210618  0.90340286\n",
      " 0.7607283  0.99485564 0.9860487  0.8966469  0.9991177  0.99575233\n",
      " 0.98496103 0.93148196]\n",
      "The rewards are: [0.81742984 0.57591814 0.9897042  0.99214    0.97950006 0.5187996\n",
      " 0.99720436 0.9996662  0.99691796 0.99239516 0.99588275 0.61731344\n",
      " 0.9996145  0.9725451  0.88757426 0.9676779  0.950742   0.9989222\n",
      " 0.9985618  0.9994802  0.9324562  0.9995943  0.99991727 0.9871674\n",
      " 0.99480164 0.99774194 0.9820354  0.9972313  0.9869479  0.64501995\n",
      " 0.99228925 0.90728956]\n",
      "The rewards are: [0.916531   0.8387152  0.96534115 0.98656195 0.9510335  0.6064924\n",
      " 0.9808473  0.84438705 0.9946175  0.99895525 0.99879897 0.9990927\n",
      " 0.9529991  0.994487   0.93588805 0.9818094  0.9204205  0.8865882\n",
      " 0.9974987  0.88857514 0.99861705 0.5891651  0.9978296  0.97223353\n",
      " 0.99979323 0.9987569  0.52056086 0.994848   0.99660033 0.99939466\n",
      " 0.9986166  0.9993185 ]\n",
      "The rewards are: [0.99370617 0.94809264 0.8592644  0.97126657 0.99936706 0.98178387\n",
      " 0.8679352  0.9788286  0.9964012  0.9975962  0.8585502  0.91813266\n",
      " 0.99564266 0.99425334 0.9902773  0.96951383 0.9446858  0.91485506\n",
      " 0.96364903 0.992722   0.9535234  0.9947661  0.5373117  0.9908835\n",
      " 0.66739184 0.988821   0.9658609  0.99791044 0.9882059  0.9714407\n",
      " 0.9980452  0.8710204 ]\n",
      "The rewards are: [0.9563012  0.99703586 0.9949083  0.97549736 0.99784386 0.9880702\n",
      " 0.9981743  0.9215672  0.8691715  0.92151296 0.9430923  0.9976603\n",
      " 0.9749669  0.9070454  0.8207954  0.99956495 0.99357563 0.92890024\n",
      " 0.61365    0.99859816 0.9528349  0.99686843 0.99568945 0.9921542\n",
      " 0.98928016 0.9967804  0.94854707 0.998938   0.99989665 0.8760684\n",
      " 0.99626344 0.82427   ]\n",
      "The rewards are: [0.8836247  0.911727   0.9817733  0.98583025 0.9984414  0.98262286\n",
      " 0.9980718  0.9975286  0.9777067  0.9647258  0.9087478  0.63146305\n",
      " 0.97436213 0.9978661  0.96055484 0.9915353  0.99934584 0.9988463\n",
      " 0.99407566 0.90557635 0.6014615  0.6733263  0.9960408  0.9957932\n",
      " 0.97666276 0.996309   0.9858483  0.99789256 0.8158359  0.9954763\n",
      " 0.99075633 0.93193275]\n",
      "The rewards are: [0.9680465  0.73894507 0.9793372  0.9922024  0.99936336 0.937964\n",
      " 0.9774269  0.97900796 0.8881759  0.90198904 0.9838598  0.99486744\n",
      " 0.99738663 0.9278084  0.964543   0.9784895  0.9654809  0.80195814\n",
      " 0.8672723  0.9824942  0.99578166 0.99770325 0.90949696 0.8937797\n",
      " 0.9976312  0.9960729  0.57560855 0.9605753  0.8711206  0.9949344\n",
      " 0.9997209  0.9921577 ]\n",
      "The rewards are: [0.99885845 0.92844844 0.9485977  0.96743625 0.8944612  0.9860774\n",
      " 0.9999051  0.86108685 0.6399426  0.9653037  0.9972156  0.99372935\n",
      " 0.99785775 0.95197785 0.8792594  0.7574825  0.8879729  0.99944013\n",
      " 0.9486509  0.98415864 0.9879935  0.99097204 0.9472374  0.9733935\n",
      " 0.87310106 0.9498469  0.9931578  0.5934915  0.8815139  0.60408765\n",
      " 0.9758449  0.9891444 ]\n",
      "The rewards are: [0.9976495  0.93567145 0.9838648  0.995426   0.80391145 0.6083304\n",
      " 0.99916804 0.99619764 0.99378115 0.96194005 0.65876114 0.50782776\n",
      " 0.95352745 0.99218714 0.9732046  0.5389804  0.9998503  0.5185717\n",
      " 0.9984158  0.99993944 0.9872851  0.9100854  0.9997099  0.99840266\n",
      " 0.99711406 0.9693717  0.9980312  0.99370533 0.9870849  0.7712031\n",
      " 0.99622947 0.99928856]\n",
      "The rewards are: [0.99888927 0.9987923  0.9993174  0.99142003 0.906302   0.9965668\n",
      " 0.9848312  0.93951195 0.7568871  0.93967444 0.99737275 0.9974003\n",
      " 0.9978346  0.868831   0.99949455 0.9944512  0.9389302  0.9892758\n",
      " 0.999421   0.9930876  0.9999188  0.9353571  0.9965899  0.80370384\n",
      " 0.9968689  0.9995166  0.9541208  0.9923361  0.8183268  0.7259093\n",
      " 0.997656   0.95509076]\n",
      "The rewards are: [0.9815165  0.99367493 0.845343   0.89382875 0.99347854 0.997122\n",
      " 0.99788254 0.9720981  0.99733585 0.93917555 0.9920562  0.9832202\n",
      " 0.9987684  0.9987936  0.7548561  0.9851189  0.5816344  0.5778971\n",
      " 0.9088212  0.9995807  0.8370146  0.9471345  0.9949944  0.99104816\n",
      " 0.9928369  0.8918679  0.67789435 0.9991405  0.99896157 0.79296494\n",
      " 0.9803257  0.98928666]\n",
      "The rewards are: [0.99944836 0.99991953 0.99808806 0.99714714 0.9982955  0.98947805\n",
      " 0.9117554  0.9968612  0.9971788  0.8591781  0.97587955 0.99975413\n",
      " 0.9993506  0.98225224 0.8753659  0.9922741  0.9948001  0.93427783\n",
      " 0.99599046 0.94696254 0.99894434 0.9946667  0.9994796  0.96311307\n",
      " 0.99316895 0.89039767 0.9702378  0.98672056 0.9659589  0.84333545\n",
      " 0.862322   0.82926023]\n",
      "The rewards are: [0.9876159  0.9804827  0.9553563  0.99886286 0.8743895  0.9635669\n",
      " 0.997474   0.9016236  0.9502098  0.989026   0.9931184  0.9311671\n",
      " 0.89735574 0.8553177  0.9824363  0.8939117  0.98356473 0.772414\n",
      " 0.9353141  0.9905025  0.99668866 0.99814546 0.8849522  0.9723371\n",
      " 0.9832802  0.9988782  0.99599093 0.999074   0.97941667 0.9962043\n",
      " 0.8385419  0.9628303 ]\n",
      "The rewards are: [0.864981   0.7579086  0.9198581  0.87615085 0.9585886  0.99203\n",
      " 0.6803438  0.9989372  0.9920134  0.9992411  0.9927227  0.75535685\n",
      " 0.9785824  0.5362077  0.9787476  0.9954294  0.99553984 0.9856924\n",
      " 0.99576604 0.99932694 0.9991346  0.9945427  0.9996805  0.995948\n",
      " 0.9979804  0.9869763  0.99715865 0.99981624 0.8976585  0.99054974\n",
      " 0.87167275 0.8193004 ]\n",
      "The rewards are: [0.9946455  0.79224443 0.99514425 0.99779344 0.7848489  0.9900247\n",
      " 0.99983776 0.9728914  0.7634576  0.9881706  0.7396192  0.5783748\n",
      " 0.9756123  0.87974805 0.99499786 0.9976586  0.9998671  0.81604785\n",
      " 0.8744588  0.7493976  0.9985892  0.98141277 0.7555762  0.99791414\n",
      " 0.97235394 0.94376767 0.9932532  0.8396499  0.60495776 0.9969649\n",
      " 0.9997348  0.9453296 ]\n",
      "The rewards are: [0.54136944 0.81907576 0.9715251  0.9925884  0.9986303  0.9920839\n",
      " 0.6360945  0.9993554  0.9967091  0.8464768  0.99473226 0.990436\n",
      " 0.59173256 0.99649906 0.9959816  0.9940154  0.68855643 0.9980288\n",
      " 0.9118195  0.76261    0.757371   0.97462046 0.97575206 0.9954986\n",
      " 0.9001997  0.89696246 0.9975141  0.8810942  0.99822944 0.99766326\n",
      " 0.9935441  0.6771082 ]\n",
      "The rewards are: [0.9522151  0.895843   0.9108052  0.9982054  0.9978606  0.6913878\n",
      " 0.93264043 0.896395   0.9997042  0.7333261  0.9760765  0.9890704\n",
      " 0.98388726 0.99964535 0.97516793 0.99003804 0.61772615 0.9984969\n",
      " 0.99564844 0.9515483  0.9997969  0.9680738  0.90339714 0.57423156\n",
      " 0.9918727  0.983167   0.84126866 0.9966272  0.96773964 0.99975234\n",
      " 0.99356407 0.9599607 ]\n",
      "The rewards are: [0.98657644 0.99125415 0.60778964 0.95325243 0.72508985 0.948715\n",
      " 0.9975672  0.9962303  0.9927725  0.99180895 0.65293473 0.99857926\n",
      " 0.96809614 0.9972922  0.91888404 0.9995092  0.77868515 0.9979152\n",
      " 0.95308834 0.98613596 0.9818205  0.99891675 0.99606115 0.60589767\n",
      " 0.92393243 0.8554002  0.9960693  0.8566375  0.993137   0.9997483\n",
      " 0.6709745  0.9355691 ]\n",
      "The rewards are: [0.9979334  0.90709966 0.8069114  0.8351118  0.9983729  0.99515027\n",
      " 0.78629965 0.9962441  0.9946024  0.9458462  0.96722955 0.89774144\n",
      " 0.99943465 0.99846053 0.99708635 0.9978097  0.9947195  0.9946455\n",
      " 0.927701   0.95993084 0.9948836  0.99784684 0.88064826 0.9983804\n",
      " 0.9965481  0.8329601  0.99396086 0.99722147 0.80959994 0.9958996\n",
      " 0.9953401  0.99727964]\n",
      "The rewards are: [0.9679037  0.99726486 0.58344394 0.99934906 0.9948566  0.97508585\n",
      " 0.9936538  0.970801   0.9971206  0.7475255  0.6837745  0.9837051\n",
      " 0.9336534  0.99322104 0.9850743  0.9185723  0.78536516 0.6635086\n",
      " 0.9755932  0.99671173 0.98687077 0.7856239  0.97782576 0.9806598\n",
      " 0.9989453  0.9973767  0.9972754  0.9990677  0.99997413 0.9917321\n",
      " 0.89963794 0.9930763 ]\n",
      "The rewards are: [0.9576429  0.99278235 0.9939873  0.9730271  0.9994591  0.96254957\n",
      " 0.8987183  0.9580759  0.9895489  0.7416966  0.99732554 0.9961731\n",
      " 0.99849164 0.8682086  0.99108773 0.7322632  0.99946636 0.99805474\n",
      " 0.9993845  0.84390235 0.68614733 0.77633363 0.9791064  0.9997763\n",
      " 0.9916831  0.92872846 0.9533256  0.9981185  0.98244816 0.9887561\n",
      " 0.99163824 0.90251255]\n",
      "The rewards are: [0.97740424 0.9977035  0.9995776  0.9990526  0.99877006 0.99502796\n",
      " 0.90284914 0.999691   0.99877125 0.9943744  0.99644417 0.93249524\n",
      " 0.9868977  0.96862596 0.99163496 0.9945127  0.9985286  0.9863695\n",
      " 0.70497936 0.9999449  0.9948304  0.9987086  0.9987998  0.99980897\n",
      " 0.99596965 0.98985404 0.9862919  0.99862087 0.97614175 0.83313924\n",
      " 0.9943258  0.9781446 ]\n",
      "The rewards are: [0.9966397  0.9989812  0.5606168  0.91455007 0.89282995 0.9337668\n",
      " 0.73593575 0.99958116 0.88730556 0.5663897  0.9990877  0.9707615\n",
      " 0.98233646 0.9990946  0.9960936  0.9998584  0.90885794 0.99738497\n",
      " 0.989302   0.97671354 0.9967313  0.98503405 0.9993143  0.9991841\n",
      " 0.9899733  0.99332124 0.99160963 0.9968784  0.9375905  0.99170035\n",
      " 0.9995578  0.6433919 ]\n",
      "The rewards are: [0.9912054  0.9945639  0.99653983 0.9842994  0.97987086 0.74892247\n",
      " 0.9905076  0.81528693 0.98194665 0.99388266 0.9223016  0.8381102\n",
      " 0.9958883  0.99720794 0.98745453 0.9962871  0.99485165 0.9974964\n",
      " 0.9870855  0.98921585 0.9994647  0.9536706  0.9948671  0.9272593\n",
      " 0.98514646 0.9477423  0.9495093  0.9940006  0.9669445  0.71976703\n",
      " 0.63781637 0.9600416 ]\n",
      "The rewards are: [0.9931839  0.98749125 0.99986196 0.99954873 0.99332595 0.98990333\n",
      " 0.9962464  0.99453497 0.96146774 0.95341766 0.99566877 0.9967024\n",
      " 0.9866833  0.9999589  0.5808735  0.9850487  0.9982261  0.99277276\n",
      " 0.9988681  0.9927055  0.9926467  0.9848712  0.9911726  0.99890363\n",
      " 0.9954401  0.9985176  0.97469115 0.9990507  0.99735236 0.9409487\n",
      " 0.8371077  0.74947333]\n",
      "The rewards are: [0.9338117  0.65064687 0.980224   0.7935242  0.8454668  0.9961727\n",
      " 0.9911492  0.9021078  0.62257886 0.9995153  0.99108315 0.9950681\n",
      " 0.999782   0.9995467  0.99559975 0.99356645 0.9989334  0.99564326\n",
      " 0.8781301  0.9874627  0.9993236  0.9135502  0.9979919  0.96441597\n",
      " 0.9878565  0.9975803  0.99720144 0.99860495 0.69259214 0.9491613\n",
      " 0.9973648  0.64497095]\n",
      "The rewards are: [0.96622735 0.7871766  0.99865437 0.98328304 0.69674027 0.9954182\n",
      " 0.937964   0.99974793 0.9975018  0.7216937  0.99529284 0.84095037\n",
      " 0.94080114 0.98683494 0.9338894  0.9629994  0.9948295  0.951056\n",
      " 0.97399706 0.99163944 0.99829036 0.6663034  0.98520654 0.8947582\n",
      " 0.9467222  0.95898443 0.54669684 0.897006   0.87958616 0.74512774\n",
      " 0.998004   0.999966  ]\n",
      "The rewards are: [0.9898078  0.95963204 0.94163096 0.987189   0.74510175 0.90818197\n",
      " 0.9995704  0.65916795 0.9867301  0.9991334  0.994696   0.9802043\n",
      " 0.99717194 0.576634   0.960857   0.51057935 0.6973292  0.8409987\n",
      " 0.9987538  0.9939043  0.96023583 0.72482276 0.9000462  0.9958117\n",
      " 0.98244    0.9661122  0.99592006 0.9943228  0.7920133  0.98754483\n",
      " 0.9971723  0.97128916]\n",
      "The rewards are: [0.9413838  0.9964606  0.5133505  0.9947724  0.96901816 0.9634062\n",
      " 0.9997439  0.8173675  0.9962205  0.99920493 0.9990176  0.991219\n",
      " 0.89910054 0.9936562  0.98955816 0.95383114 0.9978694  0.99750346\n",
      " 0.941387   0.6572734  0.6691136  0.96670794 0.99881625 0.99218047\n",
      " 0.9979504  0.9853763  0.99888676 0.99821496 0.9638317  0.99810374\n",
      " 0.9601175  0.7586135 ]\n",
      "The rewards are: [0.9938067  0.99668723 0.99922955 0.9967866  0.9996587  0.9746516\n",
      " 0.7699313  0.9374868  0.9552141  0.9988531  0.99161536 0.99295145\n",
      " 0.9963182  0.9925281  0.99947673 0.99919635 0.99548066 0.9815693\n",
      " 0.9929848  0.9970084  0.99931395 0.9759917  0.9980527  0.99560475\n",
      " 0.99367213 0.99587893 0.99501085 0.9929605  0.96856135 0.926507\n",
      " 0.99133986 0.99834585]\n",
      "The rewards are: [0.8278784  0.9984843  0.9724204  0.87181413 0.9988733  0.9683696\n",
      " 0.9968837  0.90633976 0.9974922  0.9941591  0.97910416 0.9921915\n",
      " 0.9726887  0.9607172  0.99975854 0.9944694  0.9864119  0.6445916\n",
      " 0.99127007 0.99808204 0.9992347  0.6818787  0.9983308  0.91273135\n",
      " 0.9974962  0.99932826 0.9960601  0.9982262  0.9554827  0.94466275\n",
      " 0.9655056  0.9942456 ]\n",
      "The rewards are: [0.836143   0.99995005 0.9412484  0.8312843  0.99281    0.9602803\n",
      " 0.9971654  0.8524862  0.9994555  0.94352883 0.5598015  0.7744341\n",
      " 0.5557731  0.9380984  0.9817463  0.9935727  0.92857444 0.99848574\n",
      " 0.92178917 0.99281645 0.99401313 0.92324805 0.87805    0.99554694\n",
      " 0.8869231  0.99697256 0.99778396 0.9578227  0.6884586  0.9982083\n",
      " 0.997875   0.9693729 ]\n",
      "The rewards are: [0.99762064 0.99888104 0.9903756  0.93474174 0.954252   0.83965063\n",
      " 0.9960854  0.9966228  0.7083486  0.9983741  0.9998894  0.9974598\n",
      " 0.9989311  0.9500325  0.9985337  0.998245   0.9660257  0.9961138\n",
      " 0.9998932  0.997177   0.94591886 0.99885345 0.84383774 0.98790747\n",
      " 0.99549156 0.9810417  0.99993074 0.99949956 0.99190617 0.8081688\n",
      " 0.9330892  0.7997912 ]\n",
      "The rewards are: [0.9818248  0.9908048  0.8815115  0.9983438  0.9812056  0.8496026\n",
      " 0.953554   0.73618513 0.9863419  0.99630034 0.95632976 0.9709533\n",
      " 0.88200253 0.9986426  0.99795616 0.9927315  0.8581096  0.99850947\n",
      " 0.9976683  0.8705506  0.99230546 0.9921848  0.73270965 0.6998509\n",
      " 0.87670106 0.92100585 0.97058177 0.9909236  0.72671306 0.9066063\n",
      " 0.99466276 0.9884614 ]\n",
      "The rewards are: [0.9911849  0.9914009  0.9906176  0.9989957  0.7571855  0.82644314\n",
      " 0.9988607  0.9905399  0.98453254 0.99986315 0.9975909  0.98793435\n",
      " 0.9115138  0.94989455 0.99453133 0.99996793 0.6294253  0.9445272\n",
      " 0.99580294 0.9938446  0.8825751  0.9827702  0.9988275  0.9931051\n",
      " 0.79036117 0.9971205  0.99889225 0.99411774 0.70072865 0.98409593\n",
      " 0.5361358  0.8557315 ]\n",
      "The rewards are: [0.9953185  0.9990497  0.99992216 0.9961332  0.987998   0.983643\n",
      " 0.9856337  0.98689866 0.9850943  0.9818116  0.99904054 0.99673367\n",
      " 0.9207686  0.9988624  0.96509147 0.9931283  0.566792   0.7342235\n",
      " 0.969232   0.9912348  0.9986634  0.9845457  0.9296867  0.99622834\n",
      " 0.95753115 0.6220144  0.9348326  0.9376318  0.990159   0.980467\n",
      " 0.8246826  0.98419523]\n",
      "The rewards are: [0.9999249  0.86093485 0.97237813 0.99404424 0.9725928  0.9981811\n",
      " 0.99841523 0.987541   0.9921433  0.9895291  0.93510205 0.8350738\n",
      " 0.9990814  0.5954993  0.75390404 0.9665835  0.9924517  0.9950599\n",
      " 0.9588894  0.5568373  0.57306427 0.8629538  0.9992812  0.99743325\n",
      " 0.9984432  0.9545728  0.9981281  0.9973918  0.9993845  0.99788946\n",
      " 0.9873226  0.9993869 ]\n",
      "The rewards are: [0.99703574 0.9316777  0.636417   0.81858045 0.8336676  0.6642876\n",
      " 0.9969036  0.79940116 0.99402493 0.82826376 0.9826378  0.6063185\n",
      " 0.99888474 0.99861515 0.9982855  0.7603558  0.9527131  0.99911755\n",
      " 0.98918766 0.9955332  0.99983704 0.99668676 0.94974387 0.9987972\n",
      " 0.98559105 0.99976486 0.9959038  0.9403189  0.98264056 0.9898196\n",
      " 0.99844754 0.86519474]\n",
      "The rewards are: [0.99716383 0.99969053 0.96537495 0.9913624  0.99742365 0.99777216\n",
      " 0.9988493  0.9970523  0.98334724 0.9992537  0.99986684 0.99919194\n",
      " 0.995751   0.90738505 0.9976882  0.7475731  0.9109266  0.9859633\n",
      " 0.9829821  0.9810096  0.6786703  0.94939274 0.76252484 0.93033767\n",
      " 0.9985209  0.96021694 0.9901426  0.99973434 0.99102366 0.99186033\n",
      " 0.94833446 0.98959386]\n",
      "The rewards are: [0.96827376 0.9975758  0.99786144 0.9552528  0.9966018  0.64139396\n",
      " 0.93868023 0.9128372  0.93946224 0.99899894 0.9261707  0.998151\n",
      " 0.9972274  0.8528493  0.99811673 0.7841758  0.9938164  0.992527\n",
      " 0.9999021  0.8368365  0.884114   0.99269354 0.95604277 0.71517295\n",
      " 0.91541535 0.9771832  0.99029154 0.99849856 0.98143756 0.9934813\n",
      " 0.98531544 0.9997199 ]\n",
      "The rewards are: [0.98919743 0.8882191  0.6806477  0.99525684 0.98029387 0.9990502\n",
      " 0.9981974  0.82086885 0.9175169  0.9998747  0.9959341  0.90692115\n",
      " 0.9481411  0.9978846  0.6221347  0.6875834  0.9950878  0.99853766\n",
      " 0.9875907  0.9910087  0.9543788  0.99442095 0.8859326  0.9998066\n",
      " 0.99905103 0.6085592  0.9310555  0.96346915 0.99935895 0.9969326\n",
      " 0.93666536 0.9966704 ]\n",
      "The rewards are: [0.9947702  0.86876214 0.93966967 0.98903847 0.8071607  0.98911536\n",
      " 0.9871933  0.9957463  0.9750156  0.9948547  0.9832181  0.99701285\n",
      " 0.9965784  0.99958223 0.690637   0.92422825 0.9720799  0.9995227\n",
      " 0.99736506 0.97663695 0.98135155 0.90127623 0.9991517  0.9998878\n",
      " 0.97941935 0.5037639  0.99629384 0.96273637 0.9989643  0.9183446\n",
      " 0.9927241  0.8478648 ]\n",
      "The rewards are: [0.99729186 0.9738385  0.67637    0.6009462  0.9988086  0.99435294\n",
      " 0.77253324 0.9994067  0.5731475  0.9943222  0.9978161  0.5104934\n",
      " 0.9718062  0.634952   0.99698764 0.9184692  0.99070424 0.994338\n",
      " 0.9507521  0.99674183 0.9447197  0.9932214  0.9182638  0.9981084\n",
      " 0.99179864 0.8715225  0.80782294 0.996788   0.9208753  0.55806875\n",
      " 0.8023523  0.97974247]\n",
      "The rewards are: [0.99883467 0.9875881  0.734854   0.8985533  0.9866637  0.93533903\n",
      " 0.992718   0.9989999  0.9740214  0.5596268  0.98203593 0.99792457\n",
      " 0.96325576 0.99722266 0.99542135 0.9766545  0.8566348  0.9980848\n",
      " 0.9902148  0.9563787  0.99598914 0.9981425  0.9279817  0.96789205\n",
      " 0.93680793 0.97051865 0.9917625  0.987665   0.99151564 0.9322087\n",
      " 0.9768872  0.9826485 ]\n",
      "The rewards are: [0.9430957  0.606304   0.960673   0.9958584  0.9979233  0.9911891\n",
      " 0.99802786 0.9231989  0.9995759  0.99586713 0.99940634 0.85296863\n",
      " 0.7668111  0.98545164 0.998014   0.99953187 0.99932206 0.9945509\n",
      " 0.9989029  0.9470878  0.98843443 0.962191   0.99341875 0.8444666\n",
      " 0.95142204 0.9579276  0.9845664  0.99671054 0.80052435 0.9961133\n",
      " 0.98944014 0.9999641 ]\n",
      "The rewards are: [0.9956547  0.9858897  0.9835909  0.82577103 0.991264   0.9874445\n",
      " 0.87174803 0.96493095 0.9894385  0.99842876 0.96967643 0.96718544\n",
      " 0.959971   0.99643767 0.99922836 0.8775079  0.9988997  0.7768261\n",
      " 0.99345446 0.9982938  0.6215585  0.99766773 0.9990752  0.9997181\n",
      " 0.95118845 0.99966264 0.8098358  0.9230617  0.99480397 0.99868923\n",
      " 0.9993625  0.7517176 ]\n",
      "The rewards are: [0.93381804 0.951961   0.96971357 0.9972065  0.9401513  0.9733988\n",
      " 0.9998559  0.9958742  0.99765116 0.97121596 0.99415094 0.9802532\n",
      " 0.9980433  0.99729687 0.9883774  0.6584523  0.8801992  0.96976244\n",
      " 0.9599372  0.999443   0.9977314  0.7248824  0.9977981  0.98525107\n",
      " 0.9836385  0.996451   0.996894   0.9998721  0.99483067 0.8656473\n",
      " 0.9135306  0.96630913]\n",
      "The rewards are: [0.9993093  0.99539256 0.99846125 0.9910108  0.6155857  0.9961671\n",
      " 0.9967182  0.9996463  0.9918794  0.99825054 0.99847347 0.9739249\n",
      " 0.9958383  0.9797467  0.99290097 0.99002737 0.9795801  0.9974727\n",
      " 0.9863557  0.9991825  0.99033934 0.946181   0.99628264 0.9807663\n",
      " 0.92843646 0.99719006 0.87482756 0.9971219  0.8545134  0.9992543\n",
      " 0.9980204  0.9951574 ]\n",
      "The rewards are: [0.9742615  0.9951515  0.9994375  0.99471337 0.53068334 0.7633548\n",
      " 0.9916972  0.9858183  0.9997836  0.97005713 0.99383634 0.99660134\n",
      " 0.94594806 0.98975486 0.99524826 0.910791   0.9878334  0.9980788\n",
      " 0.78739536 0.9009813  0.99770254 0.9987717  0.80734855 0.999863\n",
      " 0.9976     0.9949987  0.8588553  0.89488477 0.92963725 0.97646517\n",
      " 0.8980302  0.76578   ]\n",
      "The rewards are: [0.9570455  0.8321198  0.9878803  0.99370897 0.815215   0.7543254\n",
      " 0.9136     0.9996896  0.84732556 0.98884356 0.99636024 0.99843425\n",
      " 0.9418994  0.99633384 0.7339381  0.6426029  0.98614776 0.9991085\n",
      " 0.99041766 0.9897385  0.6267728  0.99497104 0.99222285 0.9993162\n",
      " 0.99857974 0.98342746 0.998408   0.9299173  0.99749374 0.89221364\n",
      " 0.9998252  0.99464583]\n",
      "The rewards are: [0.9752773  0.89646524 0.90422076 0.9975349  0.99785334 0.9200966\n",
      " 0.6318802  0.9871133  0.99050903 0.99909127 0.99427646 0.9707879\n",
      " 0.95245796 0.99057543 0.99485683 0.9997682  0.9934743  0.7775524\n",
      " 0.84463036 0.97774124 0.5964267  0.97423846 0.9937989  0.9647977\n",
      " 0.9992348  0.9993654  0.98795044 0.8747775  0.6758604  0.9685389\n",
      " 0.99530655 0.635385  ]\n",
      "The rewards are: [0.9994343  0.99806017 0.99574846 0.9845748  0.99616677 0.99924856\n",
      " 0.9981641  0.98969275 0.9912621  0.97227263 0.7106459  0.9907855\n",
      " 0.99669135 0.99520123 0.9992667  0.96828127 0.83713895 0.9985279\n",
      " 0.9933571  0.8562456  0.9722171  0.95911866 0.97160745 0.59962493\n",
      " 0.8034593  0.99340266 0.9630496  0.78927374 0.94744885 0.9970029\n",
      " 0.9600299  0.85053825]\n",
      "The rewards are: [0.99981135 0.93957525 0.677238   0.97990716 0.9994591  0.99215275\n",
      " 0.9798891  0.99524    0.99990094 0.97015834 0.99436826 0.98985356\n",
      " 0.97555995 0.9165674  0.99983335 0.6010464  0.99853075 0.9937598\n",
      " 0.9894146  0.98339415 0.99897385 0.99960846 0.91590387 0.9998683\n",
      " 0.6124639  0.96773183 0.9991794  0.72250354 0.9796712  0.99955386\n",
      " 0.99310327 0.6312107 ]\n",
      "The rewards are: [0.7702849  0.9997298  0.9986356  0.9707235  0.89052325 0.99923325\n",
      " 0.7365993  0.79236484 0.5623036  0.9877238  0.5863595  0.9530614\n",
      " 0.9977452  0.98697436 0.997727   0.9991208  0.8252513  0.9961176\n",
      " 0.98910695 0.9933363  0.7352847  0.6061949  0.9053653  0.9975763\n",
      " 0.9991277  0.9789666  0.91887546 0.99883574 0.9727011  0.99765575\n",
      " 0.9650917  0.9666409 ]\n",
      "The rewards are: [0.92916596 0.9879507  0.9252352  0.9162164  0.9993364  0.99514115\n",
      " 0.9849686  0.98564976 0.83626837 0.9583248  0.9490067  0.980537\n",
      " 0.81463856 0.99066824 0.9990119  0.98634714 0.99461067 0.97477055\n",
      " 0.9869582  0.99562126 0.9914328  0.991121   0.99736124 0.99572396\n",
      " 0.9543511  0.7274821  0.59563994 0.5955981  0.9994973  0.9976941\n",
      " 0.9939319  0.72417545]\n",
      "The rewards are: [0.9948802  0.9936945  0.71313685 0.997591   0.9999782  0.99262893\n",
      " 0.63360274 0.99828374 0.98807496 0.7042491  0.91438913 0.99920374\n",
      " 0.9880443  0.8815625  0.83485484 0.9187513  0.99869245 0.9952524\n",
      " 0.9927521  0.9968804  0.71950746 0.9930401  0.9996136  0.9999217\n",
      " 0.8746053  0.988372   0.9931734  0.99220663 0.99700826 0.9338197\n",
      " 0.99863356 0.9997464 ]\n",
      "The rewards are: [0.9955989  0.9855268  0.96009487 0.99856985 0.99744886 0.9567213\n",
      " 0.99977857 0.96222466 0.98561096 0.8614157  0.96879    0.9769842\n",
      " 0.88820314 0.8722175  0.98908013 0.9869797  0.9926806  0.99120903\n",
      " 0.98009056 0.99686414 0.96737236 0.99875855 0.98131275 0.9990676\n",
      " 0.65242815 0.72420263 0.9999528  0.8701366  0.98959863 0.9970805\n",
      " 0.9983103  0.98966813]\n",
      "The rewards are: [0.9998373  0.98679334 0.98965085 0.9923253  0.99939644 0.81058115\n",
      " 0.9921228  0.99543923 0.8897138  0.9815294  0.98955554 0.995138\n",
      " 0.56598556 0.89835787 0.986148   0.9263934  0.99938893 0.96924365\n",
      " 0.9969694  0.99017733 0.9198985  0.999316   0.9723126  0.9996302\n",
      " 0.9983498  0.9818102  0.96920705 0.9433967  0.9992536  0.75064653\n",
      " 0.9221134  0.9144795 ]\n",
      "The rewards are: [0.9964986  0.80859065 0.9995565  0.96702576 0.860582   0.9248578\n",
      " 0.98578495 0.99702114 0.99958915 0.97329366 0.9999893  0.99221766\n",
      " 0.9861733  0.9848481  0.9956109  0.66094285 0.9639715  0.82817054\n",
      " 0.9900961  0.99939513 0.9874796  0.9988367  0.99915683 0.9970783\n",
      " 0.8402622  0.9804843  0.8705026  0.9995975  0.5809313  0.763254\n",
      " 0.9992415  0.9722124 ]\n",
      "The rewards are: [0.9954039  0.9930601  0.9978917  0.98225534 0.9986687  0.99117917\n",
      " 0.9578341  0.84854865 0.9956624  0.98229206 0.98108184 0.997624\n",
      " 0.9862953  0.96154344 0.9760696  0.99817705 0.99291694 0.8394012\n",
      " 0.97023654 0.9971288  0.99949026 0.99835974 0.9981343  0.97551334\n",
      " 0.9952899  0.9898811  0.99750143 0.9987631  0.9544062  0.990272\n",
      " 0.8929297  0.98781556]\n",
      "The rewards are: [0.5531977  0.9998005  0.99540687 0.9974948  0.9960836  0.87925416\n",
      " 0.9062447  0.9991867  0.9276589  0.99404234 0.9152525  0.9976295\n",
      " 0.9850841  0.9628197  0.9966092  0.9985084  0.9891915  0.9402694\n",
      " 0.99906033 0.9980141  0.9866811  0.99850476 0.99919754 0.98978186\n",
      " 0.97670627 0.9286517  0.99390775 0.968453   0.93879896 0.99042237\n",
      " 0.9946615  0.8557813 ]\n",
      "The rewards are: [0.6249231  0.9992493  0.9554971  0.9984427  0.9635248  0.78885704\n",
      " 0.9983581  0.9976903  0.97367233 0.993537   0.9181971  0.9783891\n",
      " 0.8419937  0.99532217 0.90555483 0.99192566 0.9956552  0.9941579\n",
      " 0.99705184 0.6517003  0.9438803  0.9957273  0.9753621  0.75676817\n",
      " 0.9019735  0.95873994 0.9902469  0.6248961  0.66947097 0.99879056\n",
      " 0.9981515  0.9947607 ]\n",
      "The rewards are: [0.99574924 0.96045387 0.99964    0.99954164 0.9990343  0.9367427\n",
      " 0.99983454 0.98136693 0.8316389  0.8922945  0.99975294 0.82276636\n",
      " 0.99754936 0.9966897  0.5932423  0.98283374 0.9991677  0.9982628\n",
      " 0.9995338  0.9886701  0.75775796 0.9558825  0.9980471  0.99984455\n",
      " 0.99357235 0.9989398  0.9848075  0.99499387 0.9988863  0.9978229\n",
      " 0.5037901  0.9892964 ]\n",
      "The rewards are: [0.813285   0.9735433  0.9982582  0.9980646  0.955296   0.9842068\n",
      " 0.9984983  0.8970612  0.9985453  0.9991423  0.9898977  0.9934156\n",
      " 0.97507125 0.9939454  0.914649   0.9912333  0.97821724 0.9992155\n",
      " 0.99910563 0.9990101  0.99700576 0.9764904  0.9923388  0.999326\n",
      " 0.99971133 0.9997869  0.9980434  0.999236   0.9446533  0.7177952\n",
      " 0.99153566 0.9959776 ]\n",
      "The rewards are: [0.9986993  0.99864584 0.9987546  0.83567405 0.987778   0.9918826\n",
      " 0.9928491  0.9638276  0.99815124 0.85260147 0.8825679  0.9951278\n",
      " 0.98355246 0.9245449  0.99008137 0.99925965 0.9893798  0.94473755\n",
      " 0.86393195 0.9919241  0.9528869  0.99256176 0.91170514 0.99862957\n",
      " 0.9564726  0.9987715  0.98073304 0.9954217  0.9036458  0.9960175\n",
      " 0.9990914  0.99519485]\n",
      "The rewards are: [0.96207213 0.99468094 0.99633825 0.99358046 0.9913657  0.90507156\n",
      " 0.8843725  0.9975896  0.72530806 0.9359179  0.9902153  0.9963898\n",
      " 0.7214439  0.97593665 0.9788374  0.8020747  0.9737811  0.9967468\n",
      " 0.9961604  0.9932916  0.9989612  0.99941957 0.99061537 0.87815094\n",
      " 0.9974819  0.99594927 0.9938391  0.854553   0.783648   0.97686964\n",
      " 0.913574   0.9964032 ]\n",
      "The rewards are: [0.9984648  0.9945714  0.9969625  0.52835774 0.9896035  0.98975044\n",
      " 0.98184377 0.81976736 0.98409146 0.9965024  0.9986877  0.7944953\n",
      " 0.99852353 0.9963754  0.9747361  0.96314836 0.9864204  0.83866966\n",
      " 0.99627644 0.997063   0.99777776 0.9790354  0.9991472  0.9952932\n",
      " 0.7809791  0.93551475 0.99976355 0.9783797  0.99977404 0.8764647\n",
      " 0.8236989  0.9675377 ]\n",
      "The rewards are: [0.9978911  0.9997727  0.99601066 0.89918244 0.9811652  0.9245301\n",
      " 0.99677867 0.97829574 0.9899087  0.99410266 0.7422178  0.9920997\n",
      " 0.99883384 0.99938154 0.9966696  0.88952607 0.97631073 0.99390984\n",
      " 0.7888113  0.9997613  0.9993063  0.9979929  0.6782208  0.99590117\n",
      " 0.9985996  0.99160755 0.99002445 0.980409   0.9992704  0.988736\n",
      " 0.98291415 0.9997143 ]\n",
      "The rewards are: [0.9158754  0.92406625 0.9758238  0.99549234 0.99255824 0.99764484\n",
      " 0.9977863  0.9832375  0.9986572  0.99373287 0.81529045 0.9983523\n",
      " 0.9833366  0.9793234  0.9937697  0.6816888  0.99842644 0.995856\n",
      " 0.99713683 0.9943151  0.87651837 0.9986884  0.99875736 0.9931727\n",
      " 0.9892225  0.9971679  0.5035345  0.9999647  0.9961882  0.905008\n",
      " 0.8446146  0.9969478 ]\n",
      "The rewards are: [0.9788067  0.9788536  0.99677926 0.98489535 0.9695388  0.9458796\n",
      " 0.95784134 0.99696106 0.9929974  0.9234289  0.99659234 0.9779148\n",
      " 0.9998559  0.7518566  0.9964737  0.5014017  0.88302743 0.9987758\n",
      " 0.9598633  0.96831983 0.989815   0.98678166 0.9963542  0.96652234\n",
      " 0.99967587 0.9971951  0.99599177 0.90682966 0.9981823  0.98036677\n",
      " 0.9746373  0.99905807]\n",
      "The rewards are: [0.99352324 0.9881544  0.881721   0.99440104 0.78354853 0.999655\n",
      " 0.8988068  0.99838316 0.99981064 0.99417156 0.999877   0.99908817\n",
      " 0.99019545 0.9920582  0.8250936  0.9653328  0.99994063 0.999458\n",
      " 0.99087816 0.8079618  0.9811218  0.9991524  0.97466475 0.9636487\n",
      " 0.99783105 0.5258012  0.65062517 0.89144063 0.9782866  0.9978254\n",
      " 0.98123497 0.94351405]\n",
      "The rewards are: [0.99012053 0.99851626 0.9544587  0.9990011  0.99875665 0.8142833\n",
      " 0.9973832  0.98330325 0.99625564 0.9798621  0.99607384 0.8449468\n",
      " 0.9929422  0.639212   0.99830544 0.9986424  0.9913625  0.6189925\n",
      " 0.9977005  0.99472165 0.9791702  0.99894565 0.8598411  0.9538181\n",
      " 0.9655914  0.9994025  0.9340531  0.7347143  0.79557717 0.6511809\n",
      " 0.9996643  0.99883586]\n",
      "The rewards are: [0.9990427  0.99503076 0.9945749  0.97757256 0.97663045 0.98480636\n",
      " 0.9955179  0.9997173  0.99920183 0.999788   0.9774803  0.98475885\n",
      " 0.9866508  0.9923458  0.9915918  0.99754506 0.9835133  0.9962035\n",
      " 0.9981096  0.874096   0.98878366 0.9838411  0.9601431  0.9933555\n",
      " 0.9999529  0.95337236 0.97751915 0.55796635 0.9897105  0.79222506\n",
      " 0.6780032  0.9904178 ]\n",
      "The rewards are: [0.790935   0.9929034  0.99953234 0.98032296 0.5714095  0.98847663\n",
      " 0.9982323  0.9989471  0.9955106  0.9929564  0.99869305 0.99898726\n",
      " 0.95743006 0.9991437  0.9829448  0.6025612  0.9952596  0.98069465\n",
      " 0.9803853  0.8088273  0.9481038  0.98899764 0.9997458  0.5018362\n",
      " 0.57233846 0.99114734 0.9948591  0.94304395 0.9812294  0.98535556\n",
      " 0.8476067  0.5326816 ]\n",
      "The rewards are: [0.99547064 0.99023575 0.9925948  0.9884914  0.98252535 0.9181078\n",
      " 0.99506783 0.9951534  0.8395499  0.9905263  0.9978115  0.9954922\n",
      " 0.95926416 0.999313   0.98857844 0.9995369  0.9904981  0.9459998\n",
      " 0.91616386 0.60258687 0.9801775  0.99954635 0.87986165 0.9885181\n",
      " 0.984681   0.94533056 0.9782542  0.880426   0.9992423  0.98901564\n",
      " 0.9452667  0.9991918 ]\n",
      "The rewards are: [0.9966696  0.99923444 0.9995572  0.962805   0.9726209  0.9663467\n",
      " 0.9369322  0.9875874  0.9984469  0.62403995 0.98796487 0.9966582\n",
      " 0.9999434  0.96223366 0.9996119  0.9970125  0.99990535 0.9995521\n",
      " 0.5497341  0.99971026 0.98530513 0.9946812  0.96374136 0.9621113\n",
      " 0.7356003  0.9557791  0.9951232  0.99403125 0.99846625 0.8825373\n",
      " 0.99472886 0.998642  ]\n",
      "The rewards are: [0.9972187  0.9971577  0.96728927 0.97144157 0.65256387 0.9962843\n",
      " 0.99915576 0.997247   0.74245113 0.8753199  0.9504153  0.9220585\n",
      " 0.9959804  0.91958946 0.99422944 0.9994392  0.5406521  0.98801595\n",
      " 0.84371316 0.9678976  0.8707154  0.9948002  0.9997285  0.937277\n",
      " 0.7350684  0.99029034 0.9997019  0.9842853  0.6468325  0.99141335\n",
      " 0.9881655  0.99544746]\n",
      "The rewards are: [0.99877995 0.9545276  0.97607076 0.9750769  0.99899095 0.9726036\n",
      " 0.99914    0.98537165 0.9813571  0.99566936 0.9972192  0.994156\n",
      " 0.99994636 0.99974483 0.82143545 0.99932325 0.95530134 0.9947337\n",
      " 0.8706889  0.83804226 0.99700063 0.99972695 0.9974849  0.7645548\n",
      " 0.9655556  0.94549793 0.99721116 0.9977513  0.97601056 0.99890935\n",
      " 0.99914944 0.97245884]\n",
      "The rewards are: [0.9979424  0.6408907  0.9890154  0.7346803  0.98082685 0.9954014\n",
      " 0.99783725 0.99841666 0.87307674 0.9967326  0.9998165  0.9697534\n",
      " 0.8633107  0.99969673 0.99976    0.99994504 0.9974457  0.99952245\n",
      " 0.99779665 0.96205765 0.99970776 0.99801576 0.9627475  0.9994211\n",
      " 0.99825877 0.99053544 0.88190955 0.9947792  0.9932221  0.62375903\n",
      " 0.99155504 0.57504886]\n",
      "The rewards are: [0.98013777 0.99971443 0.99728036 0.94385916 0.9957962  0.8245162\n",
      " 0.98798066 0.9889233  0.974831   0.6110421  0.8463169  0.99373347\n",
      " 0.9157409  0.9967127  0.9994392  0.99869776 0.909809   0.99317616\n",
      " 0.85057425 0.99935466 0.99551153 0.99892247 0.9773221  0.85746646\n",
      " 0.9263533  0.96318287 0.9876294  0.9963586  0.99168175 0.997472\n",
      " 0.9968078  0.983519  ]\n",
      "The rewards are: [0.984606   0.7164464  0.8607859  0.98045015 0.86653525 0.9428974\n",
      " 0.98948216 0.9946331  0.900743   0.9759119  0.9992073  0.9716259\n",
      " 0.8538573  0.99300075 0.92801297 0.9992724  0.82407695 0.9961094\n",
      " 0.9460015  0.9836404  0.9998884  0.913794   0.963918   0.9952739\n",
      " 0.9166289  0.9587193  0.97284734 0.99893326 0.9761791  0.97681594\n",
      " 0.99803966 0.99878925]\n",
      "The rewards are: [0.95956147 0.9981615  0.56394845 0.99156183 0.9986388  0.9682648\n",
      " 0.99296534 0.9958047  0.9980003  0.9982621  0.9839371  0.99821293\n",
      " 0.5469902  0.999871   0.9943646  0.9968927  0.9403185  0.9985996\n",
      " 0.9991528  0.9771388  0.9854556  0.9652556  0.63272053 0.99078953\n",
      " 0.99827874 0.9992005  0.7171301  0.87790585 0.8537329  0.9982571\n",
      " 0.9818454  0.9947843 ]\n",
      "The rewards are: [0.77535117 0.80332875 0.8481649  0.992203   0.99974483 0.9987941\n",
      " 0.5004141  0.9895511  0.9993106  0.702174   0.97762716 0.99783486\n",
      " 0.96426237 0.9972716  0.9089028  0.96204203 0.7843673  0.9708043\n",
      " 0.86459637 0.8029235  0.9715072  0.69323295 0.92689854 0.6613776\n",
      " 0.9959488  0.8041487  0.9900746  0.9993131  0.999514   0.9982838\n",
      " 0.98590994 0.99678767]\n",
      "The rewards are: [0.52057606 0.98729265 0.9982015  0.97079057 0.99830294 0.9995814\n",
      " 0.96789783 0.99418527 0.9995521  0.9900698  0.72996575 0.99408746\n",
      " 0.99323165 0.9997646  0.98380464 0.9797023  0.99516594 0.5311665\n",
      " 0.99476516 0.93664485 0.9994387  0.5302324  0.9905757  0.87238\n",
      " 0.99610585 0.99992967 0.9879028  0.9898011  0.89873123 0.77283263\n",
      " 0.8137684  0.98426324]\n",
      "The rewards are: [0.9386225  0.9996861  0.91289526 0.93280643 0.99998355 0.9768613\n",
      " 0.83930284 0.91672283 0.98184115 0.8339082  0.99897623 0.9979766\n",
      " 0.99392724 0.99775875 0.99709606 0.9924711  0.7613882  0.99911696\n",
      " 0.9732072  0.99952185 0.95839804 0.99778396 0.9979954  0.8421423\n",
      " 0.9849043  0.97105205 0.99914396 0.97433203 0.9982992  0.9707812\n",
      " 0.83017313 0.81644046]\n",
      "The rewards are: [0.9983777  0.8940319  0.9984975  0.97785586 0.99810225 0.99941707\n",
      " 0.8216153  0.9435381  0.97059256 0.99993813 0.9994874  0.99818254\n",
      " 0.99955887 0.9536784  0.98014337 0.9193803  0.9906052  0.9995378\n",
      " 0.77739865 0.993323   0.98418313 0.9999943  0.9928335  0.9757746\n",
      " 0.97954607 0.99020606 0.9929028  0.9006684  0.7546094  0.9944817\n",
      " 0.9133415  0.98621815]\n",
      "The rewards are: [0.9938111  0.9986179  0.97302455 0.7349466  0.9984414  0.9220386\n",
      " 0.9809553  0.9451696  0.9694309  0.85533255 0.992677   0.8591678\n",
      " 0.803636   0.9955537  0.99901974 0.998021   0.886802   0.999936\n",
      " 0.968578   0.8323124  0.98811674 0.9991714  0.9924971  0.9906357\n",
      " 0.9118315  0.50904524 0.60349405 0.9779328  0.99993217 0.8513285\n",
      " 0.99217504 0.99935347]\n",
      "The rewards are: [0.9192993  0.998323   0.99934405 0.9006476  0.9950787  0.98493433\n",
      " 0.99977845 0.9977191  0.64375705 0.99205106 0.9802199  0.9125135\n",
      " 0.9945146  0.9998653  0.9996513  0.9528634  0.99502426 0.8977575\n",
      " 0.9991393  0.99642736 0.9977386  0.996478   0.9549303  0.99431205\n",
      " 0.99894625 0.6580892  0.73441017 0.8740925  0.9223134  0.9604885\n",
      " 0.94589275 0.9992569 ]\n",
      "The rewards are: [0.9612149  0.8027903  0.8960171  0.9988507  0.9257018  0.78944755\n",
      " 0.6091527  0.750296   0.9994197  0.99961406 0.9794505  0.9994469\n",
      " 0.9397234  0.9961325  0.9903398  0.98717356 0.96109277 0.68793017\n",
      " 0.99960464 0.9918174  0.9989145  0.99220055 0.99035674 0.9905946\n",
      " 0.80948234 0.9990158  0.9954072  0.99829334 0.68605864 0.9661098\n",
      " 0.9993319  0.99934417]\n",
      "The rewards are: [0.89646214 0.9921584  0.9981293  0.93603384 0.79484934 0.9017826\n",
      " 0.99984133 0.9993193  0.98369664 0.6030737  0.52222776 0.996808\n",
      " 0.97030085 0.9613102  0.9857401  0.9916636  0.8704684  0.65524125\n",
      " 0.9168107  0.7956912  0.9972988  0.93382025 0.8742389  0.9830465\n",
      " 0.9925029  0.93319756 0.99075705 0.9958616  0.9917922  0.9972017\n",
      " 0.99490863 0.8755736 ]\n",
      "The rewards are: [0.99861956 0.97628856 0.93847567 0.91913766 0.98987246 0.634924\n",
      " 0.9971957  0.8442828  0.95777553 0.99720544 0.98627186 0.5776547\n",
      " 0.9943715  0.9996388  0.8409843  0.9991334  0.9992599  0.9840274\n",
      " 0.88106227 0.6065185  0.9570114  0.89440876 0.94631934 0.9916156\n",
      " 0.9998073  0.99971455 0.57458377 0.99938715 0.997532   0.9983944\n",
      " 0.9869882  0.90458965]\n",
      "The rewards are: [0.99941635 0.99685246 0.82890123 0.9994435  0.9953002  0.9859294\n",
      " 0.8700079  0.99461293 0.9488886  0.99145645 0.992634   0.9942849\n",
      " 0.9992912  0.77644026 0.999331   0.9943276  0.9770636  0.84786546\n",
      " 0.99002564 0.9998274  0.90136033 0.9907195  0.9993007  0.8451894\n",
      " 0.784139   0.9829032  0.5573809  0.84637755 0.97126997 0.7925941\n",
      " 0.96651644 0.99835926]\n",
      "The rewards are: [0.99056554 0.761217   0.5053271  0.796181   0.8416625  0.9984718\n",
      " 0.73642254 0.83903265 0.99658173 0.86247855 0.9995128  0.9918541\n",
      " 0.8113157  0.9851291  0.9210797  0.98995984 0.98245597 0.99641454\n",
      " 0.7003807  0.99786526 0.99035114 0.997248   0.97040313 0.77325135\n",
      " 0.6431843  0.9977648  0.5907056  0.7961742  0.99969876 0.99412537\n",
      " 0.9994247  0.97828954]\n",
      "The rewards are: [0.9988695  0.9985184  0.9978436  0.99969816 0.9831467  0.9301988\n",
      " 0.9991596  0.995765   0.9972573  0.9975648  0.7257842  0.9988524\n",
      " 0.88745445 0.99912935 0.99539703 0.9985215  0.997652   0.9985813\n",
      " 0.9914601  0.9994905  0.9984926  0.99775887 0.99543273 0.9992742\n",
      " 0.9242459  0.81178904 0.997666   0.97977453 0.566366   0.64655805\n",
      " 0.98949105 0.9989214 ]\n",
      "The rewards are: [0.6363991  0.8953042  0.9928768  0.9642946  0.97296405 0.67560315\n",
      " 0.79631484 0.8927129  0.87830365 0.5171715  0.5827254  0.99517655\n",
      " 0.9988248  0.9629088  0.99314076 0.99163985 0.93346703 0.99920684\n",
      " 0.995817   0.8825202  0.9781124  0.9809795  0.9883664  0.9565266\n",
      " 0.7215692  0.86243004 0.9996878  0.9283221  0.9990625  0.99808335\n",
      " 0.9956292  0.98149145]\n",
      "The rewards are: [0.90828973 0.9220927  0.6998811  0.8980033  0.77817804 0.5042104\n",
      " 0.96477115 0.9996947  0.99280715 0.9986908  0.88911575 0.97851425\n",
      " 0.777079   0.7935601  0.9559481  0.98041266 0.9993542  0.81863034\n",
      " 0.9769355  0.98372066 0.9948724  0.99506396 0.99728084 0.9995846\n",
      " 0.9869223  0.9996897  0.9968541  0.9987835  0.95986193 0.9877039\n",
      " 0.9986249  0.9812195 ]\n",
      "The rewards are: [0.99927753 0.92901903 0.9899188  0.9977284  0.9897496  0.9984302\n",
      " 0.9928532  0.9983163  0.9981225  0.9767994  0.9996278  0.9986395\n",
      " 0.9523845  0.99429905 0.9961313  0.96760637 0.95858115 0.99770325\n",
      " 0.7825204  0.99837697 0.91551566 0.9996877  0.98752767 0.894128\n",
      " 0.9841426  0.9971769  0.982939   0.9699238  0.9514735  0.91057324\n",
      " 0.6223443  0.999076  ]\n",
      "The rewards are: [0.8549106  0.9951533  0.63670003 0.9710624  0.7786569  0.99881256\n",
      " 0.6760753  0.9840953  0.9962366  0.62649417 0.9925494  0.994827\n",
      " 0.92438763 0.9984546  0.9975667  0.99827003 0.9944607  0.8840579\n",
      " 0.6269795  0.934173   0.9915798  0.9913891  0.7598325  0.9985393\n",
      " 0.990396   0.9934371  0.9162172  0.99043006 0.92191005 0.9984775\n",
      " 0.81714326 0.88683003]\n",
      "The rewards are: [0.9895494  0.7605995  0.99772197 0.9951776  0.99492466 0.99849725\n",
      " 0.9997695  0.8330885  0.99887675 0.9994261  0.9588653  0.9961563\n",
      " 0.9808806  0.97745425 0.9933096  0.97444296 0.66410387 0.9945358\n",
      " 0.6839447  0.99464154 0.99867827 0.5259402  0.99059826 0.99708325\n",
      " 0.9116759  0.9885479  0.99067116 0.9880778  0.99958533 0.9449744\n",
      " 0.9815362  0.6818365 ]\n",
      "The rewards are: [0.9444058  0.9967648  0.99968076 0.70506185 0.9981092  0.9926742\n",
      " 0.9990466  0.88509816 0.65973467 0.9998739  0.999479   0.9947336\n",
      " 0.70021087 0.9844774  0.9997429  0.97083503 0.98644525 0.8671507\n",
      " 0.9992574  0.7592855  0.9533513  0.53248715 0.72367805 0.9953507\n",
      " 0.8659813  0.9982999  0.9951761  0.9993686  0.9968395  0.998201\n",
      " 0.81186664 0.75922847]\n",
      "The rewards are: [0.99033606 0.99886596 0.9354998  0.99803036 0.99986315 0.5916623\n",
      " 0.91252244 0.9935022  0.9994673  0.97694665 0.72804254 0.9884985\n",
      " 0.99661475 0.99998426 0.93576694 0.89414954 0.909348   0.9808173\n",
      " 0.79665065 0.9983564  0.9672345  0.99737954 0.99901986 0.99968815\n",
      " 0.99191535 0.9882786  0.9997868  0.86093307 0.9798963  0.99972945\n",
      " 0.9738932  0.9997657 ]\n",
      "The rewards are: [0.97367984 0.93987244 0.99444324 0.9521832  0.9991709  0.9572552\n",
      " 0.6355754  0.9132269  0.99911183 0.9950648  0.9984586  0.9121452\n",
      " 0.9872364  0.9950718  0.9862985  0.9887489  0.97418004 0.9990823\n",
      " 0.9929148  0.936603   0.9911355  0.98671615 0.99984133 0.9154799\n",
      " 0.9738158  0.9998388  0.99147934 0.99864393 0.9738152  0.9974795\n",
      " 0.9877984  0.9992173 ]\n",
      "The rewards are: [0.99865925 0.7805273  0.96208274 0.9978363  0.99550617 0.93444675\n",
      " 0.87442106 0.9603933  0.9828812  0.9998826  0.99809724 0.9949877\n",
      " 0.9836881  0.9256733  0.999496   0.7714003  0.9577496  0.97402227\n",
      " 0.99841225 0.97040534 0.9826188  0.99968565 0.94009125 0.7868816\n",
      " 0.9628568  0.84730494 0.9979144  0.914711   0.9842911  0.836617\n",
      " 0.9982704  0.99884355]\n",
      "The rewards are: [0.98375916 0.98864716 0.8362657  0.9895716  0.99892455 0.99953127\n",
      " 0.99962807 0.9974298  0.99857223 0.8501404  0.8735633  0.9981268\n",
      " 0.9997607  0.97487664 0.99368155 0.8759726  0.9940591  0.98456925\n",
      " 0.9887449  0.61301315 0.93865544 0.9971584  0.99459535 0.9948961\n",
      " 0.9761372  0.52589995 0.9952614  0.98863155 0.73421663 0.99585634\n",
      " 0.92972404 0.9966794 ]\n",
      "The rewards are: [0.98731333 0.76439023 0.9954195  0.5352844  0.63548946 0.9886021\n",
      " 0.9596837  0.9950991  0.95664245 0.9998913  0.65928686 0.97623605\n",
      " 0.99860317 0.7494906  0.9956974  0.9852342  0.99889344 0.95264393\n",
      " 0.9858174  0.95222497 0.9984207  0.78027314 0.99331856 0.97287273\n",
      " 0.5845297  0.88011277 0.99544513 0.99950457 0.66042006 0.7773702\n",
      " 0.99831885 0.97553194]\n",
      "The rewards are: [0.81509256 0.9663234  0.7166538  0.9771309  0.99625504 0.98874307\n",
      " 0.9933509  0.996391   0.72642374 0.5808882  0.99535614 0.8700417\n",
      " 0.9948625  0.99515593 0.63088095 0.95557797 0.9858781  0.99436015\n",
      " 0.979486   0.99982977 0.9996433  0.5260101  0.998064   0.9409249\n",
      " 0.97917616 0.984298   0.9948698  0.99558604 0.9968876  0.97108036\n",
      " 0.9961254  0.9989467 ]\n",
      "The rewards are: [0.91840523 0.98417825 0.777046   0.9933955  0.8994773  0.7409493\n",
      " 0.96825    0.9915366  0.9125284  0.9870799  0.9778006  0.8550573\n",
      " 0.99056554 0.5773705  0.99897194 0.9987447  0.98743016 0.54707575\n",
      " 0.999982   0.6674046  0.81105554 0.9988391  0.9931358  0.99985814\n",
      " 0.96982217 0.98475444 0.9808745  0.8580385  0.9879957  0.9997907\n",
      " 0.98296344 0.9838171 ]\n",
      "The rewards are: [0.9935674  0.9868751  0.9998425  0.9935986  0.73807925 0.99978703\n",
      " 0.98826104 0.9975497  0.9475133  0.99892634 0.9245024  0.9926081\n",
      " 0.9997032  0.9893901  0.9454952  0.90145165 0.9996921  0.9955935\n",
      " 0.9355843  0.9422343  0.639654   0.9989685  0.99855787 0.99760276\n",
      " 0.83977693 0.76213    0.99871504 0.99888355 0.94420725 0.99900514\n",
      " 0.98687685 0.9981865 ]\n",
      "The rewards are: [0.9535492  0.52984095 0.9690525  0.94757664 0.9890688  0.6151972\n",
      " 0.996543   0.9858278  0.92411953 0.9981768  0.9426359  0.8314106\n",
      " 0.9961876  0.98976773 0.5892124  0.9974323  0.7193782  0.9997693\n",
      " 0.8278378  0.999345   0.7015395  0.9957563  0.999795   0.6845972\n",
      " 0.7361824  0.97365713 0.99856853 0.9981937  0.99804175 0.79400826\n",
      " 0.998505   0.99480057]\n",
      "The rewards are: [0.97546184 0.9944258  0.9689734  0.9779207  0.90115106 0.9960162\n",
      " 0.9895767  0.9998901  0.98549104 0.99961156 0.9077506  0.9710641\n",
      " 0.9973718  0.96319735 0.98871744 0.6208222  0.94746053 0.99576\n",
      " 0.739744   0.9969779  0.99554235 0.9951864  0.97806305 0.99140245\n",
      " 0.9986676  0.92472297 0.9998491  0.9949378  0.99753547 0.50912154\n",
      " 0.7021112  0.9887449 ]\n",
      "The rewards are: [0.98134214 0.8776128  0.9993888  0.9965035  0.9997311  0.77903813\n",
      " 0.94875544 0.9263987  0.74057    0.9926682  0.9779267  0.9410841\n",
      " 0.8758188  0.9239862  0.7484453  0.8921481  0.9950539  0.9833392\n",
      " 0.9993808  0.9934186  0.72058487 0.52930564 0.99916613 0.9970805\n",
      " 0.9908702  0.82433504 0.99968255 0.9921292  0.9910165  0.90616965\n",
      " 0.9994174  0.94090134]\n",
      "The rewards are: [0.99275714 0.9940216  0.9839101  0.9976891  0.89345205 0.9358626\n",
      " 0.9992699  0.8079639  0.98870766 0.99527645 0.99066377 0.9985072\n",
      " 0.897387   0.9957782  0.9947633  0.9992986  0.95010066 0.9974064\n",
      " 0.77334136 0.993961   0.9984646  0.94468117 0.97624546 0.9993444\n",
      " 0.99833906 0.9947141  0.9365064  0.6751684  0.5863691  0.9913953\n",
      " 0.9985618  0.996759  ]\n",
      "The rewards are: [0.985472   0.9891523  0.880025   0.99903023 0.99964094 0.9931445\n",
      " 0.9992931  0.9997224  0.9870658  0.9970018  0.5360255  0.8779498\n",
      " 0.9073624  0.75967836 0.99263424 0.98631674 0.9863318  0.9096737\n",
      " 0.9059726  0.9820837  0.88978225 0.9991129  0.94444937 0.9401544\n",
      " 0.999879   0.97584903 0.92409873 0.65831894 0.99761754 0.8450097\n",
      " 0.9948084  0.9996517 ]\n",
      "The rewards are: [0.98522586 0.89288634 0.99929416 0.9991487  0.9941089  0.99510777\n",
      " 0.86813617 0.99547714 0.9983524  0.975371   0.99995816 0.98237866\n",
      " 0.53837204 0.9977806  0.9977997  0.9922775  0.9984548  0.9942484\n",
      " 0.97254485 0.9983175  0.9981681  0.9145015  0.99623483 0.9760252\n",
      " 0.9799706  0.9882476  0.9934795  0.9985331  0.959167   0.53118294\n",
      " 0.9999198  0.6997637 ]\n",
      "The rewards are: [0.9678017  0.97528785 0.99957746 0.99353117 0.9905003  0.9725248\n",
      " 0.98898435 0.707737   0.74339557 0.99648726 0.99877805 0.5989983\n",
      " 0.99541724 0.9674022  0.99524647 0.7444872  0.95001113 0.5544179\n",
      " 0.91751486 0.99846363 0.99689686 0.9999032  0.97247654 0.99691975\n",
      " 0.9995426  0.99675816 0.70528215 0.9809919  0.9588724  0.8621343\n",
      " 0.9983851  0.91672367]\n",
      "The rewards are: [0.9900566  0.98495007 0.995987   0.98581564 0.9987632  0.94209784\n",
      " 0.99905664 0.9669775  0.9986356  0.99932253 0.9717002  0.9523704\n",
      " 0.690808   0.97283304 0.82803035 0.8818825  0.9997688  0.98032266\n",
      " 0.997581   0.9978849  0.9984682  0.9970739  0.9930923  0.99657404\n",
      " 0.9984127  0.9981596  0.7314437  0.95838076 0.9987921  0.98901784\n",
      " 0.9806717  0.9947773 ]\n",
      "The rewards are: [0.9124227  0.9986393  0.98273855 0.8763428  0.9961796  0.9266776\n",
      " 0.6026418  0.9991277  0.9964484  0.9727255  0.99373746 0.9893665\n",
      " 0.9756251  0.9202282  0.9788527  0.98055446 0.99820864 0.9907671\n",
      " 0.9358493  0.99708813 0.99993706 0.9854386  0.99926704 0.9964394\n",
      " 0.998722   0.99262446 0.9700225  0.9961403  0.8219241  0.99207497\n",
      " 0.99778277 0.9474779 ]\n",
      "The rewards are: [0.99507034 0.9647719  0.99984    0.9805258  0.99838436 0.9968755\n",
      " 0.9939143  0.9995834  0.9941942  0.9955266  0.95825016 0.5090797\n",
      " 0.99729556 0.99699414 0.9717943  0.9856958  0.9924533  0.9982937\n",
      " 0.99851066 0.95982814 0.8290898  0.9936219  0.98603016 0.53314096\n",
      " 0.9975076  0.9099886  0.9997304  0.9867137  0.99980766 0.9243644\n",
      " 0.9109678  0.9956195 ]\n",
      "The rewards are: [0.99752134 0.985685   0.9830443  0.5266463  0.9981384  0.8200153\n",
      " 0.9920432  0.9997229  0.9890871  0.892958   0.9942107  0.7099432\n",
      " 0.95909137 0.99542725 0.99400926 0.9922408  0.9961786  0.6946098\n",
      " 0.99459213 0.95579726 0.96226835 0.99125075 0.6178307  0.9373059\n",
      " 0.9996408  0.7846072  0.97975427 0.9904156  0.999688   0.99311227\n",
      " 0.9974286  0.9571737 ]\n",
      "The rewards are: [0.99102485 0.9234002  0.99238425 0.97857887 0.891893   0.98490787\n",
      " 0.99930704 0.9888326  0.9732073  0.88951397 0.9891312  0.9802955\n",
      " 0.9984585  0.8670838  0.9499296  0.9894539  0.9903132  0.99917907\n",
      " 0.9928758  0.99719065 0.9970463  0.52588135 0.9975846  0.98293084\n",
      " 0.99649173 0.9866129  0.99724483 0.97732973 0.99943477 0.9972735\n",
      " 0.6703172  0.87140256]\n",
      "The rewards are: [0.9995158  0.99842936 0.92730725 0.9953572  0.9986625  0.99114746\n",
      " 0.99984646 0.999818   0.9994118  0.8980986  0.9572165  0.9745274\n",
      " 0.987501   0.6936594  0.9943733  0.6516053  0.99976045 0.9999517\n",
      " 0.9975803  0.8991515  0.98547864 0.97723174 0.9863093  0.9995491\n",
      " 0.9998354  0.99657506 0.99239045 0.77530587 0.9988914  0.9997397\n",
      " 0.99830675 0.9988701 ]\n",
      "The rewards are: [0.99777836 0.9997985  0.8491202  0.9989944  0.981978   0.99710923\n",
      " 0.909728   0.9914938  0.983392   0.6241102  0.99651814 0.99917954\n",
      " 0.9519164  0.9992949  0.99993503 0.992059   0.9902147  0.9992449\n",
      " 0.9714112  0.97532994 0.9849726  0.9541044  0.99907744 0.94912297\n",
      " 0.81444514 0.99699676 0.8659269  0.99453884 0.9992316  0.58245593\n",
      " 0.86605674 0.99990463]\n",
      "The rewards are: [0.9940978  0.8637398  0.9980312  0.99976784 0.9348415  0.97950256\n",
      " 0.6173618  0.99539125 0.9628753  0.99431866 0.9992506  0.90891725\n",
      " 0.78922695 0.9939614  0.9989436  0.92351294 0.9624629  0.9966683\n",
      " 0.99980825 0.8920419  0.9987972  0.5530543  0.68196917 0.98955524\n",
      " 0.99838424 0.99340326 0.92673904 0.99954164 0.9403572  0.9996753\n",
      " 0.994412   0.9942027 ]\n",
      "The rewards are: [0.9722011  0.9969458  0.9261064  0.99411786 0.9457479  0.99778855\n",
      " 0.9408851  0.999146   0.99807596 0.9995994  0.8597857  0.99989915\n",
      " 0.8380517  0.9985864  0.9812615  0.99520785 0.9989073  0.9988913\n",
      " 0.96210647 0.51272357 0.9978769  0.76467186 0.99701345 0.99941015\n",
      " 0.9680139  0.99451727 0.93288743 0.9806918  0.9529858  0.98331386\n",
      " 0.9998275  0.97392887]\n",
      "The rewards are: [0.88126415 0.67765284 0.7688784  0.57715726 0.988303   0.9812424\n",
      " 0.9971295  0.50036496 0.99866986 0.61635655 0.9998319  0.99883264\n",
      " 0.9548221  0.87119555 0.99759054 0.9599763  0.9494676  0.7223505\n",
      " 0.99852306 0.91961384 0.99851054 0.9963031  0.6958857  0.9918292\n",
      " 0.99680245 0.99895847 0.9945562  0.9837104  0.9980478  0.8322902\n",
      " 0.57859015 0.8235765 ]\n",
      "The rewards are: [0.9977329  0.9949551  0.9978364  0.99525523 0.9966949  0.9965815\n",
      " 0.9111777  0.99866664 0.9973008  0.9999949  0.87720484 0.9881143\n",
      " 0.99866843 0.54628384 0.96518296 0.9966724  0.9307824  0.888114\n",
      " 0.9995403  0.99727935 0.99161327 0.98561573 0.99738175 0.99369365\n",
      " 0.9999474  0.99917775 0.9988937  0.9712484  0.9918493  0.99807405\n",
      " 0.9601841  0.8879408 ]\n",
      "The rewards are: [0.97607565 0.996062   0.99933285 0.99941957 0.9982981  0.984472\n",
      " 0.79355377 0.9896249  0.99995637 0.9994778  0.94423276 0.99153835\n",
      " 0.8444895  0.575298   0.99764735 0.96747386 0.99592495 0.9972255\n",
      " 0.9964785  0.99925834 0.9994641  0.97151256 0.9631287  0.9995983\n",
      " 0.99322927 0.97831434 0.6094566  0.53192425 0.9999504  0.9932086\n",
      " 0.9681857  0.9977137 ]\n",
      "The rewards are: [0.9910143  0.945088   0.99907804 0.999281   0.9105703  0.7725633\n",
      " 0.99926776 0.9922193  0.799179   0.939406   0.76858675 0.9994254\n",
      " 0.961637   0.68510246 0.99334735 0.99861693 0.9956898  0.8630954\n",
      " 0.7041876  0.997879   0.9940745  0.99988747 0.986315   0.99365133\n",
      " 0.982828   0.9285464  0.990892   0.9947449  0.8815575  0.9962458\n",
      " 0.9745968  0.7949815 ]\n",
      "The rewards are: [0.98676646 0.9960602  0.99961627 0.9978188  0.9188037  0.9988172\n",
      " 0.9954946  0.9967114  0.99955696 0.9851688  0.9992436  0.9686424\n",
      " 0.99914634 0.99647164 0.99460137 0.9892792  0.9989497  0.98929846\n",
      " 0.9905205  0.9952614  0.72113484 0.84855926 0.9630977  0.9992218\n",
      " 0.9888182  0.9962042  0.9986286  0.997512   0.9084366  0.89959854\n",
      " 0.99827576 0.97198075]\n",
      "The rewards are: [0.97486454 0.96758187 0.9311428  0.99991965 0.9876666  0.95942515\n",
      " 0.9956886  0.9133999  0.9724992  0.96141696 0.9924942  0.563008\n",
      " 0.999328   0.9966029  0.9978498  0.8789681  0.9374501  0.9925736\n",
      " 0.99879515 0.9984301  0.9977411  0.8124711  0.8525159  0.91661537\n",
      " 0.8364151  0.917381   0.96452844 0.99836737 0.99923337 0.93699574\n",
      " 0.93717283 0.6957804 ]\n",
      "The rewards are: [0.95901734 0.9969447  0.6241167  0.847975   0.9986155  0.9998381\n",
      " 0.9159354  0.99580634 0.98056096 0.89953643 0.997129   0.99734026\n",
      " 0.9993074  0.8889893  0.6639381  0.9991804  0.99652004 0.90761983\n",
      " 0.9990922  0.99307114 0.94621855 0.9938326  0.9989442  0.9525642\n",
      " 0.9989091  0.9789026  0.9978542  0.59107053 0.78055406 0.998611\n",
      " 0.830334   0.9968706 ]\n",
      "The rewards are: [0.9671679  0.9972632  0.99741036 0.99257773 0.5004122  0.6483004\n",
      " 0.972715   0.5063741  0.99732363 0.9985782  0.96918106 0.9617926\n",
      " 0.9984687  0.98993146 0.51774913 0.99587977 0.8284178  0.8621071\n",
      " 0.7434228  0.9989336  0.9206644  0.99949276 0.9977932  0.9998503\n",
      " 0.9985684  0.9884963  0.987128   0.992886   0.9716612  0.9983747\n",
      " 0.9985544  0.9996605 ]\n",
      "The rewards are: [0.9998306  0.99212354 0.9689038  0.9952486  0.99953675 0.85454625\n",
      " 0.9998203  0.98305756 0.99957496 0.99413776 0.9936627  0.9627017\n",
      " 0.9994752  0.99995756 0.921705   0.96715677 0.99634886 0.99075526\n",
      " 0.99977714 0.97549385 0.99178517 0.9996983  0.9867426  0.89589614\n",
      " 0.88559014 0.9980914  0.897667   0.795881   0.9966131  0.9022473\n",
      " 0.99663925 0.93898517]\n",
      "The rewards are: [0.9989472  0.99351317 0.7637283  0.9963309  0.98928154 0.9981463\n",
      " 0.99954706 0.9250575  0.9931982  0.9869582  0.89440143 0.99101335\n",
      " 0.74978656 0.62195677 0.9948003  0.98765314 0.99904066 0.99863404\n",
      " 0.9803397  0.93227565 0.9654497  0.9987072  0.9969105  0.99086726\n",
      " 0.5544804  0.9794958  0.98302126 0.9728703  0.9971842  0.9994338\n",
      " 0.9152729  0.8925274 ]\n",
      "The rewards are: [0.99972004 0.9283733  0.9963272  0.5139917  0.99981433 0.9948508\n",
      " 0.73367953 0.9806293  0.9573723  0.99310803 0.97967964 0.99827135\n",
      " 0.9961785  0.9923666  0.97630274 0.9416056  0.9549419  0.99715024\n",
      " 0.9984003  0.9963672  0.99626607 0.9891446  0.9176652  0.98583174\n",
      " 0.9974027  0.99860114 0.9426848  0.99993455 0.96260184 0.8465432\n",
      " 0.9911907  0.99843425]\n",
      "The rewards are: [0.9619435  0.83734685 0.99942833 0.99997103 0.63730735 0.99115527\n",
      " 0.96457547 0.9965815  0.99263567 0.5887434  0.954282   0.72009456\n",
      " 0.99990237 0.93916136 0.78883314 0.8594076  0.99588794 0.9041162\n",
      " 0.72169495 0.9976463  0.98781246 0.8916822  0.63867414 0.9998746\n",
      " 0.9984042  0.9993862  0.94318956 0.9976005  0.9729993  0.98952204\n",
      " 0.99571913 0.99979585]\n",
      "The rewards are: [0.99506724 0.9706157  0.99887174 0.9999125  0.9362617  0.73870134\n",
      " 0.99031126 0.987056   0.98989445 0.9718382  0.99834085 0.97875893\n",
      " 0.9104389  0.97079694 0.97600764 0.9844579  0.99987996 0.5356026\n",
      " 0.63344264 0.9306022  0.9509657  0.774285   0.99987864 0.9915406\n",
      " 0.99673283 0.96765566 0.99914193 0.99853647 0.99993753 0.99943584\n",
      " 0.87609184 0.99620545]\n",
      "The rewards are: [0.9910746  0.9538375  0.99702954 0.9989673  0.5748158  0.916689\n",
      " 0.937921   0.96058893 0.9985331  0.9957398  0.8581824  0.6326795\n",
      " 0.99398345 0.9953819  0.94330907 0.53477836 0.5424713  0.9909499\n",
      " 0.9593671  0.65729296 0.99197024 0.98662424 0.7812928  0.96496725\n",
      " 0.9996538  0.9934411  0.99947304 0.99548256 0.89218736 0.99934787\n",
      " 0.99954504 0.81647503]\n",
      "The rewards are: [0.99844354 0.9990441  0.99430877 0.55637914 0.9868124  0.9968124\n",
      " 0.9992362  0.5283193  0.99792296 0.98136926 0.9973259  0.9264719\n",
      " 0.9993874  0.95695347 0.89987683 0.94046783 0.9940041  0.99824536\n",
      " 0.9777803  0.9989247  0.9775679  0.99995005 0.9865872  0.93965644\n",
      " 0.9377226  0.64654547 0.99937373 0.9997938  0.99320954 0.8569515\n",
      " 0.9986552  0.97078806]\n",
      "The rewards are: [0.9846406  0.9636018  0.9995258  0.97200507 0.84665346 0.9923355\n",
      " 0.99188226 0.99752146 0.99690586 0.98562604 0.9987214  0.97656596\n",
      " 0.9664773  0.9873182  0.99892527 0.9985259  0.9888694  0.9742925\n",
      " 0.9949004  0.99977225 0.9811327  0.99896705 0.97099686 0.7047875\n",
      " 0.99490356 0.9872062  0.92293817 0.9958049  0.99884284 0.9457652\n",
      " 0.9754553  0.9842318 ]\n",
      "The rewards are: [0.9701685  0.9977507  0.9566417  0.9181851  0.85222685 0.99590814\n",
      " 0.98822135 0.9603781  0.8631001  0.96847    0.9922111  0.9954385\n",
      " 0.9289696  0.99975914 0.96653074 0.75289416 0.99689543 0.99995875\n",
      " 0.70311844 0.91674906 0.9947359  0.9532384  0.9969348  0.9832767\n",
      " 0.9959067  0.9975865  0.9978613  0.98308957 0.89502096 0.9454341\n",
      " 0.8019213  0.9977062 ]\n",
      "The rewards are: [0.9977315  0.7242716  0.89624685 0.79733187 0.99838865 0.9988411\n",
      " 0.848631   0.99952793 0.9915496  0.99916315 0.9974819  0.9840497\n",
      " 0.999721   0.953563   0.869925   0.9867203  0.9308357  0.98843175\n",
      " 0.9263941  0.99983275 0.97014093 0.9892442  0.86700696 0.9867373\n",
      " 0.99130565 0.9924555  0.9908313  0.99981266 0.9985613  0.9974618\n",
      " 0.9293616  0.9642812 ]\n",
      "The rewards are: [0.9946977  0.99526715 0.9676587  0.99044776 0.99896336 0.99987745\n",
      " 0.99402964 0.99740005 0.99897754 0.99790406 0.9650324  0.9903362\n",
      " 0.9971699  0.995368   0.99067605 0.9734335  0.99973696 0.99977213\n",
      " 0.94898283 0.9967428  0.9931156  0.99891376 0.9976533  0.998823\n",
      " 0.9958553  0.99984455 0.99910516 0.9973666  0.9205197  0.8809048\n",
      " 0.928175   0.964653  ]\n",
      "The rewards are: [0.983549   0.9982535  0.8813249  0.9418388  0.99896574 0.98120224\n",
      " 0.9995857  0.83194506 0.87172836 0.9991571  0.5842753  0.9970849\n",
      " 0.8682268  0.99737084 0.9746756  0.9566125  0.9911958  0.99429274\n",
      " 0.99169415 0.9977451  0.92765766 0.99131083 0.99780554 0.99919564\n",
      " 0.9771574  0.6351608  0.7607839  0.99577326 0.99818844 0.89315933\n",
      " 0.9941896  0.99908304]\n",
      "The rewards are: [0.9995432  0.99574983 0.99398816 0.99998415 0.9990595  0.9064481\n",
      " 0.9990338  0.99662435 0.9997521  0.9834268  0.99712175 0.5962252\n",
      " 0.9963924  0.99892706 0.9296342  0.9993698  0.99808854 0.5823272\n",
      " 0.99690104 0.5964515  0.91472197 0.6004713  0.5855292  0.80941767\n",
      " 0.99907637 0.99892044 0.9206963  0.99928004 0.99951243 0.9928826\n",
      " 0.6373411  0.85675246]\n",
      "The rewards are: [0.7979499  0.99988055 0.71875453 0.9952943  0.99747986 0.80792564\n",
      " 0.99812895 0.98952603 0.92476755 0.99949694 0.9943116  0.7850754\n",
      " 0.9968984  0.99893993 0.9756377  0.99443626 0.9774721  0.9961081\n",
      " 0.99008805 0.9943922  0.9890932  0.9998485  0.9971073  0.9826132\n",
      " 0.98215735 0.99911743 0.99762255 0.9952383  0.9870558  0.99770784\n",
      " 0.97101396 0.94087034]\n",
      "The rewards are: [0.99294347 0.9973188  0.9234959  0.9360455  0.7439493  0.7088938\n",
      " 0.824956   0.9992447  0.9977939  0.9990978  0.99228424 0.99928397\n",
      " 0.9967435  0.97705406 0.9768481  0.5719147  0.9220723  0.8933064\n",
      " 0.94569385 0.993808   0.98548675 0.92201465 0.9934569  0.9844462\n",
      " 0.9996037  0.8580939  0.5367695  0.95292217 0.9994287  0.57300395\n",
      " 0.70309174 0.94081116]\n",
      "The rewards are: [0.9867866  0.9834055  0.98992854 0.9896861  0.9984755  0.99746144\n",
      " 0.9565255  0.9995994  0.97317827 0.90062946 0.8995776  0.9900327\n",
      " 0.9962191  0.97153205 0.90035397 0.6381845  0.59506226 0.6239576\n",
      " 0.9591838  0.9984865  0.5246465  0.9772273  0.9955983  0.8588568\n",
      " 0.78049463 0.9960145  0.9453119  0.99753344 0.99840456 0.9021094\n",
      " 0.956203   0.99547297]\n",
      "The rewards are: [0.9643925  0.9047275  0.9812826  0.9989071  0.984894   0.538846\n",
      " 0.98586684 0.9699421  0.9941856  0.7947922  0.81231767 0.99825567\n",
      " 0.99943024 0.99279356 0.9991372  0.98367465 0.84130985 0.99734616\n",
      " 0.99684024 0.99628854 0.9819515  0.96019936 0.99703074 0.98871136\n",
      " 0.95391494 0.9988851  0.9964341  0.98071057 0.99923944 0.9997693\n",
      " 0.98992443 0.99828136]\n",
      "The rewards are: [0.7555238  0.9972308  0.99757403 0.972593   0.98085344 0.99473685\n",
      " 0.89130294 0.9992404  0.99866784 0.68297094 0.99584866 0.97218275\n",
      " 0.9943355  0.9907742  0.8873293  0.92173743 0.9983297  0.98680216\n",
      " 0.9987256  0.9809076  0.92848164 0.54271257 0.99828464 0.99749076\n",
      " 0.9988374  0.998014   0.9992212  0.99077517 0.91003203 0.997715\n",
      " 0.99708265 0.9969168 ]\n",
      "The rewards are: [0.9998441  0.9982917  0.99921894 0.6618695  0.98603475 0.99697757\n",
      " 0.8680766  0.9588453  0.996915   0.99882716 0.9980444  0.9684921\n",
      " 0.9741243  0.71295506 0.6613552  0.9910807  0.9978168  0.9965654\n",
      " 0.99648345 0.9978109  0.99134153 0.8079916  0.9935608  0.9992508\n",
      " 0.99032265 0.9757329  0.98288053 0.71190333 0.9998555  0.99937266\n",
      " 0.9772257  0.9790774 ]\n",
      "The rewards are: [0.9987657  0.9999124  0.9996561  0.9952969  0.95045257 0.97545016\n",
      " 0.9940671  0.9734625  0.9989888  0.990829   0.98854584 0.98809206\n",
      " 0.7495068  0.88502103 0.9994454  0.5944918  0.9996408  0.9409764\n",
      " 0.9489543  0.99660987 0.817522   0.9829554  0.99846375 0.9663136\n",
      " 0.9643876  0.8022627  0.61106354 0.92165965 0.99859744 0.97475964\n",
      " 0.9599619  0.6610604 ]\n",
      "The rewards are: [0.9930227  0.99849486 0.99778676 0.953845   0.993407   0.99703157\n",
      " 0.8396505  0.7341372  0.9751951  0.997684   0.9978574  0.93223155\n",
      " 0.9469119  0.8797832  0.9769757  0.99772054 0.9135111  0.98475605\n",
      " 0.9848571  0.99786335 0.9978517  0.80156845 0.8025931  0.9074058\n",
      " 0.9973711  0.99960285 0.99998856 0.99738115 0.9816713  0.99821293\n",
      " 0.96634346 0.5029265 ]\n",
      "The rewards are: [0.99963844 0.9806638  0.6661736  0.99641114 0.9772968  0.9911214\n",
      " 0.9954254  0.97824097 0.71087676 0.57302886 0.939746   0.9694634\n",
      " 0.953072   0.9995875  0.81377727 0.88794225 0.9983537  0.9992473\n",
      " 0.83022946 0.94865435 0.999127   0.9594638  0.99860126 0.991366\n",
      " 0.98263663 0.82500786 0.8770678  0.9972722  0.84752345 0.9521246\n",
      " 0.8715033  0.9933281 ]\n",
      "The rewards are: [0.9969518  0.9816773  0.9993337  0.99667263 0.7982476  0.99610364\n",
      " 0.996029   0.99687874 0.9698141  0.9930147  0.99119896 0.99955124\n",
      " 0.60189366 0.9996414  0.99188775 0.7002202  0.99488837 0.90288424\n",
      " 0.9839203  0.996058   0.80895704 0.9924386  0.6239829  0.97577935\n",
      " 0.55208296 0.99474275 0.86453456 0.95464003 0.9980854  0.79305065\n",
      " 0.84221506 0.99385566]\n",
      "The rewards are: [0.9862022  0.99846494 0.8949347  0.99671364 0.9278886  0.99707425\n",
      " 0.7124881  0.98691285 0.9997861  0.7345609  0.9972178  0.9988294\n",
      " 0.8740389  0.59714204 0.9988493  0.98165107 0.98186916 0.9915923\n",
      " 0.9373493  0.95069474 0.99139625 0.9659773  0.50036716 0.9963805\n",
      " 0.87973994 0.9993235  0.9992317  0.99641305 0.9970258  0.988884\n",
      " 0.9988116  0.9918429 ]\n",
      "The rewards are: [0.98383313 0.9874358  0.996268   0.99029166 0.9884089  0.9635743\n",
      " 0.9981718  0.5273897  0.9690883  0.68853265 0.9362161  0.9999118\n",
      " 0.84298915 0.9753847  0.5907364  0.99821943 0.99634856 0.99075586\n",
      " 0.9591636  0.99536127 0.97819257 0.9321991  0.99949026 0.99138427\n",
      " 0.9981844  0.94994175 0.91524047 0.9872958  0.99320716 0.6853653\n",
      " 0.9103321  0.99686265]\n",
      "The rewards are: [0.98877615 0.977692   0.99925    0.87021077 0.96963096 0.99854845\n",
      " 0.9983746  0.97187626 0.9970157  0.5312128  0.8729679  0.9941392\n",
      " 0.9370622  0.99374545 0.99869305 0.9974171  0.9890288  0.99493957\n",
      " 0.8045021  0.9925047  0.9117971  0.9638132  0.9988557  0.99563473\n",
      " 0.97090137 0.99885035 0.9813384  0.77365977 0.9957262  0.98400855\n",
      " 0.99671656 0.9982809 ]\n",
      "The rewards are: [0.8865482  0.99866545 0.9996362  0.993385   0.99180204 0.9728582\n",
      " 0.95200586 0.9936494  0.93747735 0.99939144 0.99734676 0.99932456\n",
      " 0.9969607  0.9932093  0.8120706  0.9941214  0.99793833 0.9898797\n",
      " 0.9487056  0.8459317  0.97927535 0.9964832  0.91373914 0.9367934\n",
      " 0.8338568  0.9681023  0.99788254 0.915446   0.9770791  0.9854456\n",
      " 0.9183257  0.99873525]\n",
      "The rewards are: [0.99601585 0.99916613 0.9977386  0.99942064 0.9696173  0.9866397\n",
      " 0.8340584  0.9944886  0.9559938  0.98419476 0.99800307 0.99920964\n",
      " 0.9953401  0.9992656  0.7513932  0.8418225  0.51392955 0.6583067\n",
      " 0.99257153 0.9932367  0.84412265 0.98934096 0.96945626 0.99206245\n",
      " 0.7006894  0.9997993  0.7252105  0.98648643 0.9901578  0.99279493\n",
      " 0.9641284  0.9896799 ]\n",
      "The rewards are: [0.96886617 0.9757463  0.7581809  0.9540391  0.99895835 0.99601537\n",
      " 0.9841235  0.9556926  0.99341476 0.9954977  0.77623594 0.97719234\n",
      " 0.9509731  0.999754   0.9977234  0.57754904 0.8946125  0.9716371\n",
      " 0.8255157  0.93760085 0.9998964  0.99853826 0.9988803  0.99737704\n",
      " 0.970257   0.99848723 0.83232117 0.8979626  0.65059656 0.9811736\n",
      " 0.99340147 0.9967955 ]\n",
      "The rewards are: [0.9515256  0.99865025 0.999648   0.9491808  0.9414193  0.99838376\n",
      " 0.99927574 0.69046795 0.61530614 0.996132   0.98073465 0.9997663\n",
      " 0.9967899  0.9785296  0.9249618  0.9372229  0.97084844 0.99988246\n",
      " 0.9927492  0.9706255  0.99547404 0.99870086 0.95267767 0.99235606\n",
      " 0.99864477 0.99972945 0.99741036 0.9847958  0.93644136 0.7542457\n",
      " 0.99680316 0.9963834 ]\n",
      "The rewards are: [0.9658808  0.8791902  0.96675235 0.9931471  0.9998697  0.9950204\n",
      " 0.9928867  0.9946077  0.9996916  0.9649012  0.99762934 0.999684\n",
      " 0.90164787 0.99310243 0.99539053 0.9932592  0.9114347  0.8728005\n",
      " 0.99616504 0.99949574 0.9957228  0.94025964 0.9263435  0.999982\n",
      " 0.9705729  0.9211783  0.9966788  0.99965596 0.8803152  0.94745326\n",
      " 0.9996958  0.9998771 ]\n",
      "The rewards are: [0.99106103 0.6839212  0.9994917  0.9961201  0.99823284 0.99779534\n",
      " 0.99348664 0.99973875 0.9689998  0.9994906  0.97179574 0.99666744\n",
      " 0.9982318  0.9987526  0.9960633  0.9980421  0.67934304 0.99486035\n",
      " 0.9981494  0.99896467 0.99918956 0.997389   0.9495467  0.99819773\n",
      " 0.98740005 0.9966767  0.99999547 0.9995252  0.99952376 0.63428396\n",
      " 0.9714315  0.98878574]\n",
      "The rewards are: [0.97308016 0.9872278  0.57504225 0.7262039  0.87108594 0.81953317\n",
      " 0.99474007 0.523366   0.9998307  0.7831117  0.7528699  0.9933531\n",
      " 0.9994848  0.9989483  0.9947056  0.980078   0.9702544  0.9930802\n",
      " 0.99863654 0.9911209  0.9792661  0.9983968  0.9963631  0.9979195\n",
      " 0.9969959  0.9620471  0.9895712  0.9402716  0.9327089  0.9989998\n",
      " 0.96803164 0.9726606 ]\n",
      "The rewards are: [0.97178495 0.9691882  0.6089464  0.99897647 0.9932422  0.9991353\n",
      " 0.9989517  0.98438686 0.9975574  0.9976802  0.9972313  0.99746394\n",
      " 0.97188604 0.99813604 0.9986224  0.87159884 0.7719058  0.7997848\n",
      " 0.9260932  0.96408504 0.99642473 0.9987532  0.98283297 0.98807937\n",
      " 0.9809405  0.9998437  0.98088545 0.9577408  0.98993754 0.99949646\n",
      " 0.6976672  0.95381856]\n",
      "The rewards are: [0.9995857  0.81855834 0.99804085 0.7345459  0.99949753 0.51110166\n",
      " 0.99877733 0.99992585 0.9993636  0.9898642  0.99431205 0.9381144\n",
      " 0.9994343  0.99504894 0.6824386  0.9710551  0.99815506 0.9995726\n",
      " 0.69861037 0.9888094  0.99481755 0.99798894 0.998429   0.9994024\n",
      " 0.9901254  0.9848172  0.99470335 0.9695841  0.9953517  0.885554\n",
      " 0.99415475 0.99408334]\n",
      "The rewards are: [0.9911815  0.9999906  0.99911433 0.92314565 0.92676073 0.79604316\n",
      " 0.76038426 0.8249891  0.9794813  0.9960989  0.9960173  0.98273534\n",
      " 0.9805017  0.99998784 0.8101912  0.96146226 0.9625773  0.96761394\n",
      " 0.95440257 0.79055667 0.9955165  0.9947489  0.85231876 0.93253416\n",
      " 0.95006    0.99789256 0.9990742  0.9439007  0.99935025 0.76923954\n",
      " 0.87727594 0.99951804]\n",
      "The rewards are: [0.59244204 0.9839759  0.998024   0.8255981  0.9982362  0.9094855\n",
      " 0.89203215 0.9701325  0.6105298  0.9936646  0.99865746 0.9944682\n",
      " 0.9993531  0.9889416  0.9734886  0.99938977 0.91254926 0.99815756\n",
      " 0.9610313  0.98219085 0.99596953 0.99554527 0.9853408  0.98889554\n",
      " 0.9898282  0.99895275 0.99405175 0.8712496  0.8814562  0.9980398\n",
      " 0.9982798  0.9963601 ]\n",
      "The rewards are: [0.9977889  0.94503266 0.8447668  0.9923632  0.99018234 0.9976205\n",
      " 0.9241585  0.932062   0.97163635 0.90684265 0.92495334 0.96760947\n",
      " 0.9996271  0.99924207 0.99657416 0.9976361  0.9977308  0.989115\n",
      " 0.99883527 0.5894859  0.9550553  0.9930861  0.98931503 0.993494\n",
      " 0.9651205  0.998896   0.9952858  0.9999629  0.9333888  0.9989165\n",
      " 0.9981548  0.99816626]\n",
      "The rewards are: [0.9920419  0.9986039  0.96419996 0.993385   0.9944956  0.99829835\n",
      " 0.98108333 0.9991622  0.99929154 0.9984889  0.9859212  0.99996984\n",
      " 0.57172287 0.6995616  0.9988655  0.9957995  0.97965574 0.98239005\n",
      " 0.9902024  0.9992262  0.99399406 0.99925476 0.99805045 0.9842666\n",
      " 0.99736506 0.7400713  0.97576547 0.9979311  0.994586   0.9989644\n",
      " 0.99924517 0.90971744]\n",
      "The rewards are: [0.9976761  0.74893117 0.8610662  0.9836923  0.996774   0.99896646\n",
      " 0.84145904 0.9698149  0.64703727 0.99463624 0.9993894  0.9892636\n",
      " 0.76563144 0.9954217  0.9998512  0.8848641  0.9998543  0.953302\n",
      " 0.6282663  0.9986386  0.991092   0.9911953  0.9993693  0.9989598\n",
      " 0.90884566 0.8815014  0.93284637 0.978965   0.9988438  0.9641659\n",
      " 0.997026   0.9990865 ]\n",
      "The rewards are: [0.7170271  0.846387   0.87231755 0.99898607 0.99965096 0.9985892\n",
      " 0.99839705 0.98378986 0.96062654 0.99855226 0.6584394  0.98705614\n",
      " 0.9230572  0.99628276 0.9797125  0.99995816 0.87034976 0.94526607\n",
      " 0.868315   0.98092884 0.53561455 0.9116782  0.99812955 0.9901814\n",
      " 0.99453086 0.9979493  0.97215635 0.94040215 0.99641186 0.9971878\n",
      " 0.9997112  0.9998888 ]\n",
      "The rewards are: [0.9949753  0.99846554 0.7220098  0.9782138  0.982764   0.8920959\n",
      " 0.9849278  0.81239486 0.975631   0.9965836  0.99035454 0.99850756\n",
      " 0.99458647 0.9924003  0.99873656 0.7117636  0.99943835 0.98936075\n",
      " 0.9669849  0.8282888  0.86912686 0.69102025 0.9951923  0.9942908\n",
      " 0.9773286  0.9964469  0.9803156  0.999387   0.9976164  0.987498\n",
      " 0.849258   0.91940206]\n",
      "The rewards are: [0.90789515 0.9984403  0.9940222  0.98740923 0.99403375 0.9984407\n",
      " 0.97653586 0.9946173  0.9992218  0.9954195  0.9981926  0.9544151\n",
      " 0.99623555 0.99936074 0.98692423 0.9999193  0.99710757 0.99868745\n",
      " 0.79690015 0.9598221  0.9872449  0.6196256  0.9940771  0.95856804\n",
      " 0.684311   0.9966968  0.9696305  0.9311666  0.9932405  0.9995876\n",
      " 0.9970471  0.9967788 ]\n",
      "The rewards are: [0.9994704  0.7913899  0.97594756 0.99806935 0.99290824 0.8398163\n",
      " 0.9462833  0.99925655 0.9950983  0.9993882  0.5305019  0.99910754\n",
      " 0.9924556  0.99571216 0.99920744 0.99992263 0.99815434 0.98025644\n",
      " 0.78572536 0.9992867  0.765879   0.54019403 0.99025327 0.99849975\n",
      " 0.9856491  0.9991966  0.95865196 0.99716955 0.9973762  0.77289355\n",
      " 0.9996884  0.99345917]\n",
      "The rewards are: [0.99966633 0.9967482  0.99568355 0.99961746 0.9622594  0.99205995\n",
      " 0.99242777 0.99510264 0.99860424 0.99846727 0.9997023  0.9940036\n",
      " 0.8003958  0.9998142  0.9966511  0.99686015 0.9997186  0.9880585\n",
      " 0.9253431  0.99970967 0.9520244  0.9887108  0.9970053  0.8464844\n",
      " 0.9753313  0.9834011  0.9945082  0.8521507  0.7115615  0.98753536\n",
      " 0.9951115  0.9998399 ]\n",
      "The rewards are: [0.62291795 0.9311614  0.99868923 0.98847616 0.9979442  0.963539\n",
      " 0.9953452  0.8674993  0.96391475 0.95838314 0.99984825 0.9978319\n",
      " 0.8586356  0.9935539  0.7912167  0.99664885 0.99926907 0.7030982\n",
      " 0.9972523  0.99937576 0.9886686  0.89520043 0.9961294  0.9988833\n",
      " 0.99846005 0.9978529  0.9993994  0.9300292  0.99852306 0.7482559\n",
      " 0.9974482  0.9882366 ]\n",
      "The rewards are: [0.9258151  0.9645065  0.9838796  0.90515614 0.9940013  0.9538834\n",
      " 0.9975943  0.7300611  0.7820528  0.9969689  0.99935526 0.9980527\n",
      " 0.98672026 0.8511599  0.9959072  0.9878991  0.9747049  0.9227963\n",
      " 0.9989994  0.9462334  0.8803677  0.9719445  0.9867476  0.85201067\n",
      " 0.9874576  0.96306854 0.9991596  0.9990396  0.6766114  0.99630547\n",
      " 0.91834325 0.9552953 ]\n",
      "The rewards are: [0.9989919  0.9982116  0.9998921  0.9989685  0.96466386 0.9779821\n",
      " 0.9980495  0.72404724 0.99936813 0.99508554 0.93769413 0.72035164\n",
      " 0.9988422  0.99813604 0.8236419  0.9988348  0.9992495  0.9921576\n",
      " 0.97301304 0.9925484  0.99993825 0.9959403  0.59584737 0.8837274\n",
      " 0.9677519  0.9855985  0.9902552  0.9986993  0.9990079  0.95067877\n",
      " 0.9935701  0.60121197]\n",
      "The rewards are: [0.9992192  0.9631758  0.99077237 0.9983529  0.97164786 0.99693525\n",
      " 0.6340009  0.9999602  0.9986743  0.991565   0.992663   0.8229018\n",
      " 0.99996483 0.5084468  0.9972295  0.8490361  0.99597734 0.99757975\n",
      " 0.99566334 0.99952507 0.9977452  0.8060742  0.9980804  0.9321294\n",
      " 0.99086493 0.98756    0.9018262  0.9988493  0.99949896 0.99816364\n",
      " 0.9714281  0.9985317 ]\n",
      "The rewards are: [0.99997425 0.9981317  0.99877113 0.82742804 0.9896082  0.9986834\n",
      " 0.99881256 0.9926587  0.99960226 0.9963504  0.9576146  0.99637467\n",
      " 0.99044377 0.99741155 0.9934784  0.99864155 0.9973289  0.97568023\n",
      " 0.708212   0.5156109  0.99525803 0.98573816 0.99835026 0.738581\n",
      " 0.85637444 0.9991691  0.9926766  0.9951401  0.9828571  0.995994\n",
      " 0.99814534 0.9439773 ]\n",
      "The rewards are: [0.97685856 0.9851252  0.94423133 0.9997949  0.9822922  0.9962852\n",
      " 0.99046373 0.86994237 0.9255051  0.95679724 0.98748547 0.91626984\n",
      " 0.9995591  0.999501   0.97384846 0.9768521  0.99313724 0.9661832\n",
      " 0.95054555 0.9653748  0.9547623  0.96863014 0.96918833 0.9996642\n",
      " 0.9863594  0.62932825 0.98944914 0.9541208  0.9999957  0.9976826\n",
      " 0.9813674  0.9841436 ]\n",
      "The rewards are: [0.53679484 0.74104047 0.97332025 0.7324548  0.98680973 0.9999548\n",
      " 0.9998747  0.9918943  0.99712354 0.9397595  0.99231124 0.9903436\n",
      " 0.9984647  0.9919668  0.9946384  0.99733317 0.9948401  0.96724516\n",
      " 0.9989242  0.5472721  0.99210185 0.99635965 0.9993979  0.9918508\n",
      " 0.9948415  0.74264336 0.99882895 0.993529   0.99986506 0.97531587\n",
      " 0.9597886  0.9786331 ]\n",
      "The rewards are: [0.95820516 0.99907124 0.99964654 0.92733145 0.68028563 0.9447434\n",
      " 0.7255098  0.99083734 0.6700432  0.9960062  0.9970836  0.99946254\n",
      " 0.7098938  0.9334052  0.80132484 0.9807699  0.9970283  0.98609865\n",
      " 0.99946076 0.9817554  0.88842666 0.99893636 0.8513279  0.9978047\n",
      " 0.8035088  0.99942076 0.9999198  0.7719877  0.9040129  0.9979432\n",
      " 0.88534176 0.701168  ]\n",
      "The rewards are: [0.5314783  0.98692584 0.9876351  0.91459113 0.9284693  0.99835676\n",
      " 0.9986506  0.98990357 0.8420748  0.9994241  0.99984777 0.61035067\n",
      " 0.997101   0.93029666 0.9789878  0.9993585  0.8576116  0.99406093\n",
      " 0.9995555  0.9984106  0.99158305 0.6297475  0.9969086  0.99892527\n",
      " 0.99993956 0.9987198  0.99809843 0.99872404 0.99480397 0.98591864\n",
      " 0.7354086  0.9932167 ]\n",
      "The rewards are: [0.9998826  0.75455594 0.9963678  0.9528186  0.9997075  0.9337778\n",
      " 0.9999639  0.9567377  0.9542593  0.9911863  0.9890265  0.81761366\n",
      " 0.9998016  0.97806317 0.99089503 0.97905225 0.9267452  0.96124566\n",
      " 0.57152927 0.99969006 0.9870091  0.9973099  0.99727696 0.501009\n",
      " 0.99423665 0.99082327 0.7442404  0.97274315 0.9408925  0.9287687\n",
      " 0.96913445 0.8873689 ]\n",
      "The rewards are: [0.98543304 0.9996332  0.9995535  0.54228455 0.8909643  0.9673437\n",
      " 0.9948068  0.99992836 0.9562235  0.712521   0.9982559  0.99938774\n",
      " 0.93943894 0.99544865 0.99444264 0.99708015 0.97844666 0.7869299\n",
      " 0.99889237 0.99618065 0.9205269  0.9142896  0.9755107  0.9997857\n",
      " 0.644445   0.9967339  0.9995882  0.9969964  0.9999883  0.993254\n",
      " 0.9947477  0.99559695]\n",
      "The rewards are: [0.9593962  0.9951828  0.99345374 0.9947471  0.99800056 0.6647026\n",
      " 0.9876747  0.7622374  0.99297863 0.9998567  0.98516047 0.9797657\n",
      " 0.99212307 0.81484646 0.9948191  0.99835736 0.98461294 0.98437136\n",
      " 0.99948347 0.63747525 0.9885642  0.9636478  0.999037   0.9838014\n",
      " 0.9922193  0.9447079  0.8800169  0.97571975 0.98409826 0.9994796\n",
      " 0.99938726 0.9946525 ]\n",
      "The rewards are: [0.9758773  0.99665475 0.915571   0.98768926 0.9988708  0.9277453\n",
      " 0.95820135 0.9293065  0.9966221  0.88188356 0.997844   0.99937445\n",
      " 0.9920195  0.9819526  0.9994466  0.8416498  0.9958431  0.9944988\n",
      " 0.99958223 0.99072295 0.9967169  0.9939488  0.9430481  0.97219807\n",
      " 0.99970007 0.9964761  0.9563612  0.9196844  0.6240736  0.99481153\n",
      " 0.8318202  0.9914158 ]\n",
      "The rewards are: [0.9775939  0.9962662  0.9985184  0.9986753  0.9999783  0.99778324\n",
      " 0.7468783  0.9791671  0.99392647 0.99628973 0.9998958  0.8036672\n",
      " 0.9990068  0.95075315 0.91791683 0.99914443 0.9242189  0.995445\n",
      " 0.94300026 0.9046142  0.9859368  0.9976439  0.9483442  0.99696904\n",
      " 0.99076605 0.9544393  0.99982387 0.98883456 0.99705434 0.9723198\n",
      " 0.8551231  0.9932453 ]\n",
      "The rewards are: [0.99500424 0.99573475 0.994833   0.9957625  0.9979863  0.8316997\n",
      " 0.98084074 0.8142718  0.9699506  0.9892993  0.99872005 0.8833344\n",
      " 0.99850345 0.99701345 0.9867938  0.999684   0.8070921  0.99977785\n",
      " 0.9999256  0.89617646 0.97938156 0.9997913  0.99852127 0.70615506\n",
      " 0.940119   0.92155284 0.8160021  0.7102542  0.7608882  0.99241066\n",
      " 0.9574392  0.9946385 ]\n",
      "The rewards are: [0.9910157  0.9963463  0.99113655 0.98747665 0.99471456 0.97484934\n",
      " 0.9891762  0.99996054 0.99213576 0.9973713  0.99689674 0.59011203\n",
      " 0.9061918  0.7966191  0.9958677  0.9983205  0.8838054  0.9780311\n",
      " 0.9993155  0.9960801  0.99787056 0.9955461  0.9994412  0.99979395\n",
      " 0.99964166 0.7618959  0.9950316  0.68399554 0.9997136  0.7766916\n",
      " 0.99785465 0.62913144]\n",
      "The rewards are: [0.9930385  0.99877805 0.96997863 0.5889633  0.99270165 0.9971003\n",
      " 0.9111465  0.9992391  0.97874695 0.74896973 0.99973196 0.7141925\n",
      " 0.99981135 0.99781835 0.90437293 0.9991443  0.9991636  0.66993445\n",
      " 0.99668175 0.9970567  0.9899458  0.99914134 0.99831605 0.981237\n",
      " 0.55178034 0.9997435  0.638636   0.916843   0.8845071  0.9944693\n",
      " 0.82500964 0.9872994 ]\n",
      "The rewards are: [0.9929975  0.9769288  0.99641514 0.9967901  0.99445677 0.9915285\n",
      " 0.67193586 0.9991448  0.8790747  0.9881441  0.9080969  0.9958121\n",
      " 0.9873927  0.9963142  0.99628264 0.992596   0.9473627  0.8311345\n",
      " 0.99697137 0.9909881  0.9981061  0.99931073 0.9992549  0.9986725\n",
      " 0.99806947 0.98573315 0.996509   0.99943155 0.94228834 0.9784313\n",
      " 0.99568343 0.7442644 ]\n",
      "The rewards are: [0.999038   0.84719425 0.9977811  0.6961814  0.8449831  0.9989648\n",
      " 0.99942374 0.96456593 0.86209965 0.9977586  0.9904364  0.9590811\n",
      " 0.7177473  0.9976376  0.99421436 0.7142008  0.96262294 0.9989961\n",
      " 0.99684095 0.70223695 0.9825948  0.88399285 0.99934536 0.9873378\n",
      " 0.99133646 0.9926272  0.7829073  0.7566967  0.57430935 0.9998621\n",
      " 0.9999523  0.99171704]\n",
      "The rewards are: [0.99702674 0.8790762  0.99334055 0.9977615  0.9891824  0.95276684\n",
      " 0.99926645 0.7247505  0.98806816 0.9919952  0.90056217 0.97463834\n",
      " 0.9997738  0.9964393  0.9915388  0.97922665 0.7298011  0.99989915\n",
      " 0.9973375  0.9464558  0.7202948  0.9317276  0.999474   0.99534947\n",
      " 0.9953034  0.8407796  0.9659551  0.99868494 0.9865921  0.99336433\n",
      " 0.9989095  0.7337815 ]\n",
      "The rewards are: [0.99932206 0.9973998  0.9976605  0.99311215 0.99445724 0.99867743\n",
      " 0.9999175  0.52165645 0.9997838  0.9999658  0.5031964  0.656898\n",
      " 0.9964875  0.9983     0.9994822  0.8879051  0.9845664  0.99597245\n",
      " 0.97443014 0.9984889  0.9999691  0.9656303  0.79630786 0.994842\n",
      " 0.98866546 0.99906343 0.9878781  0.78376055 0.89762914 0.99495655\n",
      " 0.99790984 0.99931157]\n",
      "The rewards are: [0.9968651  0.97066814 0.9878308  0.95805174 0.93923855 0.9407471\n",
      " 0.97157276 0.99871075 0.9899423  0.999928   0.9284201  0.9984242\n",
      " 0.67008376 0.99834454 0.93243486 0.9666471  0.9973667  0.9941168\n",
      " 0.9677884  0.9994636  0.9879872  0.9994319  0.91984063 0.9928946\n",
      " 0.9646543  0.8005364  0.99618113 0.96688163 0.87195027 0.75795925\n",
      " 0.8338708  0.9970573 ]\n",
      "The rewards are: [0.9972224  0.99719703 0.999686   0.9994622  0.6780764  0.89565855\n",
      " 0.9997662  0.92267513 0.99131703 0.9973199  0.9982827  0.99259865\n",
      " 0.9986186  0.525446   0.99090844 0.98364323 0.86642355 0.9955562\n",
      " 0.8159842  0.999073   0.8161535  0.99461854 0.6167364  0.8748161\n",
      " 0.6627788  0.89739186 0.9762955  0.74630004 0.91192484 0.55570644\n",
      " 0.9750455  0.9943098 ]\n",
      "The rewards are: [0.997898   0.97439325 0.993895   0.9993861  0.6795349  0.98275083\n",
      " 0.9978295  0.99902403 0.9984761  0.5248157  0.99389195 0.8118051\n",
      " 0.9977506  0.9970503  0.987015   0.9992254  0.9622656  0.99374443\n",
      " 0.8858055  0.5480268  0.63173926 0.95296943 0.9994655  0.86400145\n",
      " 0.9872508  0.9961958  0.9977247  0.9989429  0.99643505 0.916257\n",
      " 0.99962723 0.9921004 ]\n",
      "The rewards are: [0.97541225 0.99908197 0.6170455  0.99618894 0.9961488  0.9962148\n",
      " 0.6986333  0.998879   0.8928507  0.9998622  0.9685565  0.99716324\n",
      " 0.9984975  0.930096   0.9574184  0.8803564  0.9990687  0.99545884\n",
      " 0.9951649  0.99977964 0.8464314  0.9358925  0.99271226 0.9990017\n",
      " 0.9994073  0.9997918  0.99134094 0.88590425 0.9996362  0.9995285\n",
      " 0.93527365 0.99900097]\n",
      "The rewards are: [0.98893076 0.72873837 0.9842514  0.9763435  0.9993981  0.9313068\n",
      " 0.9997706  0.8052761  0.9983865  0.9443466  0.999164   0.9886362\n",
      " 0.99938345 0.86559933 0.9811078  0.99812037 0.9976248  0.9991266\n",
      " 0.5686178  0.9996352  0.99210244 0.9977506  0.5271985  0.99820805\n",
      " 0.9975561  0.9101128  0.99904567 0.98875135 0.97063476 0.61502385\n",
      " 0.9989166  0.9962811 ]\n",
      "The rewards are: [0.99897814 0.8848362  0.9995572  0.9888465  0.9957955  0.9235662\n",
      " 0.95813686 0.9998005  0.9498345  0.95144707 0.70562303 0.9142946\n",
      " 0.9948637  0.63042784 0.9919322  0.9978301  0.99214244 0.62735\n",
      " 0.9992324  0.9912305  0.9916604  0.9963341  0.99677604 0.99531615\n",
      " 0.9976605  0.9981154  0.997148   0.97467536 0.98676145 0.9944431\n",
      " 0.99332666 0.99988854]\n",
      "The rewards are: [0.970487   0.99157506 0.9991659  0.51040703 0.84302205 0.98263687\n",
      " 0.99762815 0.9965791  0.984288   0.99664295 0.9987723  0.9951243\n",
      " 0.99961346 0.9842606  0.96057165 0.99991727 0.99973315 0.96536857\n",
      " 0.99638605 0.9857035  0.92082804 0.5469921  0.99612755 0.99913955\n",
      " 0.9328566  0.9375154  0.9921267  0.8938998  0.99716693 0.97523004\n",
      " 0.99690175 0.95200163]\n",
      "The rewards are: [0.7801153  0.9349943  0.9190034  0.9992424  0.97422045 0.77446467\n",
      " 0.99812204 0.9870977  0.9961514  0.9986143  0.94924146 0.99952185\n",
      " 0.98135304 0.8925997  0.9283818  0.8265566  0.9377233  0.9837991\n",
      " 0.9627616  0.96885204 0.97577703 0.9999926  0.9994636  0.61486214\n",
      " 0.9988249  0.9909952  0.9974037  0.98352134 0.9995111  0.9664673\n",
      " 0.9950427  0.999897  ]\n",
      "The rewards are: [0.93186927 0.9779327  0.9434274  0.99267286 0.9994006  0.9280912\n",
      " 0.99929905 0.9483071  0.9942865  0.9896975  0.9946016  0.8337704\n",
      " 0.9959357  0.98180825 0.9881544  0.95289433 0.9726943  0.96375686\n",
      " 0.94511443 0.95743906 0.9372187  0.6997116  0.9828597  0.9855144\n",
      " 0.98348236 0.9951615  0.999666   0.99843436 0.9982603  0.9993667\n",
      " 0.9997559  0.87279016]\n",
      "The rewards are: [0.9939089  0.9954085  0.9949915  0.998072   0.8445637  0.8964223\n",
      " 0.99985147 0.99973196 0.9744778  0.82745546 0.95818806 0.96202713\n",
      " 0.9921858  0.9902574  0.56365377 0.9912636  0.9256292  0.9647127\n",
      " 0.9995559  0.9794114  0.9985077  0.9997212  0.9553729  0.72142357\n",
      " 0.99883336 0.9998889  0.985835   0.9338728  0.98084074 0.9989266\n",
      " 0.9988398  0.86033326]\n",
      "The rewards are: [0.6380023  0.94849247 0.67316836 0.97208303 0.99072194 0.96346605\n",
      " 0.9972459  0.7519415  0.5009447  0.9966893  0.9989806  0.54420465\n",
      " 0.84224266 0.9900912  0.9993197  0.9955259  0.9901877  0.99851424\n",
      " 0.9937435  0.99862957 0.99875367 0.9991104  0.92877126 0.99581474\n",
      " 0.9652916  0.98596895 0.95901066 0.82510555 0.999863   0.99824584\n",
      " 0.99712175 0.78730506]\n",
      "The rewards are: [0.9187496  0.6727826  0.9997009  0.9884107  0.999278   0.99930537\n",
      " 0.5592146  0.98479384 0.99870944 0.9906883  0.98757076 0.97712964\n",
      " 0.9978235  0.9998529  0.908609   0.9864087  0.9954833  0.99968743\n",
      " 0.9982961  0.9981298  0.99983203 0.99409384 0.9926024  0.997936\n",
      " 0.9992368  0.6072591  0.9963697  0.80262583 0.5943513  0.99575496\n",
      " 0.9994684  0.7937617 ]\n",
      "The rewards are: [0.9924521  0.9820026  0.9972156  0.9998598  0.9959266  0.9583097\n",
      " 0.9682093  0.8289564  0.9988117  0.9974541  0.9827604  0.6311305\n",
      " 0.99564385 0.999879   0.9964419  0.9872169  0.990644   0.6834849\n",
      " 0.53371596 0.8197531  0.99444157 0.99988055 0.99940395 0.8847562\n",
      " 0.9472261  0.9991033  0.9993594  0.989783   0.9994617  0.88621145\n",
      " 0.97408366 0.7785669 ]\n",
      "The rewards are: [0.9790455  0.96310776 0.9909565  0.9994137  0.9999856  0.98895395\n",
      " 0.99839634 0.9878318  0.9860719  0.8679962  0.64762175 0.9881579\n",
      " 0.99007285 0.55021286 0.99605715 0.99821043 0.9813136  0.78551155\n",
      " 0.56572664 0.9986564  0.9865313  0.99988866 0.8163666  0.97387785\n",
      " 0.7959446  0.96343803 0.9350445  0.96181315 0.9653157  0.98945284\n",
      " 0.97632027 0.5412426 ]\n",
      "The rewards are: [0.9998598  0.9690402  0.99981636 0.7296697  0.9878379  0.8303701\n",
      " 0.9709645  0.97504574 0.99083215 0.81364363 0.9580727  0.99073946\n",
      " 0.9991321  0.97598404 0.91817194 0.9989613  0.97769517 0.9669688\n",
      " 0.9888784  0.91485846 0.9821478  0.9984779  0.997551   0.9983997\n",
      " 0.97003067 0.6913069  0.97193074 0.810232   0.99853206 0.99791294\n",
      " 0.9179038  0.996546  ]\n",
      "The rewards are: [0.9982374  0.9296176  0.98740965 0.9892146  0.9967879  0.8915979\n",
      " 0.9993943  0.5517041  0.9890204  0.9971886  0.9701563  0.632911\n",
      " 0.9810308  0.998889   0.9988172  0.976405   0.9897674  0.7105471\n",
      " 0.99977726 0.99932015 0.94750464 0.99476874 0.9990038  0.98223543\n",
      " 0.99701834 0.9995895  0.9560856  0.9806244  0.9958391  0.9751404\n",
      " 0.9980556  0.998181  ]\n",
      "The rewards are: [0.9902222  0.9985066  0.7675305  0.99582136 0.9210887  0.9997801\n",
      " 0.9735432  0.9977575  0.9987929  0.9864942  0.9952201  0.71977293\n",
      " 0.897842   0.99860805 0.9987404  0.87241864 0.81751055 0.99594694\n",
      " 0.6547253  0.9985241  0.9937263  0.9954756  0.98151636 0.98885506\n",
      " 0.99979573 0.9967204  0.9993468  0.9562285  0.99262005 0.9795233\n",
      " 0.999673   0.97454655]\n",
      "The rewards are: [0.99909663 0.8144218  0.96062326 0.9529358  0.99769884 0.9903646\n",
      " 0.9992255  0.9977496  0.7800264  0.99759597 0.99924904 0.999678\n",
      " 0.9776094  0.98923653 0.95770425 0.9083757  0.9865433  0.9977239\n",
      " 0.99797076 0.9922275  0.99785703 0.99853873 0.9854387  0.9809492\n",
      " 0.9943422  0.966969   0.9872004  0.99998367 0.99808097 0.9637251\n",
      " 0.9996075  0.9974854 ]\n",
      "The rewards are: [0.9709517  0.99999833 0.99774206 0.94985926 0.97146183 0.96375936\n",
      " 0.9984297  0.59413314 0.9960848  0.99671316 0.93841183 0.9713111\n",
      " 0.99657947 0.99896836 0.9446374  0.9966689  0.9886545  0.99773455\n",
      " 0.9639608  0.9525044  0.99507976 0.99857235 0.99567896 0.9984774\n",
      " 0.9996111  0.9889581  0.9992748  0.8908518  0.9950296  0.98315984\n",
      " 0.9767734  0.9979691 ]\n",
      "The rewards are: [0.98082376 0.87329644 0.99592835 0.9990969  0.99680114 0.9719925\n",
      " 0.99570435 0.9093556  0.9990125  0.99962234 0.9616238  0.97698045\n",
      " 0.9988588  0.99580246 0.88071936 0.9888508  0.9963917  0.9493704\n",
      " 0.9064608  0.83715487 0.99583024 0.9657368  0.977022   0.91047186\n",
      " 0.99977106 0.9939281  0.9990152  0.972771   0.9992843  0.9699546\n",
      " 0.99911624 0.9985453 ]\n",
      "The rewards are: [0.9994203  0.9991621  0.7926734  0.9971517  0.9628973  0.8291487\n",
      " 0.98781604 0.8787995  0.99740607 0.9030746  0.99996614 0.9997583\n",
      " 0.997827   0.9953876  0.9990445  0.9997315  0.9995048  0.99952257\n",
      " 0.9723393  0.9246912  0.99792874 0.99903667 0.9973738  0.9966897\n",
      " 0.97659826 0.6988863  0.9941246  0.9866443  0.91740006 0.5251975\n",
      " 0.94531786 0.998922  ]\n",
      "The rewards are: [0.9862229  0.54190654 0.99856097 0.9831429  0.97048765 0.9959752\n",
      " 0.9049512  0.9998149  0.51191425 0.81875587 0.9987814  0.8366571\n",
      " 0.92923856 0.9985261  0.9989409  0.99748755 0.9951434  0.97817755\n",
      " 0.96281517 0.99620146 0.997563   0.9974381  0.9059311  0.9999529\n",
      " 0.9981818  0.75380373 0.9991423  0.5715273  0.9904207  0.9971528\n",
      " 0.97521925 0.97859657]\n",
      "The rewards are: [0.96997076 0.99826956 0.9970113  0.99884087 0.95632344 0.9999951\n",
      " 0.7353712  0.9532302  0.9638317  0.9992581  0.9575503  0.8653381\n",
      " 0.95475876 0.99790037 0.8210419  0.99005556 0.99969614 0.8811408\n",
      " 0.9834909  0.9975211  0.99969816 0.7925412  0.98283005 0.99652785\n",
      " 0.76822716 0.996512   0.99916303 0.97970325 0.9909219  0.98728985\n",
      " 0.9998148  0.99973744]\n",
      "The rewards are: [0.9999713  0.9866209  0.999148   0.9964234  0.99923    0.99178946\n",
      " 0.98263645 0.9961201  0.97392255 0.8505971  0.9997799  0.91930526\n",
      " 0.99731845 0.9921927  0.51741606 0.9485208  0.9981974  0.9555092\n",
      " 0.7818671  0.95404756 0.9285652  0.943169   0.62528515 0.6914749\n",
      " 0.99638784 0.9982158  0.997707   0.99982446 0.97092795 0.98222625\n",
      " 0.9959811  0.6109223 ]\n",
      "The rewards are: [0.9975339  0.99768996 0.99940336 0.9981712  0.99997616 0.9545464\n",
      " 0.99777347 0.98869777 0.979756   0.99926823 0.9960647  0.998814\n",
      " 0.9968219  0.8724881  0.9865884  0.62170064 0.9643292  0.99863523\n",
      " 0.95378166 0.697651   0.73168874 0.9982735  0.83767104 0.9979615\n",
      " 0.9969374  0.9998456  0.99668247 0.7623523  0.99904877 0.9678143\n",
      " 0.998552   0.99770784]\n",
      "The rewards are: [0.99556446 0.9733244  0.99664104 0.96430814 0.998348   0.9944654\n",
      " 0.99561846 0.9033378  0.9991835  0.997996   0.9978636  0.9994456\n",
      " 0.92843324 0.9976217  0.973032   0.9965539  0.99781823 0.9996748\n",
      " 0.99977905 0.9935242  0.7442497  0.9982693  0.9987577  0.97905785\n",
      " 0.99781764 0.9943409  0.99915576 0.76971954 0.9978405  0.999542\n",
      " 0.9968906  0.99742705]\n",
      "The rewards are: [0.99736744 0.99854064 0.921882   0.99783593 0.9618718  0.9916182\n",
      " 0.9955793  0.8314413  0.9990576  0.9981907  0.91329837 0.57038647\n",
      " 0.98102176 0.9968465  0.99913174 0.9897915  0.99999213 0.52137494\n",
      " 0.9995702  0.9156569  0.9787556  0.9095298  0.9987412  0.99799746\n",
      " 0.98678523 0.9966563  0.9828965  0.8688626  0.9977144  0.99967587\n",
      " 0.8875579  0.98202825]\n",
      "The rewards are: [0.93788743 0.9959125  0.9942438  0.8410559  0.9958455  0.995943\n",
      " 0.9975879  0.99954    0.96279436 0.9797722  0.8589674  0.7550095\n",
      " 0.738412   0.9919852  0.86811495 0.8974834  0.9975593  0.9094171\n",
      " 0.9996865  0.78251994 0.99238867 0.9412799  0.99991846 0.96516\n",
      " 0.68620545 0.97394764 0.989164   0.9924515  0.99965656 0.9969584\n",
      " 0.98590183 0.9803437 ]\n",
      "The rewards are: [0.9887262  0.99991643 0.8572431  0.99758375 0.98311377 0.9982426\n",
      " 0.98553306 0.99612457 0.9997956  0.98762894 0.9827237  0.8082858\n",
      " 0.9989556  0.9988226  0.999435   0.987341   0.5416367  0.93595356\n",
      " 0.9095233  0.9958955  0.9966851  0.97594804 0.9960691  0.9526634\n",
      " 0.9848813  0.7724982  0.99912566 0.99974173 0.98073053 0.9989336\n",
      " 0.8656691  0.9991479 ]\n",
      "The rewards are: [0.99961156 0.9930193  0.9784218  0.92752606 0.9893026  0.501773\n",
      " 0.9636714  0.99926037 0.9846741  0.9720535  0.998126   0.9964336\n",
      " 0.9670834  0.9999864  0.99947137 0.9305922  0.9978617  0.8835134\n",
      " 0.9478656  0.9901073  0.99514186 0.99959487 0.9945215  0.9963877\n",
      " 0.9425576  0.999658   0.98850644 0.9799762  0.9922707  0.9987533\n",
      " 0.9954543  0.6287167 ]\n",
      "The rewards are: [0.9947066  0.9962507  0.98572254 0.57478106 0.90275586 0.92341864\n",
      " 0.99351317 0.99148303 0.9978605  0.9855226  0.9976883  0.99868125\n",
      " 0.99849343 0.6529375  0.96957076 0.58386385 0.98324454 0.9977831\n",
      " 0.8563857  0.99465656 0.9678067  0.99047345 0.9955947  0.73047423\n",
      " 0.9985305  0.88795793 0.9507414  0.9841585  0.99624556 0.9944338\n",
      " 0.82733476 0.89015955]\n",
      "The rewards are: [0.9948737  0.9808672  0.9893947  0.99554944 0.9943803  0.9995567\n",
      " 0.58812404 0.9947836  0.99520904 0.9990164  0.9990909  0.9960007\n",
      " 0.9763306  0.9927825  0.5803263  0.9925128  0.99963236 0.9483186\n",
      " 0.99008906 0.9993974  0.82955676 0.9839557  0.99983895 0.9940461\n",
      " 0.997575   0.9620558  0.99884343 0.964439   0.99430627 0.99777776\n",
      " 0.98655546 0.9908668 ]\n",
      "The rewards are: [0.9619994  0.99747926 0.99807835 0.9988765  0.9969626  0.9977083\n",
      " 0.99500555 0.997292   0.999153   0.9977296  0.8610194  0.98514974\n",
      " 0.73814577 0.977404   0.99695766 0.99518114 0.86900187 0.848585\n",
      " 0.94209075 0.61030835 0.972703   0.9979614  0.9921113  0.9984383\n",
      " 0.5834585  0.9994742  0.9794852  0.9946408  0.99927014 0.9855181\n",
      " 0.9982426  0.8614583 ]\n",
      "The rewards are: [0.9644628  0.99177766 0.53792727 0.99908173 0.99936646 0.9249473\n",
      " 0.8525009  0.99760014 0.9949669  0.5169869  0.996723   0.9994924\n",
      " 0.99834704 0.94091284 0.9984106  0.6191477  0.9994061  0.9962495\n",
      " 0.9997789  0.9692355  0.9464034  0.5131193  0.9993193  0.97034305\n",
      " 0.9990319  0.99907875 0.99942636 0.9883886  0.9920353  0.7145948\n",
      " 0.9889199  0.99971586]\n",
      "The rewards are: [0.98897797 0.9964463  0.9999589  0.9987306  0.79055876 0.826872\n",
      " 0.8333535  0.9955556  0.99897826 0.99972945 0.99480516 0.9889733\n",
      " 0.9693471  0.9978543  0.99896586 0.974698   0.9379769  0.99948394\n",
      " 0.99471337 0.9916128  0.99928004 0.9999236  0.9988857  0.99893516\n",
      " 0.8308758  0.9899511  0.9901356  0.9965385  0.99154925 0.6735235\n",
      " 0.66450304 0.99469995]\n",
      "The rewards are: [0.6891187  0.9990885  0.9979614  0.9509136  0.9499893  0.85366964\n",
      " 0.9774619  0.8623783  0.7958846  0.78524786 0.9977576  0.973511\n",
      " 0.9992084  0.9689553  0.98806655 0.9059256  0.9984944  0.9959733\n",
      " 0.9954164  0.94180924 0.99552166 0.99680555 0.98864895 0.9967018\n",
      " 0.99879706 0.99848586 0.9604665  0.99561465 0.99261075 0.95227075\n",
      " 0.9995347  0.99947506]\n",
      "The rewards are: [0.59863794 0.91692024 0.9969662  0.57420945 0.99735296 0.75510895\n",
      " 0.9996443  0.9403672  0.9918662  0.9332202  0.9729687  0.9989791\n",
      " 0.9718991  0.9993364  0.9852036  0.9982668  0.72655827 0.5868501\n",
      " 0.9961337  0.9983266  0.8896676  0.97974557 0.97174996 0.72240084\n",
      " 0.987895   0.9791495  0.9991284  0.6900895  0.96710724 0.99241966\n",
      " 0.98252237 0.9995598 ]\n",
      "The rewards are: [0.8953676  0.99422956 0.57229733 0.76354116 0.9968772  0.78746575\n",
      " 0.9511395  0.99516726 0.9478513  0.98761207 0.9987317  0.9530004\n",
      " 0.9994893  0.5494473  0.99369663 0.99815136 0.93972677 0.9988294\n",
      " 0.9998354  0.9858708  0.9977118  0.98482716 0.9961106  0.9978746\n",
      " 0.9995272  0.99330103 0.9963775  0.9976763  0.9981192  0.9908647\n",
      " 0.9961935  0.9990213 ]\n",
      "The rewards are: [0.9991811  0.9993625  0.83424884 0.9814657  0.95749706 0.98026466\n",
      " 0.9903989  0.9933982  0.9978528  0.9830251  0.9772638  0.9900975\n",
      " 0.99956006 0.99961746 0.9943236  0.7520556  0.88802594 0.9826226\n",
      " 0.9974458  0.9697556  0.9293326  0.9564908  0.9993963  0.9875568\n",
      " 0.9973609  0.8692057  0.99170035 0.99611735 0.99969363 0.98996526\n",
      " 0.9977781  0.99452126]\n",
      "The rewards are: [0.9960227  0.9929913  0.9974867  0.78657955 0.99022865 0.99362284\n",
      " 0.99911994 0.8448368  0.99800235 0.8730853  0.9999405  0.9978667\n",
      " 0.95479846 0.9494289  0.9971137  0.8599252  0.9900738  0.90896404\n",
      " 0.9941486  0.98464847 0.9709126  0.9997515  0.9942812  0.8226743\n",
      " 0.99965537 0.9839574  0.99740654 0.99917185 0.99579525 0.7314255\n",
      " 0.7014331  0.9993575 ]\n",
      "The rewards are: [0.9993789  0.99850875 0.9759445  0.9984118  0.9967135  0.9406531\n",
      " 0.867459   0.9989121  0.9860109  0.99990904 0.9917753  0.64704305\n",
      " 0.98990697 0.9818813  0.9987011  0.9974298  0.9138369  0.88254374\n",
      " 0.9733952  0.55469584 0.9998623  0.9938461  0.9937989  0.99513125\n",
      " 0.9937914  0.9679307  0.99943715 0.99205136 0.9990577  0.9998739\n",
      " 0.8354637  0.846873  ]\n",
      "The rewards are: [0.9931979  0.7437773  0.9990552  0.916265   0.9995036  0.99830854\n",
      " 0.95914257 0.9551247  0.9991768  0.78563505 0.98451614 0.82006973\n",
      " 0.95899606 0.98005086 0.9203799  0.9957039  0.9209356  0.9975363\n",
      " 0.9797992  0.8484493  0.9885351  0.99861884 0.62978464 0.998939\n",
      " 0.9957325  0.9133161  0.89424735 0.9647969  0.9899587  0.8482012\n",
      " 0.7683515  0.9039387 ]\n",
      "The rewards are: [0.9994548  0.99521756 0.94309175 0.99174094 0.9921091  0.9967476\n",
      " 0.91926074 0.99942243 0.9969373  0.9982596  0.8168375  0.9986009\n",
      " 0.99473417 0.99284405 0.99925107 0.9860161  0.6451228  0.9977003\n",
      " 0.9693253  0.9974146  0.99977165 0.9078894  0.9953477  0.9933606\n",
      " 0.9780628  0.95849234 0.9948196  0.9888208  0.94395787 0.75167924\n",
      " 0.9991093  0.996431  ]\n",
      "The rewards are: [0.98580986 0.9983059  0.70488846 0.99560565 0.9978669  0.99969625\n",
      " 0.9764965  0.9988722  0.9996344  0.9976623  0.84545773 0.9995627\n",
      " 0.998662   0.9925528  0.9888543  0.9834055  0.9664429  0.9992692\n",
      " 0.9978656  0.99734735 0.9978142  0.9780586  0.511416   0.9985781\n",
      " 0.99610436 0.9993698  0.9998481  0.99919814 0.8752293  0.9986186\n",
      " 0.99503964 0.52174586]\n",
      "The rewards are: [0.9999064  0.9967258  0.9969252  0.95280886 0.8835655  0.9922805\n",
      " 0.8069141  0.7985591  0.9543685  0.9565049  0.9960043  0.9996847\n",
      " 0.99585754 0.9794661  0.99511456 0.999476   0.9982666  0.9598078\n",
      " 0.86535835 0.9959734  0.57087576 0.98945236 0.99954444 0.7270935\n",
      " 0.99994147 0.9179938  0.9902192  0.99977535 0.9982343  0.98744303\n",
      " 0.6997227  0.9987835 ]\n",
      "The rewards are: [0.9878824  0.99954647 0.99684685 0.99460137 0.96252847 0.9993327\n",
      " 0.99925154 0.96881783 0.73042655 0.9743146  0.9548902  0.9989606\n",
      " 0.868542   0.99942076 0.999175   0.99737334 0.90068024 0.99895006\n",
      " 0.9999504  0.9878186  0.999863   0.99992454 0.977653   0.57769084\n",
      " 0.9993104  0.87159723 0.99953735 0.9759411  0.9990073  0.99986553\n",
      " 0.6619442  0.99982625]\n",
      "The rewards are: [0.9995024  0.9994436  0.99698013 0.94242764 0.55327904 0.9610528\n",
      " 0.99990785 0.9992349  0.978092   0.99378306 0.9833286  0.99555814\n",
      " 0.99256223 0.9769398  0.8470882  0.9664991  0.9971631  0.99880004\n",
      " 0.9792875  0.9972579  0.976537   0.97840846 0.99686426 0.9945779\n",
      " 0.99128    0.99959284 0.6363795  0.9991704  0.9436427  0.7622518\n",
      " 0.99951553 0.9855436 ]\n",
      "The rewards are: [0.9984577  0.95196664 0.9974431  0.9925114  0.66003805 0.60873413\n",
      " 0.99793905 0.95848054 0.9940124  0.93995094 0.999255   0.9964154\n",
      " 0.7182468  0.9992956  0.99974865 0.9998939  0.9839611  0.9925862\n",
      " 0.9953009  0.99528056 0.95475984 0.9493753  0.7343553  0.9987192\n",
      " 0.98336154 0.9762216  0.99489486 0.7861687  0.98509383 0.997053\n",
      " 0.9944291  0.9904903 ]\n",
      "The rewards are: [0.78118306 0.96478415 0.64701295 0.9985493  0.96745336 0.9994925\n",
      " 0.9974316  0.9985493  0.99769586 0.9987024  0.98886603 0.99950945\n",
      " 0.99745876 0.9992711  0.99998045 0.93395215 0.99426174 0.9980096\n",
      " 0.818247   0.9984345  0.5440267  0.99682695 0.98776513 0.9995202\n",
      " 0.99970835 0.9986761  0.99992216 0.99169534 0.9948743  0.9333547\n",
      " 0.78877217 0.9937265 ]\n",
      "The rewards are: [0.8770119  0.96477073 0.9990491  0.98640674 0.9984804  0.98984045\n",
      " 0.98541623 0.9928235  0.9928323  0.99619824 0.916586   0.99651706\n",
      " 0.96995306 0.9467601  0.9972836  0.99774396 0.9950435  0.99432796\n",
      " 0.998933   0.9401665  0.99953103 0.99964905 0.9879532  0.9912053\n",
      " 0.9987392  0.9967212  0.9994974  0.56852275 0.9987425  0.9956044\n",
      " 0.9988242  0.9999832 ]\n",
      "The rewards are: [0.9959799  0.9976991  0.98364407 0.95803267 0.99794525 0.9940063\n",
      " 0.9984486  0.91368127 0.99781966 0.9245377  0.99727374 0.9971486\n",
      " 0.99719125 0.9799729  0.998638   0.9267261  0.98946416 0.9576027\n",
      " 0.9900518  0.9448629  0.99958664 0.9941881  0.99948907 0.9712227\n",
      " 0.99761426 0.99345136 0.99334115 0.99974376 0.991683   0.99627787\n",
      " 0.9929431  0.9609449 ]\n",
      "The rewards are: [0.99815303 0.9998592  0.9995346  0.98967266 0.9991627  0.99933237\n",
      " 0.78142965 0.98338205 0.7738092  0.6585628  0.99711525 0.98008645\n",
      " 0.9968534  0.9995701  0.9976891  0.9961628  0.90056187 0.999231\n",
      " 0.89927006 0.98364323 0.9981408  0.9978163  0.99294657 0.99058086\n",
      " 0.9976501  0.9994809  0.9986565  0.99279565 0.9993944  0.99696845\n",
      " 0.9916387  0.7916755 ]\n",
      "The rewards are: [0.99672014 0.9996619  0.9936935  0.99830496 0.9030667  0.9952513\n",
      " 0.95990115 0.9997857  0.99644816 0.8416765  0.8673865  0.9421726\n",
      " 0.9967192  0.8859444  0.9905337  0.7765733  0.9760985  0.7562626\n",
      " 0.905006   0.9993999  0.9179241  0.9997242  0.93655634 0.99643743\n",
      " 0.5617194  0.9990465  0.69517386 0.99731785 0.99913365 0.9967495\n",
      " 0.97984594 0.9925856 ]\n",
      "The rewards are: [0.99611086 0.9998808  0.980149   0.99956983 0.99832577 0.94522095\n",
      " 0.99598193 0.782406   0.99396    0.9968503  0.9951355  0.9313862\n",
      " 0.99701154 0.90500677 0.9952974  0.9991806  0.9969965  0.96337867\n",
      " 0.98443896 0.99588877 0.6359526  0.96435314 0.78826624 0.95112956\n",
      " 0.99978    0.9991823  0.99449736 0.99933136 0.99704677 0.60367626\n",
      " 0.9991524  0.9966628 ]\n",
      "The rewards are: [0.9974343  0.9790621  0.9995633  0.8723863  0.99905723 0.99850273\n",
      " 0.90038425 0.9976121  0.97286624 0.97443867 0.96379614 0.9971661\n",
      " 0.9842584  0.9842875  0.9600795  0.9961039  0.99517584 0.8714982\n",
      " 0.9777028  0.9746445  0.9951873  0.6803135  0.99659497 0.9971129\n",
      " 0.9981108  0.5155038  0.9862605  0.9850397  0.9846475  0.7788368\n",
      " 0.5365612  0.9999734 ]\n",
      "The rewards are: [0.99239373 0.9979214  0.99617755 0.7287561  0.8527213  0.75679314\n",
      " 0.9972681  0.97817665 0.603731   0.99972385 0.98863107 0.97933495\n",
      " 0.97324365 0.9956104  0.92722034 0.9966556  0.9989706  0.6167894\n",
      " 0.9998148  0.97422326 0.9780472  0.99649435 0.9999628  0.99544334\n",
      " 0.6718799  0.9998348  0.92214406 0.99896777 0.7329951  0.9997913\n",
      " 0.94605124 0.9881809 ]\n",
      "The rewards are: [0.9905067  0.9726378  0.9471257  0.5266666  0.996269   0.7316193\n",
      " 0.9991423  0.9751535  0.99367225 0.97389245 0.8832251  0.81553406\n",
      " 0.9866498  0.92506003 0.9983828  0.9950375  0.9966839  0.91301626\n",
      " 0.9457463  0.95685136 0.9996215  0.99981433 0.8666817  0.9845014\n",
      " 0.70309997 0.9723088  0.9998091  0.9725989  0.9987331  0.97865534\n",
      " 0.91551423 0.95245445]\n",
      "The rewards are: [0.9575892  0.8650791  0.9884803  0.9981812  0.99809676 0.70255095\n",
      " 0.9922667  0.9993137  0.97310346 0.8770341  0.9979786  0.99769825\n",
      " 0.96874803 0.9783246  0.9959351  0.93813354 0.9946154  0.9999006\n",
      " 0.9969374  0.9961591  0.9977392  0.9919369  0.99498725 0.9988257\n",
      " 0.98759204 0.9990308  0.9896408  0.9812061  0.99321425 0.99088585\n",
      " 0.7700584  0.99826187]\n",
      "The rewards are: [0.9993351  0.99440247 0.99967873 0.95758444 0.78980786 0.9996667\n",
      " 0.7753466  0.98196626 0.71464056 0.99914443 0.9981982  0.9994394\n",
      " 0.94233406 0.9590832  0.8312851  0.856499   0.9994505  0.9991622\n",
      " 0.9991208  0.94607055 0.9577434  0.9132603  0.99888796 0.99359727\n",
      " 0.9989698  0.9719539  0.98986125 0.9927004  0.99807477 0.97912496\n",
      " 0.9982685  0.9703031 ]\n",
      "The rewards are: [0.9998474  0.9979115  0.9989384  0.99642724 0.67485946 0.9995881\n",
      " 0.9972064  0.9992725  0.91116273 0.9998419  0.7208773  0.8897354\n",
      " 0.93379986 0.99723804 0.9999832  0.9941549  0.9924273  0.9997987\n",
      " 0.9922463  0.9995322  0.9692152  0.98032963 0.9919084  0.99043816\n",
      " 0.99811894 0.9822159  0.99373406 0.99999166 0.98589605 0.7797146\n",
      " 0.99208415 0.94354516]\n",
      "The rewards are: [0.99975973 0.999382   0.89560443 0.99905044 0.7663721  0.99973506\n",
      " 0.9947107  0.98944443 0.9978005  0.9985898  0.5978249  0.86000717\n",
      " 0.999091   0.8078382  0.99969757 0.99898523 0.98865813 0.98016423\n",
      " 0.99974626 0.88353366 0.8871543  0.998555   0.9967981  0.98694694\n",
      " 0.9777548  0.6894889  0.7844027  0.99249023 0.7017725  0.9673652\n",
      " 0.9962727  0.75230217]\n",
      "The rewards are: [0.62125057 0.8227432  0.85645235 0.9954364  0.99446243 0.5960134\n",
      " 0.97856677 0.9970517  0.9993728  0.96054727 0.998135   0.96518975\n",
      " 0.9740381  0.7575401  0.999673   0.59557444 0.9996111  0.99969983\n",
      " 0.9922464  0.99985933 0.74302894 0.99626464 0.99743253 0.995621\n",
      " 0.94311595 0.999406   0.99957615 0.98222166 0.9997851  0.999811\n",
      " 0.99865305 0.9984664 ]\n",
      "The rewards are: [0.9972156  0.99677473 0.9960742  0.981293   0.8794864  0.98596\n",
      " 0.99935263 0.9991404  0.9996189  0.9801942  0.99864393 0.9123537\n",
      " 0.99778724 0.9960492  0.94705707 0.9963683  0.999838   0.9949898\n",
      " 0.9360522  0.99344784 0.9930548  0.85000795 0.969315   0.9998287\n",
      " 0.99997103 0.9897288  0.90106547 0.732426   0.95175624 0.9960705\n",
      " 0.909874   0.5048963 ]\n",
      "The rewards are: [0.7942599  0.99361587 0.9997198  0.9997621  0.7517866  0.9964228\n",
      " 0.7372145  0.99785113 0.9977196  0.99894553 0.9915575  0.9988312\n",
      " 0.9828157  0.86623085 0.9969162  0.99896896 0.9339452  0.99836856\n",
      " 0.99722207 0.96910673 0.9991788  0.93882793 0.99620867 0.8527972\n",
      " 0.9978004  0.99941945 0.9954627  0.98916185 0.84806037 0.93797576\n",
      " 0.7768274  0.99827194]\n",
      "The rewards are: [0.9932633  0.9187171  0.9987644  0.9699505  0.9999207  0.88812596\n",
      " 0.9997726  0.6505262  0.9975689  0.77545196 0.9811628  0.98713255\n",
      " 0.83772534 0.90922403 0.9953868  0.8894115  0.92478925 0.9860107\n",
      " 0.9992078  0.88554114 0.9947135  0.9927596  0.9957671  0.84300584\n",
      " 0.9930569  0.9304426  0.99048084 0.8416953  0.8756655  0.9976412\n",
      " 0.99553937 0.9933426 ]\n",
      "The rewards are: [0.9746463  0.5337183  0.65026695 0.95152247 0.95717055 0.99699533\n",
      " 0.6077998  0.9965634  0.9964651  0.9979527  0.9973648  0.9997341\n",
      " 0.9983714  0.9943298  0.9967057  0.9961593  0.79669607 0.99932957\n",
      " 0.99141955 0.99576735 0.9865284  0.9998976  0.9646743  0.9972676\n",
      " 0.98428553 0.99814475 0.99865484 0.8089853  0.697389   0.9979704\n",
      " 0.9965055  0.9969734 ]\n",
      "The rewards are: [0.7373502  0.99290884 0.99989045 0.9947914  0.99688905 0.9835211\n",
      " 0.99372065 0.9789342  0.97288406 0.9988825  0.97746176 0.9967541\n",
      " 0.9981698  0.91763115 0.8616918  0.9990263  0.6507023  0.9433757\n",
      " 0.9793035  0.9907006  0.9989374  0.9583742  0.9973436  0.93975085\n",
      " 0.9994004  0.9990766  0.9955396  0.9943506  0.99866915 0.99089444\n",
      " 0.99166906 0.9661442 ]\n",
      "The rewards are: [0.98639953 0.9791805  0.999718   0.9996691  0.9864992  0.9974106\n",
      " 0.8548245  0.9963224  0.9962057  0.9927106  0.9559576  0.99990225\n",
      " 0.9991467  0.98764706 0.54841596 0.99820065 0.9690542  0.761545\n",
      " 0.99304354 0.8440254  0.9137791  0.99801743 0.99900466 0.9470936\n",
      " 0.99988496 0.9901751  0.94100577 0.96954095 0.99917185 0.99856204\n",
      " 0.9987883  0.98121727]\n",
      "The rewards are: [0.9586384  0.995564   0.9983012  0.6589965  0.99075985 0.9919703\n",
      " 0.9992685  0.98170197 0.9902304  0.5949124  0.5401986  0.9997414\n",
      " 0.98587245 0.9921172  0.99834657 0.9584603  0.9996216  0.9977666\n",
      " 0.98820823 0.51125735 0.9978988  0.98242444 0.99790704 0.9909683\n",
      " 0.9992055  0.9929671  0.99140584 0.5721389  0.9898437  0.9944465\n",
      " 0.9530212  0.9920441 ]\n",
      "The rewards are: [0.9985176  0.79048324 0.9970765  0.99615073 0.99803025 0.99450135\n",
      " 0.94846416 0.99960357 0.9896616  0.9849246  0.9261385  0.995349\n",
      " 0.9311138  0.99524885 0.91261494 0.9933843  0.74319273 0.99715376\n",
      " 0.99851614 0.99999344 0.8505942  0.9987124  0.82589936 0.9925425\n",
      " 0.9826916  0.9997595  0.99635637 0.999113   0.9229633  0.9701395\n",
      " 0.55106175 0.90222406]\n",
      "The rewards are: [0.9995484  0.99774534 0.99813074 0.9923366  0.99829334 0.9084794\n",
      " 0.9958961  0.715059   0.9948578  0.97149163 0.9962463  0.93111897\n",
      " 0.98254526 0.99264866 0.9878297  0.86731696 0.92558587 0.9628364\n",
      " 0.9901542  0.9880762  0.9241762  0.93586516 0.9681123  0.9943877\n",
      " 0.9907912  0.8770568  0.9994999  0.9893981  0.95327085 0.7583385\n",
      " 0.9979559  0.99120444]\n",
      "The rewards are: [0.99860746 0.9936986  0.9995752  0.9586857  0.99990916 0.9995223\n",
      " 0.90384424 0.96698976 0.99400604 0.9996673  0.99967253 0.99655056\n",
      " 0.99923277 0.9800978  0.99054796 0.9980965  0.99384403 0.99631566\n",
      " 0.95399135 0.6524981  0.87372994 0.99260324 0.99838936 0.99976474\n",
      " 0.9861411  0.9989673  0.99014765 0.9974553  0.93028635 0.9999366\n",
      " 0.9961516  0.6251662 ]\n",
      "The rewards are: [0.999923   0.7689292  0.9947436  0.992638   0.999688   0.9900898\n",
      " 0.8166184  0.94328034 0.6924957  0.9996431  0.804494   0.995086\n",
      " 0.9993755  0.87631047 0.99913174 0.99685436 0.99979824 0.9544764\n",
      " 0.9983016  0.9988794  0.9045972  0.927028   0.82265574 0.9990715\n",
      " 0.9982278  0.9997243  0.9121192  0.9969241  0.9491116  0.99975306\n",
      " 0.9607884  0.9986395 ]\n",
      "The rewards are: [0.6255663  0.954428   0.53686273 0.99274313 0.9950873  0.99822694\n",
      " 0.9819624  0.9995468  0.99458647 0.91548145 0.9764475  0.9920216\n",
      " 0.99930453 0.9548761  0.907083   0.9974527  0.99768865 0.8034816\n",
      " 0.97088474 0.9979752  0.56581295 0.87430567 0.99987316 0.96449727\n",
      " 0.9763049  0.998638   0.98973924 0.9930139  0.7612303  0.99715245\n",
      " 0.9921733  0.6809162 ]\n",
      "The rewards are: [0.96619517 0.77437663 0.9991948  0.98930234 0.97249573 0.99815327\n",
      " 0.9901051  0.9994723  0.99192977 0.98279953 0.74864596 0.9958996\n",
      " 0.9660421  0.937381   0.99985063 0.98099935 0.83182085 0.9927886\n",
      " 0.99005413 0.9418963  0.9817614  0.9041371  0.6598342  0.99936944\n",
      " 0.9997032  0.9504417  0.9998198  0.99880946 0.9971021  0.651677\n",
      " 0.99995506 0.9766291 ]\n",
      "The rewards are: [0.9443755  0.99438053 0.5427053  0.5008695  0.9954124  0.9477289\n",
      " 0.95179486 0.99538934 0.6426811  0.74846786 0.9957854  0.7928357\n",
      " 0.99842775 0.93676585 0.8657285  0.99686074 0.99504167 0.99334973\n",
      " 0.9856813  0.75031173 0.9195823  0.99721944 0.86150086 0.99396133\n",
      " 0.5629286  0.9985697  0.9988092  0.9974788  0.9932554  0.99855775\n",
      " 0.54174644 0.9623699 ]\n",
      "The rewards are: [0.92196536 0.9763797  0.9681637  0.7596239  0.99788827 0.99219716\n",
      " 0.99604887 0.9518976  0.9953994  0.9967709  0.97785974 0.987922\n",
      " 0.9919653  0.9017869  0.99994886 0.99595994 0.8481256  0.9018451\n",
      " 0.9643123  0.7334766  0.83973616 0.9790854  0.9994777  0.9955343\n",
      " 0.68867517 0.99936837 0.9974177  0.8465308  0.9994356  0.9985038\n",
      " 0.6461254  0.8542474 ]\n",
      "The rewards are: [0.9359965  0.99933004 0.99990845 0.99925    0.84632397 0.8610856\n",
      " 0.9968784  0.9996941  0.98962027 0.98845637 0.530043   0.99715626\n",
      " 0.9992188  0.7325257  0.85785246 0.9996069  0.5802895  0.991943\n",
      " 0.99311197 0.999637   0.9969182  0.9996544  0.9572342  0.96235347\n",
      " 0.5706793  0.99931324 0.9987134  0.9994555  0.59193176 0.9942808\n",
      " 0.69447386 0.5618076 ]\n",
      "The rewards are: [0.99219394 0.9949779  0.70711887 0.9884587  0.97305465 0.99657506\n",
      " 0.9899228  0.9976229  0.95106316 0.99971575 0.9957028  0.99939287\n",
      " 0.956099   0.9727181  0.99941957 0.9765253  0.9984131  0.9938012\n",
      " 0.89911056 0.9997323  0.995565   0.9999789  0.9898822  0.99949276\n",
      " 0.7186187  0.7648919  0.994121   0.973437   0.9687253  0.99306446\n",
      " 0.91759306 0.9861697 ]\n",
      "The rewards are: [0.7949664  0.99751806 0.9338433  0.9505928  0.9995987  0.9911705\n",
      " 0.9946951  0.61270195 0.95331156 0.9770702  0.5070717  0.5773744\n",
      " 0.9973744  0.9997633  0.55922806 0.996748   0.998678   0.9847077\n",
      " 0.9986784  0.99296814 0.9054314  0.5687509  0.99860865 0.9949732\n",
      " 0.9555217  0.996693   0.99930084 0.8406701  0.9031347  0.9957171\n",
      " 0.8968275  0.9915571 ]\n",
      "The rewards are: [0.73592544 0.994733   0.997936   0.98524666 0.9993923  0.99782383\n",
      " 0.99926823 0.623268   0.9996244  0.9051679  0.99880755 0.9995845\n",
      " 0.83698237 0.90958625 0.99777156 0.97235143 0.99785405 0.99904484\n",
      " 0.9973749  0.9997212  0.9956721  0.9937046  0.81670785 0.8785114\n",
      " 0.9641142  0.63318366 0.993822   0.99939656 0.94377    0.9604929\n",
      " 0.9552692  0.9033516 ]\n",
      "The rewards are: [0.997886   0.9440271  0.94307303 0.87630385 0.9447552  0.7579481\n",
      " 0.99667776 0.99902844 0.9990055  0.9972063  0.9792636  0.99174654\n",
      " 0.98279774 0.99973196 0.99986863 0.917664   0.9879963  0.9901301\n",
      " 0.9930896  0.8392753  0.99749786 0.9922948  0.8443869  0.99970883\n",
      " 0.9985592  0.99119204 0.996687   0.9976399  0.99058187 0.9806927\n",
      " 0.9989241  0.9981413 ]\n",
      "The rewards are: [0.98820364 0.9983375  0.9978157  0.99985874 0.744117   0.9958811\n",
      " 0.954905   0.99954337 0.9532352  0.99999356 0.99996567 0.9846363\n",
      " 0.99557084 0.9456663  0.9969158  0.7884841  0.9970611  0.9526394\n",
      " 0.99530447 0.86814433 0.9953902  0.91952455 0.9828583  0.9864433\n",
      " 0.977997   0.9993881  0.96149385 0.99727756 0.73095286 0.9824917\n",
      " 0.9716636  0.6488779 ]\n",
      "The rewards are: [0.9024091  0.9990074  0.66989547 0.5047881  0.94470805 0.999408\n",
      " 0.9908593  0.99988484 0.9998491  0.67070585 0.9995621  0.9986651\n",
      " 0.99909663 0.87050045 0.94121414 0.9831527  0.99667144 0.89017636\n",
      " 0.9705964  0.71290296 0.9971384  0.9839475  0.9978728  0.96900463\n",
      " 0.9964803  0.9985362  0.7550308  0.99943227 0.99932134 0.7519237\n",
      " 0.63849187 0.99928147]\n",
      "The rewards are: [0.9924896  0.99218565 0.9883437  0.9217965  0.9982261  0.8970285\n",
      " 0.9987405  0.970628   0.93171906 0.88292783 0.99537826 0.9305258\n",
      " 0.9970106  0.99750394 0.99863845 0.99144053 0.6877918  0.9749332\n",
      " 0.99967813 0.84011483 0.997727   0.91350216 0.99914515 0.64439636\n",
      " 0.99959487 0.74237996 0.9945549  0.96412194 0.9997316  0.9920413\n",
      " 0.999382   0.5062582 ]\n",
      "The rewards are: [0.8540178  0.9382823  0.99955314 0.9987972  0.99403244 0.9854536\n",
      " 0.9987185  0.9682673  0.9968522  0.99974877 0.50784725 0.69486\n",
      " 0.7395692  0.93175584 0.9694378  0.84751683 0.9963302  0.972306\n",
      " 0.9993635  0.99350303 0.99623495 0.9987394  0.99905115 0.7808548\n",
      " 0.94517803 0.9944501  0.8068883  0.99863774 0.9924279  0.9995453\n",
      " 0.9972145  0.9991447 ]\n",
      "The rewards are: [0.9933395  0.93148416 0.8276043  0.7465994  0.99974185 0.9997547\n",
      " 0.72177726 0.9959858  0.92057794 0.654414   0.99288493 0.9990901\n",
      " 0.9706891  0.9867004  0.94207287 0.9999722  0.99710363 0.9245705\n",
      " 0.6604159  0.99479735 0.99107164 0.97173643 0.98116285 0.99876994\n",
      " 0.99872273 0.9961164  0.9997677  0.99666154 0.70839715 0.9989415\n",
      " 0.91871154 0.87768716]\n",
      "The rewards are: [0.99091095 0.994549   0.9984124  0.7978761  0.99442035 0.99944574\n",
      " 0.9239746  0.996597   0.9998487  0.8438831  0.99964964 0.9682903\n",
      " 0.9287052  0.997142   0.9995421  0.8830865  0.9997873  0.92193955\n",
      " 0.9431093  0.94815016 0.96622175 0.98007137 0.92800814 0.98219913\n",
      " 0.9983199  0.9606843  0.81011736 0.99018097 0.8714488  0.8770089\n",
      " 0.9539703  0.8844856 ]\n",
      "The rewards are: [0.9556922  0.7954691  0.9734806  0.5277359  0.5087964  0.98165834\n",
      " 0.9929334  0.57896113 0.8764823  0.93579835 0.99980575 0.99710506\n",
      " 0.9999536  0.5752907  0.9998468  0.9905347  0.9931832  0.8177799\n",
      " 0.9615785  0.99384886 0.9903746  0.99843043 0.9997627  0.9993857\n",
      " 0.9957503  0.57998335 0.9981761  0.70724475 0.999469   0.9992899\n",
      " 0.5024637  0.99991226]\n",
      "The rewards are: [0.91574    0.9554146  0.9989773  0.9666364  0.999271   0.9983821\n",
      " 0.96839744 0.9971328  0.9961396  0.99982065 0.97166246 0.6717021\n",
      " 0.9962483  0.99892646 0.5210848  0.9998499  0.94718975 0.99625105\n",
      " 0.56481624 0.503914   0.9608658  0.96644753 0.99349517 0.9616195\n",
      " 0.95994216 0.6730599  0.9883123  0.99966633 0.9587865  0.79924\n",
      " 0.9466368  0.99952805]\n",
      "The rewards are: [0.9831649  0.99942553 0.96920806 0.9971411  0.99911124 0.9946189\n",
      " 0.9658284  0.9965268  0.99720025 0.9626091  0.99054515 0.99766976\n",
      " 0.9799596  0.68646497 0.9995314  0.77266717 0.9787037  0.53668183\n",
      " 0.9996018  0.98896056 0.9466097  0.99761754 0.99289566 0.9999746\n",
      " 0.99091816 0.99959105 0.99643874 0.9955401  0.99984634 0.9929355\n",
      " 0.9874933  0.99196917]\n",
      "The rewards are: [0.99910563 0.90833116 0.9997855  0.60269    0.99998546 0.9992859\n",
      " 0.7429266  0.7028175  0.82737434 0.9807554  0.9925271  0.84598917\n",
      " 0.9931427  0.91628605 0.994177   0.998678   0.78438    0.9357652\n",
      " 0.85084856 0.6712418  0.9959417  0.9755941  0.9965244  0.9734213\n",
      " 0.9980659  0.5727577  0.9782734  0.9471209  0.9401783  0.9989618\n",
      " 0.9997489  0.92925686]\n",
      "The rewards are: [0.7172377  0.99981064 0.9653788  0.9988852  0.9995573  0.9937078\n",
      " 0.8333557  0.99884367 0.9479453  0.9833103  0.5485357  0.946357\n",
      " 0.68407124 0.9994117  0.9998759  0.99379045 0.9890226  0.9966204\n",
      " 0.99440175 0.9984493  0.85453266 0.66753936 0.97701025 0.9466899\n",
      " 0.9966697  0.9989606  0.99556595 0.98332995 0.99282575 0.99766135\n",
      " 0.9975362  0.9994325 ]\n",
      "The rewards are: [0.97306246 0.990651   0.99870074 0.98649734 0.9948848  0.97228324\n",
      " 0.99574655 0.99748117 0.9858602  0.98920035 0.68555456 0.989865\n",
      " 0.98404354 0.77692425 0.9846587  0.9930147  0.993608   0.99610585\n",
      " 0.9995134  0.9731799  0.99996746 0.99356973 0.778688   0.6572937\n",
      " 0.9793392  0.99872154 0.9784549  0.97791106 0.5223679  0.99685293\n",
      " 0.955522   0.8340983 ]\n",
      "The rewards are: [0.9903071  0.9978023  0.9988644  0.9949799  0.99202347 0.7337243\n",
      " 0.99784315 0.9959908  0.9994848  0.76752913 0.9983689  0.9990694\n",
      " 0.99935406 0.99952245 0.99953854 0.99700123 0.98670584 0.990948\n",
      " 0.97409123 0.8692626  0.9821239  0.81717855 0.99803454 0.97635114\n",
      " 0.99404246 0.678637   0.94603014 0.9897855  0.9842286  0.9852791\n",
      " 0.9996202  0.9977575 ]\n",
      "The rewards are: [0.999156   0.97614586 0.92674834 0.99937963 0.9962328  0.9998677\n",
      " 0.8060032  0.99326986 0.94701993 0.9989378  0.9990706  0.9991246\n",
      " 0.9026498  0.8270488  0.6262235  0.94362473 0.9911623  0.9382072\n",
      " 0.59333867 0.99828064 0.99990845 0.7470163  0.99852705 0.99913317\n",
      " 0.9859227  0.9812981  0.9997986  0.99566084 0.99825376 0.97218037\n",
      " 0.8890197  0.9498551 ]\n",
      "The rewards are: [0.97733235 0.9781917  0.9984896  0.9512684  0.96428084 0.9859561\n",
      " 0.87683946 0.99969995 0.9998259  0.99840707 0.99955267 0.89431864\n",
      " 0.95318854 0.99517834 0.9791468  0.99968517 0.99720156 0.9940467\n",
      " 0.99521196 0.9964774  0.9992507  0.99983656 0.992897   0.99752194\n",
      " 0.9998592  0.9994727  0.8356776  0.99961424 0.98732376 0.93261665\n",
      " 0.7662833  0.9252389 ]\n",
      "The rewards are: [0.95979947 0.993026   0.8947315  0.9995486  0.99730754 0.9939095\n",
      " 0.9510638  0.9499142  0.9971944  0.75396985 0.9536706  0.99132943\n",
      " 0.9995697  0.96826607 0.9995096  0.5740588  0.9970599  0.9759394\n",
      " 0.9828743  0.9362957  0.98289263 0.9857755  0.9907293  0.97500926\n",
      " 0.99633706 0.99613684 0.8669929  0.9299922  0.97952133 0.5362678\n",
      " 0.9849578  0.98906136]\n",
      "The rewards are: [0.9984119  0.96388996 0.53604007 0.5000762  0.9987929  0.99561465\n",
      " 0.76846546 0.98865616 0.9941544  0.9943614  0.99376994 0.99905294\n",
      " 0.999033   0.995531   0.99986374 0.9973743  0.99865294 0.84602034\n",
      " 0.9986394  0.99689746 0.98675585 0.9979006  0.99311006 0.99734014\n",
      " 0.9489709  0.6253298  0.934983   0.9986846  0.6973917  0.97185624\n",
      " 0.99968755 0.63287085]\n",
      "The rewards are: [0.87164557 0.998909   0.9992607  0.986      0.9938845  0.9718507\n",
      " 0.60654426 0.999681   0.7972546  0.9832312  0.9969035  0.9485912\n",
      " 0.9636427  0.97774565 0.99954706 0.99898547 0.98719937 0.99298096\n",
      " 0.9904564  0.8864465  0.9445304  0.9997125  0.98853534 0.99796414\n",
      " 0.99900776 0.9973137  0.50497115 0.949167   0.99709225 0.96835816\n",
      " 0.99595934 0.994766  ]\n",
      "The rewards are: [0.99668497 0.99555737 0.9869904  0.7287461  0.92620236 0.9999018\n",
      " 0.99904805 0.9406474  0.9960937  0.99818015 0.92049134 0.99883693\n",
      " 0.9863499  0.99997234 0.72379684 0.656957   0.77258784 0.9612423\n",
      " 0.9999361  0.85313797 0.9945127  0.90840405 0.92992705 0.891516\n",
      " 0.9977124  0.9998472  0.99096173 0.99994147 0.99876887 0.97995293\n",
      " 0.81191486 0.9950818 ]\n",
      "The rewards are: [0.9773147  0.9995584  0.991774   0.955708   0.9874281  0.99784887\n",
      " 0.99795437 0.99147683 0.9978916  0.8198567  0.95807    0.99892324\n",
      " 0.9586483  0.9989015  0.99934334 0.9689997  0.99996865 0.9633346\n",
      " 0.8382833  0.99715817 0.86064    0.99989164 0.9970688  0.9996488\n",
      " 0.9992986  0.9985316  0.84857154 0.9999293  0.99852055 0.9948019\n",
      " 0.999966   0.948375  ]\n",
      "The rewards are: [0.998104   0.9866492  0.9975611  0.99265504 0.9990119  0.9203941\n",
      " 0.9820417  0.99991035 0.9766541  0.99104625 0.9930146  0.9404225\n",
      " 0.9457062  0.9351584  0.9891216  0.95819116 0.9730429  0.9084215\n",
      " 0.93968725 0.9995395  0.8928849  0.9997472  0.62672484 0.97818094\n",
      " 0.9988656  0.9306825  0.8880146  0.99393386 0.9959877  0.86997956\n",
      " 0.971565   0.9021937 ]\n",
      "The rewards are: [0.99709606 0.8903689  0.63342214 0.9604753  0.9658793  0.9971374\n",
      " 0.9998671  0.9456541  0.9990507  0.94739974 0.99544513 0.9966336\n",
      " 0.9729471  0.98958826 0.99311125 0.9953681  0.7642983  0.91316026\n",
      " 0.8706487  0.98163074 0.870498   0.9984579  0.84103763 0.99904424\n",
      " 0.99666166 0.9998838  0.9999192  0.97928554 0.9999696  0.9975439\n",
      " 0.9926651  0.99453884]\n",
      "The rewards are: [0.9995043  0.9851981  0.8982265  0.99786973 0.9135114  0.994511\n",
      " 0.99781454 0.999316   0.98305374 0.99739325 0.99851745 0.99986625\n",
      " 0.9739828  0.99574476 0.9800237  0.8135602  0.9419653  0.99931407\n",
      " 0.99017406 0.93140644 0.99762243 0.991651   0.82285357 0.9912663\n",
      " 0.9978994  0.67942935 0.99899215 0.99878484 0.99040645 0.96084136\n",
      " 0.99749124 0.97760254]\n",
      "The rewards are: [0.9981862  0.99883956 0.97092235 0.99821544 0.9374533  0.97572124\n",
      " 0.99435884 0.9960674  0.7740842  0.99922144 0.97854996 0.99553394\n",
      " 0.941693   0.9928559  0.6242037  0.9974911  0.92682636 0.82934463\n",
      " 0.98865396 0.99152195 0.9981554  0.99965453 0.9881897  0.99544805\n",
      " 0.99408084 0.99948055 0.99589455 0.99589074 0.9915768  0.9998883\n",
      " 0.90825826 0.9994438 ]\n",
      "The rewards are: [0.91689056 0.99868304 0.9598069  0.95714974 0.9996088  0.9990946\n",
      " 0.9193978  0.99803597 0.9966863  0.6404419  0.98215586 0.99133366\n",
      " 0.99723697 0.99237883 0.9976411  0.9964651  0.9989557  0.79855394\n",
      " 0.99911505 0.99924684 0.9996972  0.9982179  0.92867225 0.81224066\n",
      " 0.7054161  0.9986657  0.9018769  0.9938181  0.9995372  0.99919695\n",
      " 0.65523887 0.99118185]\n",
      "The rewards are: [0.6287778  0.9995371  0.9999846  0.9991461  0.9904019  0.98745024\n",
      " 0.99831295 0.994093   0.9674375  0.9991239  0.99999464 0.9812164\n",
      " 0.99962914 0.994522   0.9409624  0.99652547 0.9997079  0.99923193\n",
      " 0.9726812  0.9953543  0.98120016 0.85181296 0.9972881  0.9655678\n",
      " 0.98063296 0.99964416 0.99853265 0.7899594  0.9504753  0.9874657\n",
      " 0.8790183  0.9953597 ]\n",
      "The rewards are: [0.97735035 0.787401   0.95573735 0.6190745  0.9702002  0.87111443\n",
      " 0.9356481  0.9555219  0.9419143  0.98927176 0.95717055 0.99424076\n",
      " 0.7488085  0.99433386 0.99355996 0.9977004  0.99974316 0.99931717\n",
      " 0.66891813 0.99991536 0.98157114 0.94475806 0.9994209  0.99445724\n",
      " 0.9956571  0.9995326  0.8439185  0.94643605 0.9888602  0.95741665\n",
      " 0.95360774 0.9998222 ]\n",
      "The rewards are: [0.99764377 0.99956185 0.97369283 0.994718   0.9724965  0.9999405\n",
      " 0.99915314 0.81675005 0.98326117 0.9928514  0.9995994  0.99563426\n",
      " 0.98515147 0.9722207  0.9598323  0.9424782  0.99982184 0.99867684\n",
      " 0.7564492  0.9512262  0.94129294 0.99728453 0.643831   0.9986034\n",
      " 0.99958867 0.98943514 0.5229364  0.53473014 0.9900831  0.997503\n",
      " 0.72674936 0.9964678 ]\n",
      "The rewards are: [0.9974523  0.99815553 0.84097296 0.9897356  0.9734442  0.9941584\n",
      " 0.9509024  0.99487865 0.9414404  0.9999373  0.99779415 0.9859013\n",
      " 0.9847996  0.9843166  0.99845934 0.82558864 0.9998074  0.95069873\n",
      " 0.8422457  0.7919998  0.99323434 0.99936455 0.9998217  0.98800313\n",
      " 0.9947745  0.99897027 0.999326   0.9999894  0.99378467 0.9828137\n",
      " 0.9997048  0.8361131 ]\n",
      "The rewards are: [0.99536335 0.8279512  0.9997665  0.996797   0.99643266 0.97389424\n",
      " 0.76524556 0.9993432  0.9985386  0.729133   0.97472376 0.9861829\n",
      " 0.9996606  0.578597   0.99315166 0.9964276  0.9913885  0.99979514\n",
      " 0.99990726 0.9423964  0.9082257  0.92103267 0.9927417  0.99283147\n",
      " 0.9992156  0.9977012  0.988837   0.974287   0.9442028  0.9919288\n",
      " 0.98662645 0.8524426 ]\n",
      "The rewards are: [0.8381907  0.99815756 0.9053604  0.9979796  0.99924076 0.9954293\n",
      " 0.97120374 0.9978502  0.99888426 0.9995577  0.99938345 0.6199824\n",
      " 0.9745565  0.99442863 0.99941957 0.9989774  0.6160206  0.9920803\n",
      " 0.99970144 0.9991886  0.99884135 0.9997737  0.99961215 0.7493948\n",
      " 0.99979895 0.97718996 0.98646843 0.9794779  0.9968851  0.99195975\n",
      " 0.9991203  0.9820838 ]\n",
      "The rewards are: [0.74716234 0.9921548  0.99390775 0.9996258  0.9999099  0.9590303\n",
      " 0.8624383  0.99860793 0.99191463 0.9999417  0.97857773 0.98990446\n",
      " 0.7378061  0.9992906  0.6889965  0.8990487  0.9842451  0.9973285\n",
      " 0.8821628  0.6969848  0.999811   0.9985997  0.7304481  0.99445\n",
      " 0.99491924 0.9998086  0.68082386 0.9416032  0.84426534 0.9944066\n",
      " 0.9658142  0.9967078 ]\n",
      "The rewards are: [0.99943656 0.9940937  0.9979006  0.84623677 0.9953505  0.88285005\n",
      " 0.99757606 0.8130133  0.9987112  0.93042815 0.9908386  0.9920183\n",
      " 0.9809502  0.95641685 0.9994011  0.9903251  0.9771787  0.9940797\n",
      " 0.9886708  0.54806197 0.8550966  0.5840335  0.99807847 0.92053795\n",
      " 0.98229563 0.9901315  0.9846673  0.9817886  0.996718   0.53873974\n",
      " 0.7230712  0.99100935]\n",
      "The rewards are: [0.984876   0.9963559  0.9964463  0.9991478  0.91892266 0.9434386\n",
      " 0.99579084 0.98356473 0.9340161  0.9762299  0.99551696 0.96590626\n",
      " 0.85611147 0.9992324  0.9968077  0.9904851  0.98799485 0.9504149\n",
      " 0.9967709  0.9982048  0.982579   0.99358445 0.9736525  0.9994301\n",
      " 0.999892   0.8431674  0.9967121  0.98410994 0.99863523 0.7601206\n",
      " 0.9735058  0.5953903 ]\n",
      "The rewards are: [0.9682095  0.999273   0.9768023  0.9990213  0.99021846 0.98843634\n",
      " 0.98802316 0.8465272  0.9984102  0.6616304  0.90871155 0.9885999\n",
      " 0.9922076  0.9871314  0.99839634 0.9991617  0.89869404 0.9936179\n",
      " 0.99960595 0.99647564 0.5416558  0.998976   0.6728132  0.9964334\n",
      " 0.94795024 0.9870249  0.9996834  0.99624616 0.996009   0.99247\n",
      " 0.70224357 0.9851896 ]\n",
      "The rewards are: [0.99973565 0.9843507  0.93101054 0.85690594 0.9993955  0.99840814\n",
      " 0.99848014 0.5881428  0.7949097  0.99828845 0.99978274 0.94879156\n",
      " 0.9882984  0.9998566  0.99847764 0.9975178  0.7057698  0.99649364\n",
      " 0.9597687  0.6084043  0.7202057  0.8261525  0.9923826  0.99800795\n",
      " 0.9420836  0.9979771  0.8318507  0.9607952  0.77201146 0.9717672\n",
      " 0.9538367  0.9976751 ]\n",
      "The rewards are: [0.9380234  0.99988425 0.959941   0.95832676 0.9835433  0.8436894\n",
      " 0.9369364  0.99917656 0.99780864 0.9885732  0.99861896 0.99997056\n",
      " 0.686771   0.9754591  0.96144044 0.99772376 0.9988267  0.9866714\n",
      " 0.98722667 0.998716   0.96977085 0.96453077 0.9973412  0.9982407\n",
      " 0.9985545  0.99207157 0.9977857  0.99584913 0.99702805 0.6620758\n",
      " 0.8747271  0.90054274]\n",
      "The rewards are: [0.9443757  0.5423163  0.9964211  0.9939031  0.968327   0.9993699\n",
      " 0.63438123 0.9766912  0.9961261  0.9973037  0.9956344  0.98754287\n",
      " 0.99784625 0.9991049  0.9969217  0.99864846 0.9907851  0.87328464\n",
      " 0.96383536 0.9983576  0.9971306  0.98654765 0.5442676  0.83271253\n",
      " 0.9945754  0.9970661  0.95838624 0.9581099  0.9947566  0.97836256\n",
      " 0.99964833 0.99141544]\n",
      "The rewards are: [0.9581187  0.9991211  0.989962   0.9994586  0.9415035  0.9936227\n",
      " 0.9988028  0.9999323  0.9943586  0.82651114 0.51207757 0.97186536\n",
      " 0.9963522  0.99774253 0.99226147 0.87226933 0.9724979  0.99957985\n",
      " 0.9886381  0.99824476 0.96216625 0.9981194  0.98654115 0.99917465\n",
      " 0.99953806 0.8520107  0.99959284 0.9993212  0.9395264  0.9895034\n",
      " 0.9964114  0.97489685]\n",
      "The rewards are: [0.87972915 0.63699543 0.9919797  0.99933004 0.96256393 0.9969029\n",
      " 0.8797955  0.99767107 0.99903846 0.9997782  0.71895003 0.9732487\n",
      " 0.9995129  0.6654919  0.56220895 0.99853456 0.9951931  0.6552008\n",
      " 0.99959797 0.9975555  0.9988778  0.99885285 0.9919275  0.9927059\n",
      " 0.9989951  0.99993634 0.9990484  0.9982297  0.9979715  0.9961228\n",
      " 0.52494055 0.9984524 ]\n",
      "The rewards are: [0.99764603 0.9585478  0.9992888  0.9254173  0.86836797 0.9959699\n",
      " 0.735664   0.8136619  0.73420554 0.9975611  0.9938412  0.9970373\n",
      " 0.9990614  0.9935469  0.9990792  0.81577027 0.999323   0.9981585\n",
      " 0.9986803  0.9972621  0.9382713  0.9952866  0.98300374 0.99738854\n",
      " 0.9376297  0.99646616 0.99385685 0.5722381  0.9907103  0.5740326\n",
      " 0.99724007 0.9935041 ]\n",
      "The rewards are: [0.99916744 0.5764663  0.99120104 0.9837789  0.99901915 0.9890798\n",
      " 0.9697038  0.99131495 0.99998665 0.98417664 0.99923515 0.98836344\n",
      " 0.9983839  0.90045834 0.9997403  0.9929389  0.99501884 0.96857285\n",
      " 0.9850118  0.9992094  0.9871804  0.93549156 0.9982346  0.9605457\n",
      " 0.99758804 0.9768712  0.97428936 0.9487635  0.941897   0.94639724\n",
      " 0.9985567  0.9754626 ]\n",
      "The rewards are: [0.98672384 0.9864406  0.99705136 0.99831474 0.9974638  0.9898642\n",
      " 0.994076   0.5061323  0.5977377  0.5926475  0.9450331  0.9744334\n",
      " 0.9979274  0.9706817  0.7485209  0.99904126 0.9979651  0.99779093\n",
      " 0.9909072  0.9792438  0.99452883 0.78498745 0.9950539  0.94465774\n",
      " 0.87344074 0.5742614  0.5457797  0.9996995  0.9993474  0.996642\n",
      " 0.9969177  0.99937314]\n",
      "The rewards are: [0.9997855  0.99886984 0.9954893  0.94584835 0.88997096 0.97073764\n",
      " 0.9574666  0.99777573 0.9958877  0.9982948  0.9969331  0.9948585\n",
      " 0.7238094  0.9976332  0.87675005 0.94735074 0.9955499  0.9998797\n",
      " 0.99892235 0.93527097 0.54591805 0.68368685 0.85927194 0.99979776\n",
      " 0.9990821  0.99661666 0.9787183  0.98491424 0.9998616  0.64792514\n",
      " 0.7514734  0.82041484]\n",
      "The rewards are: [0.9988166  0.8054121  0.9713994  0.9556993  0.9802218  0.9738841\n",
      " 0.99838483 0.99909675 0.9601728  0.59590876 0.56385    0.99527514\n",
      " 0.9997377  0.9990029  0.91487    0.999946   0.9996356  0.92697066\n",
      " 0.9127199  0.999803   0.9447525  0.99669015 0.99951863 0.8607397\n",
      " 0.9549277  0.99257576 0.8910249  0.9823695  0.9767795  0.9027079\n",
      " 0.99830544 0.9998543 ]\n",
      "The rewards are: [0.5801991  0.9993678  0.9841899  0.5106247  0.9944798  0.99939096\n",
      " 0.95045936 0.99762684 0.9999684  0.92648846 0.99403965 0.9988896\n",
      " 0.9905482  0.98527455 0.7960138  0.9889341  0.9828098  0.9996209\n",
      " 0.9993131  0.7717653  0.99770796 0.99971515 0.97083056 0.58112025\n",
      " 0.99881893 0.69964755 0.9972568  0.98703325 0.7510266  0.9938175\n",
      " 0.99939454 0.99868554]\n",
      "The rewards are: [0.5068136  0.99847084 0.7232549  0.9997378  0.9986222  0.9913549\n",
      " 0.99545395 0.98556143 0.99716574 0.9976046  0.98249096 0.67109317\n",
      " 0.99820673 0.99747473 0.99467033 0.62368715 0.9845664  0.93541884\n",
      " 0.99852294 0.9630211  0.9803735  0.9979102  0.9992631  0.80711925\n",
      " 0.9979773  0.9697263  0.99453557 0.99418515 0.9927643  0.9265359\n",
      " 0.9999198  0.6530881 ]\n",
      "The rewards are: [0.99674124 0.9985857  0.9984889  0.88259053 0.998922   0.98280925\n",
      " 0.9985598  0.99963045 0.99692553 0.99192715 0.98283273 0.9948468\n",
      " 0.9965779  0.9986791  0.9766817  0.98211515 0.98999095 0.9987147\n",
      " 0.9959961  0.9988913  0.9550236  0.9892265  0.99903893 0.99840826\n",
      " 0.9837067  0.5583772  0.9992537  0.9345115  0.998591   0.997428\n",
      " 0.86298186 0.99855417]\n",
      "The rewards are: [0.98709214 0.9907381  0.99865544 0.99987733 0.9978131  0.9984017\n",
      " 0.97558856 0.9965887  0.9740239  0.99919075 0.99667776 0.92554045\n",
      " 0.99900717 0.9770074  0.9965528  0.9996512  0.9997489  0.99978906\n",
      " 0.9707117  0.9873146  0.55566293 0.68801117 0.9884692  0.606269\n",
      " 0.77196914 0.96984285 0.7627383  0.88644254 0.99311393 0.97582006\n",
      " 0.97364885 0.7011181 ]\n",
      "The rewards are: [0.9969199  0.9950911  0.7593835  0.988622   0.99950373 0.99873656\n",
      " 0.9998697  0.9831972  0.9540342  0.9612305  0.99911374 0.9960061\n",
      " 0.9946741  0.80925    0.9999062  0.996855   0.85030043 0.9529464\n",
      " 0.97638047 0.9583343  0.7629224  0.9925875  0.996811   0.99838674\n",
      " 0.9906662  0.9099577  0.9999014  0.6587843  0.99781966 0.9883875\n",
      " 0.9975897  0.9897166 ]\n",
      "The rewards are: [0.993489   0.9981323  0.9689914  0.9948679  0.9981914  0.998978\n",
      " 0.9825555  0.947781   0.9791589  0.99989235 0.99551624 0.9999894\n",
      " 0.9966307  0.8526241  0.9993697  0.9766209  0.9991947  0.9955974\n",
      " 0.9884475  0.7982069  0.99942434 0.99833196 0.9850943  0.9951316\n",
      " 0.9984865  0.9331973  0.99627006 0.95474696 0.99778205 0.99690264\n",
      " 0.96156377 0.98320836]\n",
      "The rewards are: [0.9992834  0.9805499  0.9929783  0.8887241  0.9073257  0.99858993\n",
      " 0.9880592  0.700622   0.8407775  0.9986468  0.9627409  0.9975684\n",
      " 0.99945027 0.99662125 0.9994242  0.5604145  0.8865626  0.9979875\n",
      " 0.99696976 0.99978596 0.99716777 0.99977165 0.87568015 0.99912864\n",
      " 0.9543406  0.92786926 0.73117405 0.9859497  0.9986148  0.97622824\n",
      " 0.97646654 0.9885478 ]\n",
      "The rewards are: [0.5996144  0.5089571  0.9971566  0.983906   0.9960387  0.97308177\n",
      " 0.54251456 0.5166725  0.5959846  0.99910694 0.99896383 0.9982494\n",
      " 0.9629748  0.97909796 0.999141   0.99184096 0.95585495 0.9991078\n",
      " 0.7214759  0.76510817 0.95538753 0.9984566  0.9917605  0.99974793\n",
      " 0.9769     0.94323003 0.99888474 0.99560237 0.5741699  0.71237\n",
      " 0.9996673  0.98154724]\n",
      "The rewards are: [0.996675   0.9919843  0.998367   0.9970293  0.9986714  0.9996593\n",
      " 0.9833678  0.9945557  0.99007726 0.57421875 0.9910409  0.9965257\n",
      " 0.99637526 0.9370583  0.79368085 0.99472094 0.9984175  0.65751225\n",
      " 0.9981419  0.99494225 0.7149477  0.9977055  0.9986046  0.9985819\n",
      " 0.8279106  0.9999664  0.9777309  0.7260382  0.9984994  0.9968605\n",
      " 0.93285614 0.9958527 ]\n",
      "The rewards are: [0.99760604 0.7361125  0.9854313  0.7754496  0.9976361  0.9941778\n",
      " 0.9942411  0.9657985  0.94614226 0.99651873 0.57554924 0.98803526\n",
      " 0.6371911  0.750925   0.9413702  0.57441354 0.99539894 0.93093365\n",
      " 0.9994216  0.9400651  0.98589826 0.9903204  0.9126334  0.9983125\n",
      " 0.9984309  0.99996305 0.9998078  0.50606316 0.99820983 0.6023105\n",
      " 0.98864436 0.99873954]\n",
      "The rewards are: [0.9996574  0.9937529  0.9860183  0.99954695 0.9909407  0.8865325\n",
      " 0.9570547  0.99986935 0.99985135 0.9999529  0.9891376  0.99732757\n",
      " 0.99993944 0.9961302  0.9999548  0.9942233  0.9960128  0.64448583\n",
      " 0.9497825  0.99919075 0.9734972  0.9954822  0.98737013 0.97711265\n",
      " 0.98412365 0.9588313  0.9855478  0.9057764  0.91748136 0.86171067\n",
      " 0.64418113 0.7987786 ]\n",
      "The rewards are: [0.9997242  0.9388841  0.9997621  0.9999814  0.9921699  0.9920974\n",
      " 0.989997   0.9998951  0.9973053  0.8165338  0.99975485 0.67836\n",
      " 0.9995395  0.9993523 ]\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n",
      "The rewards are: []\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model using Q-learning REINFORCEMENT LEARNING Technique\n",
    "# NAME: Q_learning\n",
    "# PARAMETERS:Call the Q_learning function with the following parameters:\n",
    "#            X_train_vectors: Training input data (features)\n",
    "#            y_train: Training target labels\n",
    "#            model: The trained neural network model\n",
    "#            Adam(learning_rate): Adam optimizer with specified learning rate\n",
    "#            epochs: Number of training epochs\n",
    "#            batch_size: Batch size for training\n",
    "#            gamma: Discount factor for rewards\n",
    "# PURPOSE: This is used to call the function named Q_learning with the provided arguments as input parameters.The purpose of this line of code is to invoke the Q_learning function and pass in the required input parameters for it to train the model with the reinforcement technique . \n",
    "# PRECONDITION: X_train_vectors, y_train, model, epochs, batch_size, gamma, and learning_rate should be appropriately defined and initialized before this function call.\n",
    "# POSTCONDITION: The model's weights and biases being updated based on the policy gradient algorithm, the function is designed to update the model's parameters during training.\n",
    "\n",
    "q_learning(X_train_vectors, y_train, model, optimizer, epochs=1, batch_size=32, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5d7d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## NN_Policy Gradient ##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a9fd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Policy Gradient REINFORCEMENT LEARNING Technique for NN model\n",
    "# NAME: policy_gradient\n",
    "# PURPOSE: To implement the policy gradient algorithm for training a neural network model (model) using given input data (x) and target labels (y) with a specified optimizer (optimizer). The algorithm is trained for a given number of epochs (epochs) and batch size (batch_size), and uses a discount factor (gamma) for computing the model loss.\n",
    "#          The purpose of this code is to train a neural network model using the policy gradient algorithm, where the model's weights are updated based on the computed policy gradient and model loss, and the training process is performed in batches for efficiency.\n",
    "# INVARIANTS: Calculates the length of the input data (x) using getnnz() method.\n",
    "#             Iterates over each epoch.\n",
    "#             For each epoch, iterates over the input data (x) in batches of size batch_size.\n",
    "#             For each batch, computes the logits (raw output) of the model for the input data using model(x_batch).\n",
    "#             Computes the log probabilities of the logits using tf.math.log(tf.clip_by_value(logits, 1e-10, 1.0)).\n",
    "#             Creates one-hot encoded labels from the target labels (y_batch) using tf.one_hot() method.\n",
    "#             Computes the policy gradient loss by multiplying the log probabilities with the one-hot encoded labels and taking the negative mean using tf.reduce_mean(tf.reduce_sum(labels * log_probs, axis=1)).\n",
    "#             Computes the gradients of the policy gradient loss with respect to the model's trainable weights using tape.gradient().\n",
    "#             Applies the gradients to the optimizer using optimizer.apply_gradients() to update the model's weights.\n",
    "#             Computes the average reward for the current batch and uses it as a baseline.\n",
    "#             Computes the model loss by multiplying the policy gradient loss with the average reward and the discount factor (gamma).\n",
    "#             Computes the gradients of the model loss with respect to the model's trainable weights using tape.gradient().\n",
    "#             Applies the gradients to the optimizer using optimizer.apply_gradients() to update the model's weights.\n",
    "#             The purpose of this code is to train a neural network model using the policy gradient algorithm, where the model's weights are updated based on the computed policy gradient and model loss, and the training process is performed in batches for efficiency.\n",
    "\n",
    "import matplotlib.pyplot as plt #install the libraries to get the histogram\n",
    "import tensorflow as tf\n",
    "\n",
    "def policy_gradient(x, y, model, optimizer, epochs, batch_size, gamma): #class to define the policy_gradient RL technique\n",
    "    length = x.getnnz()  #Calculates the length of the input data (x) using getnnz() method.\n",
    "    for epoch in range(epochs): #Iterates over each epoch.\n",
    "        epoch_rewards = [] #empty lists that are likely intended to store the rewards for each epoch during the training of a neural network.\n",
    "        epoch_losses = [] #empty lists that are likely intended to store the losses for each epoch during the training of a neural network.\n",
    "        for batch_start in range(0, length, batch_size): #It is used to iterate over the input data (x) in batches of size batch_size during the training process. It starts from the beginning of the input data and increments in steps of batch_size until it reaches the end of the data.\n",
    "            batch_end = min(batch_start + batch_size, length) # It calculates the ending index (batch_end) of the current batch during the iteration over the input data (x) in batches. It ensures that the ending index does not exceed the total length of the data (length) to avoid accessing data beyond the available range. \n",
    "            x_batch = x[batch_start:batch_end].toarray() # Extracting a batch of data from the array 'x' using the start and end indices of the batch.toarray() converters the batch to an array, if it's in sparse format, for further processing\n",
    "            y_batch = y[batch_start:batch_end] #Extracting a batch of labels from the array 'y' using the start and end indices of the batch\n",
    "            with tf.GradientTape() as tape: #tf.GradientTape() is a TensorFlow API that provides a mechanism for automatic differentiation, which is a key technique used in machine learning optimization algorithms, such as gradient descent. It allows you to compute gradients of a computation with respect to its input variables, which can then be used to update the values of those variables during optimization.\"tape\" refers to a mechanism provided by TensorFlow that records operations for the purpose of computing gradients. The tape acts as a context within which computations are recorded, and these computations can later be used to compute gradients using the tape.gradient() method.\n",
    "                logits = model(x_batch) #Passing the batch of input data 'x_batch' through the model to obtain logits.Logits are the output of the model before applying any activation function, typically used for classification tasks Logits represent the raw, unnormalized scores for each class, which can be used for further processing or prediction.'model' is the trained model that takes 'x_batch' as input and produces logits as output\n",
    "                log_probs = tf.math.log(tf.clip_by_value(logits, 1e-10, 1.0)) # calculates the log probabilities by taking the natural logarithm (tf.math.log()) of the model's predicted logits (logits). The tf.clip_by_value() function is used to clip the logits to a specific range to avoid numerical instability. In this case, the minimum value is set to 1e-10 and the maximum value is set to 1.0. The resulting log probabilities are stored in the log_probs variable.\n",
    "                labels = tf.one_hot(y_batch, depth=output_dim) #Converting the batch of labels 'y_batch' into one-hot encoding using 'tf.one_hot' function One-hot encoding represents categorical labels as binary vectors with a single '1' and remaining '0's.'y_batch' is the input tensor containing the batch of labels to be converted to one-hot encoding.'output_dim' specifies the depth of the one-hot encoding, which should be equal to the number of classes in the classification task\n",
    "                loss = -tf.reduce_mean(tf.reduce_sum(labels * log_probs, axis=1)) #Compute the cross-entropy loss. labels: Ground truth labels. log_probs: Log probabilities predicted by the model\n",
    "                grads = tape.gradient(loss, model.trainable_weights) #grads typically refers to the computed gradients of the loss function with respect to the trainable weights of a machine learning model.The tape.gradient() function in TensorFlow is used to compute the gradients of a given function (in this case, the loss function) with respect to a list of variables (in this case, the model.trainable_weights). These gradients can then be used in an optimization algorithm, such as gradient descent, to update the model weights and improve the model's performance during training.Compute the gradients of the loss with respect to the trainable weights of the model.loss: The computed loss value.model.trainable_weights: List of trainable weights of the model\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights)) #It applies the computed gradients (grads) to update the model weights (model.trainable_weights) using an optimizer. The zip() function is used to create pairs of gradients and corresponding model weights, which are then passed to the apply_gradients() method of the optimizer to perform the weight update step. This step is a key part of the optimization process in training machine learning models, as it helps to adjust the model weights based on the gradients of the loss function, with the goal of minimizing the loss and improving the model's performance.\n",
    "            \n",
    "            avg_reward = np.mean((logits.numpy().argmax(axis=1) == y_batch).astype(int)) #calculates the average reward, which is computed as the mean accuracy of the model's predicted logits compared to the ground truth labels (y_batch). It mentions that logits represents the model's predicted logits, and y_batch represents the ground truth labels. The result of the comparison between the predicted logits and ground truth labels is cast to an integer array using astype(int), and then the mean is calculated using np.mean(). The calculated average reward is stored in the avg_reward variable.\n",
    "            rewards = avg_reward #Rewards for the model\n",
    "            print(\"The rewards are:\",rewards) #prints the rewards\n",
    "            epoch_rewards.append(rewards) #appends the rewards obtained by the network during the current epoch to the epoch_rewards list. This allows us to keep track of the rewards obtained by the network during each epoch of training.\n",
    "            model_loss = loss * rewards * gamma # calculates the model loss, which is obtained by multiplying the original loss (loss) with the rewards for the current step (rewards) and the discount factor (gamma). The loss variable represents the original loss value, while rewards represents the rewards obtained for the current step, and gamma is the discount factor used in the computation. The resulting model loss is stored in the model_loss variable.\n",
    "            print(\"The model loss is:\",model_loss) #prints the model loss\n",
    "            epoch_losses.append(model_loss.numpy()) # appends the loss obtained by the network during the current epoch to the epoch_losses list. This allows us to keep track of the loss obtained by the network during each epoch of training.The numpy() method is used to extract the numerical value of the TensorFlow loss object, which is a symbolic representation of the loss function used to train the network. This numerical value is then appended to the epoch_losses list.\n",
    "            #Now we computing the gradient using rewards and model loss\n",
    "            with tf.GradientTape() as tape: # #tf.GradientTape() is a TensorFlow API that provides a mechanism for automatic differentiation, which is a key technique used in machine learning optimization algorithms, such as gradient descent. It allows you to compute gradients of a computation with respect to its input variables, which can then be used to update the values of those variables during optimization.\"tape\" refers to a mechanism provided by TensorFlow that records operations for the purpose of computing gradients. The tape acts as a context within which computations are recorded, and these computations can later be used to compute gradients using the tape.gradient() method.\n",
    "                logits = model(x_batch) #Passing the batch of input data 'x_batch' through the model to obtain logits.Logits are the output of the model before applying any activation function, typically used for classification tasks Logits represent the raw, unnormalized scores for each class, which can be used for further processing or prediction.'model' is the trained model that takes 'x_batch' as input and produces logits as output\n",
    "                log_probs = tf.math.log(tf.clip_by_value(logits, 1e-10, 1.0)) # calculates the log probabilities by taking the natural logarithm (tf.math.log()) of the model's predicted logits (logits). The tf.clip_by_value() function is used to clip the logits to a specific range to avoid numerical instability. In this case, the minimum value is set to 1e-10 and the maximum value is set to 1.0. The resulting log probabilities are stored in the log_probs variable.\n",
    "                model_loss = tf.reduce_mean(tf.reduce_sum(labels * log_probs * model_loss, axis=1)) #calculates the model loss by taking the element-wise multiplication (*) of the ground truth labels (labels), the logarithm of the clipped logits representing the predicted probabilities (log_probs), and the model loss calculated as the product of the original loss, rewards, and gamma (model_loss). Then, the tf.reduce_sum() function is used to compute the sum along the appropriate axis, and the tf.reduce_mean() function is used to compute the mean of the resulting values. The final computed model loss is stored in the model_loss variable.\n",
    "                grads = tape.gradient(model_loss, model.trainable_weights) #calculates the gradients of the computed model loss (model_loss) with respect to the trainable weights of the model (model.trainable_weights). The tape.gradient() function is used to compute these gradients, and the resulting gradients are stored in the grads variable.\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights)) #It applies the computed gradients (grads) to update the model weights (model.trainable_weights) using an optimizer. The zip() function is used to create pairs of gradients and corresponding model weights, which are then passed to the apply_gradients() method of the optimizer to perform the weight update step. This step is a key part of the optimization process in training machine learning models, as it helps to adjust the model weights based on the gradients of the loss function, with the goal of minimizing the loss and improving the model's performance.\n",
    "            \n",
    "            \n",
    "           \n",
    "    # Plot reward histogram\n",
    "    plt.hist(epoch_rewards, bins=20) #creates a histogram plot of the distribution of the rewards obtained by the network during training, using 20 bins. This allows us to visualize how often the network obtained rewards in different ranges, which can provide insight into its overall performance.\n",
    "    plt.title(\"Reward Histogram Policy Gradient NN\") #sets the title of the plot to \"Reward Histogram Policy Gradient NN\", which describes the type of algorithm used and the type of data being plotted.\n",
    "    plt.xlabel(\"Reward\") #sets the x-axis label to \"Reward\", which describes the meaning of the values being plotted on the x-axis.\n",
    "    plt.ylabel(\"Frequency\") #sets the y-axis label to \"Frequency\", which describes the number of occurrences of rewards in each bin.\n",
    "    plt.show() #displays the plot on the screen. This allows us to see the distribution of the rewards obtained by the network during training and gain insights into its performance.\n",
    "    \n",
    "        \n",
    "    # Plot loss histogram\n",
    "    plt.hist(epoch_losses, bins=20) # creates a histogram plot of the distribution of the losses obtained by the network during training, using 20 bins. This allows us to visualize how often the network had a certain level of loss during the training process, which can provide insights into how well the network is learning and improving over time.\n",
    "    plt.title(\"Loss Histogram Policy Gradient NN\") # sets the title of the plot to \"Loss Histogram Policy Gradient NN\", which describes the type of algorithm used and the type of data being plotted.\n",
    "    plt.xlabel(\"Loss\") # sets the x-axis label to \"Loss\", which describes the meaning of the values being plotted on the x-axis.\n",
    "    plt.ylabel(\"Frequency\") #sets the y-axis label to \"Frequency\", which describes the number of occurrences of losses in each bin.\n",
    "    plt.show() # displays the plot on the screen. This allows us to see the distribution of the losses obtained by the network during training and gain insights into its performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be91c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters and Neural network model \n",
    "learning_rate = 0.001\n",
    "epochs=1\n",
    "batch_size = 32\n",
    "gamma = 0.99 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba0e321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the NN model and define the optimizer\n",
    "# Name: Neural Network model\n",
    "# Purpose: to define and create a neural network or classification model for a given dataset.\n",
    "# Invariants: The Input function defines the input layer of the neural network with shape=(input_dim,), where input_dim is the number of features in the training data.        \n",
    "#             Two Dense functions are used to define the hidden layers of the neural network. The first hidden layer has 64 neurons and relu activation function, while the second hidden layer has output_dim neurons and softmax activation function. The output_dim variable represents the number of unique target labels in the training data.\n",
    "#             The Model function is used to create an instance of the neural network or classification model with inputs=inputs and outputs=x. The model takes the input layer and hidden layers as input and outputs the predicted target labels.\n",
    "#             Finally, the Adam optimizer with a learning rate of 0.001 is set to update the weights of the neural network or classification model during training.\n",
    "\n",
    "\n",
    "inputs = Input(shape=(input_dim,)) #defines an input layer for the neural network or classification model with the specified number of features or input dimensions.The Input function takes shape=(input_dim,) as an argument, where input_dim is an integer representing the number of features in the training data. The shape parameter is a tuple that specifies the input shape of the layer.This line of code is important as it initializes the neural network or classification model and sets the input shape for the subsequent layers.\n",
    "x = Dense(32, activation='relu')(inputs) #defines a hidden layer in the neural network or classification model.The Dense function creates a fully connected layer with 64 neurons and relu activation function. The activation parameter specifies the activation function used to introduce non-linearity into the model.The (inputs) at the end of the line specifies that the input to this layer is the inputs layer that was previously defined.This line of code is important because it adds a layer of computation to the neural network or classification model, which helps it learn complex representations of the input data. The relu activation function is commonly used in deep learning models and helps in speeding up the training process by preventing vanishing gradients.\n",
    "x = Dense(output_dim, activation='softmax')(x) #defines the output layer of the neural network or classification model.The Dense function creates a fully connected layer with output_dim neurons and softmax activation function. The output_dim parameter specifies the number of unique target labels in the training data. The softmax activation function converts the output of the layer into a probability distribution over the target labels, where the highest probability is assigned to the predicted target label.The (x) at the end of the line specifies that the input to this layer is the output of the previous hidden layer x.This line of code is important because it is the final layer of the neural network or classification model, which produces the predicted target labels. The softmax activation function is commonly used for multi-class classification problems and ensures that the predicted probabilities sum up to 1.0 over all target labels.\n",
    "model1 = Model(inputs=inputs, outputs=x) #creates an instance of the neural network or classification model with the specified input and output layers.The Model function takes inputs=inputs and outputs=x as arguments. The inputs parameter specifies the input layer of the model, which was previously defined using the Input function. The outputs parameter specifies the output layer of the model, which was defined using the Dense function.This line of code is important because it connects the input and output layers to create a neural network or classification model. The model is an instance of the Model class from Keras, which provides high-level APIs for building and training deep learning models. The model can be trained using various optimization algorithms and loss functions to minimize the difference between the predicted and actual target labels.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) ##creates an instance of the Adam optimization algorithm for the neural network or classification model.The optimizers.Adam function is a popular optimization algorithm used for training deep neural networks. The learning_rate parameter specifies the step size or the size of the update made to the model weights during each iteration of the optimization algorithm.This line of code is important because it initializes the optimizer used to update the weights of the neural network or classification model during training. The choice of optimizer can significantly affect the performance of the model, and Adam is a popular choice due to its fast convergence and adaptive learning rate.\n",
    "#optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001) #RMSprop optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # is an important line of code in the process of building a deep learning model using Keras. It compiles the model by specifying the loss function, optimizer, and metrics to be used during training.In particular, the loss parameter specifies the loss function that the model will use to evaluate its performance on the training data. In this case, the 'categorical_crossentropy' loss function is used, which is commonly used for multiclass classification problems.The optimizer parameter specifies the optimization algorithm that will be used to adjust the weights of the model during training in order to minimize the loss function. Here, the optimizer variable is passed in, which should be an instance of a pre-defined optimizer class from Keras, such as Adam or RMSprop.Finally, the metrics parameter specifies the evaluation metrics that will be used to monitor the model's performance during training and testing. In this case, 'accuracy' is the metric used, which is commonly used for classification problems.Overall, model.compile is a crucial step in the process of building and training a deep learning model, as it sets up the model for optimization by specifying the necessary components for the training process.\n",
    "#model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy']) #loss:mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a0c56d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rewards are: 0.4375\n",
      "The model loss is: tf.Tensor(0.3004646, shape=(), dtype=float32)\n",
      "The rewards are: 0.625\n",
      "The model loss is: tf.Tensor(0.42812663, shape=(), dtype=float32)\n",
      "The rewards are: 0.53125\n",
      "The model loss is: tf.Tensor(0.3646797, shape=(), dtype=float32)\n",
      "The rewards are: 0.59375\n",
      "The model loss is: tf.Tensor(0.40690893, shape=(), dtype=float32)\n",
      "The rewards are: 0.5625\n",
      "The model loss is: tf.Tensor(0.3855689, shape=(), dtype=float32)\n",
      "The rewards are: 0.5625\n",
      "The model loss is: tf.Tensor(0.3862847, shape=(), dtype=float32)\n",
      "The rewards are: 0.5625\n",
      "The model loss is: tf.Tensor(0.38539934, shape=(), dtype=float32)\n",
      "The rewards are: 0.65625\n",
      "The model loss is: tf.Tensor(0.44908553, shape=(), dtype=float32)\n",
      "The rewards are: 0.5\n",
      "The model loss is: tf.Tensor(0.34267107, shape=(), dtype=float32)\n",
      "The rewards are: 0.6875\n",
      "The model loss is: tf.Tensor(0.47014302, shape=(), dtype=float32)\n",
      "The rewards are: 0.65625\n",
      "The model loss is: tf.Tensor(0.4487378, shape=(), dtype=float32)\n",
      "The rewards are: 0.59375\n",
      "The model loss is: tf.Tensor(0.40654165, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.5335196, shape=(), dtype=float32)\n",
      "The rewards are: 0.65625\n",
      "The model loss is: tf.Tensor(0.44829398, shape=(), dtype=float32)\n",
      "The rewards are: 0.625\n",
      "The model loss is: tf.Tensor(0.4274848, shape=(), dtype=float32)\n",
      "The rewards are: 0.71875\n",
      "The model loss is: tf.Tensor(0.4901934, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.57334626, shape=(), dtype=float32)\n",
      "The rewards are: 0.65625\n",
      "The model loss is: tf.Tensor(0.44785884, shape=(), dtype=float32)\n",
      "The rewards are: 0.65625\n",
      "The model loss is: tf.Tensor(0.44841188, shape=(), dtype=float32)\n",
      "The rewards are: 0.6875\n",
      "The model loss is: tf.Tensor(0.46815914, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.5322028, shape=(), dtype=float32)\n",
      "The rewards are: 0.6875\n",
      "The model loss is: tf.Tensor(0.46872646, shape=(), dtype=float32)\n",
      "The rewards are: 0.6875\n",
      "The model loss is: tf.Tensor(0.4678607, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.53040606, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.52968055, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.52923024, shape=(), dtype=float32)\n",
      "The rewards are: 0.65625\n",
      "The model loss is: tf.Tensor(0.44625705, shape=(), dtype=float32)\n",
      "The rewards are: 0.71875\n",
      "The model loss is: tf.Tensor(0.48870614, shape=(), dtype=float32)\n",
      "The rewards are: 0.53125\n",
      "The model loss is: tf.Tensor(0.36128446, shape=(), dtype=float32)\n",
      "The rewards are: 0.71875\n",
      "The model loss is: tf.Tensor(0.48732078, shape=(), dtype=float32)\n",
      "The rewards are: 0.53125\n",
      "The model loss is: tf.Tensor(0.3623782, shape=(), dtype=float32)\n",
      "The rewards are: 0.75\n",
      "The model loss is: tf.Tensor(0.50763726, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.52639097, shape=(), dtype=float32)\n",
      "The rewards are: 0.5625\n",
      "The model loss is: tf.Tensor(0.38155887, shape=(), dtype=float32)\n",
      "The rewards are: 0.6875\n",
      "The model loss is: tf.Tensor(0.46328443, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.5234502, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.5441823, shape=(), dtype=float32)\n",
      "The rewards are: 0.6875\n",
      "The model loss is: tf.Tensor(0.46147898, shape=(), dtype=float32)\n",
      "The rewards are: 0.71875\n",
      "The model loss is: tf.Tensor(0.4840285, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.5185733, shape=(), dtype=float32)\n",
      "The rewards are: 0.59375\n",
      "The model loss is: tf.Tensor(0.40087742, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.56503856, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5823162, shape=(), dtype=float32)\n",
      "The rewards are: 0.75\n",
      "The model loss is: tf.Tensor(0.50142324, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5831631, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5748419, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.53748053, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.5372744, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.57838506, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.51927435, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.57457125, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.553336, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.6144732, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5758161, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.53602123, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.5915855, shape=(), dtype=float32)\n",
      "The rewards are: 0.625\n",
      "The model loss is: tf.Tensor(0.4183368, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.5113998, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.5261544, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.59182644, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.6426311, shape=(), dtype=float32)\n",
      "The rewards are: 0.75\n",
      "The model loss is: tf.Tensor(0.49410433, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.50989836, shape=(), dtype=float32)\n",
      "The rewards are: 0.6875\n",
      "The model loss is: tf.Tensor(0.45518702, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.52329683, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.5806136, shape=(), dtype=float32)\n",
      "The rewards are: 0.75\n",
      "The model loss is: tf.Tensor(0.49004793, shape=(), dtype=float32)\n",
      "The rewards are: 0.71875\n",
      "The model loss is: tf.Tensor(0.46997032, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.5463712, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.6091013, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.5378606, shape=(), dtype=float32)\n",
      "The rewards are: 0.75\n",
      "The model loss is: tf.Tensor(0.49520004, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.5282497, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.5883917, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.62632555, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.53587407, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.5452482, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.5718792, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.5721654, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.59360075, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.50175095, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.561779, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5568517, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.57908034, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.55040526, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.56347376, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.5581732, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.55216956, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.58542675, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.5849408, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.57168424, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.58903056, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.51687, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.5522745, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.53238606, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5358732, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.56680167, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.52466947, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5377746, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.53936535, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.5463651, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.54496855, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.52928007, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5347887, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.5063128, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.56999874, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.5795281, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.5688997, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.5068716, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.51005226, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.5174582, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.5533173, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.5078671, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.55824965, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.56368357, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5252778, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.52641165, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.5617192, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.55484635, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.49759302, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.4956936, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.5115806, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.5206927, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.5492952, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.54580784, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5235293, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.51431704, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.4928146, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.5314182, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.52896416, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.5041849, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.5041683, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.4978774, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.56496054, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.5193122, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.47216862, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.49793398, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.51845443, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.49575037, shape=(), dtype=float32)\n",
      "The rewards are: 0.71875\n",
      "The model loss is: tf.Tensor(0.41268113, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.48995623, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.4943961, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.51450855, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.48883477, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.49139816, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.50008774, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.47472873, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.5046769, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.47800314, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.4655906, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.49437237, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.50128764, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.48335657, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.46494907, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.45466167, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.49142367, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.49176905, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.5085593, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.49910694, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.48932573, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.49342653, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.4825917, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.46551228, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.50222665, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.52943283, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.4504236, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.46358195, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.46638852, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.4625645, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.46733838, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.4398434, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.47739255, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.46754703, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.45711708, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.47998205, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.46244532, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.43496665, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.47390088, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.4536808, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.44038507, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.4289509, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.41651136, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.42920187, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.46028417, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.4477449, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.45317584, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.49102464, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.41862312, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.41166586, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.4478151, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.484074, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.46414405, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.43533054, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.40430877, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.42596444, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.44780645, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.4536046, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.4164517, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.45594302, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.4259225, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.42369342, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.4072823, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.38628337, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.4147015, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.4539195, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.44276735, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.39529702, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.4090803, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.42199963, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.41188276, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.4062244, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.40292218, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.4173383, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.42335278, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.4120312, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.44276506, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.4202827, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.42166224, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.38914067, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.33646262, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.35988766, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.39804235, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.35362872, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.39960197, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.37848383, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.37160376, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.37661332, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.38271135, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.38601035, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.34657213, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.34422997, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.4011638, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.33709738, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.33883524, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.39847484, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.35655123, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.35379556, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.34483552, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.34694743, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.36751044, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.35943317, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.34860834, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.37522206, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.33461007, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.37667793, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.3509774, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.33986142, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.3693792, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.4048871, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.3397045, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.3343342, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.3365571, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.34422866, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.41159806, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.30875897, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.31253445, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.32801646, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.33841276, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.34668857, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.32411474, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.3741168, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.3360556, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.37217304, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.36964795, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.34279126, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.2972312, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.3481849, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.3527329, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.3017661, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.2967821, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.291292, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.3398973, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.2917926, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.28530356, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.306837, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.30286396, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.35710824, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.3252038, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2673354, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.283743, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.31466255, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.31771496, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.26749542, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.30940762, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.30137143, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.28194514, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.36179957, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.35648388, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.25530502, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.2702825, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.28022403, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.2901879, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.2879599, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.33188635, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.26680616, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.23738968, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.3073315, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.32133394, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.2632945, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2671131, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.2717409, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.28366414, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.3170909, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.21209551, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.3016666, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.27948156, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.3028506, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.2619501, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.28913087, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.33918324, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.30132094, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.31242606, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.2264301, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.28665832, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.2530913, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.2590549, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.2952846, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.26765615, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.27629516, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.24651544, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.2722615, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.25725424, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.26598263, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.2786589, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.30965933, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.22192791, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.27908275, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.32429215, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.27654865, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.2217721, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.23013799, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.25041497, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.25928044, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.2715521, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.2309521, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.23612683, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.28633448, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.24693039, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.22632787, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.22083208, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.24844514, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.2025535, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.23114643, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.22292662, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.22956282, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.32051054, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.28090325, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.23283756, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.238884, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.24511926, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.25431997, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.26835787, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.2108809, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.1851068, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.26018542, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.263586, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.23757404, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.19550863, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.2199101, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.17814219, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19336139, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1591245, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.27030107, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.16104366, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.19208845, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.2057817, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.20905933, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.22110493, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.19603066, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2394586, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.24252664, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.24554989, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19464093, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19445877, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.18582854, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.22201215, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.18966684, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.18454671, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.2908416, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.23531282, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.25386778, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.29290277, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.29032597, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.28735942, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.22850366, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.19457883, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.16492398, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.23371056, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2512628, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16247828, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.22706348, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.20105663, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1662665, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.27135348, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.3476766, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.18452257, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.18778025, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.21382679, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.20630156, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.26475167, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.20166093, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.21384254, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.17243291, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.14657639, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.17910741, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.171255, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.16391958, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.12600835, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.26880905, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19656755, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.20947702, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.23544614, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.2324147, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.24140833, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.18587373, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.24090403, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.1860437, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.24839342, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.19299625, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.20229048, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15538453, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.21548143, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11919297, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.18839371, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.21058095, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.23677455, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.28152516, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15989979, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.18836981, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.22626515, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.2400857, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.21632029, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13587102, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16942513, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1475976, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15876628, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14491752, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.22416621, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.14804573, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2393433, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.14524837, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.17894329, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.095192246, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15591045, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.18699476, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1347084, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.110721864, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.24160537, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.20965667, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12947744, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.18631071, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.42354086, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.2535098, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.18030886, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15292959, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.1398641, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.26850328, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2043013, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.124812715, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.31866753, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.16695474, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19593415, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.21866912, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.13733695, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.28765348, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.22182949, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13243742, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14796433, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.168107, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2147954, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.17012256, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.10286198, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.17480701, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.16020693, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.14409485, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2094706, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16737005, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.23816532, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.19866908, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.2675748, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13286597, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.20750013, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1783164, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.17642014, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.19988649, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07937177, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.14941464, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13125381, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15248604, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.25294504, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.17614298, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08306503, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16261797, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08452464, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.18996906, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1941844, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.16924313, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16741297, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16194305, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.13191532, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.12423405, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.22806811, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.19682962, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.22333212, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19320662, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.24062859, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.25640747, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08585416, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19824483, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.150019, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.13298273, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.16866243, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1787735, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.10034421, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08996786, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11011764, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.24019821, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.40015292, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16806273, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14953111, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.14420706, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.182432, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15919802, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.21611272, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.20362222, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1968368, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1585462, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.094686545, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.20272063, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.17589755, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.16192372, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.117995344, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15732221, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15272292, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08505252, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.18349513, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13503663, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.26358226, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1826956, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1778792, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15528142, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.2580306, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13606642, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.2042624, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.16628695, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15373324, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.19321273, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.2021515, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13704975, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.22143528, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2323922, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15835777, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16722126, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.18524306, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.10643822, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.29395625, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.14741299, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.113723114, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.10928613, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.23250604, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.17855592, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.086420044, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.10708179, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12747633, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1353195, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.17874646, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13002926, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13119318, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16400693, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16055134, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.09116157, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13579902, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.056000136, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11174407, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.2237889, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12532152, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1669015, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.099394955, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12677608, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13335536, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.16847225, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07282701, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11513019, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13792102, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16747047, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.21865816, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.09591332, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.19554457, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1840815, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.17415805, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.12761274, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15655152, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14131165, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1555005, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08729707, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15892765, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09286801, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.18748155, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.0839894, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.11371603, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.12612261, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1326368, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.23677947, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.086754076, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11503394, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15840371, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.19408615, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.23147304, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.23990491, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.17864315, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.100426875, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10304635, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13690229, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.072826646, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11573246, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1845636, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.19653638, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.10509125, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.28818586, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.20846033, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1558162, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.24476996, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10934185, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10922861, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.18760867, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.11405067, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1779034, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12535052, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.116673455, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13587128, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14035268, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.14188561, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.24603379, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.18114488, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13904089, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2087219, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15046103, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1074881, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.109440304, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.19430389, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10683927, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.17509398, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.09731955, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13442653, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.043069217, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1850235, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.16307496, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.219939, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.19706851, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.22507243, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.069705114, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1833649, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13433407, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11215506, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.090610035, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13500507, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15569282, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13274074, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1767578, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15582702, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1866702, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.13443346, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11075775, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16865796, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09383383, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1175077, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.12759638, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11186192, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.15802339, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.14000694, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.12747104, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.18380855, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15217942, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.20447643, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10195627, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09861919, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.11173706, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13401337, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.28987563, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.18924187, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14067869, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.061959352, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12569898, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.09576924, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16341491, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11428906, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.20139453, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16518345, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12873228, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07800615, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.16597573, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09054891, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.25111642, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11852884, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1037027, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15203041, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.28385833, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.121466115, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16530605, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.063814364, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07903119, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.18281317, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08770836, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.14985225, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15379511, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.2349942, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.06841663, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.17454953, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07671922, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.18277816, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1778561, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08396318, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13013884, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.043249283, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07248171, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13025802, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2836413, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12409585, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.0969083, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.03610806, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15644576, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07688069, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.106210135, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.06335796, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.054047752, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.105628416, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.1426566, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10381132, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09174104, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.26542222, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1160824, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.14867018, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08266979, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.03990741, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.13760626, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.24635787, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07241667, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.04912131, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1445444, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.077185825, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13795172, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.058284815, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.18043323, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.24694814, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.16584766, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11774263, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07973786, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09521588, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15618536, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.2458547, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11617313, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.11045091, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16181739, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.087607354, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.20967133, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08066436, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.16728185, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14565982, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.17685474, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.21014714, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09878774, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14299451, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12756649, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.12591504, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08722711, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15503834, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.22165973, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13002115, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10810691, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.24017152, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10541027, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11393414, shape=(), dtype=float32)\n",
      "The rewards are: 0.8125\n",
      "The model loss is: tf.Tensor(0.23989964, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.22459178, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1913089, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.18136057, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08051313, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07542597, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.121495984, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07259519, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.064807355, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16503735, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1302174, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.24705058, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11587738, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13133705, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.103582874, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.109284416, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13635945, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.093893535, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.063449785, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08902831, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08224617, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19971763, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12042763, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.060836922, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10865575, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08850736, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10454006, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08385969, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.135707, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19139776, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11286217, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12920627, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10043911, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.111265615, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13888223, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07566894, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09573928, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10133879, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.053464577, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13765974, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.17145947, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.119933635, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.13242905, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.022889614, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.083824374, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1183024, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.18389778, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.17310205, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.30355877, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15220292, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14932828, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.24943356, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.05664973, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07288506, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12197049, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07260321, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.17378087, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.17771003, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12798025, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11137882, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.059990793, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.09469572, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.09935883, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.17905335, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1364801, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1753555, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.20602685, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.18442504, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.23954862, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12118995, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.073748484, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15771182, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12288914, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.25449926, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.20618019, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13021997, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.0921027, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.037797485, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.17159654, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1351931, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15289803, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.06842378, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.06824351, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.053651046, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12759124, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.303807, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.061421413, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.23998468, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1252295, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07669482, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.17409675, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13101526, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09581611, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.24062276, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.058747362, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.1291968, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15580036, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.19582243, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12991899, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1079524, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15016204, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07183704, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11562678, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.22207338, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15819557, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12039121, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.18318294, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.073451586, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.14746517, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.2159386, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.06121723, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.12132807, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11326302, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.24820754, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.0694086, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16712587, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08856041, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07648553, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.18837324, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.0976442, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10538868, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.068545245, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.20271327, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08214433, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12984598, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09365868, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.14472501, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.073739804, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13012715, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.050795965, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.0502539, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.10966168, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.09295386, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.08272807, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.17512542, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.06617191, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15559255, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.06473289, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.18302244, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.17605662, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.21666181, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.0883345, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.040697064, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.17090562, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.23792918, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15673961, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.17019819, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12765093, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13076004, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12662855, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1901976, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.17805341, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.088039614, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.037745576, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.31845337, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.06321307, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.026240408, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08220835, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12793075, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.05164275, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15898454, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1228146, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.25318548, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08447631, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13606481, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08508718, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.06601198, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12281507, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.22711074, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.16529359, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12524043, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09947932, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.05516627, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.13623516, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13787925, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1570328, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.21926683, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.046184488, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09922277, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09998163, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.24047388, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.24322036, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.077337846, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.0604265, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.047748417, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08170109, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10265722, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12829685, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.06725916, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.15108117, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.041777954, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.26725942, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12066267, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1357588, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.068789184, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.06698524, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.06556204, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.113875985, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.23481922, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.08356322, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13502857, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.0901727, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09427586, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.055511102, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.05125232, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.122260414, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12241852, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.14434797, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07771287, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.15735555, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09216746, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07993433, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13105129, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.17399956, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.088951044, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.0707057, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.082797684, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08108982, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.066989064, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13381366, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1765412, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.06505975, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15062149, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.20015565, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.10788818, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.21535344, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16161686, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.15399826, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.065378405, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.031201128, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.047637902, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14799488, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.25107995, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.19080785, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.050468206, shape=(), dtype=float32)\n",
      "The rewards are: 0.84375\n",
      "The model loss is: tf.Tensor(0.22778928, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10045371, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.027992347, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07621499, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07306696, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16964518, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.06483288, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.16201964, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.078722216, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12964939, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.20842533, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08536501, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.18356726, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.17894918, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.06500682, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07993942, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13991132, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.30307508, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.23380442, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.05987179, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15611641, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15629102, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.18977459, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07207267, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10534649, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.122066446, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.039369963, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.02010001, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.28594038, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.14445332, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13535875, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.0942535, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13650693, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11753545, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.046589117, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.05397496, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11344984, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11924075, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12728056, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19348861, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.23434196, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15460184, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.11773559, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.25634503, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.100160696, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.10899785, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11871498, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.092898786, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.04326064, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.092548184, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.18901038, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1070919, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.17477702, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.0828223, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.17652325, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07705393, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.12976046, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.09119855, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.079421766, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.0667592, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.14575621, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.18359128, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.1139089, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.13414572, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.060726255, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15294434, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.12492445, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.04537411, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11051774, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.16501114, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.17002742, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.11372176, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.092766434, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.04505131, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.10202455, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.15028502, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.08312558, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.090315565, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.12134245, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.19118223, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.13794628, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.048714086, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.21121553, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.10916555, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.062452607, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.23897302, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.19537264, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.07735699, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.18318859, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.06222718, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.13047257, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.1437099, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.05926591, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.103750125, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.23965955, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.05566566, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.22274442, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.061374296, shape=(), dtype=float32)\n",
      "The rewards are: 0.78125\n",
      "The model loss is: tf.Tensor(0.26082852, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.08623784, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.039959226, shape=(), dtype=float32)\n",
      "The rewards are: 0.875\n",
      "The model loss is: tf.Tensor(0.25676054, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.124242194, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.1644705, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.11876643, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.114120945, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.13108604, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.0780683, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.057445087, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.062362235, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.24450107, shape=(), dtype=float32)\n",
      "The rewards are: 0.96875\n",
      "The model loss is: tf.Tensor(0.14813405, shape=(), dtype=float32)\n",
      "The rewards are: 0.90625\n",
      "The model loss is: tf.Tensor(0.12303994, shape=(), dtype=float32)\n",
      "The rewards are: 0.9375\n",
      "The model loss is: tf.Tensor(0.16391209, shape=(), dtype=float32)\n",
      "The rewards are: 1.0\n",
      "The model loss is: tf.Tensor(0.07169765, shape=(), dtype=float32)\n",
      "The rewards are: 0.9285714285714286\n",
      "The model loss is: tf.Tensor(0.14425375, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "The rewards are: nan\n",
      "The model loss is: tf.Tensor(nan, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model using policy_gradient REINFORCEMENT LEARNING Technique\n",
    "# NAME: policy_gradient\n",
    "# PARAMETERS:Call the policy_gradient function with the following parameters:\n",
    "#            X_train_vectors: Training input data (features)\n",
    "#            y_train: Training target labels\n",
    "#            model: The trained neural network model\n",
    "#            Adam(learning_rate): Adam optimizer with specified learning rate\n",
    "#            epochs: Number of training epochs\n",
    "#            batch_size: Batch size for training\n",
    "#            gamma: Discount factor for rewards\n",
    "# PURPOSE: This is used to call the function named policy_gradient with the provided arguments as input parameters.The purpose of this line of code is to invoke the policy_gradient function and pass in the required input parameters for it to train the model with the reinforcement technique . \n",
    "# PRECONDITION: X_train_vectors, y_train, model1, epochs, batch_size, gamma, and learning_rate should be appropriately defined and initialized before this function call.\n",
    "# POSTCONDITION: The model's weights and biases being updated based on the policy gradient algorithm, the function is designed to update the model's parameters during training.\n",
    "\n",
    "policy_gradient(X_train_vectors, y_train, model1, Adam(learning_rate), epochs, batch_size, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e481590",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# Evaluation of the NN model #######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "126915f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_q = model(X_test_vectors.toarray()) #logits is a tensor of shape (m, k), where m is the number of test examples and k is the number of classes. It is obtained by passing the test feature matrix X_test_vectors (which is in sparse format and converted to a dense numpy array using toarray()) through the neural network model model\n",
    "predictions_q = np.argmax(logits_q.numpy(), axis=1) #predictions is a numpy array of shape (m,) that contains the predicted class labels for the test examples. It is obtained by taking the argmax of the logits tensor along the second axis (i.e., the axis corresponding to the classes). This returns the index of the class with the highest probability for each test example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58c1344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_pg = model1(X_test_vectors.toarray()) #logits is a tensor of shape (m, k), where m is the number of test examples and k is the number of classes. It is obtained by passing the test feature matrix X_test_vectors (which is in sparse format and converted to a dense numpy array using toarray()) through the neural network model model\n",
    "predictions_pg = np.argmax(logits_pg.numpy(), axis=1) #predictions is a numpy array of shape (m,) that contains the predicted class labels for the test examples. It is obtained by taking the argmax of the logits tensor along the second axis (i.e., the axis corresponding to the classes). This returns the index of the class with the highest probability for each test example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2947a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Q-Learning is of NN model : 0.9527839643652561\n"
     ]
    }
   ],
   "source": [
    "# accuracy for the Q-Learning model after Reinforcement algorithm training\n",
    "accuracy_q = np.mean(predictions_q == y_test)  # Assuming y_test is a numpy array of ground truth labels\n",
    "print(\"Accuracy of Q-Learning is of NN model :\", accuracy_q) #calculates and reports various performance metrics of the model on the test set, such as accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "032d1ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Policy gradient of NN model is : 0.9513363028953229\n"
     ]
    }
   ],
   "source": [
    "# accuracy for the Policy Gradient model after Reinforcement algorithm training\n",
    "accuracy_pg = np.mean(predictions_pg == y_test)  # Assuming y_test is a numpy array of ground truth labels\n",
    "print(\"Accuracy of Policy gradient of NN model is :\", accuracy_pg) #calculates and reports various performance metrics of the model on the test set, such as accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfc29e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Q-learning of NN model is: 0.9494636471990465\n"
     ]
    }
   ],
   "source": [
    "# f1 score for the Q-Learning model after Reinforcement algorithm training\n",
    "from sklearn.metrics import f1_score # imports the f1_score function from the sklearn.metrics module.\n",
    "score_q = f1_score(y_test,predictions_q) #calculates the F1 score of the predicted labels predictions compared to the true labels y_test, using the f1_score function. The resulting score is assigned to the variable score\n",
    "print(\"F1-score of Q-learning of NN model is:\",score_q) # prints the F1 score, which was calculated in the previous line, along with the label \"F1-score:\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd3f90d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Policy gradient of NN model is: 0.948056579103768\n"
     ]
    }
   ],
   "source": [
    "# f1 score for the Policy gradient model after Reinforcement algorithm training\n",
    "from sklearn.metrics import f1_score # imports the f1_score function from the sklearn.metrics module.\n",
    "score_pg = f1_score(y_test,predictions_pg) #calculates the F1 score of the predicted labels predictions compared to the true labels y_test, using the f1_score function. The resulting score is assigned to the variable score\n",
    "print(\"F1-score of Policy gradient of NN model is:\",score_pg) # prints the F1 score, which was calculated in the previous line, along with the label \"F1-score:\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a233f5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report of Q-Learning of NN model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      4773\n",
      "           1       0.95      0.95      0.95      4207\n",
      "\n",
      "    accuracy                           0.95      8980\n",
      "   macro avg       0.95      0.95      0.95      8980\n",
      "weighted avg       0.95      0.95      0.95      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for Q-Learning model after Reinforcement algorithm training\n",
    "from sklearn.metrics import classification_report #imports the classification_report function from the sklearn.metrics module, which can be used to generate a report on the classification performance of a model.\n",
    "print(\"classification report of Q-Learning of NN model:\") #prints the classififcation report\n",
    "print(classification_report(y_test,predictions_q)) #generates a classification report based on the predicted labels predictions and the true labels y_test, using the classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e8505ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Q-Learning of NN model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix # imports the confusion_matrix function from scikit-learn \n",
    "import seaborn as sns #seaborn library for creating visualizations.\n",
    "print(\"Confusion Matrix of Q-Learning of NN model:\") #prints a message to indicate the type of confusion matrix being displayed.\n",
    "cm = confusion_matrix(y_test, predictions_q) #Calculates the confusion matrix for the Q-Learning model predictions on the test set.\n",
    "sns.heatmap(cm, annot=True, cmap='Blues') #creates a heatmap using seaborn to visualize the confusion matrix, with annotations and a blue color map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "912cf3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report of Policy gradient of NN model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      4773\n",
      "           1       0.95      0.95      0.95      4207\n",
      "\n",
      "    accuracy                           0.95      8980\n",
      "   macro avg       0.95      0.95      0.95      8980\n",
      "weighted avg       0.95      0.95      0.95      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for Policy gradient model after Reinforcement algorithm training\n",
    "from sklearn.metrics import classification_report #imports the classification_report function from the sklearn.metrics module, which can be used to generate a report on the classification performance of a model.\n",
    "print(\"classification report of Policy gradient of NN model:\") #prints the classififcation report\n",
    "print(classification_report(y_test,predictions_pg)) #generates a classification report based on the predicted labels predictions and the true labels y_test, using the classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "534db612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Policy gradient of NN model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix #imports the confusion_matrix function from the scikit-learn library,\n",
    "import seaborn as sns #import seaborn package\n",
    "print(\"Confusion Matrix of Policy gradient of NN model:\") #prints Confusion Matrix of Policy gradient of NN model:\n",
    "cm = confusion_matrix(y_test, predictions_pg) #computes a confusion matrix to evaluate the performance of a classification model by comparing the true labels with the predicted labels.\n",
    "sns.heatmap(cm, annot=True, cmap='Blues') # creates a heatmap visualization of the confusion matrix using the seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c8b3e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #importing matplotlib\n",
    "\n",
    "# Example accuracy scores\n",
    "accuracy_scores = [accuracy_q, accuracy_pg] #creates a list called accuracy_scores that contains the accuracy scores of two classification models based on Q-learning and policy gradient, respectively.\n",
    "\n",
    "# Model names\n",
    "model_names = ['Q-Learning', 'Policy Gradient'] #creates a list called model_names that contains the names of the two classification models used to generate accuracy_scores.\n",
    "colors = ['green', 'red'] # list of colors for each bar\n",
    "\n",
    "# Set up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 6)) #creates a figure with a single subplot (axes) and sets the size of the figure to 8 inches (width) by 6 inches (height).\n",
    "# Add the bars to the plot\n",
    "for i in range(len(model_names)): #Loop over the model_names list.\n",
    "    ax.bar(model_names[i], accuracy_scores[i], color=colors[i]) #Create a bar chart with a bar for each model name, height based on the corresponding accuracy score, and color specified by colors.\n",
    "\n",
    "    # Add the accuracy score as text to the bar\n",
    "    ax.text(model_names[i], accuracy_scores[i] + 0.01, round(accuracy_scores[i], 5), ha='center') #Add text labels to each bar with the corresponding accuracy score rounded to 5 decimal places.\n",
    "\n",
    "# Add labels and titles\n",
    "ax.set_xlabel('Model') #set the x-axis label to \"Model\"\n",
    "ax.set_ylabel('Accuracy Score') #set the y-axis label to \"Model\"\n",
    "ax.set_title('Comparison of Model Accuracy Scores Bet Q-Learning and Policy Gradient of NN model') #title to \"Comparison of Model Accuracy Scores Bet Q-Learning and Policy Gradient of NN model\", respectively, for the bar chart.\n",
    "\n",
    "# Display the chart\n",
    "plt.show() #Display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eab33e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #Imports the pyplot module from the matplotlib library as plt.\n",
    "\n",
    "# define model names and their respective F1 scores\n",
    "model_names = ['Q-Learning', 'Policy Gradient'] # Define a list which will be used to plot the bar chart.\n",
    "f1_scores = [score_q, score_pg] # Define a list which will be used to  plot the bar chart for F1 scores.\n",
    "colors = ['green', 'red'] # list of colors for each bar\n",
    "# Set up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 6)) #Creates a new figure object and an axes object with a size of 8 inches by 6 inches.\n",
    "# Add the bars to the plot\n",
    "for i in range(len(model_names)):\n",
    "    ax.bar(model_names[i], f1_scores[i], color=colors[i])\n",
    "\n",
    "    # Add the accuracy score as text to the bar\n",
    "    ax.text(model_names[i], f1_scores[i] + 0.01, round(f1_scores[i], 5), ha='center')\n",
    "\n",
    "\n",
    "# add labels to the chart\n",
    "plt.title('Comparison of Model F1 Scores Bet Q-Learning and Policy Gradient of NN model') #Adds a title\n",
    "plt.xlabel('Models') #Adds xlabel to display models on the chart\n",
    "plt.ylabel('F1 Scores') #Adds ylabel to the chart.\n",
    "\n",
    "# display the chart\n",
    "plt.show() #displays the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42303c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################### LSTM Model #################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "913e745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## LSTM_Policy Gradient ##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b6d9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the necessary libraries and packages required for building and training a deep learning model for text classification.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8de459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the policy gradient function\n",
    "# NAME: policy_gradient\n",
    "# PURPOSE: To implement the policy gradient algorithm for training a LSTM model (model) using given input data (x) and target labels (y) with a specified optimizer (optimizer). The algorithm is trained for a given number of epochs (epochs) and batch size (batch_size), and uses a discount factor (gamma) for computing the model loss.\n",
    "#          The purpose of this code is to train a LSTM model using the policy gradient algorithm, where the model's weights are updated based on the computed policy gradient and model loss, and the training process is performed in batches for efficiency.\n",
    "# INVARIANTS: Calculates the length of the input data (x) using shape() method.length is an integer variable representing the number of rows in the input data x, used to determine the batch sizes and loop iterations in the training process.\n",
    "#             Iterates over each epoch.\n",
    "#             For each epoch, iterates over the input data (x) in batches of size batch_size.\n",
    "#             For each batch, computes the logits (raw output) of the model for the input data using model(x_batch).\n",
    "#             Computes the log probabilities of the logits using tf.math.log(tf.clip_by_value(logits, 1e-10, 1.0)).\n",
    "#             Creates one-hot encoded labels from the target labels (y_batch) using tf.one_hot() method.\n",
    "#             Computes the policy gradient loss by multiplying the log probabilities with the one-hot encoded labels and taking the negative mean using tf.reduce_mean(tf.reduce_sum(labels * log_probs, axis=1)).\n",
    "#             Computes the gradients of the policy gradient loss with respect to the model's trainable weights using tape.gradient().\n",
    "#             Applies the gradients to the optimizer using optimizer.apply_gradients() to update the model's weights.\n",
    "#             Computes the average reward for the current batch and uses it as a baseline.\n",
    "#             Computes the model loss by multiplying the policy gradient loss with the average reward and the discount factor (gamma).\n",
    "#             Computes the gradients of the model loss with respect to the model's trainable weights using tape.gradient().\n",
    "#             Applies the gradients to the optimizer using optimizer.apply_gradients() to update the model's weights.\n",
    "#             The purpose of this code is to train a neural network model using the policy gradient algorithm, where the model's weights are updated based on the computed policy gradient and model loss, and the training process is performed in batches for efficiency.\n",
    "\n",
    "def policy_gradient(x, y, model, optimizer, epochs, batch_size, gamma): #class to define the policy_gradient RL technique\n",
    "   \n",
    "    length = x.shape[0] #Calculates the length of the input data (x) using shape() method.\n",
    "    for epoch in range(epochs): #Iterates over each epoch.\n",
    "        epoch_rewards = [] #empty lists that are likely intended to store the rewards for each epoch during the training of a neural network.\n",
    "        epoch_losses = [] #empty lists that are likely intended to store the losses for each epoch during the training of a neural network.\n",
    "        for batch_start in range(0, length, batch_size): #It is used to iterate over the input data (x) in batches of size batch_size during the training process. It starts from the beginning of the input data and increments in steps of batch_size until it reaches the end of the data.\n",
    "            batch_end = min(batch_start + batch_size, length) # It calculates the ending index (batch_end) of the current batch during the iteration over the input data (x) in batches. It ensures that the ending index does not exceed the total length of the data (length) to avoid accessing data beyond the available range. \n",
    "            x_batch = x[batch_start:batch_end] #Extracting a batch of data from the array 'x' using the start and end indices of the batch\n",
    "            y_batch = y[batch_start:batch_end] #Extracting a batch of labels from the array 'y' using the start and end indices of the batch\n",
    "            with tf.GradientTape() as tape: #tf.GradientTape() is a TensorFlow API that provides a mechanism for automatic differentiation, which is a key technique used in machine learning optimization algorithms, such as gradient descent. It allows you to compute gradients of a computation with respect to its input variables, which can then be used to update the values of those variables during optimization.\"tape\" refers to a mechanism provided by TensorFlow that records operations for the purpose of computing gradients. The tape acts as a context within which computations are recorded, and these computations can later be used to compute gradients using the tape.gradient() method.\n",
    "                logits = model(x_batch) #Passing the batch of input data 'x_batch' through the model to obtain logits.Logits are the output of the model before applying any activation function, typically used for classification tasks Logits represent the raw, unnormalized scores for each class, which can be used for further processing or prediction.'model' is the trained model that takes 'x_batch' as input and produces logits as output\n",
    "                log_probs = tf.nn.log_softmax(logits) #code applies the softmax function to the output logits of the neural network model and then takes the logarithm of the resulting probabilities.The tf.nn.log_softmax function is a method from the TensorFlow library that applies the softmax function to the logits, which are the raw outputs of the neural network before the activation function is applied. The softmax function converts the logits into probabilities that sum to 1, allowing the outputs to be interpreted as probabilities of each class. the tf.nn.log_softmax function is used to convert the raw outputs of the neural network into probabilities that can be used for classification, and the logarithm is taken for numerical stability during the calculation of the loss function.\n",
    "                labels = tf.one_hot(y_batch, depth=output_dim) #Converting the batch of labels 'y_batch' into one-hot encoding using 'tf.one_hot' function One-hot encoding represents categorical labels as binary vectors with a single '1' and remaining '0's.'y_batch' is the input tensor containing the batch of labels to be converted to one-hot encoding.'output_dim' specifies the depth of the one-hot encoding, which should be equal to the number of classes in the classification task\n",
    "                rewards = tf.reduce_sum(labels * log_probs, axis=1) # Compute the reward using the log probability of the correct label\n",
    "                loss = -tf.reduce_mean(rewards) # Maximize the expected reward\n",
    "                grads = tape.gradient(loss, model.trainable_weights) #grads typically refers to the computed gradients of the loss function with respect to the trainable weights of a machine learning model.The tape.gradient() function in TensorFlow is used to compute the gradients of a given function (in this case, the loss function) with respect to a list of variables (in this case, the model.trainable_weights). These gradients can then be used in an optimization algorithm, such as gradient descent, to update the model weights and improve the model's performance during training.Compute the gradients of the loss with respect to the trainable weights of the model.loss: The computed loss value.model.trainable_weights: List of trainable weights of the model\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights)) #It applies the computed gradients (grads) to update the model weights (model.trainable_weights) using an optimizer. The zip() function is used to create pairs of gradients and corresponding model weights, which are then passed to the apply_gradients() method of the optimizer to perform the weight update step. This step is a key part of the optimization process in training machine learning models, as it helps to adjust the model weights based on the gradients of the loss function, with the goal of minimizing the loss and improving the model's performance.\n",
    "            \n",
    "            epoch_rewards.append(rewards) #appends the rewards obtained by the network during the current epoch to the epoch_rewards list. This allows us to keep track of the rewards obtained by the network during each epoch of training.\n",
    "            epoch_losses.append(loss.numpy()) # appends the loss obtained by the network during the current epoch to the epoch_losses list. This allows us to keep track of the loss obtained by the network during each epoch of training.The numpy() method is used to extract the numerical value of the TensorFlow loss object, which is a symbolic representation of the loss function used to train the network. This numerical value is then appended to the epoch_losses list.\n",
    "            print(\"The rewards are:\", rewards) #prints the rewards\n",
    "            \n",
    "    # Plot reward histogram\n",
    "    plt.hist(epoch_rewards, bins=20) #creates a histogram plot of the distribution of the rewards obtained by the network during training, using 20 bins. This allows us to visualize how often the network obtained rewards in different ranges, which can provide insight into its overall performance.\n",
    "    plt.title(\"Reward Histogram Policy Gradient LSTM\") #sets the title of the plot to \"Reward Histogram Policy Gradient LSTM\", which describes the type of algorithm used and the type of data being plotted.\n",
    "    plt.xlabel(\"Reward\") #sets the x-axis label to \"Reward\", which describes the meaning of the values being plotted on the x-axis.\n",
    "    plt.ylabel(\"Frequency\") #sets the y-axis label to \"Frequency\", which describes the number of occurrences of rewards in each bin.\n",
    "    plt.show() #displays the plot on the screen. This allows us to see the distribution of the rewards obtained by the network during training and gain insights into its performance.\n",
    "    \n",
    "        \n",
    "    # Plot loss histogram\n",
    "    plt.hist(epoch_losses, bins=20) # creates a histogram plot of the distribution of the losses obtained by the network during training, using 20 bins. This allows us to visualize how often the network had a certain level of loss during the training process, which can provide insights into how well the network is learning and improving over time.\n",
    "    plt.title(\"Loss Histogram Policy Gradient LSTM\") # sets the title of the plot to \"Loss Histogram Policy Gradient LSTM\", which describes the type of algorithm used and the type of data being plotted.\n",
    "    plt.xlabel(\"Loss\") # sets the x-axis label to \"Loss\", which describes the meaning of the values being plotted on the x-axis.\n",
    "    plt.ylabel(\"Frequency\") #sets the y-axis label to \"Frequency\", which describes the number of occurrences of losses in each bin.\n",
    "    plt.show() # displays the plot on the screen. This allows us to see the distribution of the losses obtained by the network during training and gain insights into its performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6d9166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters  \n",
    "input_dim = X_train_vectors.shape[1] #sets the variable input_dim equal to the number of features in the training data.'X_train_vectors.shape[1]'' retrieves the number of columns (i.e., features) in the feature matrix X_train_vectors. This value represents the number of input dimensions or features for the classification model.\n",
    "output_dim = len(np.unique(y_train)) #sets the variable output_dim equal to the number of unique target labels in the training data. These variables are likely used to define the input and output dimensions of the neural network or classification model being built.np.unique(y_train) returns the unique values of the target variable y_train. The length of this array is equal to the number of distinct target labels in the dataset.len(np.unique(y_train)) returns the number of unique target labels in the dataset. This value represents the number of output dimensions or classes for the classification model.\n",
    "\n",
    "# Reshape the data for LSTM input\n",
    "X_train_lstm = np.reshape(X_train_vectors.toarray(), (X_train_vectors.shape[0], 1, X_train_vectors.shape[1])) #X_train_vectors is the sparse matrix of shape (number of samples, number of features) that contains the training feature vectors. The toarray() method is used to convert this sparse matrix into a dense matriThe np.reshape() function is then used to reshape the dense matrix into a 3-dimensional array with shape (number of samples, 1, number of features). The first dimension represents the number of samples, the second dimension represents the number of time steps in the LSTM (which is set to 1 in this case), and the third dimension represents the number of features in each input vector.The reason for reshaping the input data in this way is because LSTM models require 3-dimensional input data, where the first dimension is the number of samples, the second dimension is the number of time steps, and the third dimension is the number of features.this line of code reshapes the training data from a dense matrix of shape (number of samples, number of features) to a 3-dimensional array of shape (number of samples, 1, number of features) that is suitable for training an LSTM model.\n",
    "X_test_lstm = np.reshape(X_test_vectors.toarray(), (X_test_vectors.shape[0], 1, X_test_vectors.shape[1])) #X_test_vectors is the sparse matrix of shape (number of samples, number of features) that contains the test feature vectors. The toarray() method is used to convert this sparse matrix into a dense matrix.The np.reshape() function is then used to reshape the dense matrix into a 3-dimensional array with shape.The reason for reshaping the test data in this way is because the LSTM model expects input data with the same shape as the training data.this line of code reshapes the test data from a dense matrix of shape (number of samples, number of features) to a 3-dimensional array of shape (number of samples, 1, number of features) that is suitable for testing the LSTM model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e830ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model and define the optimizer\n",
    "# Name: Neural Network model\n",
    "# Purpose: to define and create a LSTM neural network or classification model for a given dataset.\n",
    "# Invariants: The input_dim variable contains the number of features in the input data.\n",
    "#             The output_dim variable contains the number of classes in the target variable.\n",
    "#             The inputs variable is an input layer that takes a 3-dimensional input of shape (number of samples, 1, input_dim).\n",
    "#             The x variable is a hidden layer that applies a Long Short-Term Memory (LSTM) operation with 64 units and a Rectified Linear Unit (ReLU) activation function to the input.\n",
    "#             The model2 variable is a Keras Model that takes inputs as input and x as output.\n",
    "#             The optimizer variable is an Adam optimizer with a learning rate of 0.001 that is used to optimize the model during training.\n",
    "\n",
    "inputs = Input(shape=(1, input_dim,)) #creates an input layer in Keras with 3 dimensions, defined by the shape parameter. The first dimension is set to 1, indicating that each input sample will have a single time step. The second dimension is set to input_dim, indicating the number of features in each time step. The inputs variable stores this input layer, which will be used as the input to the subsequent layers in the model.\n",
    "x = LSTM(32, activation='relu')(inputs) # creates a Long Short-Term Memory (LSTM) layer in Keras with 64 units and the ReLU activation function. The inputs variable is passed as the input to this layer. The LSTM layer is a type of recurrent neural network layer that is commonly used for processing sequential data, such as text or time series data. The output of the LSTM layer is stored in the x variable and will be used as input to the subsequent layer in the model.\n",
    "x = Dense(output_dim, activation='softmax')(x) #creates a dense layer with output_dim number of units and the softmax activation function. The x variable is passed as the input to this layer. The purpose of this layer is to perform the final classification of the input data, with each unit representing a different class. The output of the dense layer will be a probability distribution over the different classes, with the sum of the probabilities equal to 1. The output of this layer is stored in the x variable and will be used as the output of the model.\n",
    "model2 = Model(inputs=inputs, outputs=x) # creates a Keras Model object that specifies the input and output layers of the neural network. The inputs variable represents the input layer of the model, which takes as input a tensor of shape (batch_size, 1, input_dim). The x variable represents the output layer of the model, which is the output of the last dense layer with softmax activation. The Model constructor takes two arguments: the input tensor and the output tensor. These tensors define the input and output of the model and all the layers in between. The resulting model2 object can be used to train and evaluate the neural network.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # initializes an instance of the Adam optimizer from the Keras API with a learning rate of 0.001. The Adam optimizer is a popular gradient descent optimization algorithm that is commonly used in deep learning.\n",
    "#optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001) #RMSprop optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # is an important line of code in the process of building a deep learning model using Keras. It compiles the model by specifying the loss function, optimizer, and metrics to be used during training.In particular, the loss parameter specifies the loss function that the model will use to evaluate its performance on the training data. In this case, the 'categorical_crossentropy' loss function is used, which is commonly used for multiclass classification problems.The optimizer parameter specifies the optimization algorithm that will be used to adjust the weights of the model during training in order to minimize the loss function. Here, the optimizer variable is passed in, which should be an instance of a pre-defined optimizer class from Keras, such as Adam or RMSprop.Finally, the metrics parameter specifies the evaluation metrics that will be used to monitor the model's performance during training and testing. In this case, 'accuracy' is the metric used, which is commonly used for classification problems.Overall, model.compile is a crucial step in the process of building and training a deep learning model, as it sets up the model for optimization by specifying the necessary components for the training process.\n",
    "#model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy']) #loss:mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d94e91c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rewards are: tf.Tensor(\n",
      "[-0.69345134 -0.69139534 -0.6942791  -0.69248205 -0.6931962  -0.69166046\n",
      " -0.6914742  -0.6916415  -0.69415796 -0.69282895 -0.6918977  -0.6907193\n",
      " -0.69331384 -0.6912126  -0.69495773 -0.69456875 -0.69481766 -0.69214696\n",
      " -0.69523215 -0.69412315 -0.6945771  -0.69146943 -0.69497925 -0.69278616\n",
      " -0.69518876 -0.6937492  -0.69380414 -0.6953623  -0.6918068  -0.6922477\n",
      " -0.69443095 -0.692647  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6920537  -0.69362116 -0.6921275  -0.6927142  -0.6925007  -0.69382334\n",
      " -0.69271517 -0.69300365 -0.6937326  -0.692665   -0.69371295 -0.69211143\n",
      " -0.6916281  -0.69319826 -0.69254273 -0.69315577 -0.69225943 -0.69296587\n",
      " -0.694146   -0.69298565 -0.693382   -0.6931693  -0.69367194 -0.69376636\n",
      " -0.69190735 -0.6920014  -0.693943   -0.6934016  -0.69320726 -0.69281083\n",
      " -0.6920156  -0.6922546 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6927979  -0.6934184  -0.6920156  -0.6939764  -0.6935812  -0.69354236\n",
      " -0.69299483 -0.69077164 -0.691644   -0.6932199  -0.6922516  -0.6937193\n",
      " -0.6926194  -0.6941787  -0.69315326 -0.6919652  -0.69389135 -0.69156075\n",
      " -0.69496286 -0.69311905 -0.69399077 -0.6933206  -0.69268155 -0.6933876\n",
      " -0.6938914  -0.6917177  -0.6943785  -0.694227   -0.69231343 -0.6942771\n",
      " -0.69224733 -0.69193286], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6917201  -0.693906   -0.69229007 -0.6925293  -0.6942347  -0.6925513\n",
      " -0.6916114  -0.695293   -0.69423246 -0.69371885 -0.69252616 -0.6946794\n",
      " -0.6912631  -0.6939826  -0.69155174 -0.69380033 -0.69152844 -0.69448614\n",
      " -0.6947012  -0.69173265 -0.691584   -0.69345194 -0.69165355 -0.6928704\n",
      " -0.69203305 -0.6915128  -0.6924441  -0.6919112  -0.69392824 -0.69388014\n",
      " -0.6920512  -0.69009435], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6954546  -0.69213533 -0.6921449  -0.69502234 -0.69457304 -0.69227815\n",
      " -0.6931677  -0.69417244 -0.6957361  -0.6937753  -0.69296956 -0.6909808\n",
      " -0.69492567 -0.6948997  -0.6943572  -0.6936188  -0.6922529  -0.696535\n",
      " -0.6905229  -0.6946716  -0.6911314  -0.6923576  -0.6959145  -0.6940645\n",
      " -0.69397485 -0.69437003 -0.69242656 -0.69520265 -0.69374657 -0.6949831\n",
      " -0.6951361  -0.6925853 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6943233  -0.6910399  -0.6948606  -0.6905209  -0.6927668  -0.6906587\n",
      " -0.6943823  -0.6938853  -0.69341934 -0.6920351  -0.69493055 -0.6930876\n",
      " -0.69277906 -0.6926396  -0.6911719  -0.6938132  -0.69270974 -0.69151425\n",
      " -0.69190943 -0.6923933  -0.69509053 -0.6945338  -0.69196415 -0.69383484\n",
      " -0.690677   -0.6922148  -0.6934614  -0.6947117  -0.6918439  -0.6938913\n",
      " -0.69432926 -0.69127685], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6912038  -0.69182557 -0.6937814  -0.69321615 -0.69383216 -0.6944461\n",
      " -0.69107443 -0.6952568  -0.69361466 -0.6942609  -0.6945896  -0.6928504\n",
      " -0.6947915  -0.6931456  -0.692108   -0.6937707  -0.6946782  -0.6955548\n",
      " -0.6942084  -0.6951057  -0.6921439  -0.69289976 -0.6928614  -0.6951698\n",
      " -0.6920793  -0.69357896 -0.69336593 -0.6936247  -0.69540834 -0.69141275\n",
      " -0.69163615 -0.6943524 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6923429  -0.6919281  -0.69374335 -0.6918098  -0.6910032  -0.69181454\n",
      " -0.690324   -0.6926893  -0.6933255  -0.6939955  -0.6948402  -0.69194865\n",
      " -0.6915226  -0.692239   -0.691779   -0.6921478  -0.692151   -0.6927847\n",
      " -0.694469   -0.69259065 -0.69221276 -0.6917252  -0.69282454 -0.69252676\n",
      " -0.6914681  -0.69368565 -0.69465613 -0.69364727 -0.69163054 -0.6941782\n",
      " -0.6935186  -0.6907128 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69149715 -0.692501   -0.6930078  -0.6928304  -0.69200295 -0.6906161\n",
      " -0.69348025 -0.6922526  -0.69237614 -0.69257635 -0.6911692  -0.69580215\n",
      " -0.69395727 -0.69151855 -0.6933161  -0.6936588  -0.6925156  -0.6911285\n",
      " -0.6911423  -0.6923866  -0.69435453 -0.69215596 -0.69246554 -0.69287115\n",
      " -0.6931809  -0.6922036  -0.6946905  -0.691822   -0.69321024 -0.6936278\n",
      " -0.69323087 -0.6923531 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6928147  -0.6925675  -0.691395   -0.6931044  -0.69176716 -0.6925445\n",
      " -0.6924287  -0.6913147  -0.6914159  -0.69369555 -0.6921883  -0.69310737\n",
      " -0.69354224 -0.6942948  -0.6913054  -0.69193524 -0.6912299  -0.69374156\n",
      " -0.6926061  -0.69420254 -0.694678   -0.6929832  -0.6951678  -0.6941489\n",
      " -0.69447833 -0.6919063  -0.6917448  -0.69461006 -0.6929734  -0.69345784\n",
      " -0.6934018  -0.6908365 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6941208  -0.6939587  -0.6917102  -0.69232833 -0.6904261  -0.6923931\n",
      " -0.69315445 -0.69552594 -0.69311297 -0.6931705  -0.6916002  -0.6916889\n",
      " -0.6917424  -0.69091463 -0.6933905  -0.6927615  -0.6942523  -0.69279456\n",
      " -0.6932806  -0.6928578  -0.69175625 -0.69334173 -0.6920608  -0.69269717\n",
      " -0.69305706 -0.6954726  -0.69045335 -0.69293445 -0.69448435 -0.69432175\n",
      " -0.69284815 -0.69305205], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6908543  -0.69258755 -0.69529045 -0.6923221  -0.6925155  -0.69095784\n",
      " -0.69341314 -0.69068944 -0.6935169  -0.69197357 -0.6929449  -0.6922504\n",
      " -0.69171953 -0.6905946  -0.6943032  -0.69383556 -0.69237775 -0.6918637\n",
      " -0.69330287 -0.69203246 -0.6917426  -0.6924381  -0.69317555 -0.69227177\n",
      " -0.6920817  -0.6919013  -0.695398   -0.692553   -0.6945491  -0.6950445\n",
      " -0.6947595  -0.69227386], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69244456 -0.6938843  -0.6925692  -0.6913025  -0.6936644  -0.69245034\n",
      " -0.692387   -0.69240403 -0.69300437 -0.6948556  -0.69288695 -0.6926837\n",
      " -0.6915589  -0.69269764 -0.69154894 -0.69250184 -0.69036597 -0.6940744\n",
      " -0.693178   -0.6928784  -0.69262683 -0.69368565 -0.6928057  -0.6910867\n",
      " -0.6917492  -0.69215554 -0.69202226 -0.6920284  -0.69199866 -0.6938203\n",
      " -0.69343525 -0.6933025 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69218236 -0.69147855 -0.694186   -0.6929468  -0.69218874 -0.6925663\n",
      " -0.69235575 -0.6906354  -0.69324934 -0.6929551  -0.69288284 -0.69311935\n",
      " -0.6918089  -0.6926906  -0.69347125 -0.6934333  -0.6909533  -0.6924273\n",
      " -0.69152415 -0.69057584 -0.69109905 -0.6922784  -0.69130975 -0.6930771\n",
      " -0.6928694  -0.68944544 -0.6920167  -0.6917931  -0.69219506 -0.6906244\n",
      " -0.69288594 -0.6919731 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6921541  -0.69322586 -0.6938477  -0.6934036  -0.69459677 -0.692002\n",
      " -0.69155115 -0.69350123 -0.693715   -0.69267356 -0.69395447 -0.69106\n",
      " -0.69252175 -0.69203395 -0.69161034 -0.6937375  -0.6915269  -0.6911403\n",
      " -0.6919629  -0.69397354 -0.69508004 -0.69048274 -0.69441175 -0.69286156\n",
      " -0.6910514  -0.6926204  -0.69144666 -0.6904413  -0.69218576 -0.6921928\n",
      " -0.6912394  -0.6922216 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6937883  -0.6929698  -0.6932204  -0.6920711  -0.6923842  -0.6937008\n",
      " -0.69064087 -0.6925618  -0.69420516 -0.69045967 -0.6939149  -0.69305277\n",
      " -0.6905908  -0.69380367 -0.690687   -0.6927     -0.68969935 -0.69319874\n",
      " -0.6931196  -0.69262385 -0.69119537 -0.69349706 -0.69175303 -0.6921432\n",
      " -0.6925402  -0.69247687 -0.69338053 -0.69092125 -0.6907414  -0.690636\n",
      " -0.6911538  -0.6920963 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69365215 -0.69334555 -0.69357026 -0.69120747 -0.69387656 -0.6928629\n",
      " -0.6921031  -0.6919284  -0.69305503 -0.6907567  -0.6912995  -0.69569814\n",
      " -0.68835104 -0.6927223  -0.69407046 -0.6924745  -0.69094545 -0.69191426\n",
      " -0.6911334  -0.69159913 -0.6930502  -0.6896619  -0.69298416 -0.69338435\n",
      " -0.6914541  -0.69454545 -0.6890957  -0.6935438  -0.6929054  -0.69312817\n",
      " -0.69201934 -0.6913898 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6922439  -0.6942121  -0.6914449  -0.69443583 -0.6934435  -0.69337326\n",
      " -0.69266194 -0.6895052  -0.69380116 -0.69185996 -0.6916603  -0.69062895\n",
      " -0.69055927 -0.6923189  -0.6924777  -0.69380254 -0.6924812  -0.69442767\n",
      " -0.69141066 -0.69211954 -0.69261986 -0.6929212  -0.6922398  -0.691428\n",
      " -0.6924149  -0.69033355 -0.69260514 -0.6918126  -0.69254404 -0.6915308\n",
      " -0.6919671  -0.6918384 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6905926  -0.69263697 -0.6935574  -0.6918165  -0.69440544 -0.6911951\n",
      " -0.69297695 -0.6906594  -0.6918072  -0.6910905  -0.6918112  -0.6919608\n",
      " -0.6911507  -0.69311464 -0.6891719  -0.691709   -0.6914268  -0.69359505\n",
      " -0.69574225 -0.694329   -0.69089013 -0.69169724 -0.6919653  -0.6911153\n",
      " -0.6908047  -0.69155556 -0.6903902  -0.69277257 -0.691107   -0.6950415\n",
      " -0.6936028  -0.6914198 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6944628  -0.69185185 -0.69283897 -0.6939491  -0.6933322  -0.6923676\n",
      " -0.68961746 -0.6921088  -0.6926677  -0.69259804 -0.6918133  -0.69055724\n",
      " -0.69493395 -0.69131196 -0.69279677 -0.69372416 -0.69228595 -0.69099027\n",
      " -0.6936559  -0.69217783 -0.6892103  -0.6921454  -0.6915893  -0.69197935\n",
      " -0.69110924 -0.6912114  -0.6903299  -0.6899856  -0.6912768  -0.69445485\n",
      " -0.6928976  -0.69098747], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6943358  -0.69191164 -0.690546   -0.6902038  -0.6946869  -0.6918934\n",
      " -0.69309425 -0.6923017  -0.69113517 -0.6907615  -0.69552183 -0.6936778\n",
      " -0.68917966 -0.69289905 -0.69106877 -0.68971664 -0.69277316 -0.69255215\n",
      " -0.69084674 -0.69179434 -0.6924196  -0.6903128  -0.69216484 -0.6901689\n",
      " -0.69371617 -0.6902071  -0.6921016  -0.6887803  -0.6928354  -0.6900891\n",
      " -0.69272846 -0.6899344 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.690471   -0.69477403 -0.6924399  -0.69416595 -0.69274944 -0.69397724\n",
      " -0.69093627 -0.6911246  -0.6928129  -0.6931597  -0.691195   -0.6907536\n",
      " -0.693747   -0.6901033  -0.68753064 -0.6935824  -0.69417715 -0.69071466\n",
      " -0.6894117  -0.6912753  -0.6906906  -0.69261837 -0.6931778  -0.6903051\n",
      " -0.69215596 -0.6946974  -0.6906871  -0.69216496 -0.6907733  -0.6923731\n",
      " -0.6903889  -0.69437134], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6903926  -0.6903453  -0.690202   -0.6946923  -0.6929858  -0.69146836\n",
      " -0.6918872  -0.6916601  -0.69246626 -0.69234663 -0.6875816  -0.68948543\n",
      " -0.6942945  -0.69278514 -0.69095075 -0.6917615  -0.69084936 -0.6901644\n",
      " -0.6926592  -0.69281113 -0.69041884 -0.69201285 -0.6913748  -0.69292223\n",
      " -0.69370365 -0.69216835 -0.69191474 -0.6912804  -0.68722993 -0.6932545\n",
      " -0.6900984  -0.69543684], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69042075 -0.69092447 -0.69114554 -0.6878993  -0.6915719  -0.6920612\n",
      " -0.6897436  -0.6923191  -0.6965811  -0.6916164  -0.68905026 -0.694394\n",
      " -0.6917174  -0.6946778  -0.69265544 -0.69598633 -0.6919144  -0.6916635\n",
      " -0.69100916 -0.6906217  -0.6902652  -0.690677   -0.6951803  -0.69273806\n",
      " -0.69028175 -0.6896463  -0.69077986 -0.6923986  -0.6882838  -0.6875469\n",
      " -0.6934342  -0.68679416], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6982873  -0.688309   -0.6892985  -0.69045603 -0.6933744  -0.69077677\n",
      " -0.6901399  -0.69361854 -0.6883067  -0.686603   -0.6897626  -0.69444096\n",
      " -0.68867075 -0.6912104  -0.6919267  -0.6891523  -0.69235396 -0.6924447\n",
      " -0.6917601  -0.68773943 -0.69036955 -0.6881684  -0.69026893 -0.68771833\n",
      " -0.68872505 -0.69347    -0.6961407  -0.69058853 -0.6904673  -0.69146866\n",
      " -0.69297624 -0.69383955], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6891484  -0.69317305 -0.69054645 -0.68943673 -0.6910788  -0.69624645\n",
      " -0.6883078  -0.69050974 -0.6948329  -0.6877788  -0.6924423  -0.6866347\n",
      " -0.6952752  -0.6912735  -0.6940076  -0.6888421  -0.6907475  -0.69232976\n",
      " -0.6878046  -0.69356287 -0.691587   -0.689831   -0.6942772  -0.69103193\n",
      " -0.68973076 -0.68842    -0.68896216 -0.68994856 -0.6920852  -0.6900406\n",
      " -0.68768597 -0.6948751 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6888667  -0.6885092  -0.69282156 -0.6896547  -0.6899076  -0.6926031\n",
      " -0.6912597  -0.69123954 -0.69528    -0.69106483 -0.68787515 -0.6936462\n",
      " -0.69393134 -0.69273454 -0.6875039  -0.694926   -0.68761295 -0.6932355\n",
      " -0.6925543  -0.6881397  -0.6890608  -0.69297194 -0.68948054 -0.6951183\n",
      " -0.69234747 -0.692074   -0.69151765 -0.6929026  -0.6951182  -0.69075596\n",
      " -0.6916939  -0.6886406 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69259727 -0.692106   -0.68401283 -0.6912784  -0.69091344 -0.6873882\n",
      " -0.6922846  -0.6897443  -0.6879434  -0.6897365  -0.69346315 -0.6913768\n",
      " -0.6916527  -0.6898546  -0.6927922  -0.69561785 -0.68895346 -0.6944364\n",
      " -0.6896091  -0.6897436  -0.6887042  -0.6901246  -0.68656    -0.6875393\n",
      " -0.69112384 -0.6921348  -0.69348437 -0.6880672  -0.6924005  -0.69082606\n",
      " -0.68991786 -0.6926727 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6953424  -0.69429576 -0.684635   -0.68718493 -0.6930901  -0.6899062\n",
      " -0.6918791  -0.69331825 -0.6901954  -0.6892149  -0.6882088  -0.6919198\n",
      " -0.6971142  -0.6963078  -0.6898727  -0.68991923 -0.6919519  -0.69506955\n",
      " -0.6937754  -0.689959   -0.69861543 -0.6942853  -0.6863245  -0.6869392\n",
      " -0.68754864 -0.69603175 -0.6881155  -0.69361687 -0.69155234 -0.6897381\n",
      " -0.6888787  -0.6928738 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69467247 -0.6865046  -0.69423795 -0.69414985 -0.69540054 -0.6967614\n",
      " -0.6865331  -0.6927053  -0.68826115 -0.68805254 -0.6859289  -0.69345045\n",
      " -0.68646526 -0.68868804 -0.68748975 -0.6953049  -0.6912324  -0.6987457\n",
      " -0.6888223  -0.6885826  -0.6902692  -0.6880483  -0.6854135  -0.6990727\n",
      " -0.6870829  -0.6926614  -0.691061   -0.6896673  -0.68921196 -0.6901917\n",
      " -0.690491   -0.69032836], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6896975  -0.6885988  -0.69528085 -0.6912767  -0.68869513 -0.68931776\n",
      " -0.6954197  -0.6915934  -0.6942977  -0.6893402  -0.69620013 -0.6879125\n",
      " -0.6926457  -0.6842916  -0.69852644 -0.6897291  -0.694385   -0.69234866\n",
      " -0.6880824  -0.6937729  -0.6882086  -0.697442   -0.6957012  -0.695377\n",
      " -0.6841674  -0.6882472  -0.69729185 -0.6916752  -0.6948113  -0.68747765\n",
      " -0.6928634  -0.6863478 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6884882  -0.69461787 -0.68979967 -0.6919922  -0.6886844  -0.6929878\n",
      " -0.6944048  -0.6944649  -0.68826044 -0.69136375 -0.68654996 -0.69324636\n",
      " -0.6860854  -0.6887551  -0.68681073 -0.6934018  -0.6935663  -0.69370735\n",
      " -0.6874692  -0.69736344 -0.69542015 -0.6871773  -0.68524784 -0.69371223\n",
      " -0.69121826 -0.68707824 -0.6853618  -0.68542993 -0.6909974  -0.69165766\n",
      " -0.6892954  -0.69488436], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6830359  -0.6905325  -0.69575953 -0.69745255 -0.69364566 -0.6924108\n",
      " -0.6861325  -0.69421905 -0.68973255 -0.68766564 -0.69154114 -0.6859145\n",
      " -0.6945258  -0.6945045  -0.6879514  -0.6840575  -0.6879372  -0.6853445\n",
      " -0.69191486 -0.6930404  -0.6952903  -0.6899561  -0.6934409  -0.688118\n",
      " -0.6824803  -0.69014436 -0.68552047 -0.68484783 -0.69064134 -0.6926136\n",
      " -0.69587946 -0.68780196], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6946595  -0.693085   -0.6861919  -0.6919273  -0.6956618  -0.6862178\n",
      " -0.6844399  -0.6931275  -0.6854711  -0.6957555  -0.68434715 -0.69472814\n",
      " -0.688677   -0.68666905 -0.6829201  -0.6926597  -0.6829582  -0.6931596\n",
      " -0.68522954 -0.6900666  -0.68705976 -0.69603956 -0.69415843 -0.6988504\n",
      " -0.68952936 -0.68567044 -0.6947217  -0.69113404 -0.6912062  -0.6854467\n",
      " -0.69612813 -0.68985623], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.68534774 -0.6968513  -0.6845307  -0.6857704  -0.6965003  -0.6858793\n",
      " -0.68753767 -0.6847723  -0.68618697 -0.6938353  -0.68544424 -0.69491595\n",
      " -0.6925764  -0.6826899  -0.6909979  -0.6918147  -0.68432    -0.69584876\n",
      " -0.6985252  -0.6851379  -0.6849481  -0.68809015 -0.6916521  -0.69393826\n",
      " -0.6840034  -0.68488926 -0.69161844 -0.6808796  -0.6927172  -0.68980783\n",
      " -0.6927005  -0.69126725], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6957458  -0.68739635 -0.6971499  -0.6895756  -0.685343   -0.6946604\n",
      " -0.684931   -0.6834239  -0.6969753  -0.68977576 -0.6826904  -0.6925755\n",
      " -0.68410844 -0.68273705 -0.69349074 -0.6872978  -0.6899041  -0.68641996\n",
      " -0.68407965 -0.682139   -0.69049084 -0.68340105 -0.692861   -0.6876499\n",
      " -0.68503004 -0.68475896 -0.68317664 -0.6926507  -0.69181615 -0.6908511\n",
      " -0.68508846 -0.68566334], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.68748206 -0.685308   -0.68479    -0.68669057 -0.6848339  -0.6868273\n",
      " -0.6866485  -0.6885854  -0.6928023  -0.6924248  -0.6932229  -0.69363695\n",
      " -0.6863728  -0.69026023 -0.69415456 -0.68095446 -0.6903282  -0.6897463\n",
      " -0.6910897  -0.696511   -0.6872184  -0.69761646 -0.6841823  -0.6897711\n",
      " -0.6939449  -0.6840123  -0.6847764  -0.6909001  -0.68306845 -0.69264686\n",
      " -0.68703866 -0.68869644], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6910729  -0.685918   -0.6895169  -0.68231785 -0.68481815 -0.6903362\n",
      " -0.6951857  -0.6950043  -0.686376   -0.69902176 -0.68565315 -0.6802025\n",
      " -0.6970587  -0.6822523  -0.69666505 -0.68676966 -0.69489276 -0.6901756\n",
      " -0.6925209  -0.68409854 -0.68853337 -0.685045   -0.6873142  -0.6879399\n",
      " -0.6839667  -0.6843569  -0.6903534  -0.695672   -0.68096435 -0.6839014\n",
      " -0.6964716  -0.6931318 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6852402  -0.6920882  -0.6883691  -0.6908925  -0.6947588  -0.69815755\n",
      " -0.6931316  -0.6919488  -0.68743545 -0.6964189  -0.6886789  -0.6852723\n",
      " -0.68985015 -0.6818975  -0.6818788  -0.6931486  -0.69055843 -0.6813475\n",
      " -0.6848416  -0.6961949  -0.69468427 -0.6920173  -0.68919075 -0.69023067\n",
      " -0.6918564  -0.694631   -0.6833586  -0.69071907 -0.692485   -0.6849564\n",
      " -0.6910641  -0.6853548 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6820444  -0.6973169  -0.6859893  -0.68133146 -0.6883793  -0.6798426\n",
      " -0.6797211  -0.68522424 -0.68481916 -0.6958343  -0.68311465 -0.68990827\n",
      " -0.6815347  -0.6928527  -0.69057655 -0.6998073  -0.6782281  -0.6813989\n",
      " -0.69165623 -0.68021977 -0.6901962  -0.682139   -0.683599   -0.68948317\n",
      " -0.68347186 -0.68984413 -0.68705267 -0.6859149  -0.6854509  -0.68519264\n",
      " -0.67886424 -0.6896316 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69911325 -0.6886438  -0.6962502  -0.6852345  -0.6933029  -0.69325805\n",
      " -0.6863401  -0.6942438  -0.69830257 -0.69762206 -0.68684673 -0.6920354\n",
      " -0.6938416  -0.689503   -0.68010324 -0.6961695  -0.6899894  -0.68405116\n",
      " -0.68693936 -0.6825541  -0.6958261  -0.6829102  -0.6794266  -0.6799828\n",
      " -0.68476546 -0.6921386  -0.69286317 -0.6997068  -0.6809098  -0.6897046\n",
      " -0.68285614 -0.6943242 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69297004 -0.6909175  -0.68432117 -0.6928758  -0.681421   -0.6818697\n",
      " -0.68344635 -0.68921685 -0.68985814 -0.68209404 -0.6945058  -0.68700385\n",
      " -0.6787532  -0.69606954 -0.6873218  -0.68894386 -0.6912495  -0.6928573\n",
      " -0.6852452  -0.6919681  -0.686463   -0.6912933  -0.6862892  -0.69204295\n",
      " -0.6885091  -0.69150937 -0.6967877  -0.68674636 -0.6805455  -0.6839446\n",
      " -0.68621683 -0.68868583], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6917148  -0.68849427 -0.6893598  -0.6877922  -0.6889452  -0.69574094\n",
      " -0.6801656  -0.68394035 -0.69509935 -0.6941502  -0.6870441  -0.69366705\n",
      " -0.6849693  -0.6920641  -0.6838506  -0.6902511  -0.67729145 -0.68675786\n",
      " -0.6952194  -0.68706876 -0.6929319  -0.6805826  -0.68149614 -0.686009\n",
      " -0.68799424 -0.685845   -0.6829089  -0.68832165 -0.676764   -0.6795204\n",
      " -0.6809757  -0.68171865], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69159293 -0.69467753 -0.6893648  -0.6813662  -0.6893573  -0.6869206\n",
      " -0.69103616 -0.6868963  -0.6889232  -0.6852046  -0.6925649  -0.68625057\n",
      " -0.6874055  -0.69013226 -0.67813605 -0.690985   -0.6828954  -0.68788326\n",
      " -0.67886966 -0.68456256 -0.6795967  -0.6897128  -0.6914684  -0.6852705\n",
      " -0.6881022  -0.68578285 -0.67873955 -0.6908193  -0.6953477  -0.6845427\n",
      " -0.6779839  -0.6933384 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.68760604 -0.6829008  -0.6852828  -0.6964196  -0.6981499  -0.68799794\n",
      " -0.67447495 -0.68600994 -0.6882719  -0.681476   -0.6896753  -0.69261914\n",
      " -0.7005719  -0.68680686 -0.69085133 -0.68513054 -0.6803753  -0.6751978\n",
      " -0.69369555 -0.6905347  -0.6878188  -0.67713904 -0.687168   -0.68343186\n",
      " -0.68679535 -0.6876487  -0.68258846 -0.6927567  -0.6867012  -0.6960747\n",
      " -0.6865994  -0.686286  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.68454945 -0.6867782  -0.69191104 -0.6880014  -0.6954012  -0.68501705\n",
      " -0.6849927  -0.68899643 -0.6838894  -0.68466234 -0.68214285 -0.68736064\n",
      " -0.6789215  -0.68230844 -0.6854178  -0.6772477  -0.6854471  -0.67708254\n",
      " -0.6917755  -0.67711556 -0.67158985 -0.6977789  -0.6841848  -0.6774211\n",
      " -0.6935435  -0.6868382  -0.68160444 -0.67974555 -0.67676634 -0.6904524\n",
      " -0.685236   -0.69413304], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6911001  -0.6899519  -0.681025   -0.692163   -0.6858086  -0.68802863\n",
      " -0.6962415  -0.6956818  -0.68242645 -0.6834781  -0.6788424  -0.68141735\n",
      " -0.6864254  -0.683512   -0.67838717 -0.6909886  -0.69030035 -0.6924085\n",
      " -0.6816441  -0.6798068  -0.69070476 -0.6843351  -0.68665564 -0.67952794\n",
      " -0.67857826 -0.6747567  -0.68576574 -0.6950978  -0.6875135  -0.6824977\n",
      " -0.6852043  -0.69295704], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.68117553 -0.68282807 -0.686004   -0.6738537  -0.68661624 -0.6867769\n",
      " -0.6766883  -0.68746424 -0.6876748  -0.68411654 -0.6845434  -0.67452055\n",
      " -0.6844393  -0.69297755 -0.6933761  -0.6936946  -0.6930101  -0.69026023\n",
      " -0.6979448  -0.67907435 -0.6789886  -0.69935536 -0.68411154 -0.6840734\n",
      " -0.6790638  -0.6949965  -0.6808041  -0.70163405 -0.6819622  -0.6924716\n",
      " -0.6926073  -0.6891166 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6833621  -0.68780166 -0.6903833  -0.6820451  -0.686756   -0.6756726\n",
      " -0.67867225 -0.6747371  -0.6890114  -0.6799968  -0.6739396  -0.6902904\n",
      " -0.6840973  -0.7000419  -0.689318   -0.6775342  -0.67571807 -0.68281907\n",
      " -0.6845498  -0.6846997  -0.6925662  -0.68478    -0.693799   -0.68687624\n",
      " -0.68725294 -0.6840287  -0.6829432  -0.68661284 -0.69699234 -0.6915656\n",
      " -0.69053125 -0.6892962 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6933287  -0.68052787 -0.68679345 -0.67609334 -0.69431156 -0.67983216\n",
      " -0.68964905 -0.6903679  -0.704646   -0.67993903 -0.6876559  -0.67973614\n",
      " -0.67441195 -0.687972   -0.69307053 -0.6894532  -0.6762678  -0.6889684\n",
      " -0.689325   -0.6915512  -0.69521844 -0.68063504 -0.67155075 -0.6958283\n",
      " -0.6883922  -0.67722857 -0.69314766 -0.6995037  -0.68380576 -0.6898197\n",
      " -0.6852142  -0.6924954 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.68224555 -0.6889795  -0.6727364  -0.68296593 -0.68117094 -0.6846282\n",
      " -0.6765847  -0.68660265 -0.6911673  -0.68337536 -0.67980754 -0.6886432\n",
      " -0.68519527 -0.67425555 -0.6812591  -0.67992884 -0.6889919  -0.6838855\n",
      " -0.6856867  -0.6899241  -0.686989   -0.6939857  -0.67572004 -0.6938966\n",
      " -0.6891292  -0.695317   -0.6872637  -0.67443264 -0.6818066  -0.6834737\n",
      " -0.67751384 -0.6785955 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6803589  -0.6787281  -0.6807804  -0.687731   -0.68645704 -0.68474346\n",
      " -0.6903477  -0.69177854 -0.6846002  -0.6790643  -0.68034095 -0.69421643\n",
      " -0.6883069  -0.68565935 -0.6808569  -0.66980624 -0.6806227  -0.69652\n",
      " -0.67700773 -0.6814921  -0.68701214 -0.69353354 -0.6936747  -0.6898657\n",
      " -0.67930156 -0.67294014 -0.67479855 -0.6760291  -0.68530446 -0.6784428\n",
      " -0.6925934  -0.6785117 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69363177 -0.67692435 -0.6787094  -0.69078845 -0.6938714  -0.6858326\n",
      " -0.68234336 -0.6732437  -0.6850788  -0.6916408  -0.67692673 -0.67890066\n",
      " -0.68843573 -0.6852928  -0.68710965 -0.6885045  -0.67862165 -0.6933432\n",
      " -0.6834125  -0.6745388  -0.6968869  -0.6805558  -0.6878963  -0.6760333\n",
      " -0.6886418  -0.67495066 -0.67900366 -0.6772684  -0.6793956  -0.6824095\n",
      " -0.6774487  -0.6953871 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69490564 -0.67242306 -0.6823335  -0.6792979  -0.7029318  -0.67901844\n",
      " -0.6925126  -0.6743623  -0.69740665 -0.69651604 -0.6851759  -0.6955446\n",
      " -0.690137   -0.6866871  -0.6846431  -0.68366134 -0.6758736  -0.6835924\n",
      " -0.68990207 -0.68924546 -0.6711238  -0.678484   -0.68293154 -0.68273866\n",
      " -0.68966603 -0.7017844  -0.6814309  -0.68326074 -0.6959106  -0.67705846\n",
      " -0.67944205 -0.67365587], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6980559  -0.687041   -0.67095137 -0.6928194  -0.67691135 -0.69158226\n",
      " -0.67708683 -0.67902225 -0.6777273  -0.6816932  -0.69023603 -0.6842578\n",
      " -0.6787938  -0.7002066  -0.6976006  -0.6875233  -0.70100117 -0.6904301\n",
      " -0.69384974 -0.6704342  -0.6852433  -0.672539   -0.6752016  -0.6880538\n",
      " -0.6831908  -0.69254875 -0.68024606 -0.6949383  -0.6685981  -0.691023\n",
      " -0.6836731  -0.6978016 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6856157  -0.67584014 -0.6774494  -0.6692139  -0.6738546  -0.6712263\n",
      " -0.6796734  -0.67393863 -0.679236   -0.7018986  -0.6783464  -0.67544925\n",
      " -0.6945254  -0.68774766 -0.6857534  -0.6814532  -0.6761452  -0.68558526\n",
      " -0.691375   -0.66679335 -0.68043774 -0.68757665 -0.6776697  -0.6810877\n",
      " -0.70962524 -0.67266417 -0.6859449  -0.69762903 -0.68251675 -0.6886274\n",
      " -0.68856883 -0.6967411 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6829574  -0.6780332  -0.68750834 -0.68467385 -0.68176603 -0.6889457\n",
      " -0.68417275 -0.6665783  -0.67526907 -0.6971595  -0.6743319  -0.68928355\n",
      " -0.6845642  -0.67444175 -0.6876507  -0.685584   -0.688054   -0.68620574\n",
      " -0.6900957  -0.67760104 -0.70307136 -0.7012468  -0.6786934  -0.68587863\n",
      " -0.7028511  -0.6837164  -0.6932746  -0.6850851  -0.6978932  -0.69267225\n",
      " -0.6999835  -0.7003622 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69273645 -0.67667127 -0.67952305 -0.7021048  -0.6894859  -0.67226535\n",
      " -0.6772517  -0.6726664  -0.6696468  -0.68944484 -0.6836637  -0.66828084\n",
      " -0.6816094  -0.68307066 -0.67497957 -0.6793018  -0.6779964  -0.67855465\n",
      " -0.7001033  -0.6827276  -0.6924163  -0.6846884  -0.6907895  -0.6777235\n",
      " -0.7100413  -0.68995345 -0.69153786 -0.67661065 -0.6865769  -0.6727989\n",
      " -0.6624545  -0.6747685 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.67654043 -0.6731522  -0.67830026 -0.6737075  -0.6894207  -0.6622536\n",
      " -0.68121934 -0.68890077 -0.6995847  -0.67424667 -0.68167245 -0.6698339\n",
      " -0.68579996 -0.6770344  -0.701988   -0.680047   -0.67391974 -0.6990061\n",
      " -0.6959136  -0.6625561  -0.6911498  -0.68472916 -0.67178714 -0.6751037\n",
      " -0.6775076  -0.6747552  -0.68112797 -0.6979455  -0.67257255 -0.6658278\n",
      " -0.67347825 -0.6693254 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.67601746 -0.6929567  -0.67139477 -0.6744956  -0.6888248  -0.68534964\n",
      " -0.68695104 -0.6882824  -0.66934824 -0.6666362  -0.68219984 -0.677242\n",
      " -0.68317103 -0.67663294 -0.6937274  -0.6797229  -0.66984147 -0.67661184\n",
      " -0.6804038  -0.6764242  -0.6746062  -0.6981369  -0.66905695 -0.69630563\n",
      " -0.6840846  -0.68281657 -0.6823659  -0.6968428  -0.6973127  -0.6884086\n",
      " -0.6736865  -0.67382085], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.68033975 -0.6893391  -0.68096167 -0.6688305  -0.6744187  -0.69431096\n",
      " -0.666133   -0.67656016 -0.68015444 -0.6780494  -0.67330754 -0.681812\n",
      " -0.66813284 -0.6860406  -0.67870903 -0.67105997 -0.69245744 -0.67934644\n",
      " -0.69017184 -0.6856423  -0.6723769  -0.6912191  -0.67364067 -0.68572575\n",
      " -0.6645737  -0.6725687  -0.69342804 -0.6771716  -0.6905129  -0.67938846\n",
      " -0.6651583  -0.6887233 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6802221  -0.687417   -0.66728467 -0.68381745 -0.6768028  -0.70445716\n",
      " -0.70782197 -0.70303345 -0.6875913  -0.663493   -0.67140675 -0.6755095\n",
      " -0.692537   -0.69650805 -0.6780228  -0.6984527  -0.67316    -0.67730135\n",
      " -0.68644387 -0.69149977 -0.6801049  -0.67832565 -0.6988596  -0.66290295\n",
      " -0.6744531  -0.7036093  -0.69713724 -0.689396   -0.6787931  -0.69720757\n",
      " -0.68738556 -0.67994463], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6872282  -0.69716984 -0.69376296 -0.68807226 -0.6716765  -0.6837792\n",
      " -0.6881585  -0.67655015 -0.69598407 -0.6854093  -0.6673538  -0.6689599\n",
      " -0.67975837 -0.68372476 -0.7096491  -0.6663501  -0.6706581  -0.6800464\n",
      " -0.68414176 -0.666936   -0.6829102  -0.6750184  -0.65805024 -0.67838633\n",
      " -0.69948125 -0.6723822  -0.69877183 -0.67498493 -0.68233794 -0.68284976\n",
      " -0.6804712  -0.69777155], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6949048  -0.666074   -0.6878279  -0.6873859  -0.6870295  -0.69112194\n",
      " -0.6777593  -0.6902755  -0.6962504  -0.6944043  -0.6965802  -0.67608136\n",
      " -0.6821927  -0.6630389  -0.66901994 -0.7024409  -0.6954978  -0.6698556\n",
      " -0.68544674 -0.68431485 -0.6859772  -0.6707656  -0.6993475  -0.68651927\n",
      " -0.7016597  -0.6808184  -0.6913044  -0.68401617 -0.66969085 -0.6841613\n",
      " -0.6596141  -0.6750138 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6684355  -0.6856635  -0.7000004  -0.6705192  -0.69994056 -0.66694355\n",
      " -0.6664392  -0.6722965  -0.6723158  -0.6660228  -0.69936275 -0.66005373\n",
      " -0.6578783  -0.67584264 -0.6689027  -0.6873225  -0.6811807  -0.6866335\n",
      " -0.665241   -0.6700917  -0.6615837  -0.67280936 -0.71583295 -0.7008923\n",
      " -0.6858193  -0.6862559  -0.6776715  -0.66842306 -0.6818518  -0.6973244\n",
      " -0.7128231  -0.66815394], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6649806  -0.6811157  -0.67106223 -0.6900398  -0.67751163 -0.69108117\n",
      " -0.67892474 -0.65583324 -0.6593819  -0.6653197  -0.6759101  -0.6696504\n",
      " -0.69471633 -0.6889089  -0.6858898  -0.66499436 -0.6821404  -0.6597943\n",
      " -0.67529273 -0.68252444 -0.6613324  -0.6937787  -0.68766236 -0.6922672\n",
      " -0.7025437  -0.70298266 -0.68573874 -0.6751262  -0.69160926 -0.66749054\n",
      " -0.69231164 -0.67178863], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.67229027 -0.6932122  -0.69827986 -0.6909076  -0.68319005 -0.6784954\n",
      " -0.68256605 -0.69135064 -0.67322296 -0.6936165  -0.67227316 -0.6766835\n",
      " -0.6643223  -0.6691985  -0.6850374  -0.70514524 -0.6728469  -0.6873559\n",
      " -0.6870325  -0.6640268  -0.6596879  -0.69285136 -0.66312224 -0.67153364\n",
      " -0.69180304 -0.66723645 -0.6783044  -0.7006962  -0.6962142  -0.6958124\n",
      " -0.67214113 -0.6831805 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7008589  -0.71365845 -0.6835467  -0.6716704  -0.65086573 -0.6755873\n",
      " -0.6753658  -0.6690906  -0.6682165  -0.68103516 -0.6841244  -0.7037378\n",
      " -0.6985959  -0.67209846 -0.65587604 -0.67409587 -0.6873051  -0.66866577\n",
      " -0.70594275 -0.7046429  -0.6859615  -0.7000762  -0.7012811  -0.69547486\n",
      " -0.68230814 -0.67302185 -0.6762839  -0.6747806  -0.6848934  -0.6624975\n",
      " -0.67697453 -0.70402545], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.66784555 -0.69482255 -0.6576248  -0.6829875  -0.69707453 -0.67845756\n",
      " -0.6771764  -0.67460984 -0.6959741  -0.6646142  -0.67906135 -0.7009425\n",
      " -0.6782838  -0.6701608  -0.68467194 -0.7054768  -0.6971578  -0.6587336\n",
      " -0.6851502  -0.70109606 -0.6793682  -0.6667296  -0.68522686 -0.68912035\n",
      " -0.69123507 -0.6706566  -0.68807703 -0.6638917  -0.6531249  -0.6828052\n",
      " -0.67965174 -0.6772746 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.67311335 -0.6776421  -0.7092185  -0.65780526 -0.6618452  -0.6802837\n",
      " -0.683841   -0.6522126  -0.66241485 -0.663397   -0.6708879  -0.67326045\n",
      " -0.6845952  -0.6887574  -0.66374314 -0.65960693 -0.6778459  -0.68530554\n",
      " -0.6691055  -0.6575135  -0.6826541  -0.67978257 -0.672261   -0.67796206\n",
      " -0.678526   -0.66042775 -0.6659103  -0.6826894  -0.6643433  -0.6789347\n",
      " -0.6785653  -0.67541444], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6779899  -0.6862287  -0.6706286  -0.654602   -0.7017522  -0.71109855\n",
      " -0.6869157  -0.69911075 -0.6596634  -0.66392434 -0.6679245  -0.6826091\n",
      " -0.6686545  -0.6541005  -0.65042955 -0.67625076 -0.67914194 -0.665474\n",
      " -0.6861214  -0.6955497  -0.6561162  -0.6752971  -0.6972755  -0.6667646\n",
      " -0.67177933 -0.69260156 -0.6527327  -0.67835164 -0.65810776 -0.6852739\n",
      " -0.6611542  -0.6814555 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6626599  -0.6943412  -0.6997261  -0.71190715 -0.67650217 -0.69172615\n",
      " -0.6854154  -0.6981565  -0.6702563  -0.69141597 -0.68765956 -0.6636683\n",
      " -0.65384287 -0.6970376  -0.69894665 -0.6947392  -0.6893569  -0.6690975\n",
      " -0.67315495 -0.6862767  -0.7035185  -0.67071664 -0.6904961  -0.6722291\n",
      " -0.68309987 -0.6749408  -0.6914572  -0.68304545 -0.6706154  -0.66420805\n",
      " -0.68597    -0.7061269 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.65432763 -0.70182794 -0.69225603 -0.67603683 -0.6900545  -0.6944844\n",
      " -0.6759243  -0.6955075  -0.69257325 -0.709918   -0.6876696  -0.66936755\n",
      " -0.6838133  -0.6677761  -0.69214296 -0.68919724 -0.6842845  -0.685122\n",
      " -0.6960052  -0.6966039  -0.67203724 -0.6706838  -0.6932105  -0.6580271\n",
      " -0.6950363  -0.6764809  -0.67696446 -0.6620888  -0.68286806 -0.65993655\n",
      " -0.6637     -0.66438514], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6909616  -0.67076695 -0.655364   -0.6534062  -0.64846873 -0.6709614\n",
      " -0.6950338  -0.6701822  -0.670312   -0.6615978  -0.66102827 -0.6783026\n",
      " -0.68335015 -0.6788529  -0.6659331  -0.69806886 -0.6614298  -0.66815287\n",
      " -0.6963189  -0.6682297  -0.6834868  -0.6706703  -0.6940581  -0.6856507\n",
      " -0.6710075  -0.6508708  -0.6997318  -0.6600393  -0.65283567 -0.662237\n",
      " -0.6805913  -0.68713385], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6521208  -0.6799008  -0.6701855  -0.67677045 -0.66087836 -0.6796083\n",
      " -0.6755412  -0.651912   -0.68976116 -0.6486416  -0.6666051  -0.6807604\n",
      " -0.69995695 -0.67004186 -0.6831313  -0.66889584 -0.6546235  -0.6879455\n",
      " -0.6681315  -0.6876997  -0.68327206 -0.6835872  -0.63594    -0.66847634\n",
      " -0.68197083 -0.67168826 -0.66984344 -0.6613366  -0.6725841  -0.6960341\n",
      " -0.69748336 -0.67565745], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6825743  -0.6537242  -0.65573573 -0.6489967  -0.68460584 -0.67116165\n",
      " -0.6766434  -0.66172147 -0.70374954 -0.69559336 -0.67092025 -0.66105276\n",
      " -0.6860242  -0.6775313  -0.6878423  -0.65931594 -0.6920225  -0.6517788\n",
      " -0.676559   -0.64760405 -0.654056   -0.6754067  -0.69263756 -0.70271575\n",
      " -0.68050545 -0.7077122  -0.6895333  -0.66163915 -0.67640704 -0.6894745\n",
      " -0.6773283  -0.6604419 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6711177  -0.6941302  -0.6874375  -0.66847694 -0.67766786 -0.6800762\n",
      " -0.71078867 -0.6603825  -0.6641938  -0.7077961  -0.678991   -0.6759065\n",
      " -0.689744   -0.68346083 -0.68661577 -0.6710809  -0.66245353 -0.6911605\n",
      " -0.6868284  -0.69617856 -0.6553954  -0.6700054  -0.68359995 -0.66653425\n",
      " -0.67778224 -0.6728681  -0.6729959  -0.6647152  -0.6548213  -0.67643887\n",
      " -0.6798286  -0.6632359 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6641208  -0.6720113  -0.65416396 -0.68495584 -0.66944706 -0.6820171\n",
      " -0.6870534  -0.67343533 -0.6794581  -0.6862101  -0.66314346 -0.6643834\n",
      " -0.6454092  -0.6765683  -0.67429715 -0.6519929  -0.6877947  -0.6734251\n",
      " -0.6847739  -0.6548523  -0.6785844  -0.691954   -0.67337155 -0.68306327\n",
      " -0.670026   -0.67587465 -0.65460414 -0.6653031  -0.7283666  -0.6715817\n",
      " -0.6819868  -0.6626568 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.64810413 -0.700436   -0.6658359  -0.6966417  -0.65833044 -0.6704461\n",
      " -0.6588091  -0.70883894 -0.67542195 -0.66447675 -0.6803125  -0.6790528\n",
      " -0.6833361  -0.66693395 -0.68253577 -0.690095   -0.67330617 -0.668513\n",
      " -0.67961556 -0.6890662  -0.6655089  -0.669253   -0.65024054 -0.6780631\n",
      " -0.6794604  -0.66973513 -0.6704983  -0.6611167  -0.66473657 -0.66165423\n",
      " -0.6511496  -0.69353205], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6554097  -0.6664489  -0.67979    -0.6561563  -0.6669921  -0.6437127\n",
      " -0.63339543 -0.66689485 -0.6545795  -0.70063865 -0.6649313  -0.6599108\n",
      " -0.6788279  -0.6512878  -0.65462035 -0.6873076  -0.68263704 -0.65031016\n",
      " -0.6562019  -0.6663624  -0.6795502  -0.6770243  -0.66968447 -0.63754725\n",
      " -0.6538828  -0.68289167 -0.6825368  -0.6625055  -0.6794942  -0.661103\n",
      " -0.65467435 -0.6896725 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69012314 -0.67211854 -0.6468054  -0.69793755 -0.6784671  -0.6486953\n",
      " -0.6569557  -0.66184735 -0.6696292  -0.70692587 -0.6544894  -0.6673266\n",
      " -0.7095835  -0.65335745 -0.67707336 -0.6551602  -0.6517346  -0.683097\n",
      " -0.64433724 -0.6832015  -0.6661713  -0.66046095 -0.70550716 -0.7137977\n",
      " -0.6846899  -0.68888515 -0.70410347 -0.6731161  -0.6728511  -0.6888262\n",
      " -0.7033901  -0.67988294], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6861269  -0.6854786  -0.66006577 -0.6798684  -0.6933749  -0.64524966\n",
      " -0.66930175 -0.65231866 -0.6803626  -0.692971   -0.6650832  -0.67299354\n",
      " -0.67543066 -0.677881   -0.68007666 -0.67706853 -0.65776753 -0.64194584\n",
      " -0.67231965 -0.67216206 -0.67734635 -0.6812261  -0.6601567  -0.6616083\n",
      " -0.7042271  -0.65963256 -0.6400643  -0.666228   -0.64526474 -0.67004937\n",
      " -0.6709744  -0.66882503], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.65701175 -0.69315016 -0.68592644 -0.64770937 -0.6751222  -0.6733671\n",
      " -0.6770982  -0.65687054 -0.6633558  -0.673314   -0.67953426 -0.68601173\n",
      " -0.70314026 -0.6789719  -0.6771345  -0.6516563  -0.6647985  -0.66924703\n",
      " -0.6809038  -0.6886612  -0.6957018  -0.6854031  -0.65441775 -0.6860912\n",
      " -0.6497968  -0.6537168  -0.68107307 -0.6717681  -0.6765093  -0.7238196\n",
      " -0.6687282  -0.6857976 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6786205  -0.6610413  -0.6390116  -0.63930863 -0.66566235 -0.6521271\n",
      " -0.6816707  -0.651418   -0.65555793 -0.6555358  -0.64674103 -0.69490135\n",
      " -0.6596105  -0.647343   -0.6493439  -0.6790541  -0.6629521  -0.7003712\n",
      " -0.6814002  -0.68369055 -0.69279414 -0.6681856  -0.67804456 -0.6689188\n",
      " -0.66078645 -0.67290413 -0.68143994 -0.6575674  -0.6713142  -0.64891654\n",
      " -0.6796586  -0.68501645], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.68993586 -0.65421957 -0.66774696 -0.68187344 -0.6538519  -0.6536864\n",
      " -0.66995454 -0.6885491  -0.6634585  -0.6638821  -0.68039787 -0.6906471\n",
      " -0.66139996 -0.6743912  -0.6423093  -0.6470254  -0.6523148  -0.69510114\n",
      " -0.65362585 -0.68656945 -0.68784356 -0.6912124  -0.6543967  -0.69602877\n",
      " -0.7006216  -0.7083958  -0.64334154 -0.6476399  -0.6561531  -0.6448308\n",
      " -0.71503425 -0.6935661 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.66434675 -0.69408    -0.6905476  -0.65570605 -0.684462   -0.6642123\n",
      " -0.6930133  -0.66867685 -0.645052   -0.7089458  -0.706385   -0.67693937\n",
      " -0.68316317 -0.6802809  -0.68561757 -0.6614905  -0.66887105 -0.6681828\n",
      " -0.70162153 -0.6652214  -0.6619705  -0.6842469  -0.6493195  -0.65261877\n",
      " -0.65073895 -0.65511864 -0.6929205  -0.6422021  -0.67934006 -0.6545111\n",
      " -0.6494877  -0.64589036], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6492582  -0.6914181  -0.6835738  -0.66748106 -0.6730395  -0.6752433\n",
      " -0.6719179  -0.64539254 -0.65488064 -0.6671352  -0.68880194 -0.6551705\n",
      " -0.6567647  -0.70891815 -0.65773284 -0.70764065 -0.6473072  -0.64936197\n",
      " -0.6863792  -0.64730775 -0.6481857  -0.70191324 -0.6549502  -0.66507107\n",
      " -0.67592525 -0.6349149  -0.6686084  -0.6569521  -0.69992274 -0.639095\n",
      " -0.6438421  -0.65110123], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.65423274 -0.67074984 -0.6742395  -0.6893049  -0.66505843 -0.6822312\n",
      " -0.6961369  -0.6540353  -0.67255104 -0.6714521  -0.6864103  -0.65094095\n",
      " -0.67727816 -0.7021564  -0.66336715 -0.681255   -0.65686715 -0.6725189\n",
      " -0.6939745  -0.686547   -0.65612215 -0.6667164  -0.67080873 -0.69179934\n",
      " -0.6653571  -0.67746556 -0.6670948  -0.6692425  -0.6653177  -0.68453825\n",
      " -0.6525133  -0.7112983 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.65073514 -0.65268415 -0.6503112  -0.6682946  -0.66788745 -0.68411636\n",
      " -0.6770735  -0.65503156 -0.68101156 -0.6663231  -0.676226   -0.6657361\n",
      " -0.68710434 -0.7006405  -0.6390495  -0.6616241  -0.6366898  -0.66304445\n",
      " -0.6628851  -0.68837625 -0.6719876  -0.6637888  -0.68241614 -0.65639985\n",
      " -0.6849532  -0.6527895  -0.6756897  -0.6960597  -0.6689246  -0.67796093\n",
      " -0.6596268  -0.70094526], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.674028   -0.6526588  -0.6838302  -0.6618502  -0.687201   -0.67131263\n",
      " -0.734596   -0.6659123  -0.6380814  -0.67336833 -0.67555517 -0.6967082\n",
      " -0.6619901  -0.65991956 -0.6553466  -0.644241   -0.69778    -0.64378476\n",
      " -0.7127502  -0.65825415 -0.661509   -0.67974013 -0.66366935 -0.6691629\n",
      " -0.6919126  -0.6801069  -0.63875574 -0.6840358  -0.654644   -0.6556346\n",
      " -0.6388165  -0.64520013], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6752762  -0.6675353  -0.6306167  -0.6447932  -0.6533582  -0.6812292\n",
      " -0.66915005 -0.6610731  -0.65960103 -0.6725112  -0.6522224  -0.668806\n",
      " -0.63723    -0.64745116 -0.6396188  -0.7162284  -0.6532059  -0.64762616\n",
      " -0.6356431  -0.71112776 -0.67849493 -0.6702065  -0.6638589  -0.6380452\n",
      " -0.66886663 -0.65516967 -0.6906858  -0.68110275 -0.65586936 -0.6647192\n",
      " -0.6538906  -0.67564696], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6740579  -0.6968203  -0.66159326 -0.678398   -0.67235863 -0.64567727\n",
      " -0.66581523 -0.6368046  -0.68509614 -0.6558415  -0.6815933  -0.64851993\n",
      " -0.68437374 -0.67985094 -0.63793224 -0.7053032  -0.63983715 -0.63565624\n",
      " -0.65316993 -0.6900138  -0.6421205  -0.67894506 -0.6629776  -0.63811165\n",
      " -0.6545738  -0.63747    -0.6623785  -0.6662253  -0.65354687 -0.6820806\n",
      " -0.67429054 -0.6576339 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6506799  -0.6460312  -0.6699891  -0.66318953 -0.6823074  -0.7060778\n",
      " -0.64485234 -0.67375505 -0.6728029  -0.6411599  -0.63197875 -0.6680008\n",
      " -0.6994086  -0.6356497  -0.62455285 -0.6411599  -0.65603226 -0.67401063\n",
      " -0.65475506 -0.65085745 -0.66398495 -0.68346536 -0.6882011  -0.64818406\n",
      " -0.65576226 -0.6886894  -0.72986925 -0.62991697 -0.6655479  -0.64507014\n",
      " -0.6435562  -0.64788616], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.64563584 -0.67254955 -0.68984693 -0.6859453  -0.6578188  -0.690731\n",
      " -0.65270394 -0.70698047 -0.68107575 -0.63806885 -0.6790429  -0.65341043\n",
      " -0.6747426  -0.6829615  -0.63755393 -0.63110137 -0.6734369  -0.643846\n",
      " -0.6490345  -0.71213925 -0.686601   -0.6269131  -0.66786104 -0.64565814\n",
      " -0.657332   -0.6513978  -0.6571249  -0.6897122  -0.67865205 -0.6704036\n",
      " -0.6447189  -0.6702601 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6849015  -0.67960316 -0.6540018  -0.6253504  -0.66424453 -0.67566013\n",
      " -0.64729327 -0.6512612  -0.6510243  -0.6385238  -0.6685095  -0.63739717\n",
      " -0.71495867 -0.6670429  -0.6612086  -0.6683267  -0.7245517  -0.6387177\n",
      " -0.666595   -0.66124946 -0.67402846 -0.6523404  -0.6926937  -0.65053016\n",
      " -0.61376595 -0.65130943 -0.6396447  -0.70227873 -0.64927816 -0.6591197\n",
      " -0.6530726  -0.6610108 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6233782  -0.65755    -0.6413319  -0.69138145 -0.6347335  -0.67259616\n",
      " -0.6742033  -0.67949235 -0.6528977  -0.6399322  -0.63891727 -0.6300475\n",
      " -0.6969371  -0.66768926 -0.687232   -0.70364004 -0.6788829  -0.64371526\n",
      " -0.65245324 -0.6986801  -0.62248886 -0.6821392  -0.64945835 -0.6939503\n",
      " -0.6782278  -0.6761324  -0.69948083 -0.69300187 -0.6801652  -0.6446825\n",
      " -0.6223585  -0.62295336], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.64872557 -0.63986945 -0.67955863 -0.70463204 -0.6489815  -0.620525\n",
      " -0.6287147  -0.63755774 -0.6459772  -0.648458   -0.6256817  -0.66276926\n",
      " -0.6743833  -0.6553783  -0.68190753 -0.6787352  -0.6207053  -0.61879134\n",
      " -0.64796436 -0.6627642  -0.66495675 -0.6531158  -0.6514994  -0.6438067\n",
      " -0.6571055  -0.68831766 -0.61867    -0.64772123 -0.6542093  -0.6895504\n",
      " -0.64627326 -0.64881134], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.65777373 -0.6999744  -0.65641135 -0.6652908  -0.7148419  -0.67566895\n",
      " -0.6538323  -0.67825466 -0.68970925 -0.62954205 -0.6431957  -0.66953623\n",
      " -0.6545852  -0.6565487  -0.6352392  -0.6312002  -0.67036957 -0.6946329\n",
      " -0.6753639  -0.67033345 -0.64103085 -0.63599074 -0.6976187  -0.6787396\n",
      " -0.7454374  -0.66373163 -0.6474002  -0.67741174 -0.6804874  -0.6831395\n",
      " -0.62345636 -0.67178017], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7166704  -0.6632567  -0.66579145 -0.66593176 -0.6696967  -0.73131025\n",
      " -0.6287999  -0.6376906  -0.62785465 -0.64441395 -0.67987686 -0.6667573\n",
      " -0.6951736  -0.6487475  -0.6807285  -0.64096916 -0.6601566  -0.6209649\n",
      " -0.68600017 -0.6552353  -0.67540157 -0.68724835 -0.6651363  -0.60209787\n",
      " -0.6910499  -0.6484988  -0.6282419  -0.67937905 -0.6751001  -0.6917522\n",
      " -0.69718957 -0.6628076 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.68152773 -0.64084226 -0.6850252  -0.62639254 -0.6743984  -0.6254041\n",
      " -0.683744   -0.68853486 -0.67622745 -0.66991806 -0.62154335 -0.7163846\n",
      " -0.69868577 -0.6792532  -0.6352084  -0.68376684 -0.67421573 -0.65233094\n",
      " -0.62162256 -0.6760651  -0.6288493  -0.73327637 -0.62477034 -0.68585986\n",
      " -0.6892776  -0.623688   -0.68378407 -0.6306215  -0.6532053  -0.6093581\n",
      " -0.6994552  -0.657125  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6511316  -0.66610986 -0.6555431  -0.66968024 -0.631993   -0.6369617\n",
      " -0.66272634 -0.61722463 -0.66739315 -0.6568829  -0.59393334 -0.6605017\n",
      " -0.6698256  -0.6734264  -0.6695067  -0.6466428  -0.62865937 -0.6215915\n",
      " -0.61065984 -0.67598933 -0.6113215  -0.702369   -0.6832647  -0.68506694\n",
      " -0.70588565 -0.69020426 -0.6865956  -0.66198194 -0.65668756 -0.7071724\n",
      " -0.6548713  -0.68032944], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6792893  -0.6555369  -0.6339632  -0.68473035 -0.701305   -0.6650762\n",
      " -0.6427803  -0.6484312  -0.69887626 -0.6595323  -0.62596095 -0.66072243\n",
      " -0.62816185 -0.653909   -0.64096725 -0.63283163 -0.6542527  -0.6483698\n",
      " -0.6708953  -0.7075887  -0.66626006 -0.7101036  -0.6141272  -0.62078005\n",
      " -0.6691465  -0.67215484 -0.64718276 -0.6553685  -0.67995656 -0.61129355\n",
      " -0.65185386 -0.6651978 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6748894  -0.6978654  -0.70190567 -0.62971354 -0.63665575 -0.7013241\n",
      " -0.6313848  -0.67551017 -0.66537845 -0.6953038  -0.64647084 -0.73742545\n",
      " -0.7055705  -0.64333206 -0.7046987  -0.632136   -0.6444018  -0.65225405\n",
      " -0.6693013  -0.65467584 -0.6582614  -0.6629304  -0.61450875 -0.6200691\n",
      " -0.69577205 -0.6106467  -0.6317112  -0.60865366 -0.6560154  -0.7035545\n",
      " -0.7004236  -0.6394708 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.64124364 -0.6679213  -0.67625475 -0.6597341  -0.6576395  -0.7148963\n",
      " -0.6424669  -0.6776411  -0.64513785 -0.6421536  -0.6471663  -0.667817\n",
      " -0.65101105 -0.7266412  -0.7144375  -0.6734902  -0.7003685  -0.6662419\n",
      " -0.62034553 -0.648235   -0.6687681  -0.6188094  -0.6740937  -0.66484606\n",
      " -0.6667143  -0.6826146  -0.61168945 -0.6446722  -0.62155485 -0.6981151\n",
      " -0.63177025 -0.68723595], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6622354  -0.7026777  -0.67502576 -0.68568915 -0.6731768  -0.6287813\n",
      " -0.65934503 -0.6987333  -0.6388524  -0.6825328  -0.6332117  -0.6167083\n",
      " -0.67763937 -0.69915533 -0.6576816  -0.62824965 -0.6860543  -0.67227864\n",
      " -0.7092043  -0.6798329  -0.70775837 -0.7102468  -0.6562546  -0.64643973\n",
      " -0.64253783 -0.6843976  -0.6281976  -0.72219205 -0.7065432  -0.62523305\n",
      " -0.66832644 -0.64484257], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.67682636 -0.65320265 -0.6647582  -0.67291427 -0.6426763  -0.6227933\n",
      " -0.63572717 -0.611696   -0.6215217  -0.6896628  -0.6393348  -0.6408091\n",
      " -0.6814463  -0.6170198  -0.6156068  -0.62028205 -0.66924447 -0.64509636\n",
      " -0.6541047  -0.64138675 -0.6771366  -0.6351876  -0.68027204 -0.6241522\n",
      " -0.6862412  -0.70029974 -0.6246548  -0.6781653  -0.649408   -0.6881161\n",
      " -0.6689911  -0.67273   ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6675598  -0.6849798  -0.6621679  -0.6772754  -0.6608868  -0.6683274\n",
      " -0.67489827 -0.6115503  -0.6778934  -0.69461536 -0.66511714 -0.6187567\n",
      " -0.6658297  -0.632607   -0.6786289  -0.61866903 -0.64282644 -0.6112192\n",
      " -0.6833053  -0.6657443  -0.637897   -0.65992147 -0.69692856 -0.68075067\n",
      " -0.72085345 -0.66678506 -0.6609375  -0.6968497  -0.70769787 -0.6252354\n",
      " -0.70325315 -0.6651395 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6521207  -0.671565   -0.6359948  -0.68188065 -0.61017764 -0.6684123\n",
      " -0.68752533 -0.6331973  -0.65140504 -0.6099355  -0.6911315  -0.6245248\n",
      " -0.6974766  -0.6467274  -0.6528222  -0.6874027  -0.67864215 -0.6505347\n",
      " -0.64636165 -0.68451494 -0.6376588  -0.6027397  -0.6835586  -0.6498765\n",
      " -0.63873065 -0.6586137  -0.6411511  -0.65329915 -0.65020406 -0.6546181\n",
      " -0.62036955 -0.66596067], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.65229255 -0.6798154  -0.67273694 -0.7170831  -0.6331327  -0.63656616\n",
      " -0.69007176 -0.58678865 -0.66366553 -0.6278778  -0.66450584 -0.7048943\n",
      " -0.638003   -0.63669485 -0.61650443 -0.6369931  -0.6980419  -0.6350899\n",
      " -0.6530812  -0.6358087  -0.6997518  -0.6337077  -0.6326576  -0.6505924\n",
      " -0.6517517  -0.6522538  -0.7020184  -0.64843154 -0.64448875 -0.70293903\n",
      " -0.62461627 -0.683251  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.67135555 -0.6877995  -0.62893057 -0.69171244 -0.6285156  -0.6718014\n",
      " -0.7088965  -0.709077   -0.63985425 -0.7163151  -0.6953382  -0.6448481\n",
      " -0.6203053  -0.68120736 -0.66601723 -0.66130084 -0.71959656 -0.645737\n",
      " -0.64289314 -0.6053591  -0.6751925  -0.7003121  -0.5971993  -0.6581204\n",
      " -0.648112   -0.6150026  -0.67510676 -0.6345957  -0.66846335 -0.59715277\n",
      " -0.6350864  -0.6909001 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7137039  -0.638263   -0.663694   -0.6515526  -0.62558657 -0.6735226\n",
      " -0.61127853 -0.68126607 -0.634001   -0.67272574 -0.64676106 -0.6874902\n",
      " -0.6438594  -0.6331216  -0.666553   -0.62757665 -0.70054245 -0.68020624\n",
      " -0.66813844 -0.7010603  -0.74279916 -0.6583486  -0.67963403 -0.71320665\n",
      " -0.68196493 -0.7002824  -0.6753983  -0.6275015  -0.63569665 -0.66685987\n",
      " -0.61726177 -0.6491274 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.63551784 -0.66169214 -0.63337386 -0.62393737 -0.6434026  -0.6489049\n",
      " -0.6419088  -0.66471934 -0.7006153  -0.627055   -0.6451887  -0.6032678\n",
      " -0.70917404 -0.61826867 -0.67820734 -0.6234352  -0.63616073 -0.65879816\n",
      " -0.6791356  -0.64086515 -0.6994506  -0.6688748  -0.6991553  -0.67164594\n",
      " -0.6853527  -0.693389   -0.6566596  -0.6695715  -0.6532745  -0.6290302\n",
      " -0.6397313  -0.667127  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7221261  -0.5975557  -0.6750564  -0.640864   -0.68693525 -0.62060595\n",
      " -0.6388802  -0.6460206  -0.6755693  -0.6174277  -0.605811   -0.6723476\n",
      " -0.614185   -0.62733746 -0.6467867  -0.6475531  -0.6967498  -0.6085005\n",
      " -0.66560364 -0.599783   -0.6870121  -0.71585953 -0.706758   -0.6272837\n",
      " -0.69359064 -0.66907024 -0.7242298  -0.61980706 -0.70361704 -0.635046\n",
      " -0.71066594 -0.65645945], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.64208496 -0.7278012  -0.6502628  -0.6844203  -0.6580067  -0.74338365\n",
      " -0.61696506 -0.6596567  -0.6812333  -0.6775731  -0.5946247  -0.63114715\n",
      " -0.68071234 -0.6339668  -0.65606797 -0.65515494 -0.670482   -0.5996115\n",
      " -0.6006584  -0.68356407 -0.6474832  -0.67809206 -0.6876896  -0.6121099\n",
      " -0.65953124 -0.64057684 -0.6212512  -0.6372789  -0.6446403  -0.70241684\n",
      " -0.6439741  -0.6833618 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6756582  -0.6520969  -0.64776826 -0.6252419  -0.6702848  -0.69308543\n",
      " -0.7106173  -0.66052675 -0.6563233  -0.61812055 -0.61773676 -0.6175095\n",
      " -0.6715775  -0.59253925 -0.6909917  -0.6237416  -0.6349549  -0.6107197\n",
      " -0.6267078  -0.7035606  -0.62048966 -0.6495186  -0.6646568  -0.6424712\n",
      " -0.666633   -0.59270805 -0.6069269  -0.686137   -0.6950809  -0.6216124\n",
      " -0.69255227 -0.630177  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.61141026 -0.6605108  -0.6229678  -0.6887571  -0.6766072  -0.64100003\n",
      " -0.69214994 -0.66314226 -0.6423369  -0.72858053 -0.6557443  -0.6282103\n",
      " -0.6200032  -0.6083431  -0.6405503  -0.70150805 -0.6897739  -0.6015519\n",
      " -0.62281764 -0.7013415  -0.65177345 -0.6500975  -0.634357   -0.68082917\n",
      " -0.69620425 -0.6057065  -0.6230484  -0.62118846 -0.63737595 -0.6770909\n",
      " -0.649904   -0.7108996 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.67361355 -0.63969684 -0.6575082  -0.7008077  -0.6638773  -0.673229\n",
      " -0.6594582  -0.6837027  -0.5908897  -0.6359478  -0.680911   -0.6178519\n",
      " -0.7184812  -0.71192026 -0.6415058  -0.6102171  -0.64441544 -0.630996\n",
      " -0.6848055  -0.6764325  -0.6188833  -0.60058    -0.6788581  -0.6695023\n",
      " -0.6867612  -0.6525117  -0.65846735 -0.6505374  -0.660425   -0.67427284\n",
      " -0.63565654 -0.68423027], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6497577  -0.6538512  -0.6300888  -0.6419083  -0.6370841  -0.6964242\n",
      " -0.6503883  -0.67430246 -0.72568285 -0.6530922  -0.6030893  -0.63874173\n",
      " -0.64732313 -0.6425982  -0.64513886 -0.6222968  -0.6196315  -0.65734583\n",
      " -0.62527454 -0.6451924  -0.62934947 -0.6346901  -0.6478298  -0.67557776\n",
      " -0.60665464 -0.6813148  -0.65923    -0.6902384  -0.6514265  -0.6581718\n",
      " -0.6391011  -0.6544138 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5973911  -0.6548276  -0.59726715 -0.6368299  -0.67660975 -0.6237053\n",
      " -0.64712334 -0.6242637  -0.6897299  -0.6356035  -0.6275565  -0.653566\n",
      " -0.69261396 -0.67070526 -0.6796233  -0.62627697 -0.6135645  -0.6710237\n",
      " -0.6212663  -0.68600506 -0.62991613 -0.6410247  -0.6732234  -0.611155\n",
      " -0.6388721  -0.69358104 -0.6431376  -0.63941306 -0.65393066 -0.5793616\n",
      " -0.6625169  -0.64457417], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6167404  -0.5956844  -0.63504994 -0.68861157 -0.6129132  -0.6460932\n",
      " -0.64754504 -0.61049646 -0.65835255 -0.66476405 -0.6563906  -0.6332075\n",
      " -0.6929012  -0.60653853 -0.62892586 -0.6835925  -0.6285137  -0.65660435\n",
      " -0.6798717  -0.71717644 -0.6683473  -0.6433413  -0.6292939  -0.611136\n",
      " -0.6930524  -0.634172   -0.58845073 -0.6546376  -0.68294525 -0.7094351\n",
      " -0.6493532  -0.6803117 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.627639   -0.7159357  -0.7211252  -0.6387443  -0.64952755 -0.68553585\n",
      " -0.6446495  -0.6232268  -0.55705297 -0.646579   -0.6703395  -0.6282566\n",
      " -0.59537446 -0.6556542  -0.67184705 -0.58525527 -0.6708667  -0.7002325\n",
      " -0.7250016  -0.61525893 -0.59032845 -0.62301517 -0.59917426 -0.6050771\n",
      " -0.604045   -0.58995783 -0.6538363  -0.62393045 -0.65564203 -0.671618\n",
      " -0.60593295 -0.6441911 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6768549  -0.6703627  -0.6091731  -0.6828513  -0.6580581  -0.5814839\n",
      " -0.6876085  -0.64453745 -0.63389593 -0.6526235  -0.66206014 -0.5955045\n",
      " -0.64862967 -0.60986865 -0.6071787  -0.58810705 -0.64601374 -0.60081744\n",
      " -0.64615715 -0.6615278  -0.67307335 -0.6672656  -0.609813   -0.6613379\n",
      " -0.70406294 -0.59144723 -0.5655953  -0.5698113  -0.6192425  -0.64938223\n",
      " -0.65454686 -0.7134181 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6129834  -0.6634145  -0.69213134 -0.67654437 -0.6721016  -0.6347219\n",
      " -0.6502785  -0.6100521  -0.6703639  -0.5976039  -0.63073504 -0.64613056\n",
      " -0.71407616 -0.65903044 -0.61531043 -0.6052799  -0.57672524 -0.58765006\n",
      " -0.6948565  -0.6411349  -0.6351847  -0.7011152  -0.62549    -0.58857125\n",
      " -0.56185734 -0.5687939  -0.6818918  -0.6567007  -0.6409019  -0.56379044\n",
      " -0.6327834  -0.6394235 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6386078  -0.6392685  -0.66066515 -0.657302   -0.6787455  -0.66020757\n",
      " -0.6918465  -0.640442   -0.65622836 -0.61363536 -0.6513338  -0.6767405\n",
      " -0.5890167  -0.65491515 -0.67248297 -0.6018752  -0.67011225 -0.6194018\n",
      " -0.73107743 -0.64084995 -0.64317894 -0.64338565 -0.6519915  -0.6201263\n",
      " -0.59412014 -0.60958296 -0.633713   -0.63797855 -0.59227264 -0.5906931\n",
      " -0.69722486 -0.64200246], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.59878016 -0.6284267  -0.6717564  -0.64301425 -0.6747763  -0.6152535\n",
      " -0.6235649  -0.6125765  -0.6412606  -0.5953507  -0.63611    -0.61186016\n",
      " -0.6434844  -0.61307526 -0.58995    -0.64829814 -0.6148562  -0.6471547\n",
      " -0.6834522  -0.6691716  -0.64139473 -0.6647348  -0.6011491  -0.5954161\n",
      " -0.65884084 -0.5856348  -0.65007687 -0.58823836 -0.67096364 -0.5797999\n",
      " -0.68171513 -0.6105    ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.67484045 -0.6546564  -0.6508407  -0.6829922  -0.62676346 -0.61200374\n",
      " -0.64764637 -0.590263   -0.7177508  -0.63987154 -0.6870595  -0.63469076\n",
      " -0.61995137 -0.7446065  -0.6635687  -0.6671473  -0.59280926 -0.6619784\n",
      " -0.6414671  -0.6816818  -0.7021128  -0.5945289  -0.6248739  -0.7005147\n",
      " -0.58456504 -0.65275675 -0.63116366 -0.69484663 -0.6789211  -0.6346351\n",
      " -0.6377977  -0.6485393 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6424273  -0.5698532  -0.64707446 -0.6205342  -0.61479133 -0.6293049\n",
      " -0.5949389  -0.6491396  -0.607091   -0.7151432  -0.6191722  -0.6420547\n",
      " -0.6032869  -0.58590865 -0.66829675 -0.6051128  -0.61422837 -0.6576456\n",
      " -0.63102365 -0.74417    -0.7059374  -0.6331565  -0.6420033  -0.6331413\n",
      " -0.6702742  -0.54642874 -0.66888666 -0.6760862  -0.6798925  -0.637333\n",
      " -0.6294788  -0.65004086], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.60403085 -0.68003285 -0.63234806 -0.5995407  -0.6355408  -0.71075976\n",
      " -0.6196634  -0.7079939  -0.6834409  -0.5955547  -0.6247946  -0.7093053\n",
      " -0.73350155 -0.63675267 -0.6944679  -0.68496996 -0.6649537  -0.6403876\n",
      " -0.6076238  -0.6379522  -0.6145056  -0.58092964 -0.6681427  -0.6020708\n",
      " -0.6818277  -0.58247703 -0.61456746 -0.64806324 -0.62348145 -0.67096096\n",
      " -0.6377811  -0.6596191 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.63376904 -0.6441315  -0.60571057 -0.6490581  -0.60147655 -0.6500257\n",
      " -0.66575056 -0.6252757  -0.5957598  -0.6311353  -0.66355026 -0.6252912\n",
      " -0.5703674  -0.6764732  -0.60185665 -0.5737774  -0.5900185  -0.59569466\n",
      " -0.6871427  -0.6022232  -0.6180194  -0.58759546 -0.60240483 -0.5884096\n",
      " -0.62867594 -0.64530766 -0.62080306 -0.593726   -0.628711   -0.657525\n",
      " -0.58464295 -0.61528444], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.60011226 -0.69274515 -0.6287733  -0.6226276  -0.69624096 -0.6692888\n",
      " -0.6024213  -0.6875413  -0.6209688  -0.62479913 -0.64520097 -0.639342\n",
      " -0.62452626 -0.6278821  -0.6839997  -0.6147779  -0.6140046  -0.60566384\n",
      " -0.6147128  -0.63257706 -0.63091284 -0.6118279  -0.65764457 -0.65607315\n",
      " -0.6725179  -0.58350766 -0.5869888  -0.68664014 -0.6744484  -0.61406183\n",
      " -0.6919751  -0.6368513 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6522172  -0.6541192  -0.6671167  -0.6454426  -0.6264096  -0.63905525\n",
      " -0.6385461  -0.6156364  -0.6326237  -0.70954573 -0.6298358  -0.7005557\n",
      " -0.6022676  -0.675367   -0.76330084 -0.6242875  -0.6111861  -0.6228927\n",
      " -0.6669918  -0.6020205  -0.71530926 -0.5345496  -0.6294114  -0.6238401\n",
      " -0.65613556 -0.618341   -0.6099328  -0.64409846 -0.65542114 -0.59589577\n",
      " -0.6573111  -0.61228883], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.65349525 -0.6264328  -0.5536053  -0.7055062  -0.69404    -0.6683879\n",
      " -0.6545418  -0.66153985 -0.6247589  -0.68757415 -0.78847396 -0.6509176\n",
      " -0.64014804 -0.6238776  -0.63847214 -0.7652441  -0.6925408  -0.6065238\n",
      " -0.61336863 -0.63656306 -0.61429864 -0.5879347  -0.6448545  -0.5901073\n",
      " -0.6291889  -0.613041   -0.64201003 -0.8005811  -0.5800522  -0.66861516\n",
      " -0.6767986  -0.58134305], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6148204  -0.69784045 -0.7028636  -0.642849   -0.60673887 -0.63302976\n",
      " -0.6386438  -0.6327521  -0.6391009  -0.6459191  -0.6572202  -0.6206932\n",
      " -0.60193336 -0.57837677 -0.5875263  -0.6419277  -0.59668785 -0.68761384\n",
      " -0.6264993  -0.7476976  -0.67741287 -0.5867576  -0.6505833  -0.6561397\n",
      " -0.68772554 -0.64879936 -0.63453054 -0.63574    -0.5887277  -0.6999477\n",
      " -0.59805167 -0.6114476 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.643515   -0.6249937  -0.6564087  -0.6593972  -0.6366804  -0.6134013\n",
      " -0.6315333  -0.6564657  -0.62163633 -0.6187827  -0.65210104 -0.6527847\n",
      " -0.64377224 -0.59501344 -0.6381894  -0.6541115  -0.6002234  -0.66295123\n",
      " -0.6359559  -0.6420617  -0.6332113  -0.6416961  -0.6570491  -0.62254786\n",
      " -0.5907883  -0.6836216  -0.63013846 -0.6411542  -0.6542061  -0.66649765\n",
      " -0.6506046  -0.6481081 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6400124  -0.61894226 -0.6493896  -0.5776726  -0.649352   -0.66489714\n",
      " -0.6577695  -0.7120947  -0.65175647 -0.69312084 -0.59743565 -0.6212085\n",
      " -0.6474052  -0.55616844 -0.65300363 -0.61201954 -0.63279796 -0.6096035\n",
      " -0.6591371  -0.6730311  -0.6863331  -0.67954624 -0.63038003 -0.5738722\n",
      " -0.61535406 -0.7101223  -0.60353196 -0.68646145 -0.6472628  -0.62443924\n",
      " -0.60644317 -0.7045294 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.57976323 -0.66127896 -0.74688953 -0.6186856  -0.6541516  -0.62634695\n",
      " -0.6271261  -0.6086233  -0.64142424 -0.58988714 -0.68488646 -0.6280516\n",
      " -0.6834786  -0.7559079  -0.70202684 -0.6672615  -0.61042017 -0.6920827\n",
      " -0.7462672  -0.6108234  -0.6625001  -0.59932953 -0.6615323  -0.56707805\n",
      " -0.66660964 -0.71356255 -0.64973724 -0.6500062  -0.6143886  -0.6800374\n",
      " -0.70111513 -0.6654781 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.65979576 -0.67448384 -0.6132392  -0.6648632  -0.637709   -0.6634303\n",
      " -0.72406614 -0.5905873  -0.665677   -0.5904493  -0.63481027 -0.6293404\n",
      " -0.6909404  -0.57191014 -0.58705324 -0.7296326  -0.64131427 -0.7245258\n",
      " -0.61472565 -0.65007764 -0.5715707  -0.67848986 -0.63101476 -0.57706475\n",
      " -0.5938567  -0.6684321  -0.5951468  -0.6199827  -0.591689   -0.65412986\n",
      " -0.6632418  -0.6346998 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7090205  -0.5903042  -0.5931756  -0.66534764 -0.6490937  -0.63133574\n",
      " -0.637411   -0.6710762  -0.6069414  -0.5662228  -0.6600549  -0.64016604\n",
      " -0.5666708  -0.6686343  -0.6199414  -0.6444286  -0.5877205  -0.65514916\n",
      " -0.7088156  -0.64663845 -0.6122641  -0.5539228  -0.61812496 -0.6582335\n",
      " -0.6548291  -0.5834134  -0.6153897  -0.64916813 -0.56768024 -0.6304469\n",
      " -0.6308804  -0.6937016 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.62639153 -0.62576574 -0.5541745  -0.6654958  -0.6687091  -0.5772139\n",
      " -0.5473273  -0.6138505  -0.57401186 -0.62226766 -0.61973053 -0.66787535\n",
      " -0.62765074 -0.58148587 -0.7078247  -0.55879694 -0.631577   -0.59157413\n",
      " -0.5854311  -0.61449206 -0.63049555 -0.6047475  -0.63809013 -0.58560884\n",
      " -0.63719416 -0.6422617  -0.6467736  -0.65083313 -0.7041644  -0.60210466\n",
      " -0.6034234  -0.6125413 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6609638  -0.59238136 -0.6968981  -0.7011524  -0.6033722  -0.5725469\n",
      " -0.63518363 -0.65960246 -0.69720894 -0.63734734 -0.5796874  -0.6988717\n",
      " -0.5655364  -0.661006   -0.5794256  -0.6579688  -0.57587224 -0.60819304\n",
      " -0.7451437  -0.5910884  -0.710494   -0.7356591  -0.6560868  -0.60457283\n",
      " -0.65529865 -0.63420033 -0.6452614  -0.69880205 -0.57424456 -0.5739214\n",
      " -0.6900134  -0.56788826], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.64474213 -0.6394684  -0.62101483 -0.613766   -0.6573201  -0.66144377\n",
      " -0.65326905 -0.5885166  -0.63186854 -0.59431976 -0.6562169  -0.6057756\n",
      " -0.6144307  -0.62479025 -0.7164423  -0.70927477 -0.6491106  -0.6360387\n",
      " -0.6827109  -0.5948146  -0.6832899  -0.72804964 -0.6457984  -0.70475155\n",
      " -0.6009576  -0.6229166  -0.6385878  -0.6328685  -0.62336755 -0.61350083\n",
      " -0.676108   -0.66998076], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.59754527 -0.6755963  -0.665133   -0.67122066 -0.60174495 -0.6043575\n",
      " -0.69208986 -0.56117994 -0.6997715  -0.6389878  -0.6715385  -0.6602378\n",
      " -0.6871125  -0.5878742  -0.60269713 -0.7177552  -0.6396764  -0.6341603\n",
      " -0.55102754 -0.61665756 -0.5311973  -0.6451796  -0.6325828  -0.5524466\n",
      " -0.6385882  -0.6436832  -0.616184   -0.57089144 -0.604689   -0.6577874\n",
      " -0.5886787  -0.5994942 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7051432  -0.65581584 -0.6068558  -0.66200745 -0.551816   -0.5947111\n",
      " -0.5023507  -0.66582566 -0.5965024  -0.5968992  -0.54925305 -0.6123692\n",
      " -0.6315148  -0.6161648  -0.6036684  -0.6126907  -0.78870666 -0.6348109\n",
      " -0.66927767 -0.6400501  -0.60748863 -0.68120205 -0.6012302  -0.5732868\n",
      " -0.559673   -0.5566702  -0.6039455  -0.61585623 -0.576784   -0.6591661\n",
      " -0.69350135 -0.56222725], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.59209484 -0.634961   -0.65475357 -0.5726378  -0.5821606  -0.6285466\n",
      " -0.61408776 -0.58100873 -0.57656085 -0.62797904 -0.62133485 -0.632378\n",
      " -0.7487344  -0.5849352  -0.58568305 -0.58391285 -0.5739371  -0.6563207\n",
      " -0.66168356 -0.5717185  -0.6223448  -0.64287317 -0.6774687  -0.67794114\n",
      " -0.6642093  -0.6265211  -0.59107214 -0.59597856 -0.57260466 -0.6687186\n",
      " -0.63711566 -0.60282147], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.57270926 -0.5507964  -0.66382265 -0.5697218  -0.7498543  -0.6014153\n",
      " -0.72548145 -0.6045778  -0.657709   -0.60953265 -0.6186364  -0.5440573\n",
      " -0.6784645  -0.62486875 -0.67898655 -0.7001076  -0.60008514 -0.60754687\n",
      " -0.64402235 -0.596745   -0.58600485 -0.643537   -0.5831606  -0.54213774\n",
      " -0.6199549  -0.650259   -0.5965339  -0.66558397 -0.6163609  -0.55362844\n",
      " -0.655552   -0.574789  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.65424037 -0.6004493  -0.6241019  -0.530295   -0.67946184 -0.82828224\n",
      " -0.5894518  -0.6771951  -0.5747094  -0.69946396 -0.6078356  -0.55896854\n",
      " -0.6607227  -0.6655064  -0.60928    -0.6495504  -0.6060958  -0.58836144\n",
      " -0.6410531  -0.59107935 -0.65316266 -0.61444545 -0.56047165 -0.58568436\n",
      " -0.6534007  -0.7115991  -0.5777255  -0.6407991  -0.60046786 -0.6866881\n",
      " -0.58124876 -0.60678506], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5980022  -0.5873926  -0.61525065 -0.6475468  -0.667471   -0.5653336\n",
      " -0.6841583  -0.59840083 -0.6030027  -0.624912   -0.6125387  -0.58595526\n",
      " -0.6081187  -0.59294146 -0.6135708  -0.58908975 -0.74236846 -0.7575447\n",
      " -0.6132773  -0.68557584 -0.616089   -0.61873436 -0.64478254 -0.69254166\n",
      " -0.5833366  -0.6618858  -0.55194086 -0.5730127  -0.6680492  -0.5218127\n",
      " -0.5975901  -0.5614294 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.67909944 -0.65007854 -0.68169177 -0.56522936 -0.574293   -0.5920485\n",
      " -0.61673707 -0.5880424  -0.57244253 -0.6507331  -0.65301824 -0.64905155\n",
      " -0.68156666 -0.548336   -0.5308221  -0.69708693 -0.63220227 -0.5547858\n",
      " -0.6434526  -0.5912389  -0.63157415 -0.6059379  -0.68133163 -0.55547535\n",
      " -0.5244662  -0.55445606 -0.6126183  -0.60469794 -0.72451144 -0.5557046\n",
      " -0.59656274 -0.61451745], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6479169  -0.50373155 -0.55903304 -0.65036047 -0.5838525  -0.6254514\n",
      " -0.6587183  -0.6641697  -0.6095455  -0.5667084  -0.59191954 -0.58360374\n",
      " -0.62498426 -0.6298849  -0.56218004 -0.6312551  -0.63058376 -0.74692875\n",
      " -0.63721013 -0.5939157  -0.6063252  -0.6948986  -0.5802656  -0.60103786\n",
      " -0.62943774 -0.5582178  -0.6124067  -0.72740036 -0.60573006 -0.6197292\n",
      " -0.5890224  -0.5293083 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.63677025 -0.5794555  -0.6379023  -0.6335197  -0.6247169  -0.7099185\n",
      " -0.66738695 -0.6467621  -0.7090303  -0.6239385  -0.65011865 -0.57511634\n",
      " -0.5574038  -0.61005044 -0.6441846  -0.58159274 -0.5756911  -0.5691106\n",
      " -0.59465975 -0.5802855  -0.61970043 -0.72819555 -0.6708526  -0.5790749\n",
      " -0.61038107 -0.6389655  -0.6957535  -0.7032726  -0.5942094  -0.64316124\n",
      " -0.55850655 -0.5801134 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6543331  -0.5710373  -0.6162525  -0.6453682  -0.71031946 -0.559721\n",
      " -0.6169865  -0.55165213 -0.6073332  -0.6213363  -0.64719015 -0.5882852\n",
      " -0.62007976 -0.64442766 -0.5802109  -0.67423767 -0.67628175 -0.60953027\n",
      " -0.60453886 -0.7121633  -0.6247958  -0.585565   -0.51994795 -0.55513746\n",
      " -0.6774186  -0.6034338  -0.6430665  -0.6296776  -0.6121936  -0.5569034\n",
      " -0.74063385 -0.6519699 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.61064506 -0.5536801  -0.64885956 -0.57720196 -0.6193734  -0.5888186\n",
      " -0.6545252  -0.5611296  -0.63190174 -0.647136   -0.62264353 -0.57725793\n",
      " -0.5492744  -0.6298857  -0.6703259  -0.66317254 -0.66955006 -0.7103078\n",
      " -0.72191536 -0.6261788  -0.61930984 -0.57492626 -0.6095224  -0.61749417\n",
      " -0.5926016  -0.6873507  -0.6709746  -0.669117   -0.70611334 -0.54973423\n",
      " -0.5805765  -0.67821103], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.61416024 -0.55878544 -0.6190331  -0.5582334  -0.66773784 -0.69437516\n",
      " -0.5699557  -0.629893   -0.6312309  -0.5832987  -0.56016946 -0.6550244\n",
      " -0.5305855  -0.6351572  -0.5882269  -0.73030674 -0.6332298  -0.66491497\n",
      " -0.6270271  -0.60620123 -0.7422763  -0.5473071  -0.63049144 -0.6097388\n",
      " -0.6556647  -0.62539715 -0.7083968  -0.5656508  -0.62299216 -0.69333804\n",
      " -0.6352143  -0.6865871 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5653924  -0.60717505 -0.5043507  -0.6143881  -0.7060079  -0.56747174\n",
      " -0.60052025 -0.5576521  -0.5959484  -0.5969013  -0.68990517 -0.6240982\n",
      " -0.60271925 -0.5995318  -0.6424744  -0.61489135 -0.6042128  -0.6880942\n",
      " -0.64095646 -0.6297899  -0.51970977 -0.6811159  -0.5642673  -0.5669605\n",
      " -0.600488   -0.73101246 -0.55713236 -0.5447405  -0.4937052  -0.64074767\n",
      " -0.59245384 -0.63854903], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7205132  -0.59606516 -0.54336035 -0.75312483 -0.6496922  -0.5352207\n",
      " -0.6943704  -0.6216061  -0.5517413  -0.5736396  -0.54330033 -0.5378424\n",
      " -0.57165885 -0.57060194 -0.5533056  -0.6719918  -0.6482273  -0.65543574\n",
      " -0.6913765  -0.60526407 -0.5911233  -0.57012504 -0.5727681  -0.59934014\n",
      " -0.66992855 -0.53688747 -0.6506998  -0.518407   -0.632643   -0.6334195\n",
      " -0.5123453  -0.705666  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.57979226 -0.6652748  -0.7335251  -0.57169485 -0.55601984 -0.66504997\n",
      " -0.623991   -0.6153038  -0.53338003 -0.5489998  -0.5992254  -0.6058827\n",
      " -0.56425965 -0.6461943  -0.50433177 -0.679309   -0.5340692  -0.5680896\n",
      " -0.6611674  -0.56815016 -0.6239052  -0.6424321  -0.5751039  -0.52248883\n",
      " -0.63996977 -0.6186177  -0.5575343  -0.6358332  -0.6078753  -0.5855598\n",
      " -0.5885652  -0.62552917], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.63958424 -0.5523082  -0.6841722  -0.55986404 -0.61373013 -0.72032523\n",
      " -0.6808407  -0.6488385  -0.66209877 -0.61297476 -0.58143234 -0.5415716\n",
      " -0.55788517 -0.62393427 -0.55875754 -0.58076537 -0.6448926  -0.55541205\n",
      " -0.6202218  -0.5746611  -0.5612161  -0.6468955  -0.5517246  -0.6190352\n",
      " -0.69356084 -0.6610401  -0.6916198  -0.70434946 -0.54673344 -0.6314141\n",
      " -0.7279471  -0.59822047], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.50791264 -0.6246793  -0.67933166 -0.682005   -0.5923694  -0.6576988\n",
      " -0.7816708  -0.5777571  -0.7054864  -0.6481765  -0.6371193  -0.5973342\n",
      " -0.56428605 -0.60267615 -0.5181452  -0.53769475 -0.65530753 -0.56416047\n",
      " -0.66890347 -0.6269532  -0.5324539  -0.6026397  -0.51335585 -0.693405\n",
      " -0.5630132  -0.5363029  -0.5399684  -0.59072876 -0.6281451  -0.61462665\n",
      " -0.6376952  -0.68607396], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5756725  -0.55649644 -0.6349806  -0.81083626 -0.626905   -0.5722009\n",
      " -0.6672489  -0.6037441  -0.6807522  -0.6196209  -0.6542759  -0.66286886\n",
      " -0.66709995 -0.66094565 -0.5642451  -0.56567883 -0.5094172  -0.59543705\n",
      " -0.71031237 -0.68285525 -0.6395271  -0.5821184  -0.52935374 -0.5551363\n",
      " -0.53098714 -0.5187998  -0.6590202  -0.6062024  -0.60942274 -0.62345266\n",
      " -0.5715031  -0.6811049 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5960234  -0.64306206 -0.56109047 -0.56211776 -0.60138875 -0.6941992\n",
      " -0.6373218  -0.58436984 -0.645824   -0.59026235 -0.80110455 -0.5718745\n",
      " -0.6420611  -0.5869105  -0.630787   -0.5275873  -0.54977    -0.6241826\n",
      " -0.548664   -0.6081849  -0.5677976  -0.68239725 -0.5591741  -0.543867\n",
      " -0.68615276 -0.7329738  -0.63519984 -0.56840414 -0.62468874 -0.5408292\n",
      " -0.50872016 -0.66229475], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5566184  -0.60265446 -0.65165955 -0.7182028  -0.5741032  -0.6456796\n",
      " -0.6167775  -0.57134265 -0.6721927  -0.6236637  -0.50276047 -0.507026\n",
      " -0.60377616 -0.63687503 -0.7011046  -0.6328401  -0.6531386  -0.49390644\n",
      " -0.4889611  -0.57698107 -0.63195944 -0.496611   -0.66782635 -0.6546035\n",
      " -0.6154014  -0.6593764  -0.5351967  -0.6093003  -0.657735   -0.6284876\n",
      " -0.6695486  -0.6624069 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.51838875 -0.52738065 -0.49721035 -0.6729513  -0.7015574  -0.6662203\n",
      " -0.7042045  -0.6350305  -0.65530497 -0.65668744 -0.5831961  -0.603027\n",
      " -0.5769514  -0.6031681  -0.6051096  -0.5168682  -0.5070963  -0.6410991\n",
      " -0.5772352  -0.61501557 -0.62971    -0.546584   -0.5580617  -0.59353846\n",
      " -0.6957468  -0.528932   -0.62341255 -0.6478479  -0.5676273  -0.57808644\n",
      " -0.63149285 -0.5318506 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.66556513 -0.64747167 -0.5886927  -0.53589046 -0.67393535 -0.6096492\n",
      " -0.55159205 -0.6283894  -0.55472034 -0.561227   -0.54393816 -0.6481856\n",
      " -0.592248   -0.5198794  -0.5329372  -0.5783542  -0.5867447  -0.71462965\n",
      " -0.6433125  -0.5773716  -0.6028796  -0.6103083  -0.62273747 -0.7177727\n",
      " -0.58806914 -0.6798944  -0.73311627 -0.6094182  -0.6619959  -0.541576\n",
      " -0.6199744  -0.62314844], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69675565 -0.5524968  -0.713199   -0.56772655 -0.5149896  -0.6147284\n",
      " -0.6317602  -0.5512941  -0.6239341  -0.6982251  -0.64167    -0.66045904\n",
      " -0.613848   -0.62101126 -0.5989535  -0.5716446  -0.62813145 -0.624598\n",
      " -0.6574256  -0.7119084  -0.55197924 -0.7057297  -0.6443205  -0.6970228\n",
      " -0.65296906 -0.6641553  -0.5330905  -0.65889144 -0.6903103  -0.59430987\n",
      " -0.60933304 -0.592838  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5723089  -0.6282007  -0.5973358  -0.5352771  -0.49387378 -0.61217475\n",
      " -0.69251984 -0.5919143  -0.5948628  -0.57893217 -0.61615413 -0.6616447\n",
      " -0.60006875 -0.64607644 -0.62742    -0.6359588  -0.6942054  -0.68108225\n",
      " -0.61058724 -0.6232491  -0.6672701  -0.5964924  -0.5694953  -0.63190675\n",
      " -0.54737115 -0.66614395 -0.68202144 -0.6283126  -0.52887845 -0.5665835\n",
      " -0.6510694  -0.59758383], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.60215074 -0.5256274  -0.59758204 -0.6045638  -0.639541   -0.6048541\n",
      " -0.71034116 -0.61955124 -0.5577619  -0.6388156  -0.5380404  -0.5524502\n",
      " -0.5718504  -0.5495062  -0.6930392  -0.5904408  -0.49784458 -0.5591172\n",
      " -0.61626244 -0.6207944  -0.59369755 -0.44705257 -0.6031139  -0.6127322\n",
      " -0.5548636  -0.62616277 -0.7061453  -0.6255219  -0.51786834 -0.583664\n",
      " -0.5952644  -0.65268207], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.58641106 -0.493057   -0.52651864 -0.55141383 -0.6119031  -0.56188285\n",
      " -0.7624608  -0.583562   -0.5699909  -0.60530543 -0.5808634  -0.5974123\n",
      " -0.61612725 -0.5648244  -0.60071975 -0.5598788  -0.5270762  -0.61396074\n",
      " -0.7388221  -0.60250723 -0.7445614  -0.49385044 -0.651151   -0.6187758\n",
      " -0.6019311  -0.5890496  -0.633177   -0.5817468  -0.61900896 -0.61784446\n",
      " -0.60933733 -0.63874876], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.67832845 -0.67890066 -0.59053093 -0.6267413  -0.6194944  -0.5468327\n",
      " -0.47246206 -0.57508636 -0.5133717  -0.6259496  -0.5341343  -0.5563141\n",
      " -0.61725783 -0.5523229  -0.81991076 -0.5446036  -0.69881636 -0.7762202\n",
      " -0.693998   -0.5214676  -0.63627815 -0.57372934 -0.6657117  -0.586203\n",
      " -0.52273667 -0.62203205 -0.6803484  -0.5901804  -0.6338178  -0.5206963\n",
      " -0.6277056  -0.6203336 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6917888  -0.60676575 -0.66613346 -0.4994739  -0.53288245 -0.70883435\n",
      " -0.6745748  -0.60629594 -0.47082555 -0.5890012  -0.48970208 -0.5775149\n",
      " -0.6362625  -0.61049724 -0.6067041  -0.54014164 -0.52619976 -0.6287784\n",
      " -0.5508419  -0.58637655 -0.6131749  -0.5792564  -0.5575755  -0.61080915\n",
      " -0.6319475  -0.6590364  -0.53842187 -0.62683403 -0.6036828  -0.6217436\n",
      " -0.5692408  -0.58180916], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.53936744 -0.6711183  -0.7261951  -0.6092004  -0.58433783 -0.68354017\n",
      " -0.69065106 -0.6043967  -0.54462546 -0.59207624 -0.64677364 -0.56166434\n",
      " -0.5261414  -0.5174298  -0.4932917  -0.5362551  -0.53886515 -0.71137273\n",
      " -0.564292   -0.5869735  -0.5904599  -0.6659349  -0.71049964 -0.48751104\n",
      " -0.65357256 -0.6335823  -0.6047282  -0.6567742  -0.70024014 -0.6279345\n",
      " -0.5053539  -0.56637895], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.71390855 -0.52490985 -0.5428954  -0.5522598  -0.59421754 -0.5103529\n",
      " -0.51009524 -0.5379017  -0.69148225 -0.5435702  -0.57520527 -0.51582354\n",
      " -0.6038716  -0.68751675 -0.56052357 -0.56811285 -0.6382259  -0.5906613\n",
      " -0.57583773 -0.6105244  -0.65142894 -0.61628455 -0.6449304  -0.6654742\n",
      " -0.5607061  -0.7329553  -0.48634142 -0.631061   -0.6861447  -0.47512048\n",
      " -0.5025311  -0.6055843 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6934743  -0.60056496 -0.6143229  -0.512426   -0.5979326  -0.6786866\n",
      " -0.59494257 -0.56269115 -0.64082956 -0.5247432  -0.526595   -0.60309285\n",
      " -0.5725239  -0.6207685  -0.5400862  -0.56314033 -0.57325214 -0.47541872\n",
      " -0.7253325  -0.57137185 -0.557153   -0.49612463 -0.50341845 -0.5832078\n",
      " -0.63694924 -0.6556679  -0.6470544  -0.5785372  -0.66804653 -0.64805996\n",
      " -0.81171066 -0.5423417 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6076746  -0.59856594 -0.55871105 -0.71146953 -0.51619613 -0.5376997\n",
      " -0.6038279  -0.6085317  -0.48403764 -0.637303   -0.58989435 -0.6365086\n",
      " -0.64289844 -0.5383477  -0.6762004  -0.5120429  -0.61269945 -0.48884246\n",
      " -0.58583033 -0.5579267  -0.6566842  -0.61668986 -0.653813   -0.47396255\n",
      " -0.6108376  -0.48681718 -0.62837476 -0.64853865 -0.59316766 -0.60730183\n",
      " -0.6245238  -0.52294827], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6344412  -0.5412641  -0.54904616 -0.4824115  -0.61258966 -0.72239345\n",
      " -0.56598794 -0.65630955 -0.6244801  -0.51771426 -0.6900486  -0.53726673\n",
      " -0.69555104 -0.6471867  -0.63643336 -0.69126564 -0.50565606 -0.7396715\n",
      " -0.53575015 -0.562317   -0.74464613 -0.49785775 -0.53254247 -0.596002\n",
      " -0.5410575  -0.6181551  -0.5058888  -0.5960978  -0.606538   -0.55556756\n",
      " -0.5390383  -0.6019556 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5702301  -0.63206524 -0.58990103 -0.51900303 -0.6437784  -0.57995224\n",
      " -0.59291416 -0.6211495  -0.6787792  -0.6193281  -0.5471947  -0.67440933\n",
      " -0.6641874  -0.58473253 -0.5857271  -0.6975703  -0.5758921  -0.558482\n",
      " -0.49123502 -0.50939673 -0.6305412  -0.4913441  -0.62088597 -0.65650344\n",
      " -0.5323137  -0.61057067 -0.55265737 -0.59021646 -0.57468015 -0.66216755\n",
      " -0.5861109  -0.5938586 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5673478  -0.56965876 -0.6273413  -0.6069397  -0.6736719  -0.54315054\n",
      " -0.6251106  -0.4893499  -0.5603595  -0.5582891  -0.5633073  -0.5808445\n",
      " -0.5701055  -0.55388033 -0.5668242  -0.61767334 -0.46966696 -0.4974196\n",
      " -0.64306325 -0.62833935 -0.64005125 -0.6310784  -0.611941   -0.59085697\n",
      " -0.5639658  -0.53865874 -0.6124507  -0.57392246 -0.563687   -0.61155057\n",
      " -0.56762445 -0.51866853], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5833623  -0.5423608  -0.6466331  -0.59710693 -0.5630852  -0.6069921\n",
      " -0.781026   -0.73983634 -0.60196924 -0.44932264 -0.51534927 -0.6021299\n",
      " -0.5383388  -0.5269698  -0.6365144  -0.6709222  -0.5380752  -0.5585082\n",
      " -0.5099355  -0.7522907  -0.50426817 -0.46923393 -0.5602774  -0.49510032\n",
      " -0.5471115  -0.6992432  -0.6456661  -0.48597354 -0.5434516  -0.48499945\n",
      " -0.65272313 -0.6584598 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6599556  -0.47056168 -0.4372575  -0.46876812 -0.6005887  -0.5849979\n",
      " -0.5879898  -0.5954324  -0.5919683  -0.5382881  -0.6476975  -0.5567009\n",
      " -0.65984184 -0.718656   -0.49872357 -0.6055242  -0.58914614 -0.57527626\n",
      " -0.63373846 -0.57257646 -0.64516187 -0.5634926  -0.6506712  -0.5832146\n",
      " -0.5051173  -0.64992607 -0.5600036  -0.5019581  -0.6285972  -0.6623602\n",
      " -0.59496063 -0.68689615], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6476815  -0.7494623  -0.65462416 -0.5296625  -0.70943975 -0.68861216\n",
      " -0.7342113  -0.6482362  -0.68045104 -0.7238647  -0.6390576  -0.6486221\n",
      " -0.6105381  -0.64962727 -0.6673541  -0.6377209  -0.47849447 -0.49856633\n",
      " -0.5097492  -0.53073865 -0.5288233  -0.50356036 -0.49098048 -0.51111144\n",
      " -0.5623718  -0.5774386  -0.59171826 -0.67768973 -0.47189975 -0.5564751\n",
      " -0.5026824  -0.6397102 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5141512  -0.56584036 -0.56266046 -0.5520133  -0.6829814  -0.57332015\n",
      " -0.725776   -0.501417   -0.63493526 -0.5901552  -0.5857785  -0.577704\n",
      " -0.64133596 -0.5435252  -0.64421254 -0.6466342  -0.52036166 -0.4992535\n",
      " -0.52565545 -0.6541643  -0.50745845 -0.71627337 -0.64024824 -0.57379025\n",
      " -0.5901143  -0.60774463 -0.692294   -0.5540835  -0.62823296 -0.61669767\n",
      " -0.72478217 -0.6125619 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6439266  -0.5094437  -0.51613826 -0.58112574 -0.49496827 -0.67291397\n",
      " -0.6576956  -0.5279411  -0.4832042  -0.5613773  -0.5169829  -0.5460828\n",
      " -0.68218446 -0.5485964  -0.5913028  -0.7436204  -0.48712528 -0.56583196\n",
      " -0.7166015  -0.5439207  -0.54752636 -0.67547274 -0.61537504 -0.6128771\n",
      " -0.48781717 -0.6200938  -0.48098364 -0.4757868  -0.5561026  -0.54425806\n",
      " -0.5694084  -0.61475635], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.58613926 -0.5646071  -0.54475796 -0.6154653  -0.6054475  -0.48735523\n",
      " -0.6123361  -0.46468717 -0.5402248  -0.6168683  -0.4762136  -0.49989092\n",
      " -0.5229345  -0.50247794 -0.6420211  -0.5891214  -0.52627754 -0.46945179\n",
      " -0.5994411  -0.5505301  -0.5147588  -0.65651363 -0.7222936  -0.55443376\n",
      " -0.48654157 -0.5506228  -0.564822   -0.67595476 -0.48692155 -0.76422274\n",
      " -0.7589725  -0.4707339 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.56886345 -0.5662401  -0.5853138  -0.44139647 -0.6564585  -0.7436865\n",
      " -0.43234903 -0.57019496 -0.6675891  -0.56286436 -0.6598463  -0.66967195\n",
      " -0.6191081  -0.5374218  -0.63142604 -0.5791466  -0.7613977  -0.4641239\n",
      " -0.56562006 -0.70938367 -0.5509338  -0.49924454 -0.5785328  -0.6649775\n",
      " -0.42878622 -0.7492281  -0.46371463 -0.5610073  -0.49960828 -0.52851844\n",
      " -0.6083071  -0.6024176 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5130976  -0.60376847 -0.61261266 -0.6324626  -0.74806905 -0.5782844\n",
      " -0.50966024 -0.66868466 -0.5669607  -0.67007476 -0.5578675  -0.5683786\n",
      " -0.61324054 -0.48737037 -0.63288444 -0.6810575  -0.5418722  -0.5028581\n",
      " -0.5923208  -0.5942196  -0.5625444  -0.5314201  -0.5328082  -0.574183\n",
      " -0.72812706 -0.63312775 -0.56290996 -0.4828307  -0.65240324 -0.52853715\n",
      " -0.626417   -0.553375  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5184567  -0.5559118  -0.5388354  -0.5408693  -0.78707695 -0.5256748\n",
      " -0.49733984 -0.5047906  -0.6553807  -0.5640557  -0.4872376  -0.6019579\n",
      " -0.66038436 -0.5038887  -0.510044   -0.55111635 -0.64752734 -0.62955564\n",
      " -0.66682965 -0.60131675 -0.5255246  -0.545634   -0.7133825  -0.55050623\n",
      " -0.63122684 -0.5013484  -0.6453753  -0.51630324 -0.62118274 -0.62396795\n",
      " -0.60155547 -0.6071387 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.57881564 -0.52377665 -0.5932457  -0.6624251  -0.5190938  -0.60063267\n",
      " -0.53220004 -0.5051106  -0.584285   -0.6151403  -0.6119607  -0.6780689\n",
      " -0.69261706 -0.49433956 -0.7952498  -0.5076239  -0.7025255  -0.5067685\n",
      " -0.6689939  -0.50244045 -0.5964813  -0.51959974 -0.610939   -0.49136847\n",
      " -0.5502484  -0.63212687 -0.6870478  -0.7369788  -0.5817148  -0.58213395\n",
      " -0.67334306 -0.5091391 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.57900554 -0.60737276 -0.5978632  -0.5567434  -0.5764628  -0.6518836\n",
      " -0.65000933 -0.62148166 -0.61513144 -0.57468545 -0.5088606  -0.47657576\n",
      " -0.60834205 -0.5746701  -0.62148416 -0.5967833  -0.68705636 -0.51045454\n",
      " -0.65008414 -0.83043087 -0.7266983  -0.53406805 -0.6026616  -0.65171474\n",
      " -0.59988296 -0.56115425 -0.5989008  -0.5851418  -0.63956004 -0.6774658\n",
      " -0.6622053  -0.53996754], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.51833916 -0.42037177 -0.7052462  -0.5041769  -0.57220155 -0.47714257\n",
      " -0.59453857 -0.68545526 -0.5993671  -0.6164021  -0.606981   -0.6950511\n",
      " -0.5995945  -0.45010868 -0.7487808  -0.7049279  -0.60033554 -0.597985\n",
      " -0.588417   -0.49843234 -0.58435184 -0.5172122  -0.48544437 -0.61013055\n",
      " -0.4863269  -0.60440385 -0.5569693  -0.7440559  -0.58723533 -0.7012415\n",
      " -0.68521136 -0.53924954], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5373888  -0.65295756 -0.6256193  -0.5113812  -0.55601984 -0.5615432\n",
      " -0.592374   -0.5541812  -0.5153383  -0.56870794 -0.6178835  -0.56363183\n",
      " -0.5211388  -0.63089013 -0.70773494 -0.62502986 -0.732084   -0.46480253\n",
      " -0.68459475 -0.58231884 -0.5769961  -0.54408383 -0.803531   -0.46030235\n",
      " -0.7059028  -0.5931362  -0.610185   -0.61302924 -0.6696029  -0.5733241\n",
      " -0.5539409  -0.55367994], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.51827043 -0.58391    -0.593638   -0.5376195  -0.54653656 -0.59700644\n",
      " -0.6595705  -0.60229516 -0.5044452  -0.546691   -0.46552426 -0.5119659\n",
      " -0.45119023 -0.50373846 -0.6911527  -0.51850486 -0.6213597  -0.6473963\n",
      " -0.6203022  -0.720284   -0.5283559  -0.47135493 -0.5502449  -0.7685957\n",
      " -0.60117126 -0.6912458  -0.6307222  -0.51593155 -0.52127874 -0.598714\n",
      " -0.49677157 -0.67665374], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5294634  -0.5879637  -0.6394744  -0.5682862  -0.6038914  -0.5059887\n",
      " -0.5169207  -0.594093   -0.6380024  -0.635401   -0.5497676  -0.53555655\n",
      " -0.5209752  -0.61625874 -0.5504504  -0.61513686 -0.6510193  -0.6779877\n",
      " -0.6099534  -0.5415287  -0.6228368  -0.62187356 -0.5826062  -0.5842599\n",
      " -0.63851345 -0.4686677  -0.6062363  -0.6755171  -0.49392784 -0.57244706\n",
      " -0.7160758  -0.70448565], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.63259757 -0.6007778  -0.6412736  -0.40640357 -0.6038059  -0.5386953\n",
      " -0.607748   -0.5620126  -0.50905913 -0.6192898  -0.5824079  -0.59561944\n",
      " -0.5283526  -0.5484967  -0.79418683 -0.6364524  -0.63943535 -0.5588539\n",
      " -0.6694475  -0.6313212  -0.51296586 -0.47702235 -0.65676385 -0.5257491\n",
      " -0.6320279  -0.69367146 -0.6362848  -0.5007085  -0.43283305 -0.6694491\n",
      " -0.68552107 -0.46685582], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.57907045 -0.6175708  -0.60081834 -0.4630574  -0.72893476 -0.4752264\n",
      " -0.64491355 -0.45532435 -0.4533546  -0.6841309  -0.55430627 -0.57235146\n",
      " -0.49425805 -0.55853933 -0.5823769  -0.64062417 -0.5762293  -0.58322245\n",
      " -0.5463867  -0.5596226  -0.71967804 -0.7328299  -0.5666561  -0.6740881\n",
      " -0.56656766 -0.54787564 -0.6470773  -0.71488    -0.5841391  -0.6126544\n",
      " -0.6054723  -0.67171323], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.50385237 -0.6725987  -0.5198507  -0.4571163  -0.6230069  -0.5603832\n",
      " -0.5298593  -0.6907285  -0.7599566  -0.58086795 -0.51215494 -0.5113138\n",
      " -0.6169013  -0.64460313 -0.48796842 -0.48073137 -0.7238593  -0.4458949\n",
      " -0.5194196  -0.5979316  -0.4700772  -0.6126527  -0.5156735  -0.4840128\n",
      " -0.55365944 -0.55154276 -0.46911746 -0.42606345 -0.516014   -0.5019396\n",
      " -0.81662256 -0.50954187], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.48066854 -0.58526444 -0.6548873  -0.52936566 -0.6322032  -0.6264619\n",
      " -0.53914386 -0.63070923 -0.54739845 -0.56864166 -0.5482532  -0.614923\n",
      " -0.52300966 -0.57396835 -0.47290805 -0.7055871  -0.81262684 -0.54887986\n",
      " -0.6157138  -0.4849331  -0.5386065  -0.5770673  -0.6398275  -0.67067343\n",
      " -0.723655   -0.7009881  -0.4277432  -0.6622977  -0.6129025  -0.4695657\n",
      " -0.49134877 -0.72811013], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5802509  -0.6883899  -0.5474663  -0.50394475 -0.66196585 -0.6680216\n",
      " -0.6319126  -0.59677714 -0.50056016 -0.5568512  -0.5774334  -0.5118578\n",
      " -0.49931037 -0.45317686 -0.6285864  -0.45969203 -0.48829776 -0.67442435\n",
      " -0.5635853  -0.6707518  -0.5802797  -0.47376513 -0.5302093  -0.6525291\n",
      " -0.5026632  -0.6890429  -0.62364733 -0.5880596  -0.55039537 -0.53795505\n",
      " -0.51258767 -0.5294725 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6632207  -0.58275354 -0.55189407 -0.5090772  -0.5847087  -0.6541023\n",
      " -0.40322575 -0.52451056 -0.52214193 -0.61974275 -0.44666326 -0.5910103\n",
      " -0.5484341  -0.6831713  -0.5248586  -0.6132413  -0.5489173  -0.68416065\n",
      " -0.4652477  -0.44535223 -0.4225626  -0.58210236 -0.5656296  -0.5832923\n",
      " -0.57113147 -0.6918229  -0.6596291  -0.6626848  -0.51406354 -0.6495435\n",
      " -0.5500672  -0.53454196], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4564631  -0.6103566  -0.5807419  -0.5665575  -0.4159457  -0.5078546\n",
      " -0.5468146  -0.4706611  -0.49667662 -0.5859386  -0.73361087 -0.5436393\n",
      " -0.54399073 -0.47076353 -0.5629636  -0.5468334  -0.578155   -0.66762906\n",
      " -0.5565373  -0.5857961  -0.72607195 -0.5039731  -0.60096157 -0.43720853\n",
      " -0.55790234 -0.51736724 -0.46952394 -0.55438447 -0.59111565 -0.70317614\n",
      " -0.5334196  -0.6245703 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.50217265 -0.5889685  -0.61713254 -0.516621   -0.5674673  -0.5421731\n",
      " -0.7027005  -0.60165954 -0.59590316 -0.5183349  -0.622179   -0.6617532\n",
      " -0.51772845 -0.7616368  -0.5477244  -0.52614355 -0.5831553  -0.68669105\n",
      " -0.49018073 -0.5521538  -0.5302749  -0.54877996 -0.65665406 -0.50330746\n",
      " -0.4567902  -0.5122269  -0.6405861  -0.837261   -0.56035554 -0.5584793\n",
      " -0.6473067  -0.4917574 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5176786  -0.6896579  -0.50037014 -0.5777252  -0.52656966 -0.5727506\n",
      " -0.4947033  -0.4129395  -0.47808903 -0.6710398  -0.5395902  -0.45043248\n",
      " -0.5264889  -0.62065166 -0.6255941  -0.59179443 -0.70645547 -0.48627758\n",
      " -0.47978932 -0.42139998 -0.5853211  -0.68687564 -0.51841056 -0.5730258\n",
      " -0.5837841  -0.5540809  -0.54625905 -0.6494235  -0.6373791  -0.6284641\n",
      " -0.70338285 -0.6029019 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.47752827 -0.6854989  -0.45781872 -0.5233904  -0.6693304  -0.5346469\n",
      " -0.6720697  -0.5591331  -0.5707974  -0.49740565 -0.6238142  -0.57767713\n",
      " -0.5524732  -0.4857396  -0.6882492  -0.53741974 -0.7071551  -0.4780307\n",
      " -0.6666619  -0.61069906 -0.54411423 -0.4990296  -0.61194664 -0.5163085\n",
      " -0.6774665  -0.42872024 -0.5070533  -0.48836482 -0.59180653 -0.51314175\n",
      " -0.54806006 -0.54552865], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4749052  -0.56145734 -0.54081833 -0.5294432  -0.4647128  -0.62734026\n",
      " -0.6013072  -0.71616495 -0.41944757 -0.70825636 -0.5282397  -0.72137654\n",
      " -0.53981584 -0.6453729  -0.5803933  -0.52206016 -0.49080434 -0.545079\n",
      " -0.6642901  -0.52387476 -0.7934724  -0.67971957 -0.68961376 -0.634982\n",
      " -0.6298951  -0.5579122  -0.6044086  -0.52819216 -0.58969295 -0.61409706\n",
      " -0.45378107 -0.44009304], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.729691   -0.649847   -0.5668094  -0.542743   -0.59296674 -0.4545297\n",
      " -0.49554393 -0.72198063 -0.579193   -0.6130948  -0.53932434 -0.5180146\n",
      " -0.5314056  -0.74511266 -0.7119693  -0.5562554  -0.6371215  -0.6055655\n",
      " -0.49540824 -0.73184097 -0.57022357 -0.5524791  -0.51846564 -0.45499873\n",
      " -0.56341916 -0.4987839  -0.44635043 -0.5309373  -0.43928626 -0.74825704\n",
      " -0.5278629  -0.5023369 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.48154533 -0.48380846 -0.6749497  -0.5514243  -0.77895033 -0.5797421\n",
      " -0.6310465  -0.4247874  -0.5825282  -0.62433547 -0.55776095 -0.6117337\n",
      " -0.7572956  -0.52160823 -0.7930157  -0.46568492 -0.46915054 -0.88969433\n",
      " -0.60287774 -0.3910807  -0.57950366 -0.59235525 -0.7250744  -0.49922356\n",
      " -0.4359795  -0.7537668  -0.5608869  -0.5496156  -0.57123303 -0.6110555\n",
      " -0.5592938  -0.56235015], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5119221  -0.5791887  -0.57443684 -0.51430094 -0.6766082  -0.57154703\n",
      " -0.5508963  -0.5813619  -0.6594192  -0.4970643  -0.53305566 -0.5257695\n",
      " -0.5557394  -0.46183878 -0.5549291  -0.49734405 -0.5990436  -0.54412305\n",
      " -0.6262667  -0.49991444 -0.81911397 -0.59054583 -0.65204716 -0.6269246\n",
      " -0.53755915 -0.57089734 -0.52588713 -0.661741   -0.5811324  -0.5956146\n",
      " -0.4852866  -0.53963506], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6432715  -0.5120483  -0.4759044  -0.56926763 -0.54392225 -0.54644114\n",
      " -0.4854082  -0.57712835 -0.56515634 -0.74890196 -0.60825896 -0.5645217\n",
      " -0.5310012  -0.5710548  -0.5009842  -0.73055077 -0.6881589  -0.61571056\n",
      " -0.51473904 -0.4871307  -0.5517306  -0.60511583 -0.59353757 -0.5049685\n",
      " -0.49854386 -0.4631163  -0.5588415  -0.6597453  -0.5867325  -0.6075328\n",
      " -0.5941463  -0.6618512 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5975543  -0.69422996 -0.579423   -0.5571545  -0.5601522  -0.43645915\n",
      " -0.5900678  -0.48918408 -0.68059057 -0.76642394 -0.5277411  -0.49319664\n",
      " -0.57943237 -0.4717074  -0.49591106 -0.43620634 -0.76122546 -0.46973187\n",
      " -0.6284788  -0.45287275 -0.5700974  -0.6058309  -0.47889197 -0.47741294\n",
      " -0.65460336 -0.42153433 -0.7372931  -0.52199686 -0.6434494  -0.47934029\n",
      " -0.45950866 -0.5166183 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.55562586 -0.45458025 -0.5164886  -0.6437362  -0.54165345 -0.65517795\n",
      " -0.51659244 -0.50470245 -0.5795571  -0.47571307 -0.573269   -0.6124254\n",
      " -0.51788545 -0.6045786  -0.45709074 -0.74936163 -0.4613394  -0.6117467\n",
      " -0.70276225 -0.4647913  -0.73746383 -0.5689549  -0.6197843  -0.6143985\n",
      " -0.45072016 -0.6560452  -0.44502884 -0.6073137  -0.58883065 -0.5655894\n",
      " -0.44015262 -0.45791388], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5898513  -0.61016375 -0.62203586 -0.5790221  -0.5925562  -0.56381357\n",
      " -0.4391439  -0.5769502  -0.42704362 -0.61550635 -0.4675716  -0.57247835\n",
      " -0.52891386 -0.5963942  -0.50569934 -0.495925   -0.5449954  -0.55467\n",
      " -0.54423994 -0.569497   -0.49771452 -0.8155668  -0.5405216  -0.5870489\n",
      " -0.5889313  -0.46528023 -0.4968959  -0.67355406 -0.56459165 -0.53675675\n",
      " -0.5619508  -0.46455848], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.58302575 -0.66628486 -0.54849607 -0.53482145 -0.42324278 -0.5422187\n",
      " -0.49840888 -0.39147604 -0.54964685 -0.53334284 -0.5373566  -0.5625088\n",
      " -0.54976726 -0.5720077  -0.5803788  -0.5463989  -0.47291547 -0.48512334\n",
      " -0.5904949  -0.6432467  -0.5349269  -0.5593633  -0.66531086 -0.53471035\n",
      " -0.43392092 -0.8404952  -0.58519304 -0.45845097 -0.7222996  -0.7215971\n",
      " -0.62029994 -0.5625913 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.63092834 -0.4516014  -0.4350293  -0.5164121  -0.46331942 -0.47610897\n",
      " -0.5699659  -0.53644514 -0.58257025 -0.62681806 -0.4365516  -0.53210354\n",
      " -0.6071297  -0.857267   -0.7098267  -0.6830998  -0.5178725  -0.50440234\n",
      " -0.48501545 -0.56945735 -0.57956606 -0.43467367 -0.47966337 -0.4695536\n",
      " -0.66577274 -0.5409117  -0.6954122  -0.7423877  -0.7258465  -0.6505035\n",
      " -0.59619874 -0.6536397 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.630256   -0.6654026  -0.578771   -0.6039452  -0.5628368  -0.6553488\n",
      " -0.64400154 -0.6642214  -0.5809897  -0.6538316  -0.6649867  -0.77266204\n",
      " -0.51680017 -0.59785295 -0.5159157  -0.7131541  -0.74813545 -0.41383913\n",
      " -0.41309142 -0.42656866 -0.4512341  -0.45977926 -0.43318978 -0.5152332\n",
      " -0.44739366 -0.51679736 -0.5642426  -0.43565    -0.5942429  -0.3848073\n",
      " -0.49437875 -0.75368094], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5422138  -0.5369384  -0.4265304  -0.6246251  -0.50479996 -0.47626358\n",
      " -0.7181654  -0.6355619  -0.4535529  -0.66882247 -0.5981998  -0.5986951\n",
      " -0.6572825  -0.47456735 -0.5648721  -0.6404433  -0.52705866 -0.53347373\n",
      " -0.46752548 -0.5750996  -0.48926008 -0.61327744 -0.4210948  -0.48353088\n",
      " -0.60437834 -0.58557236 -0.5861692  -0.5242777  -0.5040058  -0.59682137\n",
      " -0.5580145  -0.71958816], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.66745794 -0.42998382 -0.66016865 -0.53084916 -0.55489683 -0.6455631\n",
      " -0.55590796 -0.5324407  -0.51650095 -0.70666933 -0.48582542 -0.4881122\n",
      " -0.5221296  -0.45576066 -0.70564187 -0.53284323 -0.57048833 -0.57222474\n",
      " -0.46514294 -0.64818364 -0.6012464  -0.85014796 -0.50321496 -0.46216035\n",
      " -0.61285865 -0.57744324 -0.4756284  -0.4703116  -0.6091026  -0.4798451\n",
      " -0.51607406 -0.55372584], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.55034757 -0.50429416 -0.6500034  -0.5656306  -0.5711476  -0.6110603\n",
      " -0.65387595 -0.63913476 -0.47132838 -0.47594547 -0.58269876 -0.54377216\n",
      " -0.6608273  -0.47067124 -0.52629286 -0.5852198  -0.43757418 -0.51876855\n",
      " -0.5035274  -0.50909775 -0.5300054  -0.44877067 -0.5105909  -0.5025007\n",
      " -0.38249895 -0.497568   -0.6087514  -0.5179175  -0.47903234 -0.51722395\n",
      " -0.59326136 -0.62016124], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4964729  -0.59123    -0.51117575 -0.4104382  -0.6461177  -0.65420634\n",
      " -0.56549925 -0.69299984 -0.4249995  -0.5109045  -0.6178739  -0.4373445\n",
      " -0.73516387 -0.59224916 -0.56657785 -0.5523044  -0.64302266 -0.6181425\n",
      " -0.43480465 -0.58948946 -0.615111   -0.51720417 -0.54465884 -0.57630455\n",
      " -0.6133034  -0.6073324  -0.5164676  -0.60429245 -0.5173907  -0.47970325\n",
      " -0.5796837  -0.55305624], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7173843  -0.5230601  -0.64289904 -0.51979405 -0.5346967  -0.46139863\n",
      " -0.5215659  -0.5516862  -0.5867837  -0.5239371  -0.42612907 -0.3931947\n",
      " -0.9151369  -0.62568605 -0.5727444  -0.43795407 -0.3946807  -0.68310905\n",
      " -0.6060048  -0.4609584  -0.71303606 -0.4260323  -0.69975424 -0.50326705\n",
      " -0.5042535  -0.529022   -0.48231685 -0.65127087 -0.4232569  -0.674447\n",
      " -0.51187354 -0.637362  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5288446  -0.48102954 -0.5389005  -0.50381494 -0.56629217 -0.4683722\n",
      " -0.4617344  -0.4229558  -0.49170288 -0.60499275 -0.55335397 -0.6030043\n",
      " -0.51341045 -0.6427776  -0.57801247 -0.6039542  -0.56291693 -0.5511809\n",
      " -0.6470284  -0.47804743 -0.54599684 -0.63215554 -0.60252917 -0.583213\n",
      " -0.5275326  -0.5404402  -0.52222943 -0.6604805  -0.56396616 -0.516809\n",
      " -0.47325745 -0.47474164], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.44238728 -0.4241423  -0.55514646 -0.55478483 -0.4596276  -0.5410878\n",
      " -0.4094536  -0.64617735 -0.67933655 -0.41357398 -0.5976839  -0.44321898\n",
      " -0.44352597 -0.6435156  -0.5942482  -0.56147605 -0.5752045  -0.41882184\n",
      " -0.5199456  -0.56305945 -0.46241206 -0.3673523  -0.6946832  -0.6725506\n",
      " -0.55633193 -0.56870645 -0.41860476 -0.62477505 -0.4214781  -0.5556439\n",
      " -0.49249828 -0.570908  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7530786  -0.564369   -0.49980256 -0.4113374  -0.6071985  -0.47039717\n",
      " -0.57445794 -0.47923043 -0.48473424 -0.49065757 -0.4609538  -0.70635045\n",
      " -0.7727549  -0.44378597 -0.47750744 -0.5566491  -0.42331716 -0.5782588\n",
      " -0.46594447 -0.5567658  -0.4403152  -0.5193462  -0.5856569  -0.44231102\n",
      " -0.47489423 -0.50609654 -0.7128412  -0.5238246  -0.36575508 -0.45862207\n",
      " -0.49083257 -0.43690547], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4412126  -0.5604852  -0.6327196  -0.5844938  -0.7009691  -0.3732775\n",
      " -0.69290036 -0.50680214 -0.4798468  -0.71111035 -0.47364014 -0.71364987\n",
      " -0.6594629  -0.67551476 -0.478692   -0.41320452 -0.39183968 -0.36833102\n",
      " -0.36830115 -0.7189216  -0.7227073  -0.46912467 -0.7179862  -0.43225262\n",
      " -0.5049321  -0.480933   -0.5075802  -0.50332373 -0.63608897 -0.5222066\n",
      " -0.4737174  -0.4591788 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4501245  -0.45277435 -0.6874876  -0.4577452  -0.53627026 -0.45327866\n",
      " -0.61963105 -0.43913388 -0.6469386  -0.5730296  -0.6385548  -0.5255425\n",
      " -0.47937244 -0.54072785 -0.5436663  -0.48614717 -0.46393186 -0.4686116\n",
      " -0.48190856 -0.48344833 -0.44452316 -0.44549304 -0.54447275 -0.5157613\n",
      " -0.56532824 -0.52571774 -0.5337924  -0.4465695  -0.9420537  -0.65961766\n",
      " -0.51962775 -0.49065495], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4191081  -0.4141726  -0.48184353 -0.6506529  -0.48091984 -0.4865594\n",
      " -0.43764237 -0.40624014 -0.5307594  -0.5753637  -0.5823999  -0.5209264\n",
      " -0.50194967 -0.42568603 -0.5251781  -0.50702333 -0.5535402  -0.5635402\n",
      " -0.4922488  -0.7283145  -0.5419787  -0.42771512 -0.727553   -0.57173073\n",
      " -0.5052837  -0.41664776 -0.5549554  -0.6012761  -0.5191141  -0.46944642\n",
      " -0.4069681  -0.4411551 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5522255  -0.41302013 -0.642204   -0.5695237  -0.7484641  -0.49565613\n",
      " -0.55894053 -0.5505957  -0.6755282  -0.44021487 -0.5152782  -0.48763636\n",
      " -0.483984   -0.40422672 -0.65045226 -0.42066902 -0.55459344 -0.6595115\n",
      " -0.6645237  -0.7400526  -0.48680997 -0.6639507  -0.70752645 -0.5680447\n",
      " -0.4066288  -0.5588948  -0.5359576  -0.54157996 -0.434015   -0.60188425\n",
      " -0.50144386 -0.49748498], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.54080117 -0.46034697 -0.50492936 -0.47434935 -0.5630642  -0.5557216\n",
      " -0.578839   -0.58505183 -0.55183756 -0.50433934 -0.48852772 -0.4235664\n",
      " -0.48118362 -0.50159186 -0.56398267 -0.5722471  -0.53820616 -0.7164898\n",
      " -0.51834023 -0.5267235  -0.46088582 -0.53764474 -0.5135788  -0.46920097\n",
      " -0.6114549  -0.81081045 -0.47621346 -0.89329207 -0.7375369  -0.4935904\n",
      " -0.7502953  -0.7959677 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.49704707 -0.51294714 -0.5210573  -0.49054563 -0.49923643 -0.43909255\n",
      " -0.4988653  -0.70303726 -0.5834221  -0.47752076 -0.5512948  -0.618447\n",
      " -0.50492823 -0.46661168 -0.37711123 -0.48389995 -0.79187727 -0.6409813\n",
      " -0.45648938 -0.4508255  -0.44879213 -0.6990931  -0.62744033 -0.43511793\n",
      " -0.43500358 -0.43538237 -0.67106926 -0.4551556  -0.7199925  -0.50653696\n",
      " -0.49333    -0.5672771 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5991832  -0.42896974 -0.7311251  -0.44786316 -0.5445089  -0.7949525\n",
      " -0.50419736 -0.48382854 -0.48119307 -0.49140853 -0.5767816  -0.58435285\n",
      " -0.6202729  -0.4637447  -0.6999532  -0.65195525 -0.44038087 -0.42736408\n",
      " -0.45471895 -0.45588642 -0.35700077 -0.45994148 -0.37220556 -0.535541\n",
      " -0.5831252  -0.68627983 -0.47064456 -0.40568364 -0.5089918  -0.6739497\n",
      " -0.56499976 -0.6233284 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.51953495 -0.55195194 -0.46079078 -0.61384815 -0.4059111  -0.43514803\n",
      " -0.6987941  -0.49664593 -0.4283052  -0.463717   -0.56775814 -0.59976405\n",
      " -0.5399313  -0.46297824 -0.52998406 -0.6335522  -0.54711777 -0.5824776\n",
      " -0.5701836  -0.51554936 -0.7008953  -0.6859163  -0.39509836 -0.44109327\n",
      " -0.4750234  -0.41305143 -0.4646259  -0.6702206  -0.5954082  -0.5557131\n",
      " -0.41764408 -0.4622329 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5575098  -0.5448511  -0.52855724 -0.4412241  -0.6070568  -0.47192508\n",
      " -0.5002502  -0.5765831  -0.39757565 -0.4465811  -0.68345296 -0.5836137\n",
      " -0.4680122  -0.57070774 -0.3717484  -0.48000246 -0.5347903  -0.3805572\n",
      " -0.4285618  -0.49694735 -0.5381472  -0.54657805 -0.6901639  -0.53019345\n",
      " -0.5475545  -0.5732507  -0.66904885 -0.7288231  -0.50987357 -0.47719353\n",
      " -0.8942573  -0.59989095], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4111647  -0.4634381  -0.47866082 -0.49712864 -0.82920885 -0.43913388\n",
      " -0.5220673  -0.5944745  -0.42958522 -0.41566727 -0.4184394  -0.39445856\n",
      " -0.61586326 -0.48927024 -0.37976688 -0.54756635 -0.7059928  -0.5806533\n",
      " -0.47974682 -0.40680325 -0.55686325 -0.5473119  -0.561322   -0.5695965\n",
      " -0.42450652 -0.5058924  -0.4944506  -0.50269336 -0.59178644 -0.60085416\n",
      " -0.44357583 -0.47578746], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4556423  -0.43915427 -0.3959077  -0.4300256  -0.6145174  -0.53027904\n",
      " -0.57831275 -0.5502517  -0.51457405 -0.92778337 -0.45686588 -0.6182611\n",
      " -0.37993217 -0.5014069  -0.41357666 -0.4490024  -0.44745374 -0.44709444\n",
      " -0.6305901  -0.4518499  -0.5398284  -0.4615315  -0.35046583 -0.57531726\n",
      " -0.5140196  -0.48656934 -0.42581016 -0.5546809  -0.420334   -0.46571314\n",
      " -0.4695981  -0.47981745], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.90452707 -0.7266284  -0.5157027  -0.81200236 -0.48646706 -0.54314244\n",
      " -0.63520145 -0.68778396 -0.50440514 -0.42842954 -0.49140203 -0.5657877\n",
      " -0.42459416 -0.5562843  -0.6415849  -0.5015321  -0.67862254 -0.46522987\n",
      " -0.54090124 -0.5240046  -0.4361715  -0.54912543 -0.43261078 -0.5130336\n",
      " -0.621786   -0.6160299  -0.4757774  -0.7665511  -0.5884586  -0.50508356\n",
      " -0.44856447 -0.711625  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4467771  -0.36613548 -0.5253471  -0.6746403  -0.5306342  -0.4720617\n",
      " -0.6322104  -0.42223662 -0.6431273  -0.5515298  -0.49068516 -0.39495558\n",
      " -0.58335775 -0.4158401  -0.7016985  -0.47813135 -0.48089147 -0.40629905\n",
      " -0.4103339  -0.66818345 -0.44998357 -0.51766825 -0.59570664 -0.45889378\n",
      " -0.39962018 -0.7341998  -0.41888472 -0.58149624 -0.5360882  -0.5230378\n",
      " -0.352374   -0.43680188], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.41927877 -0.61287737 -0.4991651  -0.38630223 -0.5920099  -0.42894337\n",
      " -0.41939932 -0.37723958 -0.5968194  -0.4208059  -0.38625687 -0.7005744\n",
      " -0.47484493 -0.77928793 -0.45922732 -0.44211596 -0.44204426 -0.4277177\n",
      " -0.6377667  -0.6489226  -0.50790304 -0.87820286 -0.39679483 -0.498949\n",
      " -0.42612457 -0.44476572 -0.7484343  -0.67082924 -0.3899043  -0.56418747\n",
      " -0.43922195 -0.4413353 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.44132856 -0.6911936  -0.8175963  -0.4252406  -0.5429997  -0.52202827\n",
      " -0.4934907  -0.49625325 -0.45093372 -0.46581227 -0.57749844 -0.6046347\n",
      " -0.4923897  -0.57561743 -0.45569354 -0.6135908  -0.5780604  -0.5823328\n",
      " -0.5499928  -0.43996036 -0.5537555  -0.5009717  -0.5722717  -0.37981305\n",
      " -0.5688335  -0.64740384 -0.6333189  -0.5240417  -0.43984658 -0.70638704\n",
      " -0.7201451  -0.617446  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5851577  -0.75779724 -0.6023184  -0.4486992  -0.46831086 -0.42301017\n",
      " -0.6470546  -0.48071817 -0.51445997 -0.5060711  -0.41053793 -0.44188657\n",
      " -0.43296665 -0.42707294 -0.51505405 -0.47265053 -0.397045   -0.6887601\n",
      " -0.466017   -0.6087715  -0.45336586 -0.62246954 -0.46848354 -0.43247095\n",
      " -0.50666034 -0.49805576 -0.5203836  -0.5019969  -0.5686629  -0.56113535\n",
      " -0.39742896 -0.52738905], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5185788  -0.42612863 -0.43385682 -0.5107264  -0.58904535 -0.45224467\n",
      " -0.37626907 -0.43551904 -0.42233273 -0.47648346 -0.5029448  -0.52243507\n",
      " -0.42687193 -0.7302902  -0.42256346 -0.529347   -0.66042066 -0.45849892\n",
      " -0.56695294 -0.47349983 -0.59933037 -0.40551534 -0.53584266 -0.53919363\n",
      " -0.50170255 -0.43302023 -0.4894587  -0.3832954  -0.89101505 -0.55009395\n",
      " -0.47711897 -0.64656854], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7604764  -0.4242661  -0.48580164 -0.41427374 -0.3623785  -0.4151522\n",
      " -0.5485816  -0.49754953 -0.4912754  -0.5253721  -0.49998754 -0.44609743\n",
      " -0.48793215 -0.5824591  -0.5633794  -0.44447744 -0.49392834 -0.4866016\n",
      " -0.62678003 -0.58966535 -0.55061126 -0.3905195  -0.6200336  -0.45274568\n",
      " -0.56905335 -0.5371045  -0.42528743 -0.4267484  -0.3908015  -0.42216384\n",
      " -0.4106854  -0.56105804], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.74333155 -0.5694474  -0.60813767 -0.41428235 -0.8112243  -0.374767\n",
      " -0.43080372 -0.39369565 -0.36994252 -0.610936   -0.38336104 -0.51363254\n",
      " -0.45619988 -0.5270433  -0.35611287 -0.5697676  -0.5362834  -0.87955177\n",
      " -0.6222076  -0.4589028  -0.5171701  -0.46661842 -0.339235   -0.512545\n",
      " -0.77993083 -0.60314906 -0.53601253 -0.527822   -0.6037464  -0.38553745\n",
      " -0.41342717 -0.419361  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4317299  -0.447384   -0.4119317  -0.42075253 -0.57810473 -0.5476773\n",
      " -0.42118588 -0.6786109  -0.39215696 -0.66009283 -0.47537142 -0.5666654\n",
      " -0.6516293  -0.72785556 -0.850465   -0.52703    -0.420407   -0.4683395\n",
      " -0.53931445 -0.5955622  -0.49851388 -0.42870066 -0.44473058 -0.3979876\n",
      " -0.4996935  -0.53755724 -0.6373853  -0.37362623 -0.5196048  -0.63979155\n",
      " -0.4270475  -0.50930715], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.484824   -0.46849966 -0.4695655  -0.4548532  -0.48098025 -0.60238755\n",
      " -0.41821516 -0.8525162  -0.4865569  -0.43202573 -0.49125457 -0.5174126\n",
      " -0.40971532 -0.7030569  -0.5354883  -0.45161158 -0.5382632  -0.6521119\n",
      " -0.50175375 -0.4388955  -0.5416309  -0.6566661  -0.50700927 -0.41474187\n",
      " -0.4775972  -0.6005934  -0.4089227  -0.45907533 -0.5787253  -0.42057067\n",
      " -0.6061269  -0.56760544], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5908937  -0.342135   -0.400171   -0.42102486 -0.41804063 -0.40014458\n",
      " -0.38867894 -0.48389423 -0.5788005  -0.44044802 -0.4625904  -0.40860152\n",
      " -0.57958674 -0.45561284 -0.557575   -0.61329406 -0.45924982 -0.45756754\n",
      " -0.4335364  -0.39525688 -0.53734267 -0.5031087  -0.4811809  -0.4944479\n",
      " -0.59128815 -0.9590175  -0.6233854  -0.48111716 -0.5705763  -0.66171837\n",
      " -0.54458797 -0.46650156], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.46741158 -0.4038595  -0.5699919  -0.3562989  -0.6600966  -0.49020308\n",
      " -0.4856218  -0.48288956 -0.6241714  -0.47741205 -0.500259   -0.40899256\n",
      " -0.69341993 -0.4164676  -0.60003334 -0.46376523 -0.42577544 -0.48659074\n",
      " -0.6763216  -0.60546625 -0.52737963 -0.7070351  -0.35711113 -0.42660883\n",
      " -0.6440789  -0.5728453  -0.48304886 -0.606357   -0.5387014  -0.584768\n",
      " -0.6818087  -0.5068361 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.42664042 -0.35662273 -0.7895013  -0.5350348  -0.37149766 -0.4564557\n",
      " -0.45161393 -0.3814537  -0.41912183 -0.44077328 -0.49735716 -0.562026\n",
      " -0.5265175  -0.50015193 -0.62214744 -0.55828303 -0.40812248 -0.41710308\n",
      " -0.7151572  -0.43715882 -0.57514626 -0.45474094 -0.4322861  -0.87298787\n",
      " -0.48621    -0.5646806  -0.501616   -0.38947314 -0.92242587 -0.72096956\n",
      " -0.47814128 -0.4368859 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.51101434 -0.48448938 -0.85454524 -0.37128124 -0.41803044 -0.52812666\n",
      " -0.40524384 -0.4902963  -0.6853826  -0.47702384 -0.5863453  -0.63514686\n",
      " -0.41173196 -0.50612384 -0.46525463 -0.39943084 -0.707693   -0.61005265\n",
      " -0.54217404 -0.436898   -0.56154597 -0.61764157 -0.6337715  -0.66957295\n",
      " -0.43297493 -0.42058063 -0.47236896 -0.48661977 -0.55593216 -0.57943517\n",
      " -0.51560354 -0.6465728 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.71039224 -0.48914132 -0.3716957  -0.57483387 -0.56395084 -0.45927507\n",
      " -0.4180477  -0.6796976  -0.5703805  -0.39633232 -0.5621124  -0.34999257\n",
      " -0.6538853  -0.7205808  -0.3493398  -0.41295543 -0.990975   -0.40297833\n",
      " -0.6555292  -0.4318154  -0.44361418 -0.46921992 -0.5116013  -0.40632486\n",
      " -0.73864174 -0.428965   -0.63338786 -0.3526207  -0.6180668  -0.53417975\n",
      " -0.4664436  -0.43668443], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43034387 -0.38083532 -0.43647665 -0.483026   -0.6391105  -0.55621123\n",
      " -0.49623045 -0.539212   -0.37070063 -0.56400204 -0.76837504 -0.37440118\n",
      " -0.475241   -0.42254588 -0.5612495  -0.7378404  -0.6874453  -0.5345969\n",
      " -0.3997436  -0.48143893 -0.6375286  -0.520913   -0.4150752  -0.41992778\n",
      " -0.5630104  -0.4038865  -0.40418127 -0.5461652  -0.3957709  -0.78793174\n",
      " -0.44343328 -0.46597221], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4440998  -0.38315994 -0.6129094  -0.5378452  -0.47742993 -0.6560706\n",
      " -0.5434895  -0.4333272  -0.4805843  -0.5785546  -0.6368505  -0.4058883\n",
      " -0.38577658 -0.4202565  -0.49439096 -0.37523678 -0.46660107 -0.63485813\n",
      " -0.58964825 -0.58127785 -0.6781742  -0.4265815  -0.4194065  -0.584813\n",
      " -0.50005656 -0.46933967 -0.619822   -0.6054542  -0.5204404  -0.36163986\n",
      " -0.38921204 -0.44619212], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.55841386 -0.49136394 -0.47574872 -0.41225743 -0.5510431  -0.39524257\n",
      " -0.4873082  -0.50966525 -0.60962015 -0.47357643 -0.5182327  -0.368718\n",
      " -0.46918488 -0.6757524  -0.44278395 -0.67675954 -0.40892136 -0.6247293\n",
      " -0.39906076 -0.7948832  -0.4288432  -0.56534237 -0.86116916 -0.66571337\n",
      " -0.62947625 -0.59226876 -0.5269047  -1.0795557  -0.6359391  -0.42455915\n",
      " -0.41138545 -0.42237917], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3793299  -0.5758843  -0.4640097  -0.47509587 -0.5664853  -0.47454703\n",
      " -0.4142117  -0.43833196 -0.55408365 -0.6319066  -0.62399507 -0.4153269\n",
      " -0.52296764 -0.57860553 -0.49840474 -0.57196146 -0.79018533 -0.42184186\n",
      " -0.4324349  -0.7133204  -0.63256884 -0.4072626  -0.3807044  -0.35872057\n",
      " -0.7023761  -0.49324432 -0.3904956  -0.45488    -0.70458555 -0.39633352\n",
      " -0.5740509  -0.41996264], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.48661932 -0.52259606 -0.7195265  -0.4766882  -0.4140782  -0.54639477\n",
      " -0.50506616 -0.415785   -0.4388587  -0.6487634  -0.57243824 -0.6991447\n",
      " -0.46571434 -0.44911954 -0.5540225  -0.40667546 -0.4139728  -0.5554168\n",
      " -0.63510305 -0.38095927 -0.50496763 -0.44451246 -0.46074957 -0.51911974\n",
      " -0.5800845  -0.4286137  -0.4112214  -0.70703244 -0.35677585 -0.44919515\n",
      " -0.7548222  -0.51578784], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.44201162 -0.4902482  -0.4963187  -0.47554326 -0.4273304  -0.4444574\n",
      " -0.5710028  -0.5245216  -0.56041914 -0.54580855 -0.57216775 -0.39576167\n",
      " -0.411186   -0.6191529  -0.37110186 -0.5241364  -0.47190553 -0.5664226\n",
      " -0.60010296 -0.426787   -0.49517345 -0.5307526  -0.4090038  -0.46488863\n",
      " -0.3989134  -0.6154097  -0.48891747 -0.41863534 -0.48339283 -0.40697038\n",
      " -0.5420021  -0.47553387], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5169236  -0.3979325  -0.43212542 -0.63888484 -0.5586724  -0.46775752\n",
      " -0.3539633  -0.53293115 -0.5997132  -0.6609336  -0.43555236 -0.4929593\n",
      " -0.37650865 -0.4889562  -0.5751555  -0.39288136 -0.39200515 -0.60339063\n",
      " -0.41160646 -0.39621282 -0.56079274 -0.59363556 -0.5046624  -0.53549767\n",
      " -0.4764312  -0.61382437 -0.38453367 -0.39584738 -0.59905165 -0.38709617\n",
      " -0.5922275  -0.4451393 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.97311413 -0.41978914 -0.63273287 -0.57548535 -0.5527761  -0.6694521\n",
      " -0.4255203  -0.5925508  -0.7120187  -0.6286841  -0.6484265  -0.4087559\n",
      " -0.41684437 -0.52304035 -0.4742006  -0.61186826 -0.59276104 -0.45022893\n",
      " -0.53066206 -0.45033455 -0.57401145 -0.63669735 -0.49843395 -0.6870764\n",
      " -0.40398192 -0.6505464  -0.45218354 -0.392924   -0.740036   -0.5794917\n",
      " -0.42791703 -0.6105276 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.42194313 -0.5253838  -0.36117893 -0.8381133  -0.713081   -0.6776752\n",
      " -0.7608994  -0.41815946 -0.36556113 -0.44517657 -0.45771343 -0.38021657\n",
      " -0.6021464  -0.42929402 -0.47491646 -0.43041614 -0.4667322  -0.3968995\n",
      " -0.5036973  -0.3904226  -0.3979181  -0.49981955 -0.5058138  -0.43259183\n",
      " -0.6182911  -0.39357132 -0.5871399  -0.5307082  -0.57906646 -0.3977134\n",
      " -0.3802644  -0.5444628 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.48468307 -0.54137546 -0.5672046  -0.47183472 -0.5811083  -0.56214446\n",
      " -0.41526252 -0.38745016 -0.45583338 -0.5999081  -0.42881185 -0.45222175\n",
      " -0.44339108 -0.3461426  -0.36949322 -0.63796604 -0.48329395 -0.42355806\n",
      " -0.4592475  -0.47959432 -0.39358926 -0.556786   -0.8655708  -0.39528352\n",
      " -0.4078456  -0.45726514 -0.539867   -0.37311015 -0.50093096 -0.47921318\n",
      " -0.507931   -0.40102977], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.53730094 -0.43522263 -0.8489025  -0.58072233 -0.5040208  -0.52383745\n",
      " -0.4730544  -0.4980034  -0.45399898 -0.45843333 -0.34302062 -0.54113925\n",
      " -0.40724197 -0.69007117 -0.48088783 -0.5102363  -0.6548152  -0.40509072\n",
      " -0.6101961  -0.43781772 -0.5469995  -0.4043938  -0.42407072 -0.3588607\n",
      " -0.5129251  -0.62683517 -0.56985396 -0.3496039  -0.4617052  -0.57833415\n",
      " -0.4718712  -0.37471676], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4431122  -0.41193217 -0.3720215  -0.3913581  -0.54930186 -0.44443142\n",
      " -0.38133094 -0.5561768  -0.62264276 -0.72539    -0.4106932  -0.49320507\n",
      " -0.47370255 -0.430982   -0.39164686 -0.5096054  -0.61312985 -0.5395284\n",
      " -0.47353607 -0.594187   -0.65600204 -0.4498113  -0.7310176  -0.42046094\n",
      " -0.44390038 -0.64083207 -0.37494597 -0.3606543  -0.47417724 -0.61574435\n",
      " -0.529998   -0.5090445 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6591972  -0.75666285 -0.3865134  -0.48919496 -0.39608043 -0.57213587\n",
      " -0.7012314  -0.5456495  -0.41969746 -0.54256105 -0.49735755 -0.42597884\n",
      " -0.4011343  -0.43156314 -0.37354937 -0.47028083 -0.4000721  -0.60474\n",
      " -0.41114855 -0.4436642  -0.47317845 -0.46067724 -0.67061186 -0.6485744\n",
      " -0.60639346 -0.5534338  -0.54796994 -0.3688617  -0.3795755  -0.4627213\n",
      " -0.45244715 -0.41059762], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.66581106 -0.40805113 -0.5239727  -0.39752036 -0.38893646 -0.5579089\n",
      " -0.39640248 -0.4541579  -0.38824987 -0.37929538 -0.4612575  -0.5639447\n",
      " -0.5547949  -0.51870584 -0.64392734 -0.5203661  -0.5953221  -0.42194843\n",
      " -0.43467075 -0.43915173 -0.4783653  -0.41952878 -0.36076838 -0.684985\n",
      " -0.5595106  -0.44061616 -0.41358423 -0.5123584  -0.35840598 -0.43937683\n",
      " -0.6108327  -0.3948968 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.48941654 -0.4304403  -0.62583256 -0.570672   -0.6518616  -0.8231115\n",
      " -0.4332688  -0.567632   -0.5923645  -0.4736145  -0.53876233 -0.6008126\n",
      " -0.72441256 -0.45038515 -0.369416   -0.4219257  -0.42893147 -0.70972776\n",
      " -0.5940176  -0.49846727 -0.5265303  -0.7182077  -0.42569825 -0.34973726\n",
      " -0.61836606 -0.5221799  -0.45187008 -0.5157316  -0.33899736 -0.5923948\n",
      " -0.45474875 -0.5291105 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.48765656 -0.5910561  -0.48886424 -0.4220778  -0.6577335  -0.88301086\n",
      " -0.41644332 -0.44030935 -0.64870083 -0.52798    -0.3953834  -0.40078115\n",
      " -0.4348133  -0.48954105 -0.4282877  -0.3591595  -0.40174714 -0.45496607\n",
      " -0.65555173 -0.49720818 -0.5182879  -0.5270988  -0.6586906  -0.5390675\n",
      " -0.34628582 -0.5149435  -0.48049966 -0.41964898 -0.5403753  -0.359582\n",
      " -0.39103347 -0.60709476], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6439007  -0.397569   -0.41539538 -0.68866825 -0.6330668  -0.5222864\n",
      " -0.56244665 -0.57423    -0.3901465  -0.8176134  -0.42846084 -0.3662363\n",
      " -0.40328884 -0.4274031  -0.45211154 -0.45979607 -0.41791576 -1.0567981\n",
      " -0.48573065 -0.5808842  -0.63678527 -0.62796044 -1.0422646  -0.39327717\n",
      " -0.40657315 -0.3902681  -0.47934073 -0.46517378 -0.47372574 -0.4399699\n",
      " -0.41503805 -0.44085672], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4113363  -0.49893957 -0.52646947 -0.68245476 -0.6369883  -0.6452554\n",
      " -0.45075387 -0.47587568 -0.49248865 -0.50381404 -0.45423108 -0.5645236\n",
      " -0.7102259  -0.56671625 -0.36125642 -0.6677568  -0.43119213 -0.6659224\n",
      " -0.5874054  -0.5425692  -0.6042383  -0.63758945 -0.4505134  -0.40058663\n",
      " -0.38320684 -0.39735517 -0.4509812  -0.46002486 -0.5126321  -0.7351823\n",
      " -0.42453927 -0.5515121 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5292506  -0.59421647 -0.72666496 -0.4539948  -0.46765605 -0.518338\n",
      " -0.58516085 -0.40471652 -0.75889146 -0.4346671  -0.45700938 -0.5360226\n",
      " -0.484882   -0.4328727  -0.59879863 -0.40297604 -0.38142538 -0.5237037\n",
      " -0.38999838 -0.53519005 -0.64730537 -0.3927715  -0.38508692 -0.47369492\n",
      " -0.40713647 -0.44903207 -0.653407   -0.61962396 -0.42646158 -0.38663635\n",
      " -0.455939   -0.8395187 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.58604777 -0.3642805  -0.38559753 -0.49486247 -0.43305898 -0.39403927\n",
      " -0.38743365 -0.4067287  -0.627926   -0.43342936 -0.4407152  -0.47678298\n",
      " -0.36103952 -0.4887828  -0.48942167 -0.54738706 -0.5529174  -0.51659656\n",
      " -0.50603175 -0.5695056  -0.48634613 -0.50324893 -0.581597   -0.42783746\n",
      " -0.38880032 -0.45465153 -0.38123095 -0.5337373  -0.35322738 -0.5420258\n",
      " -0.44621965 -0.4137231 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5946051  -0.5821201  -0.44105157 -0.7947911  -0.6113173  -0.5246515\n",
      " -0.38996845 -0.3900097  -0.5816936  -0.38060218 -0.5161573  -0.4243239\n",
      " -0.7260317  -0.655033   -0.5566799  -0.3744902  -0.3482942  -0.5694153\n",
      " -0.45664972 -0.47931498 -0.6236612  -0.39008322 -0.38399523 -0.5888239\n",
      " -0.664541   -0.49064738 -0.6065733  -0.5129937  -0.44261107 -0.4435845\n",
      " -0.47556478 -0.39121035], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34601852 -0.43972096 -0.5776361  -0.42005602 -0.51308894 -0.4434656\n",
      " -0.43762428 -0.3513977  -0.41722962 -0.3898364  -0.9560809  -0.65845644\n",
      " -0.48974723 -0.50953895 -0.41591144 -0.3843789  -0.47151014 -0.43884662\n",
      " -0.4326479  -0.5374618  -0.4034029  -1.0089433  -0.5099443  -0.45887816\n",
      " -0.7426423  -0.57018137 -0.50232434 -0.6258188  -0.4460463  -1.0276372\n",
      " -0.49347657 -0.47733128], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3589478  -0.58678925 -0.5148016  -0.38738242 -0.3974144  -0.8960706\n",
      " -0.44072348 -0.37714195 -0.3931445  -0.79397774 -0.6341069  -0.42941862\n",
      " -0.5521058  -0.36034736 -0.36920622 -0.5127212  -0.40491286 -0.7733332\n",
      " -0.44021523 -0.60867107 -0.42688352 -0.50929785 -0.481168   -0.39384615\n",
      " -0.4270028  -0.48505142 -0.38723612 -0.67403126 -0.37981606 -0.41123328\n",
      " -0.51900566 -0.40665346], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.8458273  -0.37809315 -0.5214348  -0.54219025 -0.5116613  -0.38819045\n",
      " -0.67710173 -0.55008185 -0.39668483 -0.35393208 -0.42360067 -0.40975562\n",
      " -0.4687884  -0.68822974 -0.3905887  -0.548707   -0.51247627 -0.43019983\n",
      " -0.6994798  -0.46163008 -0.4123264  -0.3331292  -0.54348266 -0.4229455\n",
      " -0.4685862  -0.3713804  -0.45946965 -0.3894154  -0.59575653 -0.55208564\n",
      " -0.41766718 -0.54294944], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4836409  -0.40102553 -0.49909684 -0.4923725  -0.3769087  -0.3800016\n",
      " -0.5119035  -0.4955544  -0.5969268  -0.3612434  -0.43240008 -0.34373045\n",
      " -0.4058953  -0.6403886  -0.5003104  -0.4107744  -0.38943908 -0.48902392\n",
      " -0.5819495  -0.46446994 -0.47293508 -0.739323   -0.5923055  -0.4004975\n",
      " -0.46009815 -0.7205222  -0.47103584 -0.42645273 -0.4465766  -0.54432833\n",
      " -0.38123757 -0.34051257], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.48428786 -0.5034212  -0.719219   -0.40400857 -0.38215476 -0.40779763\n",
      " -0.40825927 -0.5374065  -0.8139704  -0.3763356  -0.74339175 -0.61147785\n",
      " -0.4165786  -0.47389126 -0.5943834  -0.37989792 -0.6061412  -0.5674369\n",
      " -0.39107475 -0.582119   -0.49932426 -0.6157888  -0.43169013 -0.5765418\n",
      " -0.3303524  -0.47660455 -0.395601   -0.6123362  -0.47523922 -0.58034754\n",
      " -0.40061378 -0.512318  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37595892 -0.4288397  -0.47967255 -0.38693336 -0.4094008  -0.41680855\n",
      " -0.48386234 -0.47016793 -0.5152241  -0.36712888 -0.44675818 -0.40936968\n",
      " -0.50820786 -0.45071608 -0.420521   -0.50410104 -0.43125194 -0.4194236\n",
      " -0.44737774 -0.47833207 -0.52308065 -0.58752286 -0.6080507  -0.37589598\n",
      " -0.40521124 -0.4960513  -0.39449495 -0.5964979  -0.47395173 -0.49377996\n",
      " -0.5561094  -0.5683891 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3703191  -0.4593789  -0.33691865 -0.4392401  -0.33805194 -0.4045031\n",
      " -0.45566982 -0.47748518 -0.45936662 -0.44149476 -0.51418245 -0.39099324\n",
      " -0.6414908  -0.3736292  -0.51627624 -0.36684626 -0.3794312  -0.6370576\n",
      " -0.3785471  -0.6304347  -0.42869452 -0.49536481 -0.47642705 -0.43884885\n",
      " -0.6356879  -0.39095083 -0.495202   -0.5697343  -0.3620966  -0.4412577\n",
      " -0.4158112  -0.5052611 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4381733  -0.5017631  -0.6294182  -0.5802796  -0.50264776 -0.39175186\n",
      " -0.5824166  -0.56551963 -0.73696864 -0.5226923  -0.46220976 -0.39057225\n",
      " -0.37404647 -0.47021896 -0.36905038 -0.37389925 -0.43300045 -0.39948097\n",
      " -0.6423199  -0.71424663 -0.4309871  -0.56291646 -0.5234033  -0.52455646\n",
      " -0.49651146 -0.36438325 -0.3777931  -0.39166862 -0.3889015  -0.4600019\n",
      " -0.41487777 -0.4270667 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38831195 -0.46850616 -0.37160748 -0.36740154 -0.37602684 -0.5216528\n",
      " -0.41852003 -0.34969196 -0.500057   -0.37917382 -0.39185733 -0.581957\n",
      " -0.6455565  -0.4234609  -0.38661084 -0.56524795 -0.37361714 -0.6737784\n",
      " -0.45068303 -0.42355946 -0.4241955  -0.46859816 -0.4558376  -0.40429386\n",
      " -0.3788395  -0.6406084  -0.5101893  -0.89621246 -0.35128528 -0.5669088\n",
      " -0.4644541  -0.45508504], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.578303   -0.4441257  -0.47499505 -0.62329555 -0.36742836 -0.4923492\n",
      " -0.41043586 -0.62649214 -0.44233215 -0.6537261  -0.53645325 -0.3864665\n",
      " -0.63350326 -0.8080303  -0.3614473  -0.6021778  -0.5829045  -0.5935729\n",
      " -0.41550395 -0.3987914  -0.4673841  -0.51212156 -0.46088552 -0.5603614\n",
      " -0.44371268 -0.5401391  -0.37740642 -0.5402567  -0.50331575 -0.42450237\n",
      " -0.5888024  -0.58886915], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3742314  -0.8125556  -0.5861902  -0.6271745  -0.592434   -0.36285475\n",
      " -0.3762789  -0.8169789  -0.45329905 -0.45333436 -0.37702438 -0.383357\n",
      " -0.39891532 -0.52979416 -0.46514398 -0.47185922 -0.34911373 -0.38574627\n",
      " -0.5916879  -0.66221946 -0.3881889  -0.3327545  -0.65333354 -0.3564019\n",
      " -0.5967774  -0.52393115 -0.5622163  -0.38294446 -0.44250417 -0.38832814\n",
      " -0.5257375  -0.5342569 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4746832  -0.3873783  -0.56742096 -0.4729747  -0.35460067 -0.49149024\n",
      " -0.43422344 -0.3852689  -0.76911235 -0.3748124  -0.382685   -0.5238982\n",
      " -0.36599773 -0.41098908 -0.40373093 -0.7987061  -0.44243678 -0.51737636\n",
      " -0.40519226 -0.39875284 -0.37373084 -0.4437015  -0.36366415 -0.33328202\n",
      " -0.58235973 -0.39085075 -0.399037   -0.43753216 -0.8660732  -0.3412607\n",
      " -0.40110248 -0.53538406], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3364248  -0.43278974 -0.40877625 -0.5857129  -0.39907467 -0.52169275\n",
      " -0.5396229  -0.46610978 -0.4247939  -0.5939376  -0.50866663 -0.41832957\n",
      " -0.4541345  -0.3727856  -0.36037606 -0.44830123 -0.535367   -0.5703238\n",
      " -0.41375795 -0.47508729 -0.571147   -0.36814672 -0.45713234 -0.53716034\n",
      " -0.47826424 -0.5144456  -0.38360387 -0.43613783 -0.37668827 -0.5807311\n",
      " -0.38265508 -0.34746248], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.46797824 -0.44410402 -0.39379326 -0.7411755  -0.475262   -0.6054484\n",
      " -0.65559095 -0.56928545 -0.4863033  -0.3887111  -0.3740336  -0.45494688\n",
      " -0.48035103 -0.6632393  -0.53178716 -0.5090299  -0.6697873  -0.3625967\n",
      " -0.39936233 -0.47006118 -0.34584534 -0.38162732 -0.33600166 -0.4737114\n",
      " -0.50243056 -0.35745513 -0.45134282 -0.6385139  -0.39551842 -0.41686353\n",
      " -0.49335125 -0.4573433 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33694136 -0.61797565 -0.5320295  -0.4345407  -0.6003853  -0.38758844\n",
      " -0.44631824 -0.59195805 -0.5020064  -0.39422792 -0.44583434 -0.5649134\n",
      " -0.83075124 -0.47691345 -0.44550884 -0.3621391  -0.78313    -0.32800007\n",
      " -0.68704194 -0.6271501  -0.33373192 -0.42148998 -0.6076326  -0.39937368\n",
      " -0.4013225  -0.57781196 -0.41799653 -0.4270289  -0.6245333  -0.37215897\n",
      " -0.3703554  -0.33862215], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.39355153 -0.41042098 -0.45860028 -0.42290857 -0.42474437 -0.56044865\n",
      " -0.6058392  -0.455348   -0.5432886  -0.4245369  -0.45532277 -0.3773357\n",
      " -0.46550128 -0.49699557 -0.31772643 -0.3912537  -0.4587078  -0.39446458\n",
      " -0.42400384 -0.45585996 -0.5077771  -0.3532385  -0.3702417  -0.39903373\n",
      " -0.40228543 -0.38720834 -0.60996157 -0.48588115 -0.4798049  -0.3873994\n",
      " -0.49710768 -0.5956235 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36850658 -0.5994385  -0.6298054  -0.35096917 -0.40855217 -0.39144194\n",
      " -0.43779257 -0.35439745 -0.65288854 -0.49764255 -0.3912023  -0.593017\n",
      " -0.4901616  -0.36335486 -0.689897   -0.7124603  -0.3676169  -0.44569343\n",
      " -0.4267291  -0.67869085 -0.47903007 -0.43948883 -0.5428766  -0.8713038\n",
      " -0.4257024  -0.40938038 -0.4695676  -0.45419627 -0.45527068 -0.5955249\n",
      " -0.6792785  -0.4189586 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3719716  -0.3474587  -0.46146867 -0.58556795 -0.5390568  -0.7199695\n",
      " -0.44019145 -0.38815486 -0.40091306 -0.45333624 -0.734899   -0.39013383\n",
      " -0.4707476  -0.39295268 -0.43742487 -0.74021107 -0.39305496 -0.817592\n",
      " -0.34740657 -0.51080257 -0.3817795  -0.48656684 -0.3516432  -0.51459926\n",
      " -0.6611116  -0.36872888 -0.5239365  -0.67862266 -0.47549874 -0.38262296\n",
      " -0.4993538  -0.4148652 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.90532887 -0.3806466  -0.50647503 -0.33650228 -0.36324644 -0.61952543\n",
      " -0.44993606 -0.7262808  -0.4100266  -0.47474647 -0.4925561  -0.6986362\n",
      " -0.36322308 -0.4582458  -0.6123132  -0.32917327 -0.3749294  -0.45312655\n",
      " -0.43924576 -0.6076878  -0.45842725 -0.3926969  -0.41777346 -0.43271938\n",
      " -0.4173479  -0.4465146  -0.4178774  -0.4965795  -0.40428513 -0.37342703\n",
      " -0.42382103 -0.5475728 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.51112247 -0.40686706 -0.48608074 -0.5980464  -0.40709433 -0.40844074\n",
      " -0.84150916 -0.91208184 -0.48891148 -0.51794624 -0.71532667 -0.4130769\n",
      " -0.44089073 -0.6427119  -0.45433432 -0.52520865 -0.5559759  -0.50992507\n",
      " -0.5047499  -0.40649804 -0.64704674 -0.41596836 -0.40944862 -0.8249074\n",
      " -0.45679587 -0.3687443  -1.007061   -0.37105414 -0.5492375  -0.5162574\n",
      " -0.39406002 -0.38774902], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35763523 -0.40182093 -0.5204615  -0.4322058  -0.43689868 -0.60205704\n",
      " -0.6555459  -0.41739777 -0.37918165 -0.6122751  -0.3995223  -0.6636738\n",
      " -0.39749008 -0.52097404 -0.44129312 -0.3689308  -0.37417996 -0.8876556\n",
      " -0.5769582  -0.5133389  -0.9921102  -0.3876143  -0.46562445 -0.5832383\n",
      " -0.3601089  -0.57861996 -0.38278735 -0.5446187  -0.5669409  -0.49539837\n",
      " -0.41363782 -0.78923047], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5117484  -0.3417703  -0.44044673 -0.6245465  -0.5343246  -0.36443782\n",
      " -0.5110065  -0.3531371  -0.31758413 -0.84313893 -0.35893515 -0.42808923\n",
      " -0.5884206  -0.33642292 -0.4503523  -0.4510405  -0.44059235 -0.49237847\n",
      " -0.4439185  -0.5113808  -0.57733536 -0.48626518 -0.4656657  -0.35703582\n",
      " -0.48088592 -0.39025092 -0.35170096 -0.3578502  -0.39140975 -0.34546703\n",
      " -0.42096946 -0.4683128 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.86633587 -0.5942534  -0.48198903 -0.39860067 -0.48804575 -0.53491485\n",
      " -0.44407046 -0.37136668 -0.58255213 -0.42608035 -0.45716524 -0.35132545\n",
      " -0.4204787  -0.53387856 -0.5489656  -0.37324443 -0.4869433  -0.39925843\n",
      " -0.40463474 -0.4993085  -0.43691608 -0.49514246 -0.45193306 -0.5628393\n",
      " -0.36753434 -0.4168923  -0.3258794  -0.41058987 -0.42602888 -0.3938164\n",
      " -0.3673524  -0.35687053], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5977416  -0.5299999  -0.5080557  -0.39467493 -0.390088   -0.4405352\n",
      " -0.38429645 -0.41392842 -0.34768    -0.4038865  -0.38015822 -0.34960842\n",
      " -0.5727076  -0.4617831  -0.41090673 -0.39494658 -0.39853495 -0.6431044\n",
      " -0.3938318  -0.3591009  -0.44947278 -0.39442763 -0.51999223 -0.48834032\n",
      " -0.38073343 -0.39398235 -0.38025317 -0.61417484 -0.5971698  -0.73833394\n",
      " -0.69856215 -0.40340608], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.48969746 -0.43267226 -0.6035638  -0.35425043 -0.40388998 -0.9006938\n",
      " -0.60549766 -0.4481625  -0.46211192 -0.41666937 -0.6770616  -0.39737865\n",
      " -0.44461724 -0.40779158 -0.4761446  -0.5483283  -0.59316677 -0.35719338\n",
      " -0.43503106 -0.53117746 -0.42487082 -0.49106443 -0.36121    -0.38562274\n",
      " -0.43675497 -0.5025837  -0.38434312 -0.40182045 -0.61346275 -0.38314223\n",
      " -0.4365687  -0.35566407], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.48897904 -0.616286   -0.3398378  -0.4710837  -0.6374934  -0.37968296\n",
      " -0.34144855 -0.40650892 -0.46787432 -0.68673825 -0.44182488 -0.49720627\n",
      " -0.4006133  -0.592953   -0.56125396 -0.39506167 -0.403519   -0.46991372\n",
      " -0.41099036 -0.49245885 -0.38325778 -0.41785997 -0.38232392 -0.63076\n",
      " -0.40234986 -0.64811826 -0.5117237  -0.3972195  -0.54913735 -0.39603922\n",
      " -0.45811898 -0.44104558], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.56102407 -0.46515357 -0.66604495 -0.6620417  -0.41489086 -0.38106003\n",
      " -0.5655355  -0.53035045 -0.7480484  -0.4467274  -0.35274476 -0.39057216\n",
      " -0.49521008 -0.5580586  -0.37239736 -0.47820455 -0.3790538  -0.66655385\n",
      " -0.8638817  -0.42702284 -0.37304807 -0.4157885  -0.57174057 -0.5362166\n",
      " -0.55735904 -0.51820695 -0.36428067 -0.42051136 -0.6297345  -0.57442707\n",
      " -0.3718909  -0.43022412], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36933914 -0.72729814 -0.40470132 -0.3946545  -0.38016978 -0.38939732\n",
      " -0.45726076 -0.41871095 -0.56142616 -0.42933995 -0.7519953  -0.36193028\n",
      " -0.35519385 -0.6861072  -0.51891804 -0.35879943 -0.53536063 -0.8679372\n",
      " -0.33544156 -0.38788742 -0.4656145  -0.46913207 -0.4181572  -0.521057\n",
      " -0.41545314 -0.3509987  -0.36921644 -0.4117965  -0.4760752  -0.43539843\n",
      " -0.42575815 -0.36815035], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.44573435 -0.38946223 -0.36181056 -0.5788222  -0.34486043 -0.3996937\n",
      " -0.45916677 -0.3968878  -0.80801594 -0.40639913 -0.4062711  -0.3460956\n",
      " -0.45014685 -0.70998216 -0.36781034 -0.39987576 -0.4068041  -0.35624054\n",
      " -0.35975808 -0.4042678  -0.60349274 -0.42179364 -0.359694   -0.36345133\n",
      " -0.44944906 -0.62042624 -0.4840738  -0.44343683 -0.41513565 -0.39124107\n",
      " -0.46046168 -0.37711972], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4542382  -0.47105014 -0.44998753 -0.41826302 -0.5152146  -0.33078307\n",
      " -0.52773446 -0.66698945 -0.4473496  -0.40817416 -0.5540714  -0.70581114\n",
      " -0.74702847 -0.5356604  -0.4412117  -0.35427517 -0.39243236 -0.45399284\n",
      " -0.35722682 -0.7647346  -0.48832694 -0.56680864 -0.5652619  -0.35344958\n",
      " -0.3749568  -0.46730968 -0.46686232 -0.55551094 -0.3538047  -0.48764426\n",
      " -0.40752807 -0.4326657 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.45420945 -0.555243   -0.56773376 -0.5187677  -0.54945767 -0.63594466\n",
      " -0.35971922 -0.7013754  -0.52759314 -0.37006882 -0.59636265 -0.9015101\n",
      " -0.44836563 -0.38036138 -0.5925875  -0.38253385 -0.46751034 -0.43112692\n",
      " -0.44360223 -0.62488854 -0.36046386 -0.33708188 -0.61487263 -0.42659077\n",
      " -0.40793952 -0.42302155 -0.37621024 -0.34918782 -0.54131687 -0.8587465\n",
      " -0.35216665 -0.3875296 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5139673  -0.39535376 -0.3874585  -0.37557003 -0.38194096 -0.35805357\n",
      " -0.52268714 -0.41438657 -0.39645198 -0.35544428 -0.6123585  -0.44578618\n",
      " -0.38724032 -0.4732163  -0.42773038 -0.5339406  -0.34121162 -0.43055394\n",
      " -0.42562622 -0.84758973 -0.3904505  -0.4054052  -0.40193537 -0.41809025\n",
      " -0.42874855 -0.5311769  -0.78344464 -0.3686731  -0.3399101  -0.49737668\n",
      " -0.5425385  -0.45699608], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.50994897 -0.39268458 -0.39983085 -0.4871099  -0.9221086  -0.37698212\n",
      " -0.46757913 -0.34496167 -0.5758851  -0.39736158 -0.70991236 -0.62169254\n",
      " -0.51193905 -0.533571   -0.33733365 -0.34965372 -0.84488547 -0.368387\n",
      " -0.40950385 -0.3286851  -0.3588074  -0.48434114 -0.34391725 -0.5555012\n",
      " -0.3505562  -0.38538924 -0.3686744  -0.3564558  -0.81594783 -0.38848576\n",
      " -0.34921187 -0.40165773], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.39062718 -0.4216173  -0.3761424  -0.40128854 -0.6208812  -0.67191523\n",
      " -0.44546205 -0.33970854 -0.33245292 -0.38826555 -0.586258   -0.3502584\n",
      " -0.35072055 -0.4624527  -0.34314588 -0.36689904 -0.5942098  -0.5110148\n",
      " -0.52205485 -0.52457994 -0.5402546  -0.37787324 -0.36635292 -0.4697678\n",
      " -0.5728216  -0.72258383 -0.35409674 -0.35143375 -0.58586365 -0.35614344\n",
      " -0.45960635 -0.43951267], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34453353 -0.5458461  -0.53477854 -0.50382507 -0.35309187 -0.33224696\n",
      " -0.36881554 -1.1521393  -0.3940174  -0.59187174 -0.41712186 -0.46704668\n",
      " -0.5344186  -0.38888305 -0.44041955 -0.34501824 -0.3455012  -0.480819\n",
      " -0.38246813 -0.42929184 -0.36931607 -0.43954316 -0.41317114 -0.49787152\n",
      " -0.5067916  -0.36605042 -0.9433987  -0.41502106 -0.4010194  -0.33461183\n",
      " -0.44046098 -0.40597138], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.66280943 -0.37098104 -0.5548279  -0.5741894  -0.3712378  -0.5723291\n",
      " -0.3624133  -0.4437312  -0.36435047 -0.37010998 -0.5094342  -0.39017037\n",
      " -0.47770634 -0.47648406 -0.36324593 -0.38149855 -0.64109886 -0.5906931\n",
      " -0.41806278 -0.43196708 -0.477446   -0.51528066 -0.78699946 -0.5417999\n",
      " -0.53637934 -0.5422736  -0.5399573  -0.5718037  -0.39028448 -0.393557\n",
      " -0.37982413 -0.43120694], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3477679  -0.36885774 -0.45074904 -0.389052   -0.41770634 -0.39066437\n",
      " -0.38199514 -0.63819194 -0.3437456  -0.43565524 -0.44963205 -0.41623658\n",
      " -0.3602975  -0.383525   -0.5091515  -0.38253668 -0.40429053 -0.36644968\n",
      " -0.45482886 -0.38357097 -0.38898036 -0.35099006 -0.39016894 -0.7030046\n",
      " -0.32380295 -0.42669308 -0.4999918  -0.39533603 -0.5516573  -0.5426773\n",
      " -0.41417772 -0.3329444 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5093003  -0.70896685 -0.43981242 -0.43603793 -0.7313889  -0.43471527\n",
      " -0.49060634 -0.37028813 -0.4026333  -0.4380517  -0.35241807 -0.41629642\n",
      " -0.3762933  -0.3706489  -0.44414383 -0.45717376 -0.66313547 -0.48999804\n",
      " -0.4553301  -1.0857744  -0.35408947 -0.51163745 -0.6930231  -0.48836958\n",
      " -0.33074856 -0.5262332  -0.56111836 -0.3550496  -0.37806424 -0.811154\n",
      " -0.43128747 -0.3316359 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32754225 -0.6086424  -0.4297139  -0.33346823 -0.61265904 -0.32893035\n",
      " -0.49207172 -0.41070956 -0.42456025 -0.374747   -0.42241603 -0.40940562\n",
      " -0.4671631  -0.44073015 -0.42871696 -0.5128491  -0.46878266 -0.3997147\n",
      " -0.43606305 -0.4024274  -0.4053494  -0.834808   -0.49779385 -0.72659683\n",
      " -0.5818974  -0.4819067  -0.5181063  -0.3404534  -0.35123315 -0.35446897\n",
      " -0.5619472  -0.72724974], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3578682  -0.3457005  -0.5515244  -0.513977   -0.35623285 -0.46472403\n",
      " -0.49189445 -0.333121   -0.38277695 -0.46160498 -0.38260278 -0.4760145\n",
      " -0.438774   -0.34891495 -0.5554258  -0.37806833 -0.58156765 -0.5982895\n",
      " -0.5017476  -0.42773798 -1.0689769  -0.35835683 -0.4964142  -0.5599533\n",
      " -0.60880506 -0.35981464 -0.43931586 -0.434316   -0.48435533 -0.4488594\n",
      " -0.34901813 -0.3588547 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.45557845 -0.35637635 -0.44779056 -0.34719032 -0.6735979  -0.3730094\n",
      " -0.45706755 -0.3327523  -0.3955738  -0.37866792 -0.5889631  -0.3268568\n",
      " -0.6854282  -0.6403809  -0.32623485 -0.59172046 -0.3571932  -0.35215583\n",
      " -0.49439156 -0.34791136 -0.553671   -0.42101562 -0.7350338  -0.36284098\n",
      " -0.37890625 -0.45416212 -0.32206735 -0.5090115  -0.35437328 -0.52571595\n",
      " -0.72344375 -0.40798995], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35177654 -0.37482762 -0.4952023  -0.41426712 -0.4401143  -0.43370044\n",
      " -0.42310527 -0.4098467  -0.37282774 -0.34621567 -0.6319411  -0.3516594\n",
      " -0.35568455 -0.43033504 -0.389892   -0.5243631  -0.36000428 -0.55514944\n",
      " -0.4069785  -0.67640233 -0.3626493  -0.5801621  -0.34779063 -0.4495852\n",
      " -0.35254687 -0.47503033 -0.55697197 -0.6489311  -0.5668191  -0.39906755\n",
      " -1.0641999  -0.36174664], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3847835  -0.38618413 -0.56007093 -0.65360105 -0.42842287 -0.96071273\n",
      " -0.4423864  -0.354988   -0.32226056 -0.6095603  -0.51004475 -0.36916518\n",
      " -0.40335336 -0.56465095 -0.48573667 -0.46152794 -0.378052   -0.46193588\n",
      " -0.33414587 -0.4190327  -0.8397274  -0.6351474  -0.627727   -0.3962189\n",
      " -0.5322573  -0.52133757 -0.3717239  -0.5798594  -0.38362655 -0.84507495\n",
      " -0.44840026 -0.62942076], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.77975786 -0.35130876 -0.7942364  -0.48393118 -0.6210382  -0.38677078\n",
      " -0.649547   -0.4525376  -0.36473438 -0.3793605  -0.3744297  -0.43111786\n",
      " -0.43419942 -0.6862664  -0.44461104 -0.3601627  -0.39185762 -0.3719998\n",
      " -0.4314501  -0.48441085 -0.3499415  -0.39852464 -0.45787597 -0.5288602\n",
      " -0.54613066 -0.48325637 -0.644282   -0.427051   -0.6683084  -0.35785112\n",
      " -0.45567822 -0.5671493 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5085983  -0.33407706 -0.4065452  -0.4580739  -0.41676202 -0.35308567\n",
      " -0.47061598 -0.39129764 -0.42951345 -0.9748656  -0.44129196 -0.3696602\n",
      " -0.35393885 -0.52810305 -0.32677314 -0.62353754 -0.40322703 -0.5493256\n",
      " -0.36014864 -0.52220243 -0.89897454 -0.9382257  -0.6113634  -0.3979662\n",
      " -0.356564   -0.45820224 -0.59506273 -0.39400005 -0.5485476  -0.41236478\n",
      " -0.6138794  -0.367753  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35715416 -0.48125112 -0.55053234 -0.37823918 -0.3985255  -0.34365436\n",
      " -0.3574819  -0.34371668 -0.4032785  -0.55719626 -0.43263847 -0.37228796\n",
      " -0.4233673  -0.3769688  -0.437959   -0.6418335  -0.3729549  -0.3406558\n",
      " -0.3913398  -0.4571426  -0.4969166  -0.61625504 -0.40711963 -0.3463935\n",
      " -0.44544515 -0.34452796 -0.36853027 -0.54688966 -0.4592032  -0.3915221\n",
      " -0.36168456 -0.39468497], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3739843  -0.37166676 -0.49778974 -0.42608556 -0.37136823 -0.45139247\n",
      " -0.6939559  -0.5644598  -0.47781825 -0.43916586 -0.5296549  -0.4270087\n",
      " -0.40582156 -0.3682615  -0.35443676 -0.3955327  -0.7281845  -0.42766616\n",
      " -0.35157323 -0.45956165 -0.4707625  -0.6591614  -0.47839206 -0.40760112\n",
      " -0.9373376  -0.3669515  -0.5208281  -0.37148154 -0.5101309  -0.5377141\n",
      " -0.39108038 -0.58295375], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.41068956 -0.49046403 -0.58541965 -0.73270476 -0.36901262 -0.37149298\n",
      " -0.36489463 -0.49187082 -0.41728467 -0.697775   -0.5163482  -0.6037918\n",
      " -0.37149897 -0.32875386 -0.33264363 -0.37367532 -0.39771548 -0.3717178\n",
      " -0.33568418 -0.53725886 -0.44457835 -0.35479197 -0.3875898  -0.3856973\n",
      " -0.4943856  -0.44261062 -0.6257694  -0.3531696  -0.38636252 -0.37946326\n",
      " -0.3846233  -0.58618397], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37868956 -0.35698992 -0.47587258 -0.33590898 -0.44935036 -0.43490574\n",
      " -0.3413019  -0.34045947 -0.6107304  -0.5637197  -0.45653063 -0.34546518\n",
      " -0.55553377 -0.42624864 -0.42595306 -0.39836177 -0.3812128  -0.4682613\n",
      " -0.5547172  -0.37238562 -0.60189074 -0.46650374 -0.72646344 -0.55996233\n",
      " -0.34770173 -0.35511446 -0.3752023  -0.42144635 -0.34260905 -0.5470177\n",
      " -0.7486589  -0.5352403 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.687287   -0.43749076 -0.6864624  -0.46575987 -0.6530914  -0.39094904\n",
      " -0.3875355  -0.7599772  -0.6162897  -0.8299737  -0.5542699  -0.3691731\n",
      " -0.53759795 -0.36831823 -0.35855725 -0.3881242  -0.35617426 -0.39419064\n",
      " -0.481346   -0.41902852 -0.3599393  -0.7523987  -0.65063775 -0.7083872\n",
      " -0.7076374  -0.35095525 -0.37407026 -0.34455818 -0.546265   -0.5885593\n",
      " -0.4994333  -0.36690655], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.41837412 -0.4556774  -0.33902454 -0.4083623  -0.42537975 -0.68446755\n",
      " -0.62647    -0.41433227 -0.42995402 -0.45641178 -0.40531665 -0.4954389\n",
      " -0.97988755 -0.48280543 -0.56084746 -0.49872437 -0.34123638 -0.46819705\n",
      " -0.3310611  -0.35411045 -0.44622874 -0.43628716 -0.39303973 -0.4874974\n",
      " -0.6166699  -0.37934425 -0.35662398 -0.3887735  -0.36800054 -0.41148734\n",
      " -0.6478107  -0.35217518], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5381868  -0.39917    -0.9536655  -0.6158087  -0.32116878 -0.59671414\n",
      " -0.3431338  -0.43042466 -0.59150904 -0.34248033 -0.5303197  -0.5748787\n",
      " -0.41391763 -0.6791981  -0.37704247 -0.47457767 -0.37497652 -0.56989247\n",
      " -0.3923975  -0.5672545  -0.3308847  -0.4022588  -0.4021003  -0.33351436\n",
      " -0.39472538 -0.32767832 -0.45998544 -0.36979923 -0.3358949  -0.5271702\n",
      " -0.52019846 -0.45984387], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34248126 -0.43593124 -0.38372076 -0.48080707 -0.46000952 -0.8887659\n",
      " -0.603403   -0.36724845 -0.52982503 -0.44218093 -0.39246562 -0.3460837\n",
      " -0.4308151  -0.37054905 -0.39410004 -0.33055902 -0.54810214 -0.5170411\n",
      " -0.3861797  -0.3659645  -0.4552595  -0.3612605  -0.34948826 -0.62323445\n",
      " -0.43815646 -0.3747261  -0.41268444 -0.33014598 -0.47028977 -0.49259353\n",
      " -0.48491198 -0.35835683], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3848712  -0.44209054 -0.38558942 -0.6214924  -0.40005022 -0.77114445\n",
      " -0.48898327 -0.38840768 -0.43295205 -0.3913175  -0.41327184 -0.46689975\n",
      " -0.34156758 -0.36753145 -0.37709886 -0.33420312 -0.35694897 -0.37725806\n",
      " -0.4651901  -0.3935266  -0.43403888 -0.8602904  -0.34938973 -0.77642\n",
      " -0.6338339  -0.40860888 -0.72105813 -0.58281386 -0.4508266  -0.6471306\n",
      " -0.48936993 -0.41675243], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38700104 -0.38440943 -0.58063304 -0.34172058 -0.45440894 -0.3878464\n",
      " -0.5168629  -0.4142917  -0.41661853 -0.5064331  -0.5085612  -0.35136193\n",
      " -0.37086833 -0.7197697  -0.64076364 -0.6278874  -0.3341363  -0.7677345\n",
      " -0.36702633 -0.5556729  -0.45451337 -0.3362686  -0.34844694 -0.5927178\n",
      " -0.45115864 -0.33965904 -0.3602865  -0.45639032 -0.676606   -0.37359416\n",
      " -0.401312   -0.36036003], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34584442 -0.44121936 -0.41215685 -0.8104148  -0.5025375  -0.34852165\n",
      " -0.3301729  -0.5507465  -0.39087453 -0.6938296  -0.40107462 -0.32263964\n",
      " -0.83143663 -0.35400194 -0.5733507  -0.38117346 -0.36603197 -0.47046912\n",
      " -0.451626   -0.344108   -0.39366943 -0.36520815 -0.78949445 -0.5106449\n",
      " -0.72962487 -0.4451111  -0.33168584 -0.40582505 -0.34860072 -0.47272715\n",
      " -0.42540374 -0.60597247], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4314594  -0.31735364 -0.35570902 -0.608142   -0.336587   -0.44875666\n",
      " -0.33341298 -0.622617   -0.34882236 -0.8525616  -0.39915073 -0.5920899\n",
      " -0.5009636  -0.43056813 -0.73052925 -0.32507926 -0.3518484  -0.754478\n",
      " -0.5346232  -0.44682178 -0.58160126 -0.40018052 -0.37715685 -0.39117166\n",
      " -0.39816535 -0.35441485 -0.6105967  -0.36659786 -0.5978796  -0.38564348\n",
      " -0.9907026  -0.39429858], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.89961255 -0.3458398  -0.39830646 -0.34626046 -0.68229264 -0.44227448\n",
      " -0.34383982 -0.65125024 -0.48304826 -0.47097912 -0.3820316  -0.65072703\n",
      " -0.3810365  -0.35112527 -0.40618336 -0.4606303  -0.37818724 -0.40311784\n",
      " -0.64085156 -0.35099334 -0.5388234  -0.3680951  -0.45240796 -0.39120382\n",
      " -0.39232856 -0.7055299  -0.571538   -0.3706895  -1.030943   -0.44203737\n",
      " -0.31942877 -0.36832193], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3758227  -0.3428439  -0.6430944  -0.37992907 -0.36703053 -0.46251684\n",
      " -0.3308503  -0.45948124 -0.83850396 -0.48774207 -0.32842746 -0.412768\n",
      " -0.38179448 -0.35096934 -0.77436185 -0.32836324 -0.56066495 -0.49944526\n",
      " -0.3618867  -0.36070806 -0.3711258  -0.50164616 -0.3569588  -0.32998893\n",
      " -0.3622562  -0.41139746 -0.41887155 -0.438034   -0.6517079  -0.33408612\n",
      " -0.4635487  -0.3586532 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.47534314 -0.41569355 -0.33341604 -0.4058155  -0.374712   -0.34894255\n",
      " -0.32642788 -0.56803674 -0.39303154 -0.6270226  -0.44880718 -0.4620053\n",
      " -0.35674205 -0.4130563  -0.4776787  -0.38907146 -0.5285677  -0.49780637\n",
      " -0.42556125 -0.72018397 -0.5474597  -0.3999449  -0.32363245 -0.98530906\n",
      " -0.46657866 -0.38152143 -0.37370527 -0.44145367 -0.37755433 -0.6681316\n",
      " -0.38541147 -0.37755165], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.66662997 -0.6514969  -0.3441574  -0.72619414 -0.40048903 -0.35732064\n",
      " -0.3725533  -0.4288419  -0.49987835 -0.5689813  -0.34470066 -0.38801473\n",
      " -0.3830308  -0.6437093  -0.6100867  -0.3742432  -0.8303126  -0.7165026\n",
      " -0.34933022 -0.34154513 -0.89411145 -0.93237126 -0.4204416  -0.67949367\n",
      " -0.5884334  -0.3606858  -0.4477588  -0.44782615 -0.34488207 -0.6965207\n",
      " -0.6136879  -0.6523329 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33460313 -0.33291492 -0.43826705 -0.38490206 -0.37261274 -0.70166814\n",
      " -0.40583506 -0.34691036 -0.63995534 -0.319975   -0.5550761  -0.8259623\n",
      " -0.35007396 -0.9788646  -0.3529514  -0.38276938 -0.7301575  -0.7361282\n",
      " -0.34334785 -0.33933568 -0.5009258  -0.48065114 -0.35589528 -0.33128947\n",
      " -0.44890574 -0.53359604 -0.6109379  -0.34875423 -0.42097938 -0.6600251\n",
      " -0.49271154 -0.50507903], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3557127  -0.33959207 -0.35701388 -0.60300636 -0.34294415 -0.36024934\n",
      " -0.34642133 -0.40123466 -0.51118696 -0.42117757 -0.4276029  -0.6287302\n",
      " -0.71183586 -0.4612447  -0.37260526 -0.34459764 -0.33019578 -0.3671568\n",
      " -0.39977658 -0.4178314  -0.40962416 -0.5875913  -0.38903987 -0.40000507\n",
      " -0.4843024  -0.32656556 -0.7222126  -0.40873688 -0.3739902  -0.4010913\n",
      " -0.4079871  -0.46874034], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3420397  -0.3868766  -0.5482684  -0.5229975  -0.33429122 -0.46885276\n",
      " -0.63174844 -0.42922628 -0.38428247 -0.3780305  -0.32822487 -0.34789854\n",
      " -0.5237895  -0.33167046 -0.5665872  -0.39476296 -0.4578448  -0.3383038\n",
      " -0.3571816  -0.3373738  -0.43415415 -0.56234145 -0.38837856 -0.36595038\n",
      " -0.32306874 -0.35238212 -0.3822438  -0.4553053  -0.39720988 -0.7350548\n",
      " -0.64479786 -0.6985947 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35166895 -0.56502616 -0.54639626 -0.419957   -0.34639898 -0.39600223\n",
      " -0.8434498  -0.3204593  -0.65870506 -0.46180367 -0.45970756 -0.44729137\n",
      " -0.35485402 -0.39788014 -0.4430711  -0.62189484 -0.5564297  -0.37628627\n",
      " -0.34708434 -0.46826735 -0.5325737  -0.35675874 -0.3363415  -0.40840685\n",
      " -0.34700397 -0.44821763 -0.5396679  -0.47407448 -0.42285818 -0.40555856\n",
      " -0.33363074 -0.3486224 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.40853423 -0.6399034  -0.5503566  -0.42015415 -0.8754333  -0.42839834\n",
      " -0.3457744  -0.34387565 -0.63705903 -0.6661036  -0.418245   -0.41898\n",
      " -0.8488736  -0.552987   -0.38500604 -0.32620808 -0.37835774 -0.44839412\n",
      " -0.34767392 -0.35359448 -0.32798186 -0.410975   -0.38544154 -0.3264048\n",
      " -0.55518055 -0.40644303 -0.40911135 -0.44832575 -0.41715452 -0.42586046\n",
      " -0.40336713 -0.5089549 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35332817 -0.3415608  -0.336646   -0.46624246 -0.69781554 -0.35958877\n",
      " -0.6730706  -0.631567   -0.55665684 -0.54208165 -0.39533514 -0.36779764\n",
      " -0.34441012 -0.37178734 -0.57412255 -0.33212972 -0.32582286 -0.42596808\n",
      " -0.7132611  -0.36400253 -0.34705353 -0.70701635 -1.0466297  -0.34170616\n",
      " -0.3329395  -0.41009766 -0.43652448 -0.46244776 -0.32378605 -0.63041407\n",
      " -0.3226173  -0.40407145], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43761697 -0.40016392 -0.7899111  -0.36318576 -0.43048364 -0.34868416\n",
      " -0.5300839  -0.37917155 -0.40787596 -0.38166776 -0.62876415 -0.35430095\n",
      " -0.36938208 -0.33811784 -0.34235135 -0.43510234 -0.33201554 -0.43983182\n",
      " -0.615744   -0.49740452 -0.3273204  -0.41804856 -0.55402344 -0.3470123\n",
      " -0.49262863 -0.39168513 -0.38077545 -0.6941445  -0.37038544 -0.49175543\n",
      " -0.3916827  -0.42625114], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3681926  -0.3722772  -0.523638   -0.49052334 -0.37763786 -0.9320215\n",
      " -0.61834395 -0.40389428 -0.49297574 -0.42514235 -0.36084342 -0.4844453\n",
      " -0.47787136 -0.336951   -0.3805242  -0.32571062 -0.4027     -0.49116147\n",
      " -0.5895194  -0.4477207  -0.5686582  -0.33048356 -0.3383923  -0.47461313\n",
      " -0.38766465 -0.43634605 -0.4201174  -0.44152153 -0.3469502  -0.35712448\n",
      " -0.33773494 -0.37255278], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3902091  -0.6145526  -0.37522295 -0.34634745 -0.35753384 -0.3450477\n",
      " -0.96097255 -0.33671463 -0.36509463 -0.39946923 -0.3590071  -0.33148947\n",
      " -0.5209662  -0.3884     -0.32537052 -0.49062037 -0.60784024 -0.42178622\n",
      " -0.36214957 -0.3466518  -0.48823613 -0.4840601  -0.40636292 -0.62854075\n",
      " -0.38648927 -0.48305768 -0.85742044 -0.6757764  -0.5295471  -0.48113823\n",
      " -0.40905812 -0.78538305], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.60375714 -0.3464128  -0.39696923 -0.62791264 -0.43319657 -0.34029806\n",
      " -0.49938273 -0.41968    -0.33844286 -0.6897167  -0.39694542 -0.3324412\n",
      " -0.43140882 -0.49130982 -0.43429747 -0.3398512  -0.40275413 -0.39818168\n",
      " -0.4543007  -0.7575837  -0.43680596 -0.32917672 -0.37485492 -0.34350157\n",
      " -0.8504425  -0.3507511  -0.41833773 -0.34782928 -0.48664725 -0.5328729\n",
      " -0.6714728  -0.3830581 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.8530921  -0.53764814 -0.36243957 -0.3833808  -0.3270687  -0.41030914\n",
      " -0.37784988 -0.34858155 -0.39735246 -0.45806623 -0.380206   -0.47545317\n",
      " -0.33333236 -0.33805728 -0.58135384 -0.3715437  -0.4295514  -0.32354963\n",
      " -0.5248719  -0.33994666 -0.39556417 -0.5313787  -0.3193659  -0.42897448\n",
      " -0.42699873 -0.5785309  -0.54498345 -0.44049168 -0.38259158 -0.4319064\n",
      " -0.3782336  -0.4449361 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.40008497 -0.3333612  -0.35810956 -0.3494585  -0.61492574 -0.3592107\n",
      " -0.38990864 -0.45771855 -0.5418214  -0.58430964 -0.35950124 -0.37355125\n",
      " -1.082475   -0.44120708 -0.34480825 -0.45767057 -0.36213753 -0.4202338\n",
      " -0.33704162 -0.44639438 -0.3721929  -0.35566476 -0.39000228 -0.3488137\n",
      " -0.41267836 -0.33406323 -0.38380897 -0.3486813  -0.34626678 -0.5330658\n",
      " -0.3718988  -0.3556844 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38853475 -0.335177   -0.3245224  -0.33756146 -0.3489835  -0.44336897\n",
      " -0.34538424 -0.43947825 -0.31982797 -0.37703258 -0.4434561  -0.585649\n",
      " -0.6395591  -0.4854154  -0.7838975  -0.36792547 -0.34545815 -0.40629056\n",
      " -0.35079366 -0.3316127  -0.5288905  -0.67151725 -0.592967   -0.578954\n",
      " -0.4555758  -0.4844705  -0.4920043  -0.3257301  -0.36876947 -0.4791777\n",
      " -0.63781804 -0.44078892], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.53582937 -0.3456378  -0.37076843 -0.4035104  -0.36367634 -0.7530435\n",
      " -0.3564005  -0.4364509  -0.4271059  -0.48576367 -0.45585376 -0.37330845\n",
      " -0.3304833  -0.34401774 -0.3340338  -0.4778381  -0.40326017 -0.42194805\n",
      " -0.32750988 -0.7204683  -0.32721472 -0.33395126 -0.7116022  -0.33815837\n",
      " -0.3489437  -0.8804226  -0.44407487 -0.47335267 -0.36136806 -0.3316745\n",
      " -0.35251546 -0.38801375], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.40886822 -0.4789819  -0.40309697 -0.52014107 -0.37385783 -0.34542358\n",
      " -0.43819845 -0.34228826 -0.4047251  -0.48496085 -0.33794227 -0.8025187\n",
      " -0.8586681  -0.4922708  -0.35785246 -0.36323482 -0.31670576 -0.33596194\n",
      " -0.3470654  -0.4787618  -0.3394977  -0.66504914 -0.47520697 -0.4045897\n",
      " -0.4436515  -0.37927392 -0.3959038  -0.36842602 -0.3511512  -0.42218253\n",
      " -0.43113938 -0.41224906], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.51898783 -0.87221074 -0.34616053 -0.36658034 -0.36152452 -0.5121803\n",
      " -0.3271451  -0.77382576 -0.3676451  -0.39168617 -0.35317284 -0.43911928\n",
      " -0.40642136 -0.33688137 -0.3679329  -0.35254678 -0.4948011  -0.33590207\n",
      " -0.317127   -0.5121573  -0.60543233 -0.62329876 -0.36160317 -0.33580697\n",
      " -0.45773846 -0.36409646 -0.39935744 -0.3842656  -0.4083894  -0.32778126\n",
      " -0.5479981  -0.43512672], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.46659696 -0.62412906 -0.37318113 -0.35362628 -0.33103523 -0.6879283\n",
      " -0.72016096 -0.38951677 -0.38536388 -0.38770187 -0.37005162 -0.33941984\n",
      " -0.38289294 -0.38611016 -0.33561543 -0.56456506 -0.36520576 -0.4843114\n",
      " -0.3353356  -0.32822195 -0.71644855 -0.47954363 -0.43554512 -0.6673813\n",
      " -0.9092052  -0.40624    -0.3311491  -0.33723247 -0.40267777 -0.33536166\n",
      " -0.36532927 -0.34016335], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.50651425 -0.491436   -0.462214   -0.8231732  -0.47086537 -0.4065344\n",
      " -0.74701226 -0.33508402 -0.34122628 -0.34040552 -0.37550336 -0.35009128\n",
      " -0.6375145  -0.3853495  -0.39498055 -0.5511007  -0.3457092  -0.38720915\n",
      " -0.34320068 -0.42679882 -1.2547114  -0.40435004 -0.6300571  -0.41771358\n",
      " -0.43177387 -0.5742276  -0.37717694 -0.40966517 -0.4302603  -0.32535234\n",
      " -0.8955982  -0.42768776], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3523683  -0.7906679  -0.44504863 -0.38441315 -0.5221148  -0.3706768\n",
      " -0.38399947 -0.40444568 -0.9546192  -0.3314668  -0.325011   -0.6372803\n",
      " -0.38166997 -0.3430285  -0.32100028 -0.32492733 -0.64506304 -0.5559207\n",
      " -0.37118664 -0.3325661  -0.65344924 -0.6125372  -0.74057555 -0.35840258\n",
      " -0.59174204 -0.9416679  -0.45514476 -0.3656652  -0.49689955 -0.34038255\n",
      " -0.41209623 -0.33025223], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33690903 -0.37840387 -0.3374582  -0.41496295 -0.3331058  -0.33969834\n",
      " -0.32613772 -0.50868195 -0.41791084 -0.38173962 -0.38139045 -0.3620049\n",
      " -0.82943356 -0.46174157 -0.34345895 -0.40061778 -0.5374714  -0.3570107\n",
      " -0.33940822 -0.5505744  -0.64907986 -0.41301602 -0.658405   -0.33877805\n",
      " -0.9747916  -0.36366484 -0.7564539  -0.3722855  -0.34100032 -0.35793954\n",
      " -0.40335947 -0.3811493 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37074646 -0.38733938 -0.49021012 -0.52762055 -0.33882493 -0.85212564\n",
      " -0.50088704 -0.586556   -0.41314214 -0.31515908 -0.5516876  -0.71535826\n",
      " -0.34919798 -0.5155976  -0.3619618  -0.7127023  -0.3649033  -0.3437524\n",
      " -0.33114326 -0.6775104  -0.33231306 -0.34203768 -0.40455925 -0.42127317\n",
      " -0.40555015 -0.4953586  -0.36367843 -0.48597324 -0.3479797  -0.39554498\n",
      " -0.41631338 -0.3871682 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.48126134 -0.40590212 -0.40915537 -0.39875758 -0.32163453 -0.4622652\n",
      " -0.39111376 -0.45386052 -0.41446295 -0.39219385 -0.33479446 -0.37211913\n",
      " -0.94970936 -0.3702417  -0.31461173 -0.46879205 -0.73022175 -0.3600965\n",
      " -0.5175227  -0.34760842 -0.32050523 -0.32977676 -0.41511    -0.46397355\n",
      " -0.4194073  -0.6292165  -0.36483213 -0.49747926 -0.842879   -0.38893494\n",
      " -0.5602465  -0.52197677], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3737707  -0.5055676  -0.35066423 -0.5204666  -0.3414222  -0.34830895\n",
      " -0.60342807 -0.44083405 -0.5141856  -0.55599564 -0.47297892 -0.41447523\n",
      " -0.3339807  -0.32304648 -0.40817082 -0.3396637  -0.66665125 -0.6485003\n",
      " -0.3493093  -0.3359415  -0.355622   -0.72847915 -0.59893614 -0.33257398\n",
      " -0.55515885 -0.47104195 -0.42415166 -0.39919752 -0.5018844  -0.3911535\n",
      " -0.41562557 -0.4655758 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5403558  -0.47970042 -0.34229505 -0.3493451  -0.8316268  -0.4418795\n",
      " -0.94903135 -0.4122932  -0.3546179  -0.38427216 -0.50826335 -0.4859643\n",
      " -0.36558777 -0.36527544 -0.36741596 -0.43922326 -0.41923204 -0.3558338\n",
      " -0.56934065 -0.40121767 -0.39868724 -0.33899713 -0.7483554  -0.3453974\n",
      " -0.37720343 -0.43719393 -0.534858   -0.55982107 -0.6739731  -0.509515\n",
      " -0.3336678  -0.35956505], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35107726 -0.36341745 -0.33655974 -0.40410608 -0.7051602  -0.37328553\n",
      " -0.6229801  -0.35972446 -0.38170618 -0.34773213 -0.51139617 -0.52809477\n",
      " -0.38238412 -0.5037105  -0.32978252 -0.44829404 -0.3746566  -0.5088122\n",
      " -0.35871923 -0.4040159  -0.43179804 -0.34090286 -0.91663253 -0.34024343\n",
      " -0.33981693 -0.31857336 -0.46320534 -0.35210267 -0.43538082 -0.44060326\n",
      " -0.36811364 -0.36033955], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38937083 -0.371684   -0.34660712 -0.4681465  -0.5125306  -0.50594634\n",
      " -0.33173478 -0.32101592 -0.3406061  -0.60521317 -0.57474685 -0.5144845\n",
      " -0.4214975  -0.35533768 -0.33585477 -0.33203274 -0.4786923  -0.4477326\n",
      " -0.3867384  -0.3452319  -0.42336643 -0.45364642 -0.41056386 -0.34407425\n",
      " -0.3251128  -0.34820074 -0.3979453  -0.6215677  -0.34628052 -0.3705526\n",
      " -0.32175076 -0.3921539 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.41727635 -0.35016116 -0.38024795 -0.49512666 -1.0037732  -0.5652786\n",
      " -0.33995777 -0.35730013 -0.34503496 -0.56020963 -0.32418343 -0.5007998\n",
      " -0.44509697 -0.34435672 -0.33162922 -0.33659253 -0.49270046 -0.3463301\n",
      " -0.45134783 -0.97276676 -0.33474916 -0.3404007  -0.5329233  -0.34627032\n",
      " -0.36596715 -0.35347152 -0.34140408 -0.861722   -0.3720495  -0.51307\n",
      " -0.5862739  -0.3539417 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32269973 -0.44231462 -0.3648856  -0.54620814 -0.37188303 -0.8324224\n",
      " -0.45804346 -0.36252278 -0.59793466 -0.31691825 -0.4324946  -0.55507624\n",
      " -0.36454678 -0.36176142 -0.4196949  -0.34130374 -0.37300572 -0.40319893\n",
      " -0.37631506 -0.4058318  -0.542012   -0.42258042 -0.5845134  -0.3796034\n",
      " -0.4476459  -0.5422514  -0.33412486 -0.7478312  -0.40194988 -0.72803783\n",
      " -0.5223057  -0.55837375], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.41369742 -0.36332285 -0.51969963 -0.35340345 -0.3491297  -0.3986333\n",
      " -0.45607018 -0.3640264  -0.39948753 -0.3637824  -0.40106064 -0.38694194\n",
      " -0.3524893  -0.38217282 -0.5447489  -0.3263334  -0.5624163  -0.38466474\n",
      " -0.55521595 -0.76095235 -0.34443223 -0.3533244  -0.41447666 -0.42728025\n",
      " -0.3529747  -0.3769857  -0.7566248  -0.33395186 -0.38118446 -0.33987027\n",
      " -0.8247216  -0.9964591 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7371671  -0.34389663 -0.5863946  -0.34515238 -0.33281553 -0.47483975\n",
      " -0.32313    -0.3644963  -0.39903226 -0.42696893 -0.39817974 -0.3678865\n",
      " -0.350016   -0.33191606 -0.52059597 -0.33236787 -0.42183092 -0.517752\n",
      " -0.38935766 -0.46484905 -0.3368062  -0.698125   -0.44104666 -0.362112\n",
      " -0.37299785 -0.369224   -0.36622524 -0.32521042 -0.8019406  -0.4279088\n",
      " -0.31776989 -0.34831566], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.60671926 -0.4707296  -0.4044385  -0.35739285 -0.3801229  -0.38559738\n",
      " -0.47829455 -0.48858607 -0.35991153 -0.35383192 -0.38414058 -0.37907803\n",
      " -0.6958301  -0.564275   -0.3377101  -0.3366272  -0.8100955  -0.34368286\n",
      " -0.4813569  -0.343508   -0.3178053  -0.33884412 -0.81702197 -0.34185508\n",
      " -0.3461101  -0.48344472 -0.38000992 -0.34319925 -0.34820545 -0.35724667\n",
      " -0.40248823 -0.3227071 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3240217  -0.35215348 -0.37021002 -0.48792428 -0.3925417  -0.34709167\n",
      " -0.34993488 -0.3360158  -0.3419981  -0.7417345  -0.4050482  -0.38679022\n",
      " -0.33888033 -0.31981733 -0.46059623 -0.37885556 -0.4251895  -0.32337436\n",
      " -0.50549793 -0.4725902  -0.44090843 -0.40505448 -0.38095748 -0.37346765\n",
      " -0.47394112 -0.35104537 -0.38455746 -0.46434557 -0.32540795 -0.34894767\n",
      " -0.34628534 -0.6244414 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3152566  -0.37931105 -0.40988624 -0.4520402  -0.4771499  -0.3426864\n",
      " -0.41037092 -0.4462717  -0.32191503 -0.8719678  -0.35474098 -0.49953026\n",
      " -0.4143363  -0.37115392 -0.37832215 -0.4190514  -0.31834987 -0.3454158\n",
      " -0.4112173  -0.4165411  -0.31856444 -0.71566904 -0.3810535  -0.38768348\n",
      " -0.3411056  -0.40336323 -0.33500308 -0.37492424 -0.66665226 -0.35273707\n",
      " -0.5088199  -0.32658008], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.40611404 -0.45413917 -0.32834327 -0.5568697  -0.3810185  -0.34145594\n",
      " -0.33884007 -0.5682064  -0.4214903  -0.51045394 -0.8830675  -0.32784325\n",
      " -0.33196396 -0.39581135 -0.38003275 -0.35850462 -0.56917673 -0.3425774\n",
      " -0.32964072 -0.31452608 -0.32264534 -0.4245948  -0.32241505 -0.32292235\n",
      " -0.3384766  -0.34492505 -0.3923338  -0.3275158  -0.34013885 -0.38598618\n",
      " -0.3209776  -0.35471347], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33601698 -1.0668194  -0.40548784 -0.4461941  -0.37983042 -0.33666897\n",
      " -0.35910198 -0.34641802 -0.53696656 -0.49012494 -0.47333074 -0.37765607\n",
      " -0.4418015  -0.42582667 -0.4546762  -0.4048886  -1.1022022  -0.34565568\n",
      " -0.6823306  -0.32524487 -0.33508238 -0.43729624 -0.332771   -0.4843779\n",
      " -0.37875214 -0.42533597 -0.36253184 -0.5610473  -0.44375598 -0.32333684\n",
      " -0.32791558 -0.5073642 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.41715124 -0.39287856 -0.44000345 -0.45242128 -0.34492317 -0.42027277\n",
      " -0.35854375 -0.31786966 -0.3266844  -0.42892155 -0.33656648 -0.38507736\n",
      " -0.3221432  -0.34883398 -0.32627594 -0.34199658 -0.44201937 -0.5769668\n",
      " -0.7974037  -0.446064   -0.33464554 -0.3278934  -0.3480147  -0.32628077\n",
      " -0.42682526 -0.44305694 -0.32655585 -0.40262133 -0.4533723  -0.45017663\n",
      " -0.33135256 -0.32862177], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5590771  -0.34485674 -0.37771922 -0.33511496 -0.34328687 -0.5146628\n",
      " -0.38447452 -0.32784033 -0.32828498 -0.5916814  -0.39865732 -0.40955943\n",
      " -0.3365619  -0.44414276 -0.33367926 -0.35754818 -0.39440706 -0.3841508\n",
      " -0.33629075 -0.39968795 -0.33591178 -0.5550636  -0.32783914 -0.32773417\n",
      " -0.66560423 -0.44078186 -0.41145322 -0.37174076 -0.44758365 -0.3878016\n",
      " -0.37760213 -0.45427763], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36935052 -0.3346574  -0.5400412  -0.3291191  -0.3593537  -0.3304779\n",
      " -0.49105197 -0.34226406 -0.33175567 -0.5847263  -0.3353857  -0.39325374\n",
      " -0.40970615 -0.8439455  -0.33230665 -0.34015444 -0.33267605 -0.32775694\n",
      " -0.6015241  -0.34797668 -0.38462    -0.35226327 -0.5244932  -0.32392946\n",
      " -0.6972631  -0.34855697 -0.4713981  -0.5207277  -0.57849544 -0.36479694\n",
      " -0.38969165 -0.51862437], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4110814  -0.33657286 -0.5880557  -0.3346109  -0.40065396 -0.36137936\n",
      " -0.3355879  -0.33678186 -0.38715306 -0.32520112 -0.33949718 -0.3378266\n",
      " -0.32736853 -0.5166812  -0.5282994  -0.73789686 -0.33822408 -0.3335088\n",
      " -0.31836712 -0.3315047  -0.587978   -0.6257149  -0.6497723  -0.34052724\n",
      " -0.4062538  -0.52380884 -0.33818287 -0.50808334 -0.37635368 -0.3192901\n",
      " -0.6201513  -0.49442965], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33889925 -0.4209682  -0.5167854  -0.3531932  -0.40243515 -0.3303714\n",
      " -0.37666923 -0.36812884 -0.34729967 -0.3333591  -0.908952   -0.33951592\n",
      " -0.35369158 -0.345484   -0.41388202 -0.59452844 -0.45480138 -0.6269155\n",
      " -0.77806747 -0.33896706 -0.6031817  -0.32195252 -0.34077474 -0.4892587\n",
      " -0.3555392  -0.35814688 -0.44806814 -0.48586297 -0.3312311  -0.42041606\n",
      " -0.42747915 -0.56577265], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35423252 -0.33519143 -0.67168945 -0.3317312  -0.3824877  -0.36859506\n",
      " -0.33066136 -0.34804046 -0.38867903 -0.34091827 -0.41450447 -0.39770973\n",
      " -0.4959883  -0.49035013 -0.40666023 -0.6241946  -0.3958103  -0.4052924\n",
      " -0.39122495 -0.46261436 -0.46885747 -0.42316335 -0.40663418 -0.345233\n",
      " -0.3594865  -0.32850376 -0.46249896 -0.32189906 -0.3710218  -0.35749006\n",
      " -0.7162458  -0.45799315], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34266797 -0.342111   -0.8685142  -0.34534204 -0.60628986 -0.34346166\n",
      " -0.4844738  -0.7413573  -0.33512953 -0.3411851  -0.36309075 -0.54963267\n",
      " -0.3277871  -0.33951086 -0.9225185  -0.84467787 -0.38050473 -0.44645464\n",
      " -0.3479945  -0.38650402 -0.42812    -0.36283484 -0.3587314  -0.48028257\n",
      " -0.5777785  -0.5522791  -0.35056955 -0.42567995 -0.3743013  -0.32712156\n",
      " -0.33662146 -0.40198553], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7593162  -0.33372262 -0.3284077  -0.4029919  -0.40115038 -0.55523443\n",
      " -0.51675344 -0.32168606 -0.7966902  -0.417568   -0.34850278 -0.33925638\n",
      " -0.32924825 -0.47926587 -0.44214723 -0.86878943 -0.92767215 -0.34070802\n",
      " -0.4924993  -0.36408925 -0.7041873  -0.3388979  -0.3647872  -0.40076956\n",
      " -0.34376985 -0.73444664 -0.4581371  -0.5181539  -0.34860998 -0.3473856\n",
      " -0.36479753 -0.3195179 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5058322  -0.346602   -0.7211839  -0.3379124  -0.35786736 -0.4338627\n",
      " -0.40335876 -0.5153268  -0.33088282 -0.8555091  -0.34502956 -0.6772477\n",
      " -0.60753566 -0.31793773 -0.33132902 -0.48790923 -0.892375   -0.78630465\n",
      " -0.33621216 -0.38210154 -0.7393841  -0.48896676 -0.4250006  -0.3289324\n",
      " -0.3638425  -0.36113957 -0.36526832 -0.3827154  -0.35983658 -0.3159146\n",
      " -0.36053085 -0.40548173], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3322373  -0.36083445 -0.6386623  -0.33450085 -0.39427543 -0.37116084\n",
      " -0.6564347  -0.40355402 -0.33734214 -0.5227178  -0.35175264 -0.35258248\n",
      " -0.36851895 -0.34088242 -0.3518167  -0.50338316 -0.3324319  -0.43772978\n",
      " -0.31926274 -0.34124053 -0.43935987 -0.6301882  -0.735682   -0.48368597\n",
      " -0.36276782 -0.6817519  -0.33871382 -0.32477978 -0.3940023  -0.36759806\n",
      " -0.35379082 -0.35051   ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32609743 -0.3359813  -0.33286637 -0.5110411  -0.3500377  -0.603147\n",
      " -0.3351893  -0.4208369  -0.3439034  -0.5089494  -0.7405294  -0.35736224\n",
      " -0.6936569  -0.31721494 -0.34213877 -0.4343205  -0.41115472 -0.6480687\n",
      " -0.3250518  -0.504242   -0.31877673 -0.6865839  -0.33671257 -0.38507393\n",
      " -0.35282385 -0.44265443 -0.33326033 -0.33637166 -0.32793498 -0.43670875\n",
      " -0.45407736 -0.33866054], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43402734 -0.40347138 -0.33160105 -0.3549269  -0.3852192  -0.35017157\n",
      " -0.45059514 -0.35568023 -0.4838452  -0.33172306 -0.50388515 -0.33947426\n",
      " -0.34844324 -0.44825232 -0.40894583 -0.36028752 -0.47979367 -0.3600204\n",
      " -0.3678398  -0.5940232  -0.4138735  -0.4024015  -0.35105526 -0.40791994\n",
      " -0.33453625 -0.55201685 -0.5224169  -0.35047895 -0.749974   -0.32291132\n",
      " -0.35662013 -0.37865722], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3237192  -0.3611231  -0.62045395 -0.41546845 -0.36065993 -0.32661432\n",
      " -0.6584429  -0.3474789  -0.5201311  -0.5889994  -0.46936202 -0.36047557\n",
      " -0.68331444 -0.31465986 -0.32581237 -0.7830867  -0.32856283 -0.65901756\n",
      " -0.34951    -0.441421   -0.34641415 -0.33243343 -0.57176644 -0.33401716\n",
      " -0.31926507 -0.38949585 -0.43777272 -0.57835364 -0.38110977 -0.4441532\n",
      " -0.4225951  -0.32787418], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5000489  -0.5750039  -0.42356476 -0.33923176 -0.52560353 -0.364851\n",
      " -0.3220067  -0.43441036 -0.43268442 -0.32304475 -0.3376488  -0.44200075\n",
      " -0.4389836  -0.52602106 -0.51613563 -0.3765471  -0.33876854 -0.7808991\n",
      " -0.3417729  -0.35574496 -0.33511758 -0.48385417 -0.338545   -0.56909966\n",
      " -0.34703767 -0.35982263 -0.35618794 -0.37086716 -0.382581   -0.39115238\n",
      " -0.3537525  -0.34806085], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.50360245 -0.6195011  -0.41651052 -0.45470026 -0.36147147 -0.40733004\n",
      " -0.52131605 -0.36151582 -0.31776598 -0.4523949  -0.33696127 -0.3937081\n",
      " -0.5441621  -0.32684895 -0.47973007 -0.36112893 -0.46785313 -0.42324683\n",
      " -0.50060374 -0.3252156  -0.42648393 -0.4754065  -0.4437269  -0.3780399\n",
      " -0.33537567 -0.318396   -0.31906822 -0.32720327 -0.4106204  -0.4006253\n",
      " -0.37385768 -0.3224286 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.1444352  -0.32503742 -0.34654152 -0.35192284 -0.7110262  -0.33299404\n",
      " -0.48895365 -0.67910224 -0.49669528 -0.43197295 -0.3566199  -0.3820442\n",
      " -0.38174257 -0.4077009  -0.3665072  -0.5456321  -0.6607063  -0.63603365\n",
      " -0.58823615 -0.3345647  -0.50033224 -0.38287058 -0.34476238 -0.35471204\n",
      " -0.69461584 -0.33287987 -0.35702237 -0.3197996  -0.32727572 -1.21748\n",
      " -0.3351978  -0.3291371 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6323566  -0.36873168 -0.35129416 -0.34653303 -0.37015256 -0.34218568\n",
      " -0.36066043 -0.6709852  -0.6172843  -0.49794984 -0.4438486  -0.3366049\n",
      " -0.5637934  -0.4928832  -0.6505716  -0.5878817  -0.48511058 -0.41145116\n",
      " -0.33330408 -0.3302418  -0.39770362 -0.46980277 -0.33122015 -0.33727843\n",
      " -0.33943468 -0.5874447  -0.3993241  -0.5134642  -0.39845005 -0.3895765\n",
      " -0.31761476 -0.5257723 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43311024 -0.33737805 -0.4011697  -0.34531698 -0.44118577 -0.42531073\n",
      " -1.054106   -0.46596587 -0.5365143  -0.36687064 -0.4195573  -0.6607244\n",
      " -0.42982095 -0.3501637  -0.4050284  -0.78863996 -0.4526858  -0.3363267\n",
      " -0.34076008 -0.33239093 -0.71101946 -0.5103486  -0.3423444  -0.43016875\n",
      " -0.36626846 -0.40743545 -0.38372716 -0.5670644  -0.34105408 -0.41777495\n",
      " -0.4004261  -0.32258007], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3185763  -0.5135686  -0.3512454  -0.5899367  -0.32153982 -0.45448047\n",
      " -0.51862216 -0.33274543 -0.46460336 -0.37277558 -0.39848006 -0.5356957\n",
      " -0.34145492 -0.33007067 -0.41082627 -0.46188217 -0.48483092 -0.70179343\n",
      " -0.5431713  -0.33689967 -0.6371479  -0.41722113 -0.5672706  -0.33518803\n",
      " -0.56941557 -0.9413107  -0.48557428 -1.0582086  -0.5467328  -0.32659864\n",
      " -0.3269455  -0.4949001 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5460478  -0.45152658 -0.9028721  -0.40129763 -0.36050883 -0.37087128\n",
      " -0.60365057 -0.34176734 -0.3882261  -0.33050188 -0.330052   -0.46104866\n",
      " -0.45331556 -0.3849144  -0.3916872  -0.5558665  -0.3741138  -0.33209047\n",
      " -0.3691544  -0.56425935 -0.31652564 -0.45396507 -0.7375749  -0.5986168\n",
      " -0.4773777  -0.4625224  -0.7640541  -0.52791196 -0.35947135 -0.44553822\n",
      " -0.7722895  -0.6897317 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34732333 -0.56968504 -0.31835705 -0.35017645 -0.53996783 -0.5546527\n",
      " -0.35677052 -0.32436988 -0.34560734 -0.38026553 -0.60986066 -0.46525294\n",
      " -0.5342201  -0.33584216 -1.106925   -0.39202777 -0.3499745  -0.40853235\n",
      " -0.40815037 -0.51780194 -0.3255514  -0.84059453 -0.3241501  -0.3865591\n",
      " -0.3683089  -0.70628273 -0.6609807  -0.34343028 -0.58236873 -0.33689192\n",
      " -0.62729347 -0.38672593], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37965035 -0.34975088 -0.45811868 -0.3777783  -0.34622216 -0.31973994\n",
      " -0.35824662 -0.5695998  -0.4121027  -0.32230124 -0.3282896  -0.6381686\n",
      " -0.45270416 -0.48688722 -0.40935332 -0.33223087 -0.63859534 -0.4707564\n",
      " -0.33322096 -0.34637707 -0.7272146  -0.36605677 -0.3373778  -0.63182557\n",
      " -0.355691   -0.49370223 -0.52710795 -0.410935   -0.32449734 -0.6582911\n",
      " -0.4952775  -0.4141466 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32296154 -0.3531005  -0.4641419  -0.32432392 -0.32715204 -0.64407897\n",
      " -0.53403854 -0.34413636 -0.35995406 -0.33175242 -0.33841556 -0.43935856\n",
      " -0.39337805 -0.3433968  -0.39185384 -0.4039602  -0.39118212 -0.4799492\n",
      " -0.421052   -0.3434884  -0.3491763  -0.35120094 -0.32965675 -0.4979382\n",
      " -0.33520347 -0.392386   -0.4406286  -0.9160019  -0.51909834 -0.326432\n",
      " -0.46665564 -0.39109957], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3223831  -0.48131034 -0.88157654 -0.32363832 -0.33175978 -0.3178017\n",
      " -0.7308457  -0.3909634  -0.32222292 -0.33201382 -0.3736736  -0.45605695\n",
      " -0.78608686 -0.45541826 -0.3563882  -0.32260728 -0.32467827 -0.3362395\n",
      " -0.38635743 -0.40359846 -0.3302243  -0.3246239  -0.3726571  -0.33848968\n",
      " -0.3276804  -0.4047771  -0.34673566 -0.4088345  -0.34054378 -0.36339897\n",
      " -0.5663964  -0.35222825], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3772502  -0.33130068 -0.3867919  -0.8112985  -0.34705907 -0.34212953\n",
      " -0.80175066 -0.45409906 -0.3350551  -0.3557589  -0.6431619  -0.35892949\n",
      " -0.35307822 -0.40984678 -0.41506135 -0.5273355  -0.6361715  -0.3459441\n",
      " -0.57660466 -0.331309   -0.42338055 -0.81876576 -0.44034648 -0.9012071\n",
      " -0.32264724 -0.43927434 -0.44174212 -0.31814843 -0.33658248 -0.38391906\n",
      " -0.46640518 -0.3410116 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32776588 -0.330571   -0.9778448  -0.45167238 -0.3339639  -0.32083145\n",
      " -0.38087124 -0.3268395  -0.3646352  -0.33131582 -0.5355018  -0.5647905\n",
      " -0.38309664 -1.1905153  -0.403002   -0.440933   -0.39444178 -0.37726492\n",
      " -0.33323222 -0.7467257  -0.33621937 -0.3307977  -0.31449997 -0.5446246\n",
      " -0.45881277 -0.5121487  -0.5521321  -0.33405292 -0.43240827 -0.3398975\n",
      " -0.3597727  -0.5521321 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33318806 -0.35414878 -0.32663548 -0.3359618  -0.5841913  -0.32639888\n",
      " -0.32009062 -0.45299822 -0.33473563 -0.36875767 -0.35130993 -0.3191883\n",
      " -0.37837407 -0.32053015 -0.31500608 -0.34075814 -0.33091056 -0.562521\n",
      " -0.32549888 -0.84463114 -0.32750076 -0.31731611 -0.3836643  -0.34747285\n",
      " -0.6564888  -0.3573825  -0.34243727 -0.3650546  -0.35455042 -0.787812\n",
      " -0.44179353 -0.40209702], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4058423  -0.3339352  -0.45231012 -0.3562685  -0.43127462 -0.3587602\n",
      " -0.329553   -0.58968866 -0.43530694 -0.6267433  -0.3724626  -0.31787494\n",
      " -0.7048403  -0.33321327 -0.37121075 -0.46270448 -0.66695666 -0.3556438\n",
      " -0.39241385 -0.63651115 -0.3437223  -0.6104542  -0.38180637 -0.3705293\n",
      " -0.37237108 -0.49988067 -0.4138043  -0.37711254 -0.38332856 -0.5794024\n",
      " -0.5393312  -0.32259372], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32211882 -0.4253577  -0.7800911  -0.35508537 -0.3304451  -0.3591029\n",
      " -0.5693396  -0.32876363 -0.32132363 -0.33161348 -0.32561138 -0.3286072\n",
      " -0.40815783 -0.98544335 -0.47807032 -0.5362326  -0.43190733 -0.3721883\n",
      " -0.4169536  -0.36410373 -0.36224103 -0.36393633 -0.3569014  -0.49587956\n",
      " -0.35843313 -0.43483552 -0.35484675 -0.3219851  -0.33256236 -0.38174394\n",
      " -0.7931917  -0.38600805], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5022037  -0.3438269  -0.3298101  -0.42630127 -0.4546849  -0.4641756\n",
      " -0.33891636 -0.35344046 -0.3565575  -0.4161405  -0.5235071  -0.80303717\n",
      " -0.32066053 -0.46875915 -0.37656033 -0.3277462  -0.33536467 -0.32033026\n",
      " -0.32979247 -0.31961143 -0.3399026  -0.42465168 -0.34011722 -0.3568537\n",
      " -0.35624287 -0.3460449  -0.32016066 -0.49925184 -0.33832675 -0.33054438\n",
      " -0.34025353 -0.6566245 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3226703  -0.43225756 -0.39125928 -0.36599022 -0.34011915 -0.40602517\n",
      " -0.4045393  -0.432595   -0.32274824 -0.33857983 -0.88273203 -0.33093703\n",
      " -1.0462098  -0.6737125  -0.58201754 -0.4857297  -0.34303144 -0.54871166\n",
      " -0.6050643  -0.478923   -0.3148016  -0.31917524 -0.5446546  -0.6869964\n",
      " -0.32004666 -0.4576285  -0.6110662  -0.37541354 -0.3490917  -0.32251507\n",
      " -0.5360957  -0.38763487], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7110319  -0.3717913  -0.41481245 -0.33589414 -0.6696489  -0.50634456\n",
      " -0.66429055 -0.6576779  -0.39521736 -0.48988396 -0.3879835  -0.6705282\n",
      " -0.8479773  -0.3187285  -0.46262193 -0.35950714 -0.33333182 -0.31804365\n",
      " -0.6598317  -0.32523626 -0.3258824  -0.73402464 -0.4116769  -0.33275536\n",
      " -0.47244468 -0.8065249  -1.2747372  -0.46135527 -0.73782116 -0.3397491\n",
      " -0.45256564 -0.37060502], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.42663762 -0.4147255  -0.39993578 -0.38562396 -0.35716158 -0.34207797\n",
      " -0.41818896 -0.36615753 -0.32922673 -0.38916737 -0.32549834 -0.3321057\n",
      " -0.31781718 -0.33999172 -0.33557382 -0.44913334 -0.3380018  -0.38920784\n",
      " -0.3185133  -0.3198297  -0.4815957  -0.40192214 -0.5267654  -0.8882432\n",
      " -0.3826749  -0.4542132  -0.78775215 -0.31849813 -0.34278634 -0.63198584\n",
      " -0.36146548 -0.3994374 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32683048 -0.42526928 -0.954693   -0.33531505 -0.6793882  -0.32607007\n",
      " -0.3939129  -0.37430575 -0.4225597  -0.44093606 -0.40842474 -0.36403847\n",
      " -0.37727007 -0.3372763  -0.32035726 -0.5196926  -0.33366004 -0.36847633\n",
      " -0.33276355 -0.33956915 -0.3904151  -0.32561207 -0.3671003  -0.7451339\n",
      " -0.3469663  -0.32452974 -0.34693816 -0.41498798 -0.6300125  -0.43063128\n",
      " -0.44658902 -0.33472145], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3164887  -0.33526757 -0.3499043  -0.36275283 -0.33530986 -0.57429487\n",
      " -0.3232049  -0.33415544 -0.39078254 -0.4125877  -0.5892557  -0.3197348\n",
      " -0.34102643 -0.48964947 -0.6738783  -0.31844488 -0.33887097 -0.32674062\n",
      " -0.42062712 -0.384178   -0.3782694  -0.8441142  -0.588299   -0.6997633\n",
      " -0.34681472 -0.36195078 -0.627534   -0.4030407  -0.3159272  -0.40258563\n",
      " -0.49499953 -0.36349702], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.61149114 -0.40000027 -0.50415546 -0.502294   -0.33434504 -0.6351615\n",
      " -0.32944968 -0.374552   -0.41948065 -0.5720245  -0.38439432 -0.35511917\n",
      " -0.5462259  -0.50595045 -0.9550611  -0.3565421  -0.33033517 -0.39627883\n",
      " -0.35680446 -0.34925145 -0.37091136 -0.33288354 -0.32267255 -0.37410405\n",
      " -0.37889582 -0.3560628  -0.33379894 -0.36650142 -0.44610962 -0.41524303\n",
      " -0.40332618 -0.38196504], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37330467 -0.5425629  -0.31794408 -0.41696364 -0.43147874 -0.65873593\n",
      " -0.81745446 -0.3326611  -0.5381596  -0.3891209  -0.33600983 -0.32000667\n",
      " -0.42419752 -0.48059255 -1.0294222  -0.4974322  -0.9849584  -0.3509852\n",
      " -0.4252308  -0.33377308 -0.34006402 -0.338684   -0.3960032  -0.48730367\n",
      " -0.5021256  -0.3692355  -0.43475628 -0.57960516 -0.34815997 -0.35350055\n",
      " -0.3641507  -0.37863028], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3799518  -0.32648522 -0.37538412 -0.40190333 -0.36368132 -0.37878147\n",
      " -0.33092734 -0.31805754 -0.55278355 -0.44045547 -0.3599072  -0.35453814\n",
      " -0.3536452  -0.87103295 -0.3575326  -0.37898558 -0.39606175 -0.72207916\n",
      " -0.35989118 -0.34223926 -0.3847508  -0.78619796 -0.3398558  -0.33526006\n",
      " -0.8927267  -0.3863051  -0.3285437  -0.41850403 -0.33217803 -0.33016664\n",
      " -0.4752705  -0.32828394], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.49666336 -0.3525317  -0.31626534 -0.35842648 -0.5557562  -0.47895977\n",
      " -0.38052657 -0.33394128 -0.4519015  -0.3541503  -0.3956734  -0.36189476\n",
      " -0.34913594 -0.6058903  -0.38384607 -0.5084694  -0.4200474  -0.36431444\n",
      " -0.32307643 -0.37666482 -0.62999994 -0.48870894 -0.31903228 -1.0222535\n",
      " -0.33114052 -0.33568665 -0.46425968 -0.33903491 -0.3837481  -0.33537924\n",
      " -0.32153904 -0.56007206], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32442337 -0.7273263  -0.6416928  -0.3140713  -0.47854397 -0.31419274\n",
      " -0.40190876 -0.33217633 -0.3637119  -0.48671913 -0.9068667  -0.33184788\n",
      " -0.3186031  -0.3829341  -0.4334163  -0.31646454 -0.31440613 -0.3602413\n",
      " -0.34197804 -0.38037133 -0.32274696 -0.49615556 -0.35851234 -0.32094648\n",
      " -0.4681292  -0.32032216 -0.42674342 -0.4584102  -0.33882713 -0.37070516\n",
      " -0.33454454 -0.4889063 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32384306 -0.7076261  -0.33629405 -0.41430604 -0.32766458 -0.3194771\n",
      " -0.3643555  -0.35709897 -0.31697738 -0.32359776 -0.33886096 -0.39964974\n",
      " -0.31903738 -0.4547364  -0.34216586 -0.34390405 -0.6144611  -0.5208304\n",
      " -0.35063794 -0.31977776 -0.3428323  -0.35935444 -0.3446619  -0.3177718\n",
      " -0.3667952  -0.39957556 -0.38829613 -0.33242542 -0.5317062  -0.4279301\n",
      " -0.4685824  -0.33750796], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3675648  -0.31934476 -0.4187431  -0.6534136  -0.33938146 -0.3578648\n",
      " -0.39079678 -0.32473567 -0.4232473  -0.35917658 -0.33098814 -0.41386294\n",
      " -0.3546475  -0.33418214 -0.33880055 -0.38989508 -0.52706987 -0.3607049\n",
      " -0.33296695 -0.5109544  -0.36869574 -0.33560255 -0.33400494 -0.35276312\n",
      " -0.45184225 -0.33144796 -0.3234137  -0.50926936 -0.81604093 -0.8530719\n",
      " -0.38051435 -0.32076052], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33168098 -0.32765076 -0.8264606  -0.33041304 -0.35368913 -0.398773\n",
      " -0.32735237 -0.3325686  -0.35468915 -0.8650814  -0.43640444 -0.33479217\n",
      " -0.4652142  -0.40207526 -0.3543036  -0.36519557 -0.61962885 -0.36904833\n",
      " -0.32632273 -0.5013916  -0.35887787 -0.35738486 -0.38928643 -0.33161774\n",
      " -0.5687788  -0.33088866 -0.3286414  -0.31813985 -0.36311662 -0.4152634\n",
      " -0.41086182 -0.33332065], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.45776743 -0.3980891  -0.3386873  -0.44663846 -0.38003016 -0.7735199\n",
      " -0.3360693  -0.32197112 -0.3242293  -0.33865833 -0.3292815  -0.48854586\n",
      " -0.34148085 -0.3264781  -0.36038986 -0.33820564 -0.34238374 -0.3261254\n",
      " -0.3412857  -0.32755592 -0.3715783  -0.32006413 -0.6036859  -0.35129306\n",
      " -0.39450604 -0.50437504 -0.38455707 -0.70639634 -0.3649807  -0.36067247\n",
      " -0.32264456 -0.35804874], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3634515  -0.3196406  -0.37629494 -0.3178882  -0.3315491  -0.43788028\n",
      " -0.35608658 -0.3311182  -0.35564512 -0.33952042 -0.3910337  -0.33189887\n",
      " -0.49350882 -0.32553685 -0.32662085 -0.33037862 -0.32806036 -0.4097431\n",
      " -0.47462118 -0.5394027  -0.40006268 -0.37526718 -0.37007532 -0.3162404\n",
      " -0.32228035 -0.35467586 -0.5331527  -0.37094253 -0.43703884 -0.32135847\n",
      " -0.3254802  -0.6170076 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31875712 -0.32374215 -0.32764003 -0.38035813 -0.37483796 -0.5063693\n",
      " -0.3912413  -0.7935039  -0.57693475 -0.34969726 -0.5207465  -0.76814663\n",
      " -0.35903805 -0.56674755 -0.5026242  -0.40977833 -0.39326888 -0.49553245\n",
      " -0.9470111  -0.347038   -0.32582873 -0.5359863  -0.3699201  -0.31589642\n",
      " -0.32927415 -0.44426042 -0.507969   -0.53857857 -0.37829006 -0.41994745\n",
      " -0.9321294  -0.32349652], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34873044 -0.3200767  -0.5410469  -0.5937227  -0.7300288  -0.39070526\n",
      " -0.4225306  -0.35975924 -0.33510268 -0.3469171  -0.35102743 -0.8000252\n",
      " -0.46087041 -0.36239254 -0.39586133 -0.40100837 -0.46478215 -0.31571034\n",
      " -0.38018942 -0.33333626 -0.38046563 -0.3751661  -0.32444596 -0.6094186\n",
      " -0.387913   -0.48199052 -0.32792115 -0.49795878 -0.33781353 -0.35081977\n",
      " -0.46345967 -0.33267546], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.44062382 -0.46036857 -0.4577872  -0.38039732 -0.46849114 -0.32687294\n",
      " -0.35831928 -0.3731886  -0.32207504 -0.3225578  -0.4739688  -0.4123111\n",
      " -0.44274262 -0.53280807 -0.5976995  -0.3228767  -0.31960693 -0.32897222\n",
      " -0.52957857 -0.31731206 -0.37658465 -0.31949842 -0.33611906 -0.45727742\n",
      " -0.5014678  -0.42428622 -0.41563314 -0.63697404 -0.34995008 -0.44968677\n",
      " -0.69795966 -0.4568286 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3256972  -0.84858185 -0.3812649  -0.4817567  -0.4400436  -0.51646173\n",
      " -0.36236805 -0.44381166 -0.9592035  -0.3396649  -0.33229202 -0.40506783\n",
      " -0.35249257 -0.49185714 -0.45641643 -0.31894693 -0.33118573 -0.43918216\n",
      " -1.0865862  -0.33009613 -0.32243615 -0.32730675 -0.8354089  -0.34423685\n",
      " -0.4108835  -0.3159026  -0.37680712 -0.39435178 -0.3697629  -0.36789063\n",
      " -0.3861565  -0.3449403 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3135418  -0.7383373  -0.37953323 -0.3894277  -0.32456756 -0.48411375\n",
      " -0.9990862  -0.3272827  -0.34038508 -0.46089786 -0.38586938 -0.33601597\n",
      " -0.32082072 -0.3471093  -0.33309606 -0.5483851  -0.3223351  -0.31820947\n",
      " -0.38329035 -0.32285142 -0.37413004 -0.33872938 -0.72892535 -0.74470615\n",
      " -0.31932822 -0.32822427 -0.32697403 -0.3443553  -0.35480627 -0.366274\n",
      " -0.6610141  -1.117712  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35673964 -0.32525435 -0.3280892  -0.3261576  -0.7711286  -0.32905567\n",
      " -0.32230264 -0.35389233 -0.6064771  -0.36699677 -0.46993363 -0.34369892\n",
      " -0.3234866  -0.51866806 -0.5097002  -0.5632807  -1.0038878  -0.37194434\n",
      " -0.34124255 -0.5464892  -0.45225042 -0.81700194 -0.3630453  -0.40007523\n",
      " -0.33082306 -0.32570288 -0.36977005 -0.9105628  -0.41806686 -0.46305597\n",
      " -0.342196   -0.3486596 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4519326  -0.32135278 -0.36087036 -0.3353436  -0.32468182 -0.37581027\n",
      " -0.34917563 -0.4596324  -0.3182008  -0.47448212 -0.39039066 -0.3264915\n",
      " -0.5435136  -0.39544433 -0.34419292 -0.3286005  -0.4302844  -0.4321955\n",
      " -0.67161965 -0.32497066 -0.36266166 -0.45218325 -0.32441106 -0.5657098\n",
      " -0.38641614 -0.34519744 -0.34096313 -0.34147236 -0.35241875 -0.3148574\n",
      " -0.6490134  -0.69409525], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.59797025 -0.5354621  -0.3791071  -0.41101122 -0.7282575  -0.6507569\n",
      " -0.38234597 -0.3199241  -0.58647436 -0.4226659  -0.57485974 -0.35619956\n",
      " -0.3472803  -0.3352921  -0.40602142 -0.38346422 -0.41718376 -0.4137053\n",
      " -0.32063285 -0.35844606 -0.32352453 -0.39503524 -0.31709537 -0.34820467\n",
      " -0.36919025 -0.33467615 -0.35619938 -0.35086846 -0.3283983  -1.158032\n",
      " -0.56362045 -0.40632987], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32085282 -0.31926906 -0.55100816 -0.42818138 -0.32097614 -0.65095013\n",
      " -0.42028186 -0.42439345 -0.42415106 -0.44026405 -0.34169948 -0.4551063\n",
      " -0.4287051  -0.37299252 -0.33265194 -0.3214388  -0.32447726 -0.5076803\n",
      " -0.32963267 -0.55679697 -0.4103074  -0.4530993  -0.37383044 -0.4652623\n",
      " -0.32538766 -0.33673894 -0.51976085 -0.47327787 -0.5619285  -0.47345734\n",
      " -0.42674583 -0.33735237], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.42308334 -0.41551527 -0.40335542 -0.40954548 -0.6852006  -0.48645025\n",
      " -0.49297902 -0.5729933  -0.41575348 -0.4287345  -0.33572015 -0.672144\n",
      " -0.6221563  -0.32722366 -0.5363964  -0.36563995 -0.3859399  -0.800936\n",
      " -0.32413256 -0.40395573 -0.54489356 -0.34584248 -0.5318161  -0.4843886\n",
      " -0.32246447 -0.45738414 -0.32687485 -0.4097644  -0.3901979  -0.31988737\n",
      " -0.3395048  -0.7835784 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4658083  -0.44330722 -0.44415808 -0.32918957 -0.40712488 -0.33886895\n",
      " -0.35091966 -0.3732784  -0.3174393  -0.31714123 -0.3881299  -0.34185797\n",
      " -0.3747302  -0.36604148 -0.4309262  -0.3623107  -0.4341578  -0.45749798\n",
      " -0.39591295 -0.33416584 -0.32096076 -0.35954773 -0.6719307  -0.5433235\n",
      " -0.51317424 -0.35047996 -0.4074536  -0.40460214 -0.6028459  -0.32415766\n",
      " -0.3624712  -0.82220924], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32722294 -0.35134876 -0.32378122 -0.3363233  -0.34846377 -0.6596276\n",
      " -0.35784504 -0.44376487 -0.31555077 -0.34235498 -0.6702955  -0.61002433\n",
      " -0.33845586 -0.31810254 -0.32068422 -0.41949633 -0.46200252 -0.425393\n",
      " -0.35848528 -0.3181643  -0.31461555 -0.4440758  -0.33465168 -0.3808992\n",
      " -0.33235726 -0.32028198 -0.6593389  -0.4821691  -1.046062   -0.38909215\n",
      " -0.31995308 -0.47276422], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3569921  -0.32913768 -0.38680747 -0.38742718 -0.32444236 -0.5262344\n",
      " -0.4725358  -0.39267692 -0.36153573 -0.38815203 -0.39726448 -0.46063814\n",
      " -0.3402527  -0.32759157 -0.4711073  -0.31618053 -0.32585177 -0.3448824\n",
      " -0.34059787 -0.50565463 -0.36431396 -0.46472853 -0.3175791  -0.71139175\n",
      " -0.35583463 -0.4600423  -0.43105945 -0.36628324 -0.46520537 -0.3161973\n",
      " -0.34375057 -0.31652388], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37568122 -0.31410986 -0.6829703  -1.156322   -0.6940924  -0.6307045\n",
      " -0.3327774  -0.38615277 -0.31644702 -0.46353737 -0.36270827 -0.32543638\n",
      " -0.31481266 -0.57886666 -0.36904544 -0.31656635 -0.34465548 -0.32356596\n",
      " -0.3632424  -0.3149836  -0.42196095 -0.5916024  -0.41453022 -0.43012664\n",
      " -0.3903157  -0.36462727 -0.3222984  -0.34497908 -0.33159688 -0.3218307\n",
      " -0.35906053 -0.36487573], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33076474 -0.35080928 -0.34734094 -0.446042   -0.32909438 -0.47620183\n",
      " -0.34093693 -0.42144924 -0.35093728 -0.44745493 -0.40613118 -0.37185046\n",
      " -0.3313565  -0.35297254 -0.63955796 -0.32054096 -0.3593055  -0.3453829\n",
      " -0.33350787 -0.37625313 -0.38292027 -0.45033553 -0.35506383 -0.5392096\n",
      " -0.35715383 -0.36377287 -0.3193606  -0.3322826  -0.32448906 -0.32469723\n",
      " -0.31997967 -0.3273658 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31677768 -0.33539492 -0.32546642 -0.31719965 -0.5399913  -0.46276957\n",
      " -0.39266357 -0.8562529  -0.37962386 -0.36282885 -0.35311985 -0.35183573\n",
      " -0.32813928 -0.37667632 -0.36751685 -0.36522976 -0.35659787 -0.3214321\n",
      " -0.42237744 -0.32447398 -0.46815875 -0.3255489  -0.34287316 -0.3154201\n",
      " -0.6678296  -0.74686587 -0.70672286 -0.3295651  -0.4181593  -0.60571665\n",
      " -0.42836174 -0.3163299 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31593338 -0.37654236 -0.3247584  -0.83073235 -0.5421774  -0.70267344\n",
      " -0.3224635  -0.31977293 -0.31917775 -0.32697165 -0.36209846 -0.39442402\n",
      " -0.31905037 -0.86389506 -0.31554174 -0.36665842 -0.31776738 -0.35741752\n",
      " -0.52983874 -0.31592166 -0.7397945  -0.57893294 -0.33576643 -0.3513049\n",
      " -0.51918644 -0.33911085 -0.31944317 -0.7667898  -0.5542128  -0.3188848\n",
      " -0.42915806 -0.36378604], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5966814  -0.8551229  -0.45301977 -0.9712066  -0.33651137 -0.8296251\n",
      " -0.48300084 -0.39121422 -0.4491923  -0.35406604 -0.38014182 -0.3442147\n",
      " -0.45544207 -0.40822884 -0.3249755  -0.42008436 -0.35962912 -0.42334652\n",
      " -0.4782213  -0.32281783 -0.43777996 -0.49779    -0.33971915 -0.44231147\n",
      " -0.353895   -0.32500908 -0.38556242 -0.4567033  -0.32555956 -0.33670115\n",
      " -0.3606817  -0.43828   ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3383916  -0.4318022  -0.34367278 -0.35351762 -0.4917023  -0.3194972\n",
      " -1.0621276  -1.112558   -0.41923127 -0.3326927  -0.33823827 -0.3966751\n",
      " -0.6901503  -0.3637023  -0.32039985 -0.3407935  -0.46294695 -0.44829613\n",
      " -0.31923318 -0.33150584 -0.596656   -0.36756003 -0.48169908 -1.1014992\n",
      " -0.33342203 -0.4076717  -0.3362952  -0.32019034 -0.35619804 -0.5783733\n",
      " -0.32781172 -0.34058285], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.41854075 -0.31990105 -0.33193016 -0.33422711 -0.7279881  -0.64219713\n",
      " -0.31892058 -0.3264466  -0.31657365 -0.4293488  -0.33275294 -0.40190858\n",
      " -0.6279443  -0.3345391  -0.32201344 -0.33045042 -0.34656438 -0.3335322\n",
      " -0.3234915  -0.3639475  -0.32584947 -0.3329028  -0.48538575 -0.35605854\n",
      " -0.3522068  -0.31411707 -0.31943017 -0.74387217 -0.69528973 -0.3198422\n",
      " -0.37295622 -0.32681233], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4082493  -0.33608592 -0.42062336 -0.3135774  -0.5128825  -0.36324012\n",
      " -0.4343641  -0.32691747 -0.645491   -0.5679804  -0.37492213 -0.32360345\n",
      " -0.43101916 -0.32066536 -0.5101617  -0.36320755 -0.34906968 -0.31978816\n",
      " -0.34646264 -0.40908006 -0.46814397 -0.32012257 -0.5289303  -0.6634766\n",
      " -0.3312198  -0.7621883  -0.34520346 -0.32344735 -0.35200375 -0.3303657\n",
      " -0.3867514  -0.41815177], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34296155 -0.5368786  -0.39390382 -0.37130746 -0.7756463  -0.3484678\n",
      " -0.71626663 -0.33540636 -0.44135064 -0.3322267  -0.38124138 -0.31706065\n",
      " -0.48350617 -0.3207054  -0.3229864  -0.8896388  -0.53477377 -0.32422188\n",
      " -0.70296216 -0.33303267 -0.34243962 -0.33675605 -0.33775938 -0.40820166\n",
      " -0.5603906  -0.9539602  -0.52090895 -0.31422698 -0.31545523 -0.45335776\n",
      " -0.33603522 -0.35233158], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43726736 -0.32733518 -0.33223858 -0.7703824  -0.39667824 -0.31845236\n",
      " -0.70957124 -0.72043383 -0.5147389  -0.5270388  -0.33170143 -0.34539428\n",
      " -0.5372367  -0.3230489  -0.4086184  -0.33638358 -0.876228   -0.51670253\n",
      " -0.32044753 -0.65034974 -0.32329983 -0.6798192  -0.37218156 -0.33271468\n",
      " -0.7203562  -0.40829733 -0.31865937 -0.38450786 -0.37373453 -0.35568222\n",
      " -0.32084942 -0.32812417], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3691601  -0.327274   -0.31994796 -0.39462528 -0.3491884  -0.5854718\n",
      " -0.3420799  -0.5739753  -0.38993794 -0.32687998 -0.3214336  -0.35072273\n",
      " -0.31722942 -0.38500467 -0.4620514  -0.36437538 -0.53769857 -0.62121093\n",
      " -0.35276252 -0.32796013 -0.32918486 -0.52692974 -0.317061   -0.34490088\n",
      " -0.34130085 -0.385071   -0.33467302 -0.36405462 -0.6184931  -0.6903465\n",
      " -0.934609   -0.6714205 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32731423 -0.32582182 -0.40214702 -0.32968488 -0.37348586 -0.32629988\n",
      " -0.35300586 -0.62881476 -0.3320986  -0.63087344 -0.3481865  -0.46214813\n",
      " -0.46219128 -0.35022894 -0.38590723 -0.34020805 -0.33785707 -0.34556702\n",
      " -0.32113966 -0.7287891  -0.32424825 -0.33054695 -0.3176937  -0.36989433\n",
      " -0.4448736  -0.31720608 -0.38104308 -0.37435937 -0.3775608  -0.3199653\n",
      " -0.331385   -0.33441466], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32520577 -0.3199188  -0.37511122 -0.32767197 -0.35770124 -0.7742696\n",
      " -0.46383217 -0.33970836 -0.3634622  -0.3797479  -0.36822757 -0.34558424\n",
      " -0.41373983 -0.41196895 -0.33701593 -0.3257807  -0.3305107  -0.3804859\n",
      " -0.32580626 -1.0114071  -0.49901295 -0.33420134 -0.3216054  -0.34334674\n",
      " -0.31730154 -0.32058707 -0.62889314 -0.36526912 -0.35409665 -0.35559526\n",
      " -0.33243915 -0.41946387], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32121912 -0.39101717 -0.91979873 -0.32850882 -0.39837745 -0.4677595\n",
      " -0.4922198  -0.3172295  -0.32197872 -0.3520222  -0.40940872 -0.33088678\n",
      " -0.35163665 -0.34936503 -0.34737027 -0.3266697  -0.3295403  -0.3266898\n",
      " -0.39189404 -0.32086518 -0.32450792 -0.32565123 -0.79576385 -0.42455134\n",
      " -0.3245276  -0.32131353 -0.331082   -0.57449067 -0.5213949  -0.33685088\n",
      " -0.32065135 -0.31857952], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4411047  -0.82219785 -0.38987425 -0.33569372 -0.3423025  -0.32531196\n",
      " -0.32320705 -0.33179623 -0.32426497 -0.4477156  -0.37838683 -0.32130402\n",
      " -0.32769585 -0.41383016 -0.31871578 -0.5244447  -0.4595395  -0.35719362\n",
      " -0.61304593 -0.40643078 -0.32627028 -0.45954892 -0.332174   -0.4122145\n",
      " -0.32976776 -0.61656487 -0.41029224 -0.33172274 -0.3185824  -0.32279357\n",
      " -0.35261163 -0.42349827], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32335374 -0.31774282 -0.31951642 -0.46582416 -0.47566736 -0.32486817\n",
      " -0.3493177  -0.3582547  -0.3433773  -0.51776826 -0.37526006 -0.3945319\n",
      " -0.66632867 -0.31803942 -0.4157184  -0.4402467  -0.32003835 -0.33632284\n",
      " -0.3829339  -0.57224303 -0.60429585 -0.32207096 -0.37257087 -0.3875606\n",
      " -0.34855664 -0.3341843  -0.32433498 -0.3445059  -0.37642783 -0.3276585\n",
      " -0.32422894 -0.36328268], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7825289  -0.35272884 -0.34747183 -0.3502192  -0.32957512 -0.6461526\n",
      " -0.40564167 -0.9032257  -0.3442605  -0.5057376  -0.32793686 -0.3312939\n",
      " -0.58096987 -0.39683193 -0.31943467 -0.3170887  -0.32948768 -0.49064475\n",
      " -0.72785836 -0.49047422 -0.32114112 -0.4491743  -0.3213749  -0.9712678\n",
      " -0.37595987 -0.34665626 -0.49569613 -0.34778306 -0.32365668 -0.33942756\n",
      " -0.38328484 -0.69183683], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3325808  -0.34183973 -0.33850658 -0.40868375 -0.38261175 -0.34928566\n",
      " -0.4698578  -0.32342654 -0.31604296 -0.3741457  -0.51021624 -0.7428647\n",
      " -0.33195728 -0.34924826 -0.31686807 -0.54528046 -0.3262567  -0.32756194\n",
      " -0.31738037 -0.47870415 -0.31720936 -0.34018728 -0.53762424 -0.3219679\n",
      " -0.38741794 -0.32233614 -0.3967835  -0.43530014 -0.32176882 -0.32100996\n",
      " -0.86372733 -0.33495626], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33156726 -0.36070898 -0.38779503 -0.39167136 -0.62473345 -0.7566085\n",
      " -0.3825758  -0.33241916 -0.36639947 -1.0068382  -0.5165765  -0.3164346\n",
      " -0.35636485 -0.3435967  -0.31841186 -0.65542966 -0.35138217 -0.63068604\n",
      " -0.3446114  -0.31973743 -0.35182995 -0.37157476 -0.34682533 -0.69179165\n",
      " -0.31683993 -0.40171427 -0.7684244  -0.35547638 -0.6461002  -0.3877436\n",
      " -0.33678222 -0.40590498], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3536082  -0.33270758 -0.7183755  -0.36706242 -0.39761078 -0.3173427\n",
      " -0.5337945  -0.5095422  -0.3231286  -0.3940031  -0.32953542 -0.33765876\n",
      " -0.3994558  -0.32124472 -0.3382607  -0.34005594 -0.34864396 -0.3607113\n",
      " -0.3263587  -0.380408   -0.32518786 -0.35902888 -0.38667005 -0.74205863\n",
      " -0.40583324 -0.32170463 -0.38744554 -0.31841794 -0.42739424 -0.47082788\n",
      " -0.31708515 -0.31965205], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7296673  -0.31797373 -0.35351923 -0.49829018 -0.35595298 -0.32449543\n",
      " -0.3729202  -0.3270555  -0.33123076 -0.4736532  -0.5049565  -0.36023828\n",
      " -0.33668262 -0.32541546 -0.3707885  -0.9791654  -0.34908164 -0.32112098\n",
      " -0.32166022 -0.38739514 -0.32945785 -0.3395779  -0.45341665 -0.49392098\n",
      " -0.32819757 -0.36586398 -0.49049073 -0.3502621  -0.3512513  -0.38935095\n",
      " -0.4748128  -0.5272011 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36780977 -0.36633357 -0.34522608 -0.329689   -0.36950877 -0.32343924\n",
      " -0.31519735 -0.33947816 -0.32488143 -0.46928933 -0.35877776 -0.41164407\n",
      " -0.33117786 -0.41571888 -0.3153747  -0.3205548  -0.349181   -0.33349496\n",
      " -0.3304792  -0.33684808 -0.42523578 -0.32907936 -0.34552786 -0.36214575\n",
      " -0.42458332 -0.3473044  -0.31740206 -0.4826502  -0.33328938 -0.34634328\n",
      " -0.3330247  -0.43364125], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3193822  -0.32887113 -0.9180774  -0.31874108 -0.6893017  -0.33766717\n",
      " -0.31879753 -0.4145691  -0.33389202 -0.31772286 -0.35158843 -0.3973658\n",
      " -0.33861423 -0.3241393  -0.31915462 -0.33496752 -0.4954246  -0.82895577\n",
      " -0.33547878 -0.32846987 -0.31804138 -0.32393953 -0.33018208 -0.41818905\n",
      " -0.39975876 -0.5552138  -0.3531938  -0.32995248 -0.3228773  -0.3741839\n",
      " -0.6657594  -0.36361212], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34729058 -0.39645573 -0.3233382  -0.31727698 -0.31509784 -0.33070403\n",
      " -0.32792673 -0.32421    -0.36178383 -0.35311332 -0.35838515 -0.34335318\n",
      " -0.7275919  -0.32714656 -0.38871402 -0.5917798  -0.6779514  -0.3231809\n",
      " -0.5323027  -0.892548   -0.39323437 -0.37968323 -0.5529852  -0.36161238\n",
      " -0.51490206 -0.5818602  -0.352707   -0.4769842  -0.3171729  -0.32249573\n",
      " -0.34873128 -0.38827863], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34024003 -0.409586   -0.3218779  -0.35888287 -0.6616328  -0.3560521\n",
      " -0.31870773 -0.3790902  -0.32561535 -0.6212571  -0.35942793 -0.3609882\n",
      " -0.33811373 -0.48198196 -0.31746697 -0.37983587 -0.42194396 -0.34907407\n",
      " -0.34443402 -0.41343522 -0.36518112 -0.3159219  -0.40811995 -0.36980936\n",
      " -0.34220463 -0.33356646 -0.33259544 -0.33932507 -0.39937496 -0.34267634\n",
      " -0.33215863 -0.70109797], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.41416496 -0.36971998 -0.31544513 -0.34532017 -0.32109684 -0.35661647\n",
      " -0.3142637  -0.32416627 -0.32724127 -0.3861714  -0.31560773 -0.32081\n",
      " -0.3215885  -0.5936833  -0.7114441  -0.33621377 -0.31796047 -0.35971564\n",
      " -0.35260996 -0.36145902 -0.3360681  -0.4416131  -0.31428844 -0.36516273\n",
      " -0.33509737 -0.34299606 -0.34564295 -0.34506205 -0.32293177 -0.6909536\n",
      " -0.32290286 -0.32688165], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33565053 -0.3983716  -0.39603624 -0.32807434 -0.36565086 -0.66320336\n",
      " -0.38941517 -0.6181886  -0.3476426  -0.95279133 -0.32784033 -0.33442968\n",
      " -0.31826854 -0.3213328  -0.35903987 -0.55635774 -0.36530197 -0.32024616\n",
      " -0.3320288  -0.33576393 -0.32637376 -0.95013756 -0.50748    -0.39154282\n",
      " -0.37504205 -0.4037213  -0.8724364  -0.5490382  -0.92136383 -0.36166736\n",
      " -0.31991455 -0.3247585 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37056634 -0.48882157 -0.62543976 -0.37121224 -0.81739706 -0.4945091\n",
      " -0.3684958  -0.3769184  -0.48848462 -0.3486495  -0.59091824 -0.48169732\n",
      " -0.34601793 -0.3279805  -0.32496274 -0.56762993 -0.36404833 -0.33934376\n",
      " -0.4069407  -0.33268425 -0.40369472 -0.33045906 -0.46233034 -0.4741215\n",
      " -0.31503513 -0.38309875 -0.49845    -0.3840007  -0.3382926  -0.63918245\n",
      " -0.38520005 -0.32318145], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.53432506 -0.4020566  -0.3511934  -0.33020332 -0.3465101  -0.3235023\n",
      " -0.34659153 -0.42775142 -0.33162016 -0.36400545 -0.37469012 -0.32841107\n",
      " -0.38303193 -0.4205335  -0.39377943 -0.32525617 -0.3157133  -0.3710645\n",
      " -0.35647225 -0.31614178 -0.32170627 -0.3708223  -0.33074033 -0.3254178\n",
      " -0.3392626  -0.84109926 -0.36648557 -0.38620827 -0.33172488 -0.34429824\n",
      " -0.57310313 -0.37537783], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43162143 -0.34184    -0.60105616 -0.31630808 -0.35076487 -0.32548675\n",
      " -0.7534629  -0.45303035 -0.43098244 -0.37017578 -0.32810587 -0.523403\n",
      " -0.36419213 -0.3446527  -0.3283589  -0.35678977 -0.7985689  -0.3184859\n",
      " -0.36183116 -0.3864623  -0.32822418 -0.62154704 -0.5853712  -0.33408058\n",
      " -0.33327043 -0.32434943 -0.3808037  -0.36398357 -0.3795799  -0.31600255\n",
      " -0.37178504 -0.7640846 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32868427 -0.31574544 -0.742167   -0.3203745  -0.32327998 -0.3376465\n",
      " -0.5661483  -0.40778986 -0.31963515 -1.3010437  -0.4906175  -1.0988604\n",
      " -0.49993163 -0.35489246 -0.32439977 -0.32105663 -0.32128483 -1.1762304\n",
      " -0.37467152 -0.3374576  -0.63858104 -0.32769045 -0.47003278 -0.54502106\n",
      " -0.48270625 -0.31714928 -0.45427912 -0.36115518 -0.3326404  -0.33445078\n",
      " -0.45787257 -1.2196903 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32178456 -0.38831818 -0.48840514 -0.53946733 -0.38450357 -0.5269047\n",
      " -0.31551558 -0.3408401  -0.45979583 -0.33586177 -0.3344     -0.35792655\n",
      " -0.5974442  -0.34002677 -1.0774345  -1.2002665  -0.41648233 -0.40921625\n",
      " -0.33768758 -0.4516616  -0.4911102  -0.3978216  -0.32187745 -0.31658486\n",
      " -0.3701294  -0.34257868 -0.31696644 -0.33813015 -0.36700806 -0.32711408\n",
      " -0.3301273  -0.45217398], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.622184   -0.31791902 -0.31549713 -0.433124   -0.31469265 -0.44966334\n",
      " -0.47192585 -0.46343118 -0.7298975  -0.3185243  -0.32822606 -0.63202614\n",
      " -0.31423846 -0.32750386 -0.33585998 -0.45937476 -0.75499386 -0.3175311\n",
      " -0.3263618  -0.3234138  -0.32905507 -0.34301266 -0.32432196 -0.35821155\n",
      " -0.43135703 -0.41202256 -0.3676982  -0.31720668 -0.7222187  -0.3559726\n",
      " -0.36964667 -0.35059345], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32939935 -0.3696088  -0.39861563 -0.38606015 -0.3928132  -0.32015443\n",
      " -0.33868152 -0.4115542  -0.33427817 -0.36196348 -0.35430026 -0.33305863\n",
      " -0.33321968 -0.49528718 -0.36542225 -0.3255235  -0.34067208 -0.32478338\n",
      " -0.3752883  -0.3469994  -0.32521138 -0.31982365 -0.62791735 -0.39087752\n",
      " -0.40492207 -0.3741243  -0.6996434  -0.34485167 -0.3168436  -0.5662011\n",
      " -0.6542449  -0.3453186 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34910616 -0.43886828 -0.31683943 -0.36366227 -0.4240891  -0.33436376\n",
      " -0.37658536 -0.33298993 -0.5400367  -0.3872013  -0.33196044 -0.31773934\n",
      " -0.56815535 -0.45576316 -0.31913918 -0.4459161  -0.34223917 -0.32034317\n",
      " -0.36572877 -0.33464444 -0.33761537 -0.33813    -0.37513104 -0.33638203\n",
      " -0.3233891  -0.48625553 -0.34990126 -0.33476156 -0.52646565 -0.45714796\n",
      " -0.5343636  -0.32012084], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.0645987  -0.3396274  -0.33524233 -0.45300347 -0.36859366 -0.32871413\n",
      " -0.3715695  -0.43484294 -0.44335082 -0.37176022 -0.4531494  -0.32031938\n",
      " -0.33773044 -0.8865006  -0.42393994 -0.35004643 -0.41406733 -0.7829697\n",
      " -0.34012738 -0.3147394  -0.59864235 -0.3667531  -0.33542305 -0.39897516\n",
      " -0.5729257  -0.31928533 -0.49224043 -1.1431792  -0.3601656  -0.3185002\n",
      " -0.67175376 -0.31697384], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3284018  -0.36664882 -0.3445923  -0.32554123 -0.3614914  -0.77465415\n",
      " -0.4972852  -0.31745118 -0.3350851  -0.3320376  -0.33395195 -0.5213421\n",
      " -0.39402506 -0.32725683 -1.2176076  -0.5760659  -0.34118867 -0.3740526\n",
      " -0.31827113 -0.35782146 -0.32311955 -0.47140434 -0.33170202 -0.37017947\n",
      " -0.3154268  -0.33458906 -0.89065063 -0.35544705 -0.38038346 -0.36474672\n",
      " -0.47661853 -0.33656067], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36069933 -0.32173038 -0.3665149  -0.31845123 -0.57929087 -0.35724708\n",
      " -0.35798505 -0.3972167  -0.32213223 -0.42642906 -0.55733174 -0.32000804\n",
      " -0.3974691  -0.38255343 -0.32954007 -0.533628   -0.60630804 -0.47418043\n",
      " -0.34758222 -0.34089226 -0.3136966  -0.33065188 -0.32327083 -0.3365664\n",
      " -0.3305412  -0.33166343 -0.31585827 -0.44429743 -0.3248206  -0.3213986\n",
      " -0.31914353 -0.34771198], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3257368  -0.48872983 -0.45790076 -0.7295822  -0.59425294 -0.5441241\n",
      " -0.47565123 -1.1904755  -0.3262689  -0.51270306 -0.33936524 -0.31720206\n",
      " -0.52950585 -0.3186032  -0.5198928  -0.66224325 -0.3872586  -0.972468\n",
      " -0.3678888  -0.37823802 -0.3391156  -0.3144096  -0.49130613 -0.34421656\n",
      " -0.32355964 -0.46128148 -0.4092217  -0.43821383 -0.36184552 -1.0287757\n",
      " -0.31786358 -0.9715072 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33454418 -0.66593295 -0.31910834 -0.31945994 -0.42477673 -0.404819\n",
      " -0.3239579  -0.65978366 -0.362262   -0.4858045  -0.3151917  -0.34693554\n",
      " -0.40585017 -0.31532112 -0.4536808  -0.314109   -0.31812066 -0.57639\n",
      " -0.34004644 -0.328178   -0.4428224  -0.3692743  -0.6207897  -0.69529176\n",
      " -0.4609584  -0.40177268 -0.36464334 -0.35366488 -0.31599614 -0.3171071\n",
      " -0.31612214 -0.32391074], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.47204638 -0.385966   -0.3290273  -0.43996528 -0.34888494 -0.4334001\n",
      " -0.3363226  -0.35270783 -0.31935412 -0.32642174 -1.0927061  -0.32205153\n",
      " -0.46759966 -0.60595286 -0.33667952 -0.3796916  -0.3670455  -0.31632295\n",
      " -0.60506076 -0.48598403 -0.33486313 -0.3600803  -0.31905878 -0.32672215\n",
      " -0.3427201  -0.5072596  -0.31915072 -0.32469335 -0.32611114 -0.74448997\n",
      " -0.5399501  -0.33179504], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.49539867 -0.31575873 -0.49271694 -0.4376165  -0.49336696 -0.41485527\n",
      " -0.31417707 -0.33875188 -0.31869116 -0.44280848 -0.39592448 -0.9181042\n",
      " -0.5704589  -0.32786894 -0.32569653 -0.32769364 -0.9797884  -0.46878302\n",
      " -0.32262152 -0.37774572 -0.45214978 -0.3164145  -0.51683164 -0.3812444\n",
      " -0.733887   -0.31998053 -0.3618999  -0.35525328 -0.31550348 -0.38822633\n",
      " -0.38228768 -0.31422436], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35583732 -0.48886067 -0.4671592  -0.3821406  -0.32514584 -0.33898446\n",
      " -0.37903935 -0.38778484 -0.48488504 -0.32646036 -0.3228441  -0.3170927\n",
      " -0.32034802 -0.60221386 -0.50596863 -0.34063017 -0.31725138 -0.41493398\n",
      " -0.3673781  -0.3405771  -0.3185465  -0.34843406 -0.5273262  -0.3360095\n",
      " -0.31602812 -0.3549238  -0.5724219  -0.32644367 -0.36051846 -0.53526527\n",
      " -0.33336225 -0.35412902], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43355772 -0.37237406 -0.32392254 -0.32498324 -0.33057255 -0.6875856\n",
      " -0.37840724 -0.46747965 -0.32228404 -0.62842846 -0.32052305 -0.59283966\n",
      " -0.41580415 -0.4199531  -0.83134353 -0.31450745 -0.33864465 -0.5340338\n",
      " -0.4651982  -0.32512397 -0.31956336 -0.37772405 -0.5126028  -0.4315489\n",
      " -0.57370967 -0.48545    -0.70464265 -0.36073416 -0.35892615 -0.34737936\n",
      " -0.54102314 -1.2465142 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32619268 -0.40696713 -0.3641349  -0.3152478  -0.37853542 -0.32068926\n",
      " -0.37149814 -0.33192965 -0.38873762 -0.4340757  -0.3695882  -0.34991243\n",
      " -0.539261   -0.71975136 -0.47350782 -0.69071615 -0.3498699  -0.32099137\n",
      " -0.32145536 -0.50201106 -0.9841474  -0.35521936 -0.32029003 -0.3380056\n",
      " -0.38397098 -0.37028626 -0.4227229  -0.38149276 -0.3311704  -0.42977852\n",
      " -1.1435857  -0.34835437], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3223092  -0.35256413 -0.31543505 -0.3225939  -0.31690794 -0.31593972\n",
      " -0.3388129  -0.3198286  -0.41901568 -0.31730407 -0.42092156 -0.37739536\n",
      " -0.3325867  -0.45322084 -0.42426774 -0.32433566 -0.90525633 -0.3232177\n",
      " -0.32986736 -0.3405783  -0.40471858 -0.31855586 -0.31517604 -0.3796876\n",
      " -0.5096647  -0.4214933  -0.67728275 -0.3174091  -0.38347164 -0.33612177\n",
      " -0.35495132 -0.3691464 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.39219788 -0.33550224 -0.33513576 -0.3222394  -0.42094424 -0.33181417\n",
      " -0.42904845 -0.5934471  -0.36887422 -0.32359242 -0.8087552  -0.3154113\n",
      " -0.3479207  -0.38934982 -0.622813   -0.49431688 -0.32171217 -0.31639245\n",
      " -0.36433166 -0.35443068 -0.41791695 -0.32168934 -0.34441045 -0.31644094\n",
      " -0.32322526 -0.3974639  -0.61021245 -0.33173504 -0.32055038 -0.36363328\n",
      " -0.31987292 -0.3276232 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38362598 -0.31806177 -0.33424896 -0.45249945 -0.6118114  -0.3636674\n",
      " -0.38388562 -0.60943985 -0.3534637  -0.3868796  -0.3240242  -0.32354724\n",
      " -0.32166842 -0.35409933 -0.3407845  -0.3208119  -0.39943972 -0.40185267\n",
      " -0.4845085  -0.32024953 -0.926752   -0.3159711  -0.3231464  -0.36352736\n",
      " -0.45424592 -0.35829303 -0.32396635 -0.3235763  -0.35341316 -0.43664744\n",
      " -0.45180607 -0.3841015 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.40937468 -1.0476167  -0.33256185 -0.47507524 -0.8483089  -0.46953958\n",
      " -0.40881175 -0.41339958 -0.33028102 -0.32481053 -0.32106072 -0.7488597\n",
      " -0.5735648  -0.31629357 -0.3208714  -0.3352773  -0.3249066  -0.3467247\n",
      " -0.31451565 -0.31519938 -0.31654447 -0.34290987 -0.5149109  -0.4190381\n",
      " -0.31694233 -0.35456654 -0.31539983 -0.3154667  -0.46530163 -0.49555278\n",
      " -0.35622367 -0.61068654], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3619527  -0.35142252 -0.33322924 -0.5462711  -0.34466097 -0.37661737\n",
      " -0.33125907 -0.32373035 -0.33521342 -0.31959593 -0.38782594 -0.5272184\n",
      " -0.37642962 -0.71592116 -0.41044644 -0.32155323 -0.33409637 -0.32398212\n",
      " -0.41962233 -0.33505288 -0.31618506 -0.36743265 -0.5377615  -0.34318724\n",
      " -0.3343227  -0.3223819  -0.32257283 -0.99262834 -0.54814744 -0.40779445\n",
      " -0.45831123 -0.33268082], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4661904  -0.34140813 -0.38721418 -0.3177993  -0.3513726  -0.39321145\n",
      " -0.36726835 -0.3542402  -0.34101295 -0.33867174 -0.4518509  -0.34072244\n",
      " -0.4791544  -0.35683852 -0.5140876  -0.31896305 -0.32329    -0.3165482\n",
      " -0.33666608 -0.31526458 -0.31523067 -0.3144662  -0.40233982 -0.38113853\n",
      " -0.32331622 -0.31551173 -0.5109149  -0.38669354 -0.4027483  -0.31611016\n",
      " -0.33698502 -0.32102317], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.40124774 -0.5968147  -0.4746278  -0.31862086 -0.3243296  -0.3222972\n",
      " -0.33658624 -0.47044677 -0.43691778 -0.32165045 -0.3644235  -0.32209697\n",
      " -0.32109296 -0.38336575 -0.36182952 -0.32325718 -0.36585364 -0.52305967\n",
      " -0.31413266 -0.31520876 -0.35535297 -0.33550325 -0.32244754 -0.46044716\n",
      " -0.32189292 -1.133295   -0.4736308  -0.32302386 -0.32597482 -0.41051254\n",
      " -0.36467195 -0.3177521 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31918553 -0.3360361  -0.32623512 -0.41436324 -0.50950044 -0.32533184\n",
      " -0.37873876 -0.32047063 -0.31508976 -0.3161508  -0.40094098 -0.3208255\n",
      " -0.35111234 -0.67157876 -0.3655594  -0.73839927 -0.3172216  -0.7569009\n",
      " -0.77129054 -0.44279745 -0.496584   -0.3211066  -0.3401032  -0.3497849\n",
      " -0.3918665  -0.32387486 -0.37284842 -0.3431036  -0.3982726  -0.35290787\n",
      " -0.34294042 -0.3234218 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34937173 -0.46037704 -0.3769516  -0.33334568 -0.32986987 -0.3146824\n",
      " -0.32924637 -0.33308402 -0.3423223  -0.73075855 -0.34484515 -0.33787322\n",
      " -0.32350808 -0.31956622 -0.35818046 -0.32811728 -0.3571485  -0.32104608\n",
      " -0.93530524 -0.35967022 -0.36255026 -0.4598647  -0.3291105  -0.38034126\n",
      " -0.3200862  -0.35332885 -0.5466841  -0.36544913 -0.4028774  -0.3663186\n",
      " -0.3856374  -0.31682727], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33596417 -0.52992594 -0.37503386 -0.32012412 -0.31433302 -0.3374752\n",
      " -0.32351202 -0.620095   -0.5494818  -0.31666625 -0.7473275  -0.5022344\n",
      " -0.31627056 -0.3250808  -0.8924705  -0.58368963 -0.35284966 -0.32447845\n",
      " -0.3303417  -0.4806943  -0.31791684 -0.6696978  -0.3163181  -0.32294005\n",
      " -0.33108068 -0.49593982 -0.53755355 -0.7504537  -0.35746682 -0.33232802\n",
      " -0.41032037 -0.37202117], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32582337 -0.39295557 -0.3886306  -0.35449556 -0.50305474 -0.3332218\n",
      " -0.31624258 -0.31828848 -0.42420322 -0.31538966 -0.32192376 -0.3141197\n",
      " -0.32114935 -0.31467962 -0.6974609  -0.47501802 -0.44212103 -0.59335643\n",
      " -0.31371987 -0.45640376 -0.6054988  -0.31551173 -0.72929275 -0.3620011\n",
      " -0.5108739  -0.31367204 -0.36435255 -0.3274535  -0.3285395  -0.36452362\n",
      " -0.3199646  -0.34091514], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31768554 -0.369402   -0.31937647 -0.3362412  -0.3214876  -0.38404623\n",
      " -0.39965677 -0.9210838  -0.3798229  -1.0699115  -0.34322006 -0.37598348\n",
      " -0.39505646 -0.31813246 -0.6049294  -0.314791   -0.39739668 -0.31972122\n",
      " -0.3321846  -0.35497457 -0.31879908 -1.0621612  -0.35437822 -0.3247683\n",
      " -0.3271922  -0.37523377 -0.3253131  -0.37595317 -0.78964365 -0.3205075\n",
      " -1.0841798  -0.33643815], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7062954  -0.32129166 -0.3415221  -0.42617485 -0.41461048 -0.38197902\n",
      " -0.32673934 -0.38862658 -0.38753033 -0.6380934  -0.8164586  -0.50002444\n",
      " -0.96221125 -0.35823312 -0.36293295 -0.8142017  -0.31929928 -0.40904784\n",
      " -0.33427584 -0.37596333 -0.33193266 -0.33182597 -0.32353505 -0.33134133\n",
      " -0.705252   -0.34594065 -0.5044937  -0.33470055 -0.32099593 -0.34499544\n",
      " -0.31955835 -0.33104277], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34361666 -0.7305183  -0.3653014  -0.31356993 -0.33985993 -0.33809495\n",
      " -0.4725734  -0.73169565 -0.3217608  -0.3491341  -0.32717535 -0.32446226\n",
      " -0.3332314  -0.41896158 -0.9028739  -0.33894223 -0.48262078 -0.3163067\n",
      " -0.43441817 -0.94723815 -0.7455692  -0.37916344 -0.36071688 -0.3189372\n",
      " -0.3172927  -0.34542137 -0.7310319  -0.32108736 -0.71716607 -1.0582882\n",
      " -0.7265919  -0.45021948], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32398936 -0.42356727 -0.411887   -0.5655966  -0.31440473 -0.31517926\n",
      " -0.31916276 -0.7793058  -0.45789593 -0.32373336 -0.4155016  -0.40109202\n",
      " -0.33537516 -0.45607364 -0.3267476  -0.35718888 -0.3356779  -0.45868823\n",
      " -0.31850523 -0.34730253 -0.32990062 -0.33026242 -0.31600255 -0.51843077\n",
      " -0.34544027 -0.4129138  -0.36424106 -0.31578666 -0.36772212 -0.315508\n",
      " -0.39904195 -0.3962473 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.72794574 -0.31696108 -0.31965715 -0.31359226 -0.32413343 -0.32425746\n",
      " -0.32400447 -0.9339712  -0.45894048 -0.31850195 -0.35445827 -0.42824072\n",
      " -0.32134256 -0.31643903 -0.35057598 -0.32506558 -0.7239483  -0.31757745\n",
      " -0.31416315 -0.34415182 -0.8016769  -0.5636132  -0.31532678 -0.47873572\n",
      " -0.35406554 -0.7607375  -1.0371169  -0.49646965 -0.3516073  -0.36177486\n",
      " -0.3179844  -0.4926253 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33615652 -0.33526227 -0.32104126 -0.617193   -0.38592386 -0.33372545\n",
      " -0.31384808 -0.32664096 -0.32209378 -0.9166263  -0.32904306 -0.31657323\n",
      " -0.50421894 -0.35467333 -0.7094991  -0.59211934 -0.31690133 -0.38791186\n",
      " -0.7876266  -0.31430933 -0.34904084 -0.32631192 -0.3283157  -0.32247812\n",
      " -0.32992086 -0.36985457 -0.31383494 -0.42420003 -0.33935183 -0.40793413\n",
      " -0.6633161  -0.35609877], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31514978 -0.3161457  -0.32011962 -0.32282662 -0.34295946 -0.33705592\n",
      " -0.4080751  -0.6802818  -0.44776094 -0.317938   -0.3927258  -0.32742903\n",
      " -1.2012815  -0.32253605 -0.4256767  -0.3138073  -0.33804345 -0.31980175\n",
      " -0.31605724 -0.3727783  -0.40746123 -0.33437595 -0.3153352  -0.4437663\n",
      " -0.83886194 -0.32417578 -0.3523724  -0.31918216 -0.3559564  -0.3750642\n",
      " -0.31469265 -0.4072053 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3877164  -0.4703338  -0.37579274 -0.41779223 -0.85923374 -0.31556287\n",
      " -0.4892948  -0.31968045 -0.3133556  -0.3262659  -0.42865902 -0.38033336\n",
      " -0.3309485  -0.31694865 -0.87813485 -0.3260731  -0.7565476  -0.3224008\n",
      " -0.35474366 -0.7532126  -0.3854808  -0.31484076 -0.41121227 -0.32750207\n",
      " -0.38967597 -0.79027855 -0.3703662  -0.36384612 -0.34321684 -0.31974685\n",
      " -0.37664828 -0.4092013 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33170065 -0.3244869  -0.3202904  -0.39043632 -0.3582218  -0.3623079\n",
      " -0.34819216 -0.31442425 -0.31973553 -0.4871266  -0.37843305 -0.34792128\n",
      " -0.32357776 -0.36379427 -0.68283725 -0.31952214 -0.31573954 -0.37455708\n",
      " -0.36363003 -0.33062986 -0.32477614 -0.3281737  -0.35801914 -0.35372597\n",
      " -0.3511474  -0.31635725 -0.31538808 -0.3333943  -0.35504    -0.3435741\n",
      " -0.33268416 -0.32316175], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34119943 -0.33679327 -0.34000096 -0.3484907  -0.42358524 -0.33009115\n",
      " -0.31691244 -0.3163763  -0.5777768  -0.33036637 -0.31534034 -0.35113734\n",
      " -0.34463793 -0.31911796 -0.32237896 -0.33919993 -0.35836217 -0.45352572\n",
      " -0.32325745 -0.32466432 -0.37495375 -0.8705782  -0.31492725 -1.0642998\n",
      " -0.3205093  -0.47548348 -0.3384369  -0.33280486 -0.320828   -0.3357977\n",
      " -0.3423317  -0.31871074], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3143547  -0.6463905  -0.32435635 -0.41038546 -0.40345305 -0.32267392\n",
      " -0.41355836 -0.3161378  -0.3907764  -0.44960737 -0.37006205 -0.32580686\n",
      " -0.3452996  -0.35990897 -0.40979937 -0.3243748  -0.32093894 -0.61310047\n",
      " -0.3893122  -0.33333933 -0.4894348  -0.32815886 -0.31916076 -0.3148083\n",
      " -0.3376478  -0.49624926 -0.32753822 -0.3601622  -0.41006094 -0.38722202\n",
      " -0.34267414 -0.31681362], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33812776 -0.36949873 -0.3212377  -0.3142187  -0.3355775  -0.33889315\n",
      " -0.3881947  -0.348343   -0.3395521  -0.34404233 -0.31795198 -0.9473995\n",
      " -0.3734761  -0.36790276 -0.35442957 -0.93101233 -0.6070354  -0.31829965\n",
      " -0.3485065  -0.36343825 -0.3379442  -0.35757118 -0.43915886 -0.34049246\n",
      " -0.3257289  -0.3153946  -0.32049295 -0.35549992 -0.41276538 -0.365889\n",
      " -0.36614877 -0.3203204 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.52594554 -0.33431092 -0.4813348  -0.44570795 -0.7700589  -0.36241302\n",
      " -0.4846884  -0.32451215 -0.39114562 -0.4434408  -0.31497875 -0.47978586\n",
      " -0.4364113  -0.48155665 -0.32895952 -0.5183505  -0.34594378 -0.32950687\n",
      " -0.39198184 -0.42297924 -0.32427385 -0.61225533 -1.1728088  -0.3207606\n",
      " -0.3820733  -0.36137846 -0.35117954 -0.32363695 -0.35074514 -0.89093536\n",
      " -0.4071305  -0.32751513], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4926427  -0.463269   -0.38268158 -0.31434405 -0.3194778  -0.45913875\n",
      " -0.35291207 -0.32291433 -0.31503722 -0.3628549  -0.5674311  -0.31493133\n",
      " -0.6054871  -0.3498201  -0.33116263 -0.8202212  -0.31671125 -0.31700152\n",
      " -0.45789057 -0.4782242  -0.36591226 -0.48804906 -0.37064385 -0.40009362\n",
      " -0.3408559  -0.45308653 -0.50236404 -0.47583908 -0.38950247 -0.3354274\n",
      " -0.31844229 -0.33212176], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33224714 -0.32066736 -0.58573514 -0.32334864 -0.5511625  -0.31657097\n",
      " -0.3225894  -0.3163093  -0.32183424 -0.35095045 -0.36690912 -0.32076216\n",
      " -0.32573378 -0.3941916  -0.40114567 -0.31859583 -0.3250238  -0.5227216\n",
      " -0.32247543 -0.413407   -0.32064927 -0.3154575  -0.31607357 -0.32317126\n",
      " -0.31798893 -0.33089685 -0.32646665 -0.31560975 -0.31618175 -0.3272264\n",
      " -0.32111406 -0.3833817 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32513243 -0.31768876 -0.3220384  -0.6123247  -0.39294237 -0.31399378\n",
      " -0.6462504  -0.97219265 -0.34646094 -0.31999645 -0.33946407 -0.3140921\n",
      " -0.3978988  -0.32697284 -0.35505396 -0.80287063 -0.348586   -0.32522154\n",
      " -0.5163864  -0.41537696 -0.31412736 -0.42651218 -0.31471327 -0.33597177\n",
      " -0.31816697 -0.35973784 -0.33150584 -0.5601244  -0.32970476 -0.3634835\n",
      " -0.3453449  -0.32729402], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3703847  -0.31347463 -0.31541157 -0.51353246 -0.34101838 -0.31683362\n",
      " -0.3229392  -0.36921677 -0.3640002  -0.35168034 -0.36173213 -0.3693334\n",
      " -0.5120921  -0.32427153 -0.33319378 -0.3385327  -0.32308453 -0.31528407\n",
      " -0.46676373 -0.32440805 -0.42457217 -0.31510037 -0.44579795 -0.381897\n",
      " -0.32537758 -0.3190614  -0.314949   -0.31736067 -0.35990298 -0.31648237\n",
      " -0.336412   -0.31499407], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3929089  -0.8455822  -0.32924807 -0.3168462  -0.32019085 -0.31715626\n",
      " -0.31571162 -0.4179814  -0.35213822 -0.3623415  -0.32096505 -0.32409215\n",
      " -0.35046828 -0.3329351  -0.3264535  -0.32505593 -0.36081678 -0.3274505\n",
      " -0.35602874 -0.37558085 -0.33183643 -0.36416313 -0.61053526 -0.5012329\n",
      " -0.3592002  -1.0317225  -0.83215046 -0.7928018  -0.4735653  -0.34487024\n",
      " -0.32310462 -0.35090423], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3491181  -0.32030857 -0.36762276 -0.4916008  -0.33100528 -0.3559614\n",
      " -1.1691778  -0.39502603 -0.4799992  -0.36160508 -0.43812707 -0.3167598\n",
      " -0.32481173 -0.49717048 -0.35903913 -0.3236013  -0.36523837 -0.33725196\n",
      " -0.48636377 -0.40356287 -0.3777497  -0.31629333 -0.32457092 -0.3692355\n",
      " -0.3180695  -0.4919247  -0.31536    -0.35264003 -0.31771913 -0.31628639\n",
      " -0.4364943  -0.60411525], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34642488 -0.426684   -0.49484313 -0.33526295 -0.40569493 -0.37834355\n",
      " -0.45706785 -0.43354097 -0.33194488 -0.31796542 -0.3190034  -0.61490816\n",
      " -0.42162856 -0.33248207 -0.44353154 -0.4516156  -0.31568503 -0.3543378\n",
      " -0.42691565 -0.32688808 -0.31697547 -0.3243296  -0.42855126 -0.5468425\n",
      " -0.43991485 -0.54897606 -0.48128912 -0.53518087 -0.3514253  -0.41783816\n",
      " -0.31578475 -0.33932227], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7463463  -0.32337263 -0.801679   -0.50121003 -0.31878728 -0.3138593\n",
      " -0.3926304  -0.37519494 -0.31667763 -0.31914636 -0.38920572 -0.6533556\n",
      " -0.34273988 -0.3303076  -0.31493527 -0.6737961  -0.45628434 -0.37511596\n",
      " -0.32794237 -0.32198727 -0.3231042  -0.3427217  -0.4366251  -0.3317944\n",
      " -0.33754233 -0.48821485 -0.32183555 -0.33784688 -0.3140388  -0.32081163\n",
      " -0.39299595 -0.50863796], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.41646558 -0.32691008 -0.764675   -0.58319426 -0.3196059  -0.34727895\n",
      " -0.3242043  -0.40798345 -0.31708592 -0.3219374  -0.3555214  -0.32372335\n",
      " -0.3278934  -0.5902344  -0.32445917 -0.49142522 -0.41381785 -0.32767448\n",
      " -0.93681157 -0.32303715 -0.56209254 -0.31377813 -0.32464176 -0.40679047\n",
      " -0.31440005 -0.31797922 -0.3159791  -0.31569076 -0.4041625  -0.47159314\n",
      " -0.4253229  -0.35903314], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.39231881 -0.32517108 -0.34895155 -0.57460344 -0.36178285 -0.38706452\n",
      " -0.34629056 -0.5713417  -0.32233745 -0.40919843 -0.49606055 -0.52393615\n",
      " -0.3276329  -0.3304043  -0.36238042 -0.34733808 -0.33369634 -0.41671377\n",
      " -0.31472722 -0.32441607 -0.35146746 -0.34124443 -0.31653136 -0.36645994\n",
      " -0.34975213 -0.31817755 -0.42822272 -0.4562397  -0.3540468  -0.3254574\n",
      " -0.32963294 -0.35383493], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31422332 -0.31572104 -0.3373031  -0.61259544 -0.3154866  -0.31734008\n",
      " -0.6670832  -0.32961184 -0.3561219  -0.32112575 -0.4295545  -0.31574667\n",
      " -0.35676742 -0.35831493 -0.43846598 -0.31905124 -0.34113085 -0.32857302\n",
      " -0.36529535 -0.31794417 -0.32834387 -0.39933217 -0.31865025 -0.32010725\n",
      " -0.4082406  -0.33458018 -0.32233387 -0.35207316 -0.35739043 -0.4520684\n",
      " -0.35170868 -0.61293936], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31606948 -0.3663498  -0.3169093  -0.3331004  -0.79554904 -0.32322544\n",
      " -0.40731367 -0.71839887 -0.31755984 -0.34658563 -0.35888395 -0.3609251\n",
      " -0.45852667 -0.31380585 -0.35252827 -0.5990502  -0.49727756 -0.37205422\n",
      " -0.3190093  -0.98412776 -0.34374988 -0.3148753  -0.32427627 -1.1784868\n",
      " -0.3991352  -0.32194683 -0.3910607  -0.31970754 -0.32483146 -0.33000228\n",
      " -0.3782119  -0.3349579 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3143574  -0.46781504 -0.3431841  -0.34327698 -0.47791252 -0.32440907\n",
      " -0.32950413 -0.32074773 -0.36633334 -0.45842287 -0.38937092 -0.31846118\n",
      " -1.0418599  -0.3452249  -0.34301454 -0.31456628 -0.3366499  -0.3139395\n",
      " -0.34548196 -1.06589    -0.43704137 -0.9276766  -0.7293591  -0.34566277\n",
      " -0.39601612 -0.3521669  -0.31691724 -0.45227957 -0.3283164  -0.3161823\n",
      " -0.32168216 -0.36566576], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5776911  -0.33572203 -0.4077583  -0.54587775 -0.47414875 -0.32243493\n",
      " -0.41241497 -0.33714008 -0.33970192 -0.32710755 -0.3276225  -0.32698667\n",
      " -0.32062256 -0.6027936  -0.33928108 -0.37595373 -0.3241349  -0.4342652\n",
      " -0.3824013  -0.34540972 -0.55047405 -0.901953   -0.3211496  -0.33428448\n",
      " -0.35406286 -0.6081211  -0.7333259  -0.32664442 -1.0178334  -0.5827954\n",
      " -0.31475723 -0.3417714 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4197787  -0.56720245 -0.3242343  -0.34990832 -0.75924814 -0.4554575\n",
      " -0.3149302  -0.38878673 -0.44592416 -0.33353034 -0.3545852  -0.32688618\n",
      " -0.45899028 -0.32383373 -0.31370026 -0.39426932 -0.31443086 -0.3176282\n",
      " -0.3416884  -0.3243155  -0.31444538 -0.33166942 -0.9131636  -0.63929194\n",
      " -0.40065777 -0.3404017  -1.0473775  -0.38451487 -0.31510246 -0.52751404\n",
      " -0.34521323 -0.3284884 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32192963 -0.34294415 -0.33451912 -0.9015002  -0.33128536 -0.3313184\n",
      " -0.3163803  -0.3586537  -0.32947147 -0.32862264 -0.38139656 -1.2298408\n",
      " -0.3318003  -0.33769804 -0.3307662  -0.33678338 -0.59965485 -0.47864833\n",
      " -0.36170465 -0.3755814  -0.38861096 -0.3342082  -0.3949743  -0.34779423\n",
      " -0.48362863 -0.41165125 -0.34256607 -1.1279249  -0.3301969  -0.31958812\n",
      " -0.33413187 -0.33082768], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32399815 -0.41279113 -0.3238684  -0.34733286 -0.6897761  -0.43790936\n",
      " -0.33000278 -0.3272887  -0.316173   -0.32449207 -0.8511752  -0.3167353\n",
      " -0.5163537  -0.5492126  -0.90685666 -0.6563826  -0.35480627 -0.32590178\n",
      " -0.52727544 -0.32589704 -1.2436961  -0.31799394 -0.32883477 -0.631945\n",
      " -0.36607462 -0.3173766  -0.7780707  -0.37237027 -0.37873557 -0.35221216\n",
      " -0.32177317 -0.3775218 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3337164  -0.31797028 -0.33122477 -0.3275469  -0.3861722  -0.3165874\n",
      " -0.5939199  -0.31923527 -0.33736256 -0.3335942  -0.45196947 -0.38006783\n",
      " -0.37296697 -0.37405753 -0.32113898 -0.33569577 -0.32568678 -0.32996175\n",
      " -0.3185152  -0.4082352  -0.41146588 -0.31663698 -0.3634545  -0.37289563\n",
      " -0.35592026 -0.37449366 -0.31796646 -0.41218936 -0.3909939  -0.32083267\n",
      " -0.33218196 -0.31547436], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31406936 -0.38084525 -0.320673   -0.32253975 -0.40377837 -0.3889661\n",
      " -0.4930356  -0.35230336 -0.34283856 -0.40635887 -0.34098873 -0.33037674\n",
      " -0.71234894 -0.32757044 -0.32501253 -0.8457242  -0.6719891  -0.47087854\n",
      " -0.32087192 -0.4067281  -0.3329244  -0.31334504 -0.588907   -0.37242743\n",
      " -0.3217849  -0.34134713 -1.0171248  -0.31822976 -0.31530565 -0.31979665\n",
      " -0.43928903 -0.40875116], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.016543   -0.43939972 -0.34873262 -0.32965547 -0.31656507 -0.3205747\n",
      " -0.32418954 -0.3209648  -0.39375427 -0.42730218 -0.32776973 -0.33697727\n",
      " -0.61573136 -0.45746726 -0.31363058 -0.4435063  -0.35853043 -0.32834816\n",
      " -0.825835   -0.34775224 -0.42274743 -0.31529868 -0.3248704  -0.31389058\n",
      " -0.36068213 -0.33382252 -0.3426128  -0.3375002  -0.32106876 -0.34990185\n",
      " -0.5267251  -0.37003225], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31914446 -0.3843198  -0.32709077 -0.31736475 -0.3389218  -0.337703\n",
      " -0.36357617 -0.33999392 -0.31653908 -0.31832862 -0.7194613  -0.434882\n",
      " -0.3343013  -1.0232773  -0.43045086 -0.32419842 -0.3258034  -0.31691244\n",
      " -0.33653462 -0.61611074 -0.3180402  -0.3171598  -0.32177946 -0.33689174\n",
      " -0.34224492 -0.37743133 -0.3927798  -0.3450618  -0.75709504 -0.31614232\n",
      " -0.31877106 -0.31609112], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3355688  -0.8745339  -0.3366648  -0.32429704 -0.3238479  -0.32062626\n",
      " -0.32840687 -0.34008133 -0.31373772 -0.4913059  -0.3213985  -0.3244671\n",
      " -0.31966156 -1.0395846  -0.34848958 -0.35283408 -0.6599818  -0.8887954\n",
      " -0.3173727  -0.32471153 -0.4067727  -0.3370744  -0.3276998  -0.43718892\n",
      " -0.34863436 -0.3189845  -0.32838058 -0.31849214 -0.33163264 -0.35556284\n",
      " -0.3211207  -0.38555983], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31843084 -0.6002029  -0.31563243 -0.32047582 -0.314298   -0.38035274\n",
      " -0.31575152 -0.32405463 -0.45412466 -0.31953287 -0.51225233 -0.31403437\n",
      " -0.32896656 -0.31993908 -0.328621   -0.7375222  -0.32325366 -0.32976118\n",
      " -0.31932467 -0.36217993 -0.32577097 -0.84741896 -0.5678971  -0.3487137\n",
      " -0.31475556 -0.31724063 -0.31853175 -0.46255124 -0.54452974 -0.33820766\n",
      " -1.0120304  -0.3227967 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3204805  -0.31580508 -0.413805   -0.41608536 -0.32068855 -0.31799883\n",
      " -0.33570942 -0.34388867 -0.3359865  -0.48341548 -0.32073942 -0.47123903\n",
      " -0.34713474 -0.35496235 -0.34148017 -0.31614822 -0.32860684 -0.33476377\n",
      " -0.3796033  -0.36545882 -0.36794162 -0.3514778  -0.32227057 -0.33295473\n",
      " -0.31495804 -0.5977545  -0.43877813 -0.31518024 -0.3221475  -0.36608902\n",
      " -0.35999745 -0.31694788], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3358697  -0.35252643 -0.32502657 -0.34931567 -0.31447673 -0.3243415\n",
      " -0.5014114  -0.32168648 -0.33157855 -0.36446077 -0.3655929  -0.32518512\n",
      " -0.31429994 -0.3507048  -0.3245086  -0.34095252 -0.5649207  -0.31940505\n",
      " -0.44350004 -0.3411157  -0.33211553 -0.373653   -0.3160873  -0.378827\n",
      " -0.49031407 -0.31532747 -0.32834524 -0.40844187 -0.32393306 -0.31574023\n",
      " -0.31548366 -0.34078908], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6413923  -0.41433236 -0.3345313  -0.37500322 -0.32811695 -0.31942186\n",
      " -0.3200639  -0.3182898  -0.38147193 -0.3406412  -0.3142684  -0.33947426\n",
      " -0.3264786  -0.31356585 -0.31884181 -0.32444528 -0.34771797 -0.31837344\n",
      " -0.34970212 -0.36632442 -0.33313015 -0.76462555 -0.4603955  -0.36065853\n",
      " -0.31501678 -0.31973654 -0.3165178  -0.3153926  -0.36104384 -0.44420105\n",
      " -0.32734808 -0.44737285], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33430153 -0.390192   -0.61134857 -1.0379536  -0.35086426 -0.31379068\n",
      " -0.59198475 -0.9697553  -0.33415806 -0.34188092 -0.34765154 -0.42653778\n",
      " -0.46613955 -0.31592295 -0.32623595 -0.31455863 -0.39874077 -0.31451565\n",
      " -0.64176685 -0.35530126 -0.61972976 -0.3244506  -0.32314736 -0.35260853\n",
      " -0.332628   -0.318353   -0.3181315  -0.33813703 -0.31855604 -0.31507322\n",
      " -1.1622767  -0.40328264], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3840516  -0.4564737  -0.41144028 -0.33963478 -0.56226534 -0.83243746\n",
      " -0.40437248 -1.1984894  -0.37552804 -0.31583455 -0.43921995 -1.198954\n",
      " -1.2975385  -1.0010419  -0.33151132 -0.31581378 -0.4166373  -0.31376752\n",
      " -0.7580513  -0.64907193 -0.33535743 -0.33692375 -0.31708837 -0.32355118\n",
      " -0.31873095 -0.42131713 -0.55164    -0.32997948 -0.66480416 -0.34403253\n",
      " -0.3591388  -0.32786793], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31519997 -0.5766554  -0.3216737  -0.5912718  -0.33268645 -0.32024357\n",
      " -0.41937736 -0.31535703 -0.3836189  -0.34012806 -0.3310919  -0.43123728\n",
      " -0.32837647 -0.314614   -0.37466487 -0.36200118 -0.31484702 -0.3208816\n",
      " -0.31423777 -0.42461878 -0.3174623  -0.32754758 -0.7252611  -0.36060426\n",
      " -0.31709304 -1.1474925  -0.32054615 -0.31574267 -0.31405264 -0.49902874\n",
      " -0.3201897  -0.3167906 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32762232 -0.65604955 -0.3375315  -0.31625855 -0.32306305 -0.3374684\n",
      " -0.32904145 -0.32258853 -0.3578672  -0.35225523 -0.31693998 -0.83728075\n",
      " -0.3166612  -0.31884986 -0.33046746 -0.37183025 -0.31971836 -0.32196435\n",
      " -0.6082027  -0.50632155 -0.35292614 -0.31860787 -0.57815504 -0.31905168\n",
      " -0.33561003 -0.47220212 -0.49664    -0.35371107 -0.57904863 -0.3180342\n",
      " -0.32088238 -0.41886073], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3458085  -0.3298396  -0.32723594 -0.33492112 -0.34721208 -0.31450188\n",
      " -0.8200037  -0.35034645 -0.3145374  -0.37275127 -0.69905865 -0.36016104\n",
      " -0.44149682 -0.3189925  -0.45536774 -0.31501564 -0.32617143 -0.3181924\n",
      " -0.3182948  -0.3799342  -0.42349803 -0.33306104 -0.3155121  -0.73530966\n",
      " -0.56557655 -0.3151644  -0.32243416 -0.38707674 -0.6077974  -0.36723235\n",
      " -0.31506348 -0.31829038], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34458926 -0.31502694 -0.57425535 -0.3160314  -0.3231012  -0.35477066\n",
      " -0.3969532  -0.32681912 -0.3136007  -0.3256664  -0.4129331  -0.3649201\n",
      " -0.37585485 -0.32322097 -0.5603763  -0.5203983  -0.32432583 -0.32347494\n",
      " -0.31553096 -0.34827596 -1.0396042  -0.44739756 -0.3233011  -0.8959351\n",
      " -0.36590225 -0.40784726 -0.34678048 -0.317587   -0.32826918 -0.53810555\n",
      " -0.5374274  -0.37233248], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33650935 -0.3222192  -0.4111996  -0.49552026 -0.33113667 -0.3854644\n",
      " -0.31785047 -0.5629154  -0.3202793  -0.32959005 -0.32829288 -0.33677557\n",
      " -0.69173914 -0.31975994 -0.31908217 -0.31402156 -0.31436938 -0.3696597\n",
      " -0.32126933 -0.3171908  -0.38270354 -0.5296027  -0.3238634  -0.31944054\n",
      " -0.38543555 -0.31646803 -0.7747573  -0.6217743  -0.31527823 -0.8520384\n",
      " -0.3310222  -0.32138795], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3768037  -0.3686871  -0.39929035 -0.35564965 -0.33222157 -0.31833938\n",
      " -0.34439558 -0.31809223 -0.49950978 -0.33160704 -0.45713836 -0.91415524\n",
      " -0.32022998 -0.32343906 -0.31929433 -0.46180397 -0.34821856 -0.3135302\n",
      " -0.32018358 -0.47509652 -0.94483507 -0.92900467 -0.41672155 -0.5915865\n",
      " -0.344074   -0.3176224  -0.31936276 -0.32352367 -0.49435112 -0.31839615\n",
      " -0.38534415 -0.3178779 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.2357202  -0.47894263 -0.3223928  -0.4610204  -0.32085913 -0.9103128\n",
      " -0.31825882 -0.31810775 -0.6279612  -0.5545642  -0.34702033 -0.33194268\n",
      " -0.34432393 -0.32587993 -0.31472957 -0.31412727 -0.323963   -0.34075177\n",
      " -0.4193866  -0.49431026 -0.31748268 -0.5129105  -0.36050832 -0.3761292\n",
      " -0.36988437 -0.37717164 -0.31860864 -0.44392544 -0.3193414  -0.3338174\n",
      " -0.34469485 -0.3143344 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33456254 -0.3152933  -0.33269167 -0.47292307 -0.31677124 -0.3220225\n",
      " -0.31363177 -1.2841055  -0.39878365 -0.31652474 -0.316192   -0.325073\n",
      " -0.3137211  -0.45289075 -0.3194998  -0.32681876 -0.32582787 -0.33792374\n",
      " -0.31761336 -0.43309855 -0.35270858 -0.37932834 -0.37384027 -0.3348545\n",
      " -0.566613   -0.3483855  -0.51163256 -0.3389734  -0.3340566  -0.5165657\n",
      " -0.3376334  -0.32380503], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35830718 -0.31670803 -0.34668005 -0.31674397 -0.3181128  -0.6382113\n",
      " -0.32388133 -0.3190365  -0.3163127  -0.3219064  -0.3137757  -0.8255873\n",
      " -0.39169303 -0.35436308 -0.34154058 -0.3140078  -0.32880962 -0.40260175\n",
      " -0.99583805 -0.3168176  -0.4013092  -0.4109279  -0.33890843 -0.36348307\n",
      " -0.31426919 -0.3173117  -0.31753528 -0.34796977 -0.45991015 -0.35630238\n",
      " -0.31656498 -0.88197744], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3367685  -0.31657878 -0.33047223 -0.3851053  -0.3136898  -0.34127772\n",
      " -0.32070154 -0.38319838 -0.32047176 -0.3395217  -0.53629977 -0.34558448\n",
      " -0.41499555 -0.3225762  -0.31829393 -0.370593   -0.36761293 -0.32898173\n",
      " -0.31853488 -0.36120334 -0.31484738 -0.34066817 -0.32817197 -0.40546814\n",
      " -0.3306487  -0.3133326  -0.32956415 -0.32615122 -0.31548017 -0.5639548\n",
      " -0.71564686 -0.3141002 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3720721  -0.41651163 -0.34006035 -0.31803697 -0.32316607 -0.35571897\n",
      " -0.33500972 -1.0957057  -0.4987043  -0.48688883 -0.3905939  -0.31605402\n",
      " -0.3157133  -0.61662024 -0.3180945  -0.31363076 -0.3301527  -0.5243149\n",
      " -0.40493807 -0.50005406 -0.31629533 -0.3318573  -0.31424367 -0.3178752\n",
      " -0.34165162 -0.56657094 -0.39880702 -0.31878668 -0.33312503 -1.0414537\n",
      " -0.448896   -0.3212415 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3489305  -0.31386897 -0.75703675 -0.37118337 -0.313794   -0.3496396\n",
      " -0.31528878 -0.3184619  -0.66664994 -0.31687215 -0.3160866  -0.39216888\n",
      " -0.3147492  -0.33678773 -0.43192047 -0.31916362 -0.37100044 -0.42202276\n",
      " -0.44838345 -0.5605918  -0.32519218 -0.32521424 -0.34350538 -0.851073\n",
      " -0.3824622  -0.32588008 -0.6109634  -0.33833763 -0.4378558  -0.4063491\n",
      " -0.3485965  -0.5581862 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36888257 -0.32660544 -0.8213253  -0.35475913 -0.34640977 -0.32957643\n",
      " -0.31662482 -0.33628675 -0.34905908 -0.31465566 -0.3221722  -0.31520858\n",
      " -0.331326   -0.71747446 -0.42270666 -0.3229246  -0.32468674 -0.3196427\n",
      " -0.44240522 -0.31562442 -1.0720696  -0.3204593  -0.3333197  -0.41513205\n",
      " -0.31612927 -0.31378755 -0.6924345  -0.33052355 -0.41342908 -0.32460883\n",
      " -0.31405056 -0.6516657 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32225186 -0.3169233  -0.48602942 -0.32699466 -0.31450972 -0.3827409\n",
      " -0.32196262 -0.39402705 -0.3441073  -0.31676215 -0.3138339  -0.3150213\n",
      " -0.42936108 -0.323454   -0.7168652  -0.5383587  -0.35146847 -0.31787148\n",
      " -0.3506559  -0.3280814  -0.32473412 -0.38833404 -0.33370972 -0.7339381\n",
      " -0.33737966 -0.41330183 -0.317353   -0.31470537 -0.3557887  -0.3147065\n",
      " -0.32195166 -0.31954917], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43605334 -0.37095633 -0.39893323 -0.3204913  -0.3228855  -0.38172898\n",
      " -0.34278974 -0.31830877 -0.47282872 -0.9718944  -0.31483424 -0.74062586\n",
      " -0.33504367 -0.31631765 -0.3884059  -0.31857067 -0.31595302 -0.8264756\n",
      " -0.3165025  -0.32137197 -0.33170015 -0.38578063 -0.37581408 -0.33587924\n",
      " -0.3324932  -0.31522676 -0.32205066 -0.3356312  -0.31351992 -0.51849306\n",
      " -0.33202246 -0.3202183 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.39687178 -0.43445623 -0.32653245 -0.8291621  -0.63885677 -0.32052714\n",
      " -0.315787   -0.34247315 -0.34875053 -0.66226834 -0.739183   -0.34809452\n",
      " -0.31915694 -0.31382176 -0.3545908  -0.35029906 -0.37509957 -0.66127384\n",
      " -0.31601596 -0.32511312 -0.33385104 -0.366649   -0.3261592  -0.33183378\n",
      " -0.32068613 -0.3146394  -0.3134349  -0.32272038 -0.50767505 -0.31735355\n",
      " -0.41241434 -0.3140961 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31417298 -0.3243317  -0.3259687  -0.34882218 -0.3332851  -0.6230666\n",
      " -0.57129955 -0.3159106  -0.5398982  -0.32630864 -0.37118903 -0.31697497\n",
      " -0.31692928 -0.31522816 -0.31859034 -0.3178522  -0.3500329  -0.35261273\n",
      " -0.31720024 -0.35017872 -0.3485945  -0.33850652 -0.35676208 -0.31529105\n",
      " -0.3405254  -0.31767055 -0.33656222 -0.31622362 -0.31838557 -0.31903633\n",
      " -0.32555258 -0.37191904], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32384658 -1.0426681  -0.60468644 -0.32388237 -0.605857   -0.339271\n",
      " -0.49026334 -0.3599257  -0.3141036  -0.35410082 -0.3454516  -0.33640486\n",
      " -0.43957132 -0.31960225 -0.3345046  -0.9477438  -0.31910706 -0.42692342\n",
      " -0.3218715  -0.32560647 -0.31861368 -0.4480452  -0.3582462  -0.5021429\n",
      " -0.31582874 -0.38831955 -0.3238852  -0.32219085 -0.3287397  -0.37708473\n",
      " -0.34201446 -0.33537573], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33700663 -0.50890756 -0.3172124  -0.36769125 -0.31923595 -0.48180512\n",
      " -0.3162771  -0.3214423  -0.3200304  -0.3367243  -0.388346   -0.3145573\n",
      " -0.31718594 -0.3438127  -0.31715858 -0.3153907  -1.0769473  -0.3179747\n",
      " -0.32737797 -0.3185125  -0.31347734 -0.31559512 -0.6565949  -0.36518326\n",
      " -0.3904447  -0.33819833 -0.32144216 -0.31948525 -0.34621626 -0.3211413\n",
      " -0.34844577 -0.599105  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32526547 -0.31974313 -0.6622324  -0.31558514 -0.36102182 -0.32519105\n",
      " -0.3769481  -0.31630158 -1.1615849  -0.34609476 -0.31981343 -0.41829097\n",
      " -0.36754152 -0.44219747 -0.31525546 -0.31380305 -0.32195228 -0.33603454\n",
      " -0.31497684 -0.40074563 -1.2683458  -0.49970245 -0.37468374 -0.35584357\n",
      " -0.33481136 -0.38959652 -0.34313583 -0.3695017  -0.3176846  -0.31610432\n",
      " -0.7820056  -0.35145825], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37981826 -0.31902525 -0.31692642 -0.42011082 -0.32047608 -0.3835211\n",
      " -0.3847983  -0.3325237  -0.42447376 -0.60901284 -0.3404187  -0.32370517\n",
      " -0.323951   -0.31433493 -0.7454219  -0.32490072 -0.37350556 -0.35364813\n",
      " -0.31943068 -0.32910174 -0.5259301  -0.73287046 -0.33964843 -0.3849439\n",
      " -0.53964627 -0.33072716 -0.33361924 -0.3183476  -0.409277   -0.9891387\n",
      " -0.61018753 -0.36605048], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4997546  -0.4960615  -0.47962588 -0.34067124 -0.33471635 -0.31755218\n",
      " -0.3149156  -1.0302349  -0.51887333 -0.4644285  -0.32005367 -0.3366024\n",
      " -0.37484035 -0.3233551  -0.32139054 -0.33674288 -0.32708305 -0.34613195\n",
      " -0.32151693 -0.47158587 -0.31734997 -0.4022471  -0.37769032 -0.31738123\n",
      " -0.38280094 -0.3618338  -0.82414365 -0.31600517 -0.66882914 -0.35091698\n",
      " -0.3312757  -0.356268  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32751942 -0.485374   -0.36391437 -0.34328985 -0.3193349  -0.32386333\n",
      " -0.32154614 -0.36059678 -0.32709557 -0.31653666 -0.36784682 -0.5110142\n",
      " -0.43073574 -0.31535122 -0.46310008 -0.3161694  -0.57430303 -0.5692389\n",
      " -0.3187781  -1.1013238  -0.31603116 -0.33823326 -0.36519682 -0.3732939\n",
      " -0.3144009  -0.5379745  -0.3240462  -0.3337824  -0.33986402 -0.31640244\n",
      " -0.36466882 -0.31528258], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.2243264  -0.33242497 -0.32175606 -0.35371786 -0.32031667 -0.31971517\n",
      " -0.5819616  -0.34046474 -0.31801113 -0.4711795  -0.6146461  -0.31867844\n",
      " -1.0733831  -0.32153195 -0.3439514  -0.3844349  -0.31947547 -0.31779063\n",
      " -0.36864355 -0.31391314 -0.96419096 -1.0555274  -0.31366977 -0.35149357\n",
      " -0.31773838 -0.34378386 -0.41311288 -0.64800245 -0.32029963 -0.33084488\n",
      " -0.32625884 -0.33906293], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33711845 -0.41355348 -0.3508588  -0.3684971  -0.3653961  -0.44084877\n",
      " -0.6958306  -0.3176815  -0.32189992 -0.5242601  -0.31485903 -0.42514414\n",
      " -0.33265117 -0.32624128 -0.32632655 -0.37359557 -0.3296931  -0.33537045\n",
      " -0.7706573  -0.32263523 -0.47432822 -0.5293636  -0.31545347 -0.31560355\n",
      " -0.3161397  -0.37930354 -0.5538487  -0.31344736 -0.32248536 -0.3444928\n",
      " -0.37907475 -0.31531686], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6905149  -0.31415653 -0.42623216 -0.32140878 -0.81860787 -1.1754975\n",
      " -0.31819975 -0.31981447 -0.32136393 -0.41599336 -0.34756976 -0.52296144\n",
      " -0.31845364 -0.3466882  -0.3763427  -0.33634663 -0.5250314  -0.33520412\n",
      " -0.34810403 -0.31720728 -0.3138541  -0.33058316 -1.0318999  -0.3228188\n",
      " -0.32209074 -0.32413214 -0.48546028 -0.32144457 -0.36802363 -0.3709639\n",
      " -0.31473792 -0.3965704 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.0466385  -0.43337202 -0.31724158 -0.38294294 -0.32923436 -0.315884\n",
      " -0.3208868  -0.37027037 -0.33956414 -0.36066633 -0.8409239  -0.31920928\n",
      " -0.32507935 -0.32428575 -0.34144652 -0.3153034  -0.32939902 -0.32733622\n",
      " -0.34978455 -0.3142501  -0.35827786 -0.32737368 -0.33304292 -0.33837053\n",
      " -0.4316615  -0.43330187 -0.3673088  -0.33480078 -0.31787407 -0.8232331\n",
      " -0.72145355 -0.32677528], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3180871  -0.77226144 -0.31779495 -0.37975156 -0.52826476 -0.31392133\n",
      " -0.32217056 -0.32466245 -0.571157   -0.3242255  -0.33318362 -0.32231352\n",
      " -0.41938332 -0.4805896  -0.34817564 -0.40779856 -0.34614348 -0.34161663\n",
      " -0.560518   -0.36401165 -0.4034459  -0.5438208  -0.31863925 -0.3136114\n",
      " -0.32378218 -0.3146072  -0.31605637 -0.31978694 -0.3384839  -0.5706641\n",
      " -0.37255567 -0.31478247], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33395213 -0.40507832 -0.31715736 -0.31371072 -0.31623083 -0.31484103\n",
      " -0.4302451  -0.33385164 -0.32378346 -0.33015138 -0.35175171 -1.0684721\n",
      " -0.3524733  -0.31872454 -0.793415   -0.31629002 -0.32332328 -0.6261313\n",
      " -0.4085669  -0.8535497  -0.52314913 -0.36860728 -0.31485486 -0.35593703\n",
      " -0.3516135  -0.32928014 -0.36942515 -0.31420824 -0.7474014  -0.4935856\n",
      " -0.31897187 -0.34383857], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4230483  -0.31994122 -0.6280645  -0.38173932 -0.3182459  -0.4572766\n",
      " -0.34233332 -0.3210109  -0.31527084 -0.34652123 -0.314646   -0.32364348\n",
      " -0.32384667 -0.47102183 -0.31445366 -0.641012   -0.31712627 -1.0606596\n",
      " -0.51252794 -0.49832168 -0.6444724  -0.31955513 -0.31633076 -0.3292576\n",
      " -0.54625326 -0.32426152 -0.3237757  -0.63938236 -0.33887693 -0.36622095\n",
      " -0.33766896 -0.31826636], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31734112 -0.36105332 -0.32866728 -0.33089274 -0.32592002 -0.32977968\n",
      " -0.51221275 -0.38054392 -0.3463361  -0.48416442 -0.3760969  -0.522142\n",
      " -0.6735204  -0.4281868  -0.3159205  -0.38798034 -0.36321136 -0.4209765\n",
      " -0.3427856  -0.3262689  -0.3747156  -0.32595202 -0.5311727  -0.33374226\n",
      " -0.31769016 -0.3442208  -0.34065038 -0.3496728  -0.33837512 -0.33920646\n",
      " -0.3827163  -0.32278243], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3300602  -0.32142815 -0.32829854 -0.5639056  -0.3232534  -0.36635318\n",
      " -0.5205583  -0.3904769  -0.36178917 -0.35890943 -0.32948193 -1.1009431\n",
      " -0.32395524 -0.3504724  -0.31889874 -1.2141535  -0.31836444 -0.3939695\n",
      " -0.31523693 -0.36101326 -0.33633682 -0.3235467  -0.64526665 -0.31451964\n",
      " -0.3301197  -0.31415844 -0.333586   -0.31841558 -0.33603674 -0.5309189\n",
      " -0.32889372 -0.3249877 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33381903 -0.47600314 -0.3160189  -0.3952102  -0.32248226 -0.3244363\n",
      " -0.35297745 -0.34247932 -0.33046848 -0.3133366  -0.4288061  -0.3252486\n",
      " -0.32653847 -0.3485866  -0.5899793  -0.31795302 -0.3724526  -1.0157925\n",
      " -0.31831154 -0.32389185 -0.38536096 -0.3192051  -0.3632161  -0.31610423\n",
      " -0.3608942  -0.31527224 -0.79018414 -0.3258778  -1.2349396  -0.40209872\n",
      " -0.32249004 -0.9369739 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31544966 -0.48867384 -0.31465098 -0.31721023 -0.39379865 -0.38842094\n",
      " -0.4103623  -0.315787   -0.32975638 -0.32915723 -0.54464686 -0.31856218\n",
      " -0.3283987  -0.4252523  -0.32835114 -0.79486644 -0.33751392 -0.41926458\n",
      " -0.33089292 -0.3665024  -0.31660432 -0.33241224 -0.41950792 -0.5886486\n",
      " -0.34708273 -0.9048331  -0.36119738 -0.31618106 -0.31711206 -0.34879494\n",
      " -0.41348112 -0.31535235], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4968482  -0.32162097 -0.31610736 -0.33671018 -0.33728874 -0.3154328\n",
      " -1.1683936  -0.31378153 -0.33676374 -0.46178406 -0.79952884 -0.3209328\n",
      " -0.45705986 -0.35307923 -0.31818667 -0.32339972 -0.32561886 -0.31884483\n",
      " -0.4056188  -0.32256195 -0.4319557  -0.33045787 -0.32407612 -0.32144699\n",
      " -0.552111   -0.3139729  -0.38949794 -0.35232177 -0.3136959  -0.33886087\n",
      " -0.31747633 -0.33657652], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.0607784  -0.31601116 -0.3936315  -0.3357399  -0.38818502 -0.33395708\n",
      " -0.5897515  -0.31698963 -0.39691666 -0.75269645 -0.3174411  -0.39347482\n",
      " -0.39184806 -0.48745143 -0.37743363 -0.32177567 -0.3787324  -0.44633228\n",
      " -0.31756207 -0.31502774 -0.31971136 -0.3193529  -0.34552127 -0.31826887\n",
      " -0.41517863 -0.3917056  -0.7234571  -0.52027017 -0.5812619  -0.35473815\n",
      " -0.33009082 -0.3150521 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31584775 -0.31914622 -0.45348707 -0.31771192 -0.32312423 -0.62757385\n",
      " -0.52207875 -0.33166182 -0.3230361  -0.31417465 -0.3174745  -0.37585193\n",
      " -0.31643754 -0.32905552 -0.35559726 -0.35020056 -0.31817245 -0.33112478\n",
      " -0.31803274 -0.3386828  -0.3350701  -0.51370084 -0.3195005  -0.56810033\n",
      " -0.4652178  -0.35856825 -0.35042596 -0.3325861  -0.3439283  -0.3199819\n",
      " -0.31387752 -0.31704834], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38450673 -0.31781682 -0.32703936 -0.47749132 -0.31948438 -1.3067641\n",
      " -0.36548802 -0.32005012 -0.36680835 -0.35140398 -0.32784978 -0.34254366\n",
      " -0.3244545  -0.31782603 -0.3583161  -1.0823276  -0.3772829  -0.3424618\n",
      " -0.31424367 -0.31414896 -0.3484395  -0.31476098 -0.5115029  -0.32354257\n",
      " -0.3291791  -0.3275385  -0.39793092 -0.8926513  -0.9958242  -0.3339195\n",
      " -0.31518266 -0.40910476], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3153427  -0.35944572 -0.33167422 -0.32154527 -0.6111449  -0.31815112\n",
      " -0.35202008 -0.3234846  -0.31587043 -0.41826493 -0.39435828 -0.33025935\n",
      " -0.63453335 -0.45913678 -0.32878834 -0.39012736 -0.6084608  -0.5507806\n",
      " -0.60341865 -0.32574427 -0.34685296 -0.3677405  -0.32845193 -0.31690854\n",
      " -0.5071987  -0.31498832 -0.3310627  -0.40238175 -0.32493863 -0.31998363\n",
      " -0.34618312 -0.33836892], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33239385 -0.3381793  -0.33161783 -0.3151971  -0.33353904 -0.7556455\n",
      " -0.33887488 -0.80870175 -0.33698428 -0.36627203 -0.34044945 -0.33581832\n",
      " -0.3163185  -0.31719738 -0.3292667  -0.45045975 -0.31670943 -0.31741863\n",
      " -0.3156298  -0.34295642 -0.3706934  -0.42469814 -0.41562748 -0.31602186\n",
      " -0.3138019  -0.33349985 -0.31601056 -0.5034716  -0.37827444 -0.8041706\n",
      " -0.32132882 -0.31943414], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31485426 -0.33127177 -0.9485856  -0.32028398 -0.33562845 -0.3279501\n",
      " -0.36909935 -0.3175476  -0.3257459  -0.32776165 -0.31412327 -0.4769284\n",
      " -0.3706182  -0.31582975 -0.32685128 -0.3139713  -0.3834518  -0.31702906\n",
      " -0.31717828 -0.3225015  -0.31479535 -0.3380664  -0.3142812  -0.32744998\n",
      " -0.31642076 -0.36362705 -0.33405572 -0.33514932 -0.3146253  -0.31995532\n",
      " -0.9463495  -0.3325463 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3162071  -0.45167705 -0.33461237 -0.5487103  -0.32102007 -0.37794906\n",
      " -0.9985892  -0.5353371  -0.3133995  -0.46908063 -0.31767383 -1.174491\n",
      " -0.3147599  -0.3534551  -0.45271218 -0.4064825  -0.3865351  -0.854332\n",
      " -0.36325905 -0.3185529  -0.36198348 -0.35655522 -0.31833747 -0.32300237\n",
      " -0.38018396 -0.31482387 -0.39668226 -0.62803704 -0.314026   -0.34027702\n",
      " -0.33280322 -0.33258927], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31549713 -0.31418326 -1.145854   -0.5142292  -0.31611466 -0.32454774\n",
      " -0.38462391 -0.3603502  -0.32768273 -0.31771845 -0.36772203 -0.35905802\n",
      " -0.34249946 -0.33278143 -0.39520806 -0.7626565  -0.38159215 -0.35627618\n",
      " -0.31769675 -1.0171595  -0.34162045 -0.33234102 -0.33401468 -0.39910027\n",
      " -0.57461816 -0.34886736 -0.395152   -0.32897377 -0.33463597 -0.31466317\n",
      " -0.31552723 -0.31612328], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3963511  -0.36577037 -0.36585158 -0.31653258 -0.3320617  -0.31494927\n",
      " -0.5498855  -0.33385777 -0.3950383  -0.35716283 -0.3182715  -0.31370932\n",
      " -0.31365505 -0.3281265  -0.3364592  -0.44858533 -0.33227158 -0.32103866\n",
      " -0.3215209  -0.31942046 -0.37205487 -0.32408705 -0.32121894 -0.32244468\n",
      " -0.48736048 -0.45124745 -0.31479132 -0.36235204 -0.32966423 -0.32318178\n",
      " -0.31553254 -0.44028324], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34297043 -0.32176313 -0.33254892 -0.5170516  -0.32285416 -0.32565796\n",
      " -0.7439356  -0.43730438 -0.3235167  -0.31907412 -0.3177436  -0.3393429\n",
      " -0.34984773 -0.31800437 -0.31569085 -0.31568754 -0.4070825  -0.32450354\n",
      " -0.39471334 -0.35901916 -0.32505524 -0.31635934 -0.34273195 -0.39004496\n",
      " -0.31687033 -0.32354128 -0.31759462 -0.7216606  -0.3173144  -0.343014\n",
      " -0.34768286 -0.41455132], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31421444 -0.3817136  -0.39665467 -0.33485094 -0.3662464  -0.31630844\n",
      " -0.31454933 -0.41915476 -0.3615893  -0.31493577 -0.3426728  -0.3494348\n",
      " -0.46815673 -0.3268152  -0.3155642  -0.3664368  -0.3282975  -0.31837153\n",
      " -0.3196936  -0.47829437 -0.38350338 -0.55805993 -0.9823358  -0.32001126\n",
      " -0.33014223 -0.35956478 -0.3276834  -0.31912756 -0.3143909  -0.34647572\n",
      " -0.4115771  -0.33516714], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.39919353 -0.33208677 -0.31417742 -0.794562   -0.38343132 -0.34602645\n",
      " -0.32297915 -0.34339985 -0.3738867  -0.314026   -0.53096604 -0.5766337\n",
      " -0.31823176 -0.31944618 -0.43429217 -0.31678167 -0.31619078 -0.33084044\n",
      " -0.3198891  -0.31490123 -0.31865883 -0.38677686 -0.31429052 -0.3640817\n",
      " -0.31593224 -0.53533584 -0.39179647 -0.3272789  -0.4904405  -0.40114886\n",
      " -0.34046322 -0.44810537], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33360016 -0.32727093 -0.33070952 -0.5616218  -0.31675997 -0.31459737\n",
      " -0.32389116 -0.31456628 -0.52856493 -1.174988   -0.31621236 -0.32587287\n",
      " -0.3604458  -0.46540645 -0.3586149  -0.7215203  -1.0048845  -0.31429315\n",
      " -0.45599192 -0.32498866 -0.43868375 -0.440492   -0.776647   -0.3229965\n",
      " -0.3522654  -0.31770015 -0.47780985 -0.31390503 -0.31396678 -0.3212141\n",
      " -0.32922655 -0.33514854], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.51421195 -0.31610093 -0.3810842  -0.31793037 -0.3149087  -0.34327537\n",
      " -0.34247932 -0.57037765 -0.31926107 -0.46461612 -0.3230551  -0.47454777\n",
      " -0.33139345 -0.32199046 -0.35850653 -0.31739318 -0.49084637 -0.7826913\n",
      " -0.31643954 -0.793085   -0.48605418 -0.32539952 -0.33598113 -0.37711066\n",
      " -0.3177036  -0.32337072 -0.3189236  -0.31531245 -0.31622565 -0.31940106\n",
      " -0.42172664 -0.31495526], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31588408 -0.36433017 -0.52640724 -0.4442752  -0.3295626  -0.31844178\n",
      " -0.46284482 -0.46994874 -0.31422853 -0.42589474 -0.38470107 -0.3254492\n",
      " -0.39363518 -0.33796352 -0.36370337 -0.32338497 -0.3216609  -0.7602978\n",
      " -0.33097428 -0.33717555 -0.67343193 -0.3142268  -0.3163067  -0.35040623\n",
      " -0.36886007 -0.32308418 -0.3818133  -0.315805   -0.3179374  -0.322528\n",
      " -0.33552212 -0.32958123], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3142591  -0.31375775 -0.4360999  -0.3153953  -0.41063693 -0.32084686\n",
      " -0.31526572 -0.81453574 -0.77112937 -0.31594077 -0.7400813  -0.41823086\n",
      " -0.33193094 -0.48866507 -0.38084412 -0.3163451  -0.34477007 -0.5908606\n",
      " -0.32073733 -0.32218134 -0.31511813 -0.42898837 -0.31624675 -0.31545427\n",
      " -0.6633006  -0.32496893 -0.32625264 -0.31530792 -0.32172114 -0.44644502\n",
      " -0.31999853 -0.31631765], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31875816 -0.3161821  -0.36736387 -0.33218205 -0.3353096  -0.3388822\n",
      " -0.38709825 -0.39368737 -0.32541943 -0.31701404 -0.32604316 -0.35280928\n",
      " -0.56625277 -0.4325398  -0.5546049  -0.34758037 -0.48215657 -0.31436896\n",
      " -0.40441924 -0.31607348 -0.31487095 -0.8653767  -0.32070845 -0.31728974\n",
      " -0.3825918  -1.0854815  -0.5720214  -0.4738962  -0.32395834 -0.31511012\n",
      " -0.3154613  -0.31495684], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43950298 -0.3145246  -0.43482965 -0.52116466 -0.34968212 -0.34056938\n",
      " -0.31877455 -0.31560877 -0.44708908 -0.31444418 -0.3358132  -0.31658122\n",
      " -0.3846739  -0.32352763 -0.36304224 -0.3147205  -0.31764823 -0.31654283\n",
      " -0.32290336 -0.31835046 -0.3726961  -0.35222775 -0.33080286 -0.37217885\n",
      " -0.32794133 -0.33954582 -0.3804599  -0.56105566 -0.34351772 -0.48578808\n",
      " -0.33962145 -0.3164345 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.44033912 -0.3157437  -0.31696317 -0.49355912 -0.33344227 -0.3150045\n",
      " -0.3626117  -0.36736545 -0.33041555 -0.3182388  -0.31495962 -0.31559384\n",
      " -0.3140549  -0.319551   -0.31790408 -0.3215928  -0.4022872  -0.35427868\n",
      " -0.32843107 -0.33420032 -0.5270368  -0.40752563 -0.9176372  -0.5277724\n",
      " -0.31777892 -0.3141662  -0.315326   -0.32987928 -0.31555635 -0.8253412\n",
      " -0.3176209  -0.37191755], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31815076 -0.32335365 -0.33376616 -0.5337456  -0.33671206 -0.32947809\n",
      " -0.31410158 -0.3206894  -0.44666272 -0.31474757 -0.31984088 -0.32582605\n",
      " -0.3185882  -0.31702185 -0.34074998 -0.31550393 -0.34085605 -0.32141268\n",
      " -0.35202378 -0.3925659  -0.31436592 -0.33859164 -0.3157776  -0.31578004\n",
      " -0.32406414 -0.31468996 -0.35685188 -0.37068713 -0.34651363 -0.31633765\n",
      " -0.3187117  -0.41771993], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34955087 -0.36081585 -0.32506016 -0.35385886 -0.34979498 -0.32816046\n",
      " -0.3180539  -0.313744   -0.31510141 -0.31416827 -0.46734816 -0.31774724\n",
      " -0.3213047  -0.3760648  -0.9397433  -0.38734537 -0.31409124 -0.41222483\n",
      " -0.34650066 -0.31669483 -0.32260346 -0.36921248 -0.3923871  -0.31917593\n",
      " -0.32954788 -0.3140201  -0.3138899  -0.32408774 -0.3653403  -0.37909648\n",
      " -0.31766135 -0.31594694], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31798068 -0.31989846 -0.3706952  -0.5325922  -0.41330197 -0.3308919\n",
      " -0.3753961  -0.32259262 -0.32049182 -0.4184983  -1.0802405  -1.2778498\n",
      " -0.35533175 -0.3274632  -0.32834402 -0.3188112  -0.3759609  -0.36034912\n",
      " -0.31480795 -0.34996065 -0.3702325  -0.3140408  -0.4218697  -0.48971346\n",
      " -0.31428078 -0.31531608 -0.3394093  -0.3325451  -0.39339447 -0.3153747\n",
      " -0.3370549  -0.31491482], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31599864 -0.39408967 -0.32670957 -0.46819696 -0.31717116 -0.59112227\n",
      " -0.31973577 -0.31675145 -0.31640208 -0.31733122 -0.7498908  -0.36689126\n",
      " -0.3202968  -0.32166272 -0.6264781  -0.33025515 -0.38323396 -0.31596014\n",
      " -0.44031173 -0.31540826 -0.54173154 -0.31395268 -0.31846076 -0.31599864\n",
      " -0.51367295 -0.31592146 -0.32733837 -0.31750065 -0.409438   -0.31394014\n",
      " -0.4353621  -0.3160879 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32450068 -0.3150827  -0.32480544 -0.34235963 -0.34705174 -0.31995454\n",
      " -0.35352457 -0.31580013 -0.35175422 -0.3660243  -0.36658305 -0.31378782\n",
      " -0.38436243 -0.3298278  -0.84262276 -0.3195644  -1.1142776  -0.31681433\n",
      " -0.33337343 -0.31413347 -0.34618407 -0.33197844 -0.31391767 -0.31822795\n",
      " -0.45887238 -0.31638968 -0.40879297 -0.7674458  -0.33507156 -0.57583845\n",
      " -0.3150879  -0.31399995], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36580527 -0.3174078  -0.3173768  -0.31508836 -0.43996957 -0.3137215\n",
      " -0.4122493  -0.32060775 -0.36744064 -0.31659424 -0.3175332  -0.6485814\n",
      " -0.32205006 -0.33195883 -0.31732324 -0.37592125 -0.31988347 -0.3361188\n",
      " -0.32030267 -0.3428262  -0.502456   -0.32759285 -0.31902507 -0.42027387\n",
      " -0.41962835 -0.3172006  -0.31448203 -0.553232   -0.39381    -0.38711768\n",
      " -0.43561652 -0.3720243 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3139207  -0.34455463 -0.5166873  -0.73740065 -0.32335174 -0.31821954\n",
      " -0.3632558  -0.3154727  -0.35193786 -0.33176994 -0.38181043 -0.3549724\n",
      " -0.3251914  -1.0460649  -0.32064176 -0.33147168 -0.35032293 -0.33996117\n",
      " -0.3307615  -0.35272166 -0.53120565 -0.32145312 -0.41846073 -0.31750628\n",
      " -0.31436434 -0.32691592 -0.43388695 -0.3160567  -0.3809343  -0.33060476\n",
      " -0.31383562 -0.31453392], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31962538 -0.7958067  -0.39104718 -0.35851276 -0.39949936 -0.32327348\n",
      " -0.32275197 -0.3187801  -0.3146113  -0.31975275 -0.6816705  -0.40444878\n",
      " -0.33768418 -0.4316455  -0.3918939  -0.59995806 -0.40350267 -0.32606277\n",
      " -0.3233363  -0.36471105 -0.33162048 -0.42742658 -0.32344794 -0.561308\n",
      " -0.33353552 -0.33694357 -0.40142402 -0.3160939  -0.31490272 -0.37401563\n",
      " -0.3170637  -0.34058642], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34998795 -0.3152551  -0.317904   -0.42963076 -0.4965062  -0.3163451\n",
      " -0.3279603  -0.52571887 -0.34568465 -0.40203825 -0.32228166 -0.5736589\n",
      " -0.32681674 -0.32364824 -0.31512263 -0.33198363 -0.31859052 -0.6052754\n",
      " -0.31490532 -0.45354146 -0.31401557 -0.39060727 -0.37966707 -0.4975962\n",
      " -0.45200923 -0.9738754  -0.31550547 -0.3940243  -0.6745609  -0.31439516\n",
      " -0.37834042 -0.31478596], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34748784 -0.31462198 -0.32492933 -0.3167187  -0.3472435  -0.34116936\n",
      " -0.33452296 -0.318347   -0.32008016 -0.32249779 -0.32816717 -0.3136039\n",
      " -0.36442393 -0.31700343 -0.37039185 -0.605677   -0.32002    -0.3701836\n",
      " -0.3141468  -0.32909617 -0.31887612 -0.32251403 -0.318508   -0.31382918\n",
      " -0.3300471  -0.35732657 -0.31640834 -0.58979064 -0.31331918 -0.32549027\n",
      " -0.32166773 -0.36415112], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38491634 -0.3349826  -0.3157385  -0.6260641  -0.3387653  -0.3154453\n",
      " -0.9916639  -0.56596386 -0.33199057 -0.3450618  -0.31400475 -0.31595582\n",
      " -0.3479802  -0.31553558 -0.38277653 -0.3725758  -0.31530556 -0.38570857\n",
      " -0.31468657 -0.33051577 -0.31423238 -0.32890606 -0.3262918  -0.32838112\n",
      " -0.3424403  -0.32095295 -0.34984547 -0.31573474 -0.3157038  -0.32243708\n",
      " -0.3184336  -0.3141608 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31334776 -0.33001375 -0.3247075  -0.3404889  -0.31783018 -0.3153326\n",
      " -0.31863284 -0.34256995 -0.32415593 -0.31676126 -0.33473673 -0.366563\n",
      " -1.1929286  -0.38458204 -0.38489273 -0.313451   -0.31551513 -0.32026106\n",
      " -0.40880722 -0.33944064 -0.5893876  -0.32343146 -0.3140225  -0.37114373\n",
      " -0.325065   -0.32824692 -0.31498155 -0.40331864 -0.36296836 -0.38841292\n",
      " -0.47287798 -0.32471463], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.69370955 -0.4612152  -0.31404254 -0.31590068 -0.33434504 -0.34281248\n",
      " -0.321945   -0.95982194 -0.39413083 -0.31442145 -0.34074312 -0.32323414\n",
      " -0.44473454 -0.38170457 -0.32926095 -0.31394032 -0.38478166 -0.51218605\n",
      " -0.3531469  -0.4813608  -0.33193976 -0.35866135 -0.31435633 -0.31763792\n",
      " -0.3194229  -0.31861168 -0.3279531  -0.47306406 -0.3880291  -0.3193574\n",
      " -0.84776187 -0.6485416 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.9331889  -0.3327209  -0.7021597  -0.41529408 -0.34460944 -0.5383854\n",
      " -0.3165431  -0.31982088 -0.318646   -0.90762776 -0.31578258 -0.31612614\n",
      " -0.38780913 -0.3164484  -0.33116296 -1.0540912  -0.3169088  -0.3155786\n",
      " -0.55288845 -0.3306952  -0.5452918  -0.686058   -0.35289973 -0.33713913\n",
      " -0.31835124 -0.3925676  -0.31520265 -0.7369435  -0.36132538 -0.34576353\n",
      " -0.38065425 -0.35117805], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3235431  -0.6528644  -0.61391294 -0.32929626 -0.31754264 -0.3334908\n",
      " -0.32198572 -0.32067513 -0.31625327 -0.5038867  -0.3150151  -0.326602\n",
      " -0.33754426 -0.31541193 -0.55339205 -0.31592607 -0.31990436 -0.31407684\n",
      " -0.32091448 -0.33408263 -0.39971504 -0.35978934 -0.38025016 -0.31557035\n",
      " -0.33223438 -0.32269585 -0.31388518 -0.33896834 -0.3139135  -0.31975153\n",
      " -0.31874204 -0.48614833], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.47626817 -0.31620383 -0.6858092  -0.3346105  -0.34632674 -0.31422392\n",
      " -0.3174149  -0.70981276 -1.1098291  -0.3575261  -0.5047952  -0.36146334\n",
      " -0.5934955  -0.31805313 -0.3270483  -0.37958822 -0.87214315 -0.3248617\n",
      " -0.32113326 -0.4947219  -0.32239124 -0.31917375 -0.34492418 -0.36556527\n",
      " -0.90873945 -0.33220762 -0.31570077 -0.3170513  -0.32676643 -0.37978464\n",
      " -0.3184343  -0.3194583 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32838506 -0.3268181  -0.3143412  -0.31882134 -0.43498585 -0.31417385\n",
      " -0.31948957 -0.32943898 -0.31895897 -0.32028952 -0.32802978 -0.35097378\n",
      " -0.34220308 -0.31694502 -0.79486513 -0.32014543 -1.2928796  -0.6090968\n",
      " -0.3290394  -0.32776716 -0.32525212 -0.31751636 -0.31509924 -0.4494773\n",
      " -0.6690115  -0.31557167 -0.32285902 -0.36825544 -0.33888322 -0.3720759\n",
      " -0.31605837 -0.7985611 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3190521  -0.4787363  -0.5585197  -0.33937365 -0.31777492 -0.314599\n",
      " -0.36894736 -0.31589633 -0.31353238 -0.36258882 -0.34029263 -0.32811454\n",
      " -0.31466463 -0.54733324 -0.73337245 -0.31449726 -0.35053167 -0.42796606\n",
      " -1.1406028  -0.34731483 -0.31590495 -0.313711   -0.313871   -0.41483447\n",
      " -0.3168026  -0.3260158  -0.32661328 -0.31624085 -0.46535525 -0.315219\n",
      " -0.3183658  -0.796239  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7578465  -0.33075926 -0.32595658 -0.44755903 -0.31826568 -0.31375653\n",
      " -0.5165118  -0.34521028 -0.3178392  -0.8675897  -0.32426712 -0.31412876\n",
      " -0.3547138  -0.32516444 -0.32202986 -0.49831402 -0.3160102  -0.3305204\n",
      " -0.33226174 -0.32447588 -0.46897054 -0.34174252 -0.7716266  -0.32330707\n",
      " -0.35468295 -0.31370896 -0.33551827 -0.31336623 -0.34022546 -0.34614468\n",
      " -0.34343874 -0.3531155 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3425582  -0.33230716 -0.3168896  -0.35581335 -0.34704307 -0.3143612\n",
      " -0.3311169  -0.33486798 -0.3738867  -0.4687631  -0.32571855 -0.31565937\n",
      " -0.31337023 -0.34437928 -0.3137717  -0.33567625 -0.31378335 -0.3652066\n",
      " -0.73472524 -0.6464166  -0.31727898 -0.31814295 -0.34708115 -0.51398194\n",
      " -0.59185255 -0.3335949  -0.40199798 -0.31681597 -0.3298415  -0.88111\n",
      " -0.31533512 -0.5853973 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.52089703 -0.31379834 -0.3495706  -0.31633946 -0.3340088  -0.36468935\n",
      " -0.31478924 -0.32426333 -0.31368196 -0.4187522  -0.40152177 -0.32473016\n",
      " -0.32745513 -0.32246652 -0.33024925 -0.5955571  -0.42211267 -0.31601933\n",
      " -0.31878    -0.32265458 -0.7131543  -0.31777924 -0.68874675 -0.32913014\n",
      " -0.36455655 -0.31447732 -0.46045882 -0.5630434  -0.52595794 -0.3802463\n",
      " -0.31540826 -0.32293168], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32170618 -0.3664682  -0.31675684 -0.43493423 -0.66852814 -0.32467312\n",
      " -0.31543836 -0.3665752  -0.71476555 -0.31527868 -0.31596136 -0.37152857\n",
      " -0.32703224 -0.3165521  -0.5314614  -0.32067385 -0.38295278 -0.3138499\n",
      " -0.32275084 -0.35050806 -0.78645456 -0.31430548 -0.34495425 -0.36888808\n",
      " -0.33820292 -0.3154347  -0.32382157 -0.4632672  -0.32210404 -0.4182858\n",
      " -0.4324884  -0.4116699 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.314837   -0.3325209  -0.32074988 -0.4601284  -0.3349825  -0.31445366\n",
      " -0.34332663 -0.31660903 -0.33816534 -0.4097462  -0.3139458  -0.32106513\n",
      " -0.31661874 -0.32189023 -0.3137384  -0.31800342 -0.40180865 -0.31917626\n",
      " -0.64466614 -0.32444572 -0.32709378 -0.3289741  -0.3138053  -0.5508043\n",
      " -0.32087764 -0.31412178 -0.31455812 -0.31509647 -0.48555666 -0.3158669\n",
      " -0.33995855 -0.31718594], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.45688838 -0.3133841  -0.49994826 -0.31614196 -0.32478943 -0.31531563\n",
      " -0.74430454 -0.36781868 -0.31741107 -0.32442495 -0.34315407 -0.3547257\n",
      " -0.35621974 -0.33547744 -0.315239   -0.31502104 -0.3777195  -0.33019543\n",
      " -0.33309162 -0.38133395 -0.31656957 -0.32418567 -0.31518406 -0.42669207\n",
      " -0.40393025 -1.0921645  -0.31554964 -0.53777236 -0.32303172 -0.31982434\n",
      " -0.75247353 -0.4291142 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31426528 -0.3142119  -0.31503487 -0.31475922 -0.3142375  -0.3170405\n",
      " -0.31467962 -0.37074202 -0.3282464  -0.31626412 -0.31398404 -0.31416568\n",
      " -0.3194487  -0.324171   -0.38708943 -0.36258236 -0.5022195  -0.49138948\n",
      " -0.34608075 -0.34542257 -0.33045965 -0.39312816 -0.34356642 -0.6760345\n",
      " -0.3272245  -0.31392306 -0.3180904  -0.75758696 -0.3139552  -0.33904815\n",
      " -0.31888002 -0.38958386], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.338178   -0.82186794 -0.36537206 -0.91176367 -0.31752634 -0.3226248\n",
      " -0.31927547 -0.37979525 -0.31494874 -0.31739545 -0.3765462  -0.50070757\n",
      " -0.87385535 -0.58657634 -0.37588802 -0.31809926 -0.39256117 -0.3292324\n",
      " -0.3137634  -0.5771913  -0.3140753  -0.40596852 -0.3216125  -0.3333327\n",
      " -0.80870783 -0.35630965 -0.31613857 -0.37686527 -0.42905605 -0.3155467\n",
      " -0.31813133 -0.776644  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31330487 -0.38965315 -0.37018555 -0.32155314 -0.33207908 -0.31596014\n",
      " -0.3164591  -0.31370556 -0.46889222 -0.44518802 -0.42680442 -0.35524684\n",
      " -0.51554394 -0.32461762 -0.31384155 -0.31473678 -0.31361228 -0.32066554\n",
      " -0.31708166 -0.348855   -0.32380113 -0.31952873 -0.39281192 -0.31420135\n",
      " -0.41983026 -0.36652505 -0.3501505  -0.35047987 -0.44739383 -0.3146925\n",
      " -0.39997903 -0.31631973], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.46212056 -0.32000294 -0.31463608 -0.39779043 -0.3156938  -0.31338948\n",
      " -0.3194275  -0.3421926  -0.32261392 -0.33352196 -0.3139917  -0.3164763\n",
      " -0.5932155  -0.315223   -0.3556188  -0.55714375 -0.5616445  -0.32403955\n",
      " -0.31468064 -0.6768784  -0.35954118 -0.35094887 -0.37999958 -0.3169153\n",
      " -0.38094437 -0.33600277 -0.31526843 -0.3606084  -0.31700787 -0.3214896\n",
      " -0.35519603 -0.51621103], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3208964  -0.3705029  -0.62569445 -0.3381696  -0.3971172  -0.73403\n",
      " -0.3206249  -0.3303852  -0.3255333  -0.32517773 -0.3382234  -0.32322\n",
      " -0.3490558  -0.32273203 -0.3456725  -0.31587523 -0.34047145 -0.3373937\n",
      " -0.31494847 -0.43019977 -0.3167695  -0.3137215  -0.36911654 -0.3167636\n",
      " -0.7889962  -0.31627873 -0.32544377 -0.8295641  -0.32425463 -0.31585732\n",
      " -0.49872863 -0.3215572 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33699584 -0.31925067 -0.31556234 -0.3160548  -0.32628328 -0.3139357\n",
      " -0.3663387  -0.3220569  -0.97524107 -0.41519958 -0.35338736 -0.314224\n",
      " -0.37016103 -0.5635253  -0.31773674 -0.31596303 -0.3418229  -0.33119968\n",
      " -0.31540218 -0.3137114  -0.9132439  -0.44947043 -0.42370024 -0.31913495\n",
      " -0.34304804 -0.35032293 -0.31604114 -0.31473815 -0.36551765 -0.3329108\n",
      " -0.32486248 -0.46823585], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31433728 -0.4148422  -0.33884007 -0.34072897 -0.46541047 -0.32431754\n",
      " -1.305144   -0.7546567  -0.31955504 -0.5581177  -0.3626265  -0.3141783\n",
      " -0.3138275  -0.3267642  -0.3227638  -0.31501424 -0.326704   -0.31372708\n",
      " -0.37186337 -0.31406066 -0.3144607  -0.375647   -0.6641376  -0.4221558\n",
      " -0.33521992 -0.33965856 -0.31733835 -0.40007484 -0.3275012  -0.3200032\n",
      " -0.36918652 -0.3333243 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31865442 -0.31511185 -0.3225047  -0.3797006  -0.32828084 -0.3567574\n",
      " -0.31534034 -0.37526333 -0.34965843 -0.3160209  -0.4086117  -0.32052687\n",
      " -0.3139497  -0.31657654 -0.31948292 -0.31481856 -0.3161789  -0.45697504\n",
      " -0.36566848 -0.33491525 -0.34882152 -0.31358397 -0.5843114  -0.31627804\n",
      " -0.31473374 -0.5180456  -0.31870183 -0.39030352 -0.32164404 -0.70398307\n",
      " -0.33575287 -0.31405246], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31650782 -0.5250017  -0.38977462 -0.31398472 -0.31655237 -0.33645248\n",
      " -0.3286108  -0.31392863 -0.3714294  -0.4014055  -0.33294806 -0.3497759\n",
      " -0.39832214 -0.35955548 -0.31856027 -0.31434277 -0.31924054 -0.31503618\n",
      " -0.34031937 -0.406883   -0.3200524  -0.3578306  -0.31678072 -0.3181205\n",
      " -0.31660354 -0.4288769  -0.7050772  -0.3194041  -0.776204   -0.37157822\n",
      " -0.3668589  -0.43513215], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3147266  -0.3371387  -0.3136729  -0.36430055 -0.38135022 -0.32276812\n",
      " -0.3248326  -0.31509525 -0.9796587  -0.38257417 -0.3438688  -0.3150058\n",
      " -0.32098478 -0.39563304 -0.373342   -0.31703487 -0.32587785 -0.31633675\n",
      " -0.43150625 -0.31537843 -0.9632814  -0.31475356 -0.4339162  -0.3916654\n",
      " -0.32395196 -0.31982002 -0.3152531  -0.35728794 -0.3777613  -0.88008237\n",
      " -0.38828698 -0.38634494], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31413257 -0.31723368 -0.8338438  -0.34516835 -0.33009818 -0.34390497\n",
      " -0.9346658  -0.32503182 -0.3555423  -0.68372643 -0.40936503 -0.32055774\n",
      " -0.5236771  -0.32310024 -0.9559587  -0.57432103 -0.32653305 -0.3135716\n",
      " -0.31637657 -0.31940556 -0.32183674 -0.31500965 -0.3226678  -0.31684768\n",
      " -0.3446093  -0.4557814  -0.31751132 -0.32406205 -0.40302947 -0.4031657\n",
      " -0.39207545 -0.45114362], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.0418214  -0.31565696 -0.42617035 -0.7103965  -0.35183457 -0.31753743\n",
      " -0.33205402 -0.47072557 -0.3181682  -0.32673264 -0.4020232  -0.33491132\n",
      " -0.31755018 -0.32062066 -0.38368493 -0.5999174  -0.68615544 -0.33097625\n",
      " -0.3157609  -0.3211578  -0.31649488 -0.6715322  -0.5513849  -0.3199703\n",
      " -0.32564384 -0.31687927 -0.32155737 -0.43999785 -0.32943803 -1.0659442\n",
      " -0.44286573 -0.31746176], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.40229756 -0.3147037  -0.6210296  -0.32878104 -0.6739994  -0.3329351\n",
      " -0.31403035 -1.2850449  -0.31968254 -0.6392751  -0.32620722 -0.31926793\n",
      " -0.46575308 -0.56048864 -0.3150005  -0.31530008 -0.33056244 -0.39632797\n",
      " -0.97412455 -0.31652755 -0.38527393 -0.37146378 -0.31882942 -0.31368423\n",
      " -0.44984978 -0.31506497 -0.3473117  -0.511109   -0.32275325 -0.39263555\n",
      " -0.33057725 -0.31955755], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31605983 -0.43978053 -0.61806583 -0.31554523 -0.3152905  -0.31379277\n",
      " -0.31545115 -0.31926307 -0.36191452 -0.42156383 -0.44202685 -0.31400824\n",
      " -0.68129057 -0.35288215 -0.34941965 -0.32708156 -0.31574544 -0.45315224\n",
      " -0.5957326  -0.3180787  -0.34495044 -0.5718169  -0.9729055  -0.45776653\n",
      " -0.6210951  -0.33581635 -0.32145876 -0.3179355  -0.4197784  -0.3152732\n",
      " -0.31363824 -0.31494588], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34277982 -0.32422438 -0.31682336 -0.31936365 -0.45244485 -0.6693075\n",
      " -0.3505597  -0.4374789  -0.3837863  -0.3550172  -0.32294047 -0.31888878\n",
      " -0.34280378 -0.32091084 -0.3175882  -0.31548965 -0.32046154 -0.4914239\n",
      " -0.33807558 -0.9200299  -0.31655803 -0.32335114 -0.3193116  -0.3565867\n",
      " -0.31884396 -0.32382718 -0.31887907 -0.32567275 -0.31640947 -0.35008237\n",
      " -0.35594305 -0.32282156], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32142642 -0.45459396 -0.3149939  -0.3159072  -0.32550853 -0.3273756\n",
      " -0.31696185 -0.3138396  -0.33967364 -0.31390122 -0.34634662 -0.31498796\n",
      " -0.37640253 -0.31484234 -0.42204615 -0.37507695 -0.52638006 -0.36381298\n",
      " -0.9886182  -0.38425487 -0.3222362  -0.32459813 -0.32548958 -0.33086056\n",
      " -0.35182214 -0.3358161  -0.32037562 -0.3141103  -0.31494144 -0.34578258\n",
      " -0.36429226 -0.6858917 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31431994 -0.34119308 -0.3191344  -0.42329517 -0.4159756  -0.469855\n",
      " -0.32214493 -0.3210876  -0.31768677 -0.34495997 -0.31546375 -0.39837825\n",
      " -0.31712854 -0.31476244 -0.38152242 -0.31403792 -0.33273664 -0.31544635\n",
      " -0.32157344 -0.33644608 -0.5033562  -0.31913    -0.31362692 -0.31565434\n",
      " -0.32041577 -0.31713825 -0.31526458 -0.9565765  -0.9100262  -0.44518924\n",
      " -0.31638655 -0.36999497], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3274132  -0.31494117 -0.3144614  -0.31634694 -0.39553833 -0.31462705\n",
      " -0.32101452 -0.45653516 -0.343183   -0.3166367  -0.31672496 -0.42969933\n",
      " -0.31653884 -0.35378614 -0.31889042 -0.3151937  -0.3463592  -0.504088\n",
      " -0.43759912 -0.32026944 -0.31852153 -0.31667894 -0.3248082  -0.32399082\n",
      " -0.3158337  -0.3194146  -0.54754436 -0.31684166 -0.3160182  -0.31545636\n",
      " -0.33980972 -0.41478568], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3381797  -0.39693198 -0.33570296 -0.31493735 -0.54707044 -0.33644336\n",
      " -0.3910362  -0.38748357 -0.32179    -0.33575988 -0.31545123 -0.44378734\n",
      " -0.3899669  -0.34026548 -0.31448022 -0.31506628 -0.3153465  -0.3162683\n",
      " -0.33421046 -0.3193094  -0.31658262 -0.33050907 -0.3469111  -0.6762389\n",
      " -0.31746906 -0.32603353 -0.7908868  -0.59997016 -0.31564772 -0.31960857\n",
      " -0.3359231  -0.31576395], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31709418 -0.4795363  -0.40374422 -0.36251375 -0.31523728 -0.32018083\n",
      " -0.62258583 -0.3485685  -0.32628638 -0.8127668  -0.31523085 -0.36037922\n",
      " -0.52362096 -0.31345457 -0.3176419  -0.32730424 -0.3554504  -0.3223729\n",
      " -0.33247644 -0.4090024  -0.83244264 -0.31619132 -0.59369135 -0.31732732\n",
      " -0.31453758 -0.3169914  -0.32194364 -0.32149288 -0.31426877 -0.4660869\n",
      " -0.49962115 -0.8896826 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37310365 -1.0535711  -0.32828093 -0.79938567 -0.32666153 -0.31475827\n",
      " -0.31737393 -0.40128636 -0.3200522  -0.5739203  -0.32104254 -0.32989824\n",
      " -0.31552443 -0.31386524 -0.31713176 -0.31527346 -0.3244434  -1.1590141\n",
      " -0.3141655  -0.3463489  -0.6049029  -0.3168707  -0.33066344 -0.32777834\n",
      " -0.36396658 -0.31358868 -0.46515754 -0.33144918 -0.36061063 -0.5354449\n",
      " -0.3368069  -0.33251312], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32602388 -0.31668925 -0.31678218 -0.5385964  -0.3157757  -0.33007178\n",
      " -0.31368372 -0.32692978 -0.31747532 -0.317857   -0.3192376  -0.31689698\n",
      " -0.36892995 -0.3211906  -0.35362503 -0.31523868 -0.44683322 -0.41249648\n",
      " -0.38071924 -0.37366366 -0.73992956 -0.33186328 -0.3694516  -0.595265\n",
      " -0.3380398  -0.39972007 -0.44079784 -0.38674316 -0.31339315 -0.31406903\n",
      " -0.37450644 -0.3200085 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34542027 -0.34014878 -0.3135736  -0.422188   -1.1169095  -0.32938477\n",
      " -0.380809   -0.56166124 -0.32130498 -0.3161291  -0.31877705 -1.3106549\n",
      " -0.37606096 -0.34573922 -0.33548117 -0.34389    -0.34242398 -0.3390653\n",
      " -0.31392202 -0.31355312 -0.35886255 -0.3595598  -0.38083833 -0.43555766\n",
      " -0.31440055 -0.31952986 -0.32488006 -0.46624956 -0.31490332 -0.31522527\n",
      " -0.35164312 -0.33247662], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37312844 -0.3135567  -0.59726375 -0.31939697 -0.32511744 -0.31459665\n",
      " -0.33453703 -0.37219322 -0.31650478 -0.99735016 -0.31530017 -0.31598082\n",
      " -0.54469675 -0.31870815 -0.38581386 -0.37941775 -0.39962646 -0.40302023\n",
      " -0.33676738 -0.39452004 -0.3158801  -0.5592348  -0.5866294  -0.32205248\n",
      " -0.32039803 -0.31639853 -0.3159479  -1.1893215  -0.31435215 -0.3683042\n",
      " -0.33061358 -0.3463398 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3156812  -0.7841368  -0.3654346  -0.34495813 -0.31748614 -0.3168317\n",
      " -0.41187924 -0.43355232 -0.31440806 -0.35154104 -0.37227646 -0.31388336\n",
      " -0.4062133  -0.4481442  -0.39979687 -0.319536   -0.35330257 -0.3416879\n",
      " -0.33478075 -0.35651115 -0.3248113  -0.37989572 -0.35345963 -0.5319583\n",
      " -0.3146422  -0.35917622 -0.323637   -0.32984954 -0.3185862  -0.32436264\n",
      " -1.1660589  -0.3714604 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7723342  -0.32392496 -0.42053813 -0.3301448  -0.3157145  -0.330574\n",
      " -0.53359544 -1.173027   -0.8777173  -0.32016316 -0.31690264 -0.31948698\n",
      " -0.33290875 -0.31987977 -0.5886745  -0.34053963 -0.52556014 -0.31483814\n",
      " -0.31430864 -0.3218735  -0.32455352 -0.3946339  -0.33536756 -0.31538677\n",
      " -0.68390775 -0.5453007  -0.33598012 -1.0322173  -0.31545442 -0.41013592\n",
      " -0.52838176 -0.324401  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3153173  -0.35722163 -0.34983513 -0.3400557  -0.3612241  -0.35530692\n",
      " -0.41664982 -0.33888635 -0.32929695 -0.3400354  -0.31802517 -0.3326593\n",
      " -0.34212783 -0.3519588  -0.3140206  -0.32929876 -0.31698433 -0.31818718\n",
      " -0.39454165 -0.31426615 -0.31498754 -1.0997359  -0.3312089  -0.33142006\n",
      " -0.3141761  -0.3462188  -0.314444   -0.38423693 -0.40065762 -0.31779703\n",
      " -0.3145595  -0.42341468], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31771913 -0.32110584 -0.3176853  -0.31677124 -0.3141654  -0.3313398\n",
      " -0.85759556 -0.31856364 -0.4748438  -0.3393255  -0.31594276 -0.39743337\n",
      " -0.3147702  -0.44985205 -0.31955022 -0.31692487 -0.3158614  -0.40065724\n",
      " -0.32191953 -0.31419605 -0.36163083 -0.3153     -0.31675285 -0.3220436\n",
      " -0.31951764 -0.6176424  -0.5190197  -0.36233255 -0.31713358 -0.6053603\n",
      " -0.31878442 -0.32303163], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3148747  -0.333305   -0.31552958 -0.3337912  -0.49572963 -0.34838483\n",
      " -0.38065088 -0.37599394 -0.9146635  -0.38654548 -0.34778237 -0.31377012\n",
      " -0.5404385  -0.31808937 -0.42525962 -0.40510836 -0.80565155 -0.32300952\n",
      " -0.3574087  -0.31406274 -0.33213022 -0.31419832 -0.3184175  -1.1000856\n",
      " -0.3134131  -0.31533244 -0.330768   -0.33345723 -0.46449256 -0.31781805\n",
      " -0.32253027 -0.33742824], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7472886  -0.533423   -0.31378293 -0.32560304 -0.3374132  -0.51399565\n",
      " -0.35125262 -0.31701168 -0.31816065 -0.31780034 -0.41336963 -0.33430222\n",
      " -0.31644925 -0.31652597 -0.36733225 -0.32359684 -0.34207568 -0.31796187\n",
      " -0.31753007 -0.33577263 -0.469517   -0.4751562  -0.31861758 -0.3179844\n",
      " -0.3219387  -0.3200387  -0.32538265 -0.545795   -0.32802266 -0.36562565\n",
      " -0.3200354  -0.40571827], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.47410357 -0.48083818 -0.4361264  -0.4790097  -0.33158943 -0.6739249\n",
      " -0.3180943  -0.32057193 -0.6397729  -0.37257177 -0.75346494 -0.32237232\n",
      " -0.32080403 -0.3152198  -0.31615934 -0.31465253 -0.65179074 -0.31466725\n",
      " -0.32522678 -0.32199702 -0.34300724 -0.3137283  -0.31345814 -0.9037821\n",
      " -0.93990684 -0.32785589 -0.31440055 -0.36184278 -0.31723255 -0.3215023\n",
      " -0.36619863 -0.33334687], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33275604 -0.3165461  -0.3855218  -0.31887567 -0.43763283 -0.31386113\n",
      " -0.38582927 -0.31474558 -0.3228274  -0.31499964 -0.34548688 -0.43498954\n",
      " -0.32168543 -0.31989622 -0.31804183 -0.31807894 -0.57346195 -0.33229047\n",
      " -0.31691408 -0.36185125 -0.47248897 -0.51896936 -0.5838184  -0.31353438\n",
      " -0.42067003 -0.3434949  -0.32330507 -0.31744578 -0.31959626 -0.34731424\n",
      " -0.31366298 -0.77450174], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31695065 -0.3207113  -0.32215703 -0.31931305 -0.32911128 -0.39425373\n",
      " -0.42079666 -0.36669847 -0.36415088 -0.320087   -0.38597816 -0.41134223\n",
      " -0.3166119  -0.47259152 -0.32297933 -0.43555635 -0.33961314 -0.6655202\n",
      " -0.31418622 -0.46038848 -0.34111255 -0.31450555 -0.31400388 -0.32008284\n",
      " -0.31540322 -0.31576508 -0.31347618 -0.31797487 -0.31438097 -0.32198977\n",
      " -0.32405972 -0.7797266 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4150663  -0.32579187 -0.32267082 -0.34039766 -0.34659135 -0.3146307\n",
      " -0.32039735 -0.3944894  -0.31811348 -0.31705093 -0.5266221  -0.3220086\n",
      " -0.3366344  -0.3158813  -0.32299763 -0.3265553  -0.31485432 -0.32071537\n",
      " -0.77576005 -0.31371316 -0.36933157 -0.32899648 -1.117238   -0.31453583\n",
      " -0.32279184 -0.3140725  -0.32857183 -0.3143701  -0.31612265 -0.33570278\n",
      " -0.38385615 -0.34625936], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3180466  -0.37261775 -0.51383287 -0.38932067 -0.31526938 -0.45204124\n",
      " -0.31740293 -0.3188809  -0.3168039  -0.3144016  -0.3258189  -0.31340727\n",
      " -0.31584576 -0.31960425 -0.34628955 -0.3306023  -0.33901173 -0.31907576\n",
      " -0.36066866 -0.32016748 -0.3242193  -0.50630724 -1.230198   -0.32975602\n",
      " -0.3541594  -0.38918918 -0.31699502 -0.48822826 -0.31527817 -0.3977504\n",
      " -0.31542376 -0.32697052], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33925852 -0.33357167 -0.35911554 -0.3171697  -0.31544825 -0.32998103\n",
      " -0.31921414 -0.43670815 -0.3155701  -0.32513946 -0.32294023 -0.7669245\n",
      " -0.36966842 -0.33446595 -0.9700043  -0.31427294 -0.32496938 -0.34152642\n",
      " -0.3167087  -0.37941563 -0.32558212 -0.45810965 -0.8942299  -0.3203449\n",
      " -0.32756263 -0.32461858 -0.3664325  -0.32338756 -0.31477177 -0.44196963\n",
      " -0.32307315 -0.3158667 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33305162 -0.31773716 -0.35947752 -0.31453338 -0.32978106 -0.3380409\n",
      " -0.3415554  -0.3169614  -0.3296775  -0.32289404 -0.32521155 -0.31342486\n",
      " -0.5358056  -0.3151959  -0.3151745  -0.31637725 -0.45045018 -0.92661756\n",
      " -0.32937148 -0.3145078  -1.1052117  -0.31476402 -0.8061967  -0.33724168\n",
      " -0.3566833  -0.3211267  -0.32329273 -1.2842686  -0.31638506 -0.614528\n",
      " -0.35396814 -0.33891517], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3383051  -0.5332318  -0.32997167 -0.31672123 -0.39134052 -0.6059052\n",
      " -0.31514367 -0.31531563 -0.31545863 -0.35093275 -0.31865573 -0.33257562\n",
      " -0.3216337  -0.31641418 -0.63761455 -0.31867826 -0.3441159  -0.32308194\n",
      " -0.31486914 -0.34805056 -0.31361133 -0.35639396 -0.31594893 -0.4305138\n",
      " -0.64329225 -0.32696924 -0.63591236 -0.76102185 -0.32952696 -0.56795245\n",
      " -0.90458465 -0.5080819 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43798354 -0.31428477 -0.33190247 -0.3138614  -0.3254425  -0.31834978\n",
      " -0.3157336  -0.31406432 -0.39745757 -0.3501772  -0.5941535  -0.4932639\n",
      " -0.326251   -0.3486644  -0.31448534 -0.47973636 -0.3140854  -0.3263718\n",
      " -0.3195759  -0.33905149 -0.36601824 -0.5103     -0.5347485  -0.3738283\n",
      " -0.38386863 -0.33329058 -0.46653655 -0.31354702 -0.31373483 -0.8809352\n",
      " -0.31570753 -0.35385492], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31528974 -0.32009616 -0.33052656 -0.34055233 -0.31934068 -0.35817987\n",
      " -0.56690013 -0.31453714 -0.447349   -0.45176798 -0.49972084 -0.32241645\n",
      " -0.35443527 -0.31503513 -0.53611517 -0.4024166  -0.32192755 -0.31677768\n",
      " -0.31336755 -0.4208854  -0.37783378 -0.3481051  -0.56104076 -0.38502234\n",
      " -0.32974267 -0.322607   -0.79524696 -0.31616038 -0.54863507 -0.8118412\n",
      " -1.0908746  -0.3165555 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3198336  -0.41682866 -0.336972   -0.32860017 -0.32091248 -0.3148507\n",
      " -0.34158793 -0.3154306  -0.31423151 -0.32842532 -0.37573868 -0.37501043\n",
      " -0.5294729  -0.3178733  -0.32799587 -0.5583152  -0.32204342 -0.31594\n",
      " -0.32243112 -0.314663   -0.32261893 -0.34277382 -0.43882555 -0.356267\n",
      " -0.33749136 -0.32993653 -0.39531067 -0.31989378 -0.33176234 -1.1986005\n",
      " -0.3189625  -0.33109352], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43412405 -0.3183568  -0.32559186 -0.31516647 -0.36507255 -0.34310994\n",
      " -0.6710501  -0.31927562 -0.31340188 -0.37817678 -0.31340143 -0.35841224\n",
      " -0.6797178  -0.47892708 -0.31340116 -0.31681466 -0.31435922 -0.3166038\n",
      " -0.49670115 -0.53576946 -0.4524796  -0.3154973  -0.36568272 -0.3177246\n",
      " -0.31830573 -0.35219848 -0.31395563 -0.31356263 -0.37672213 -0.3156698\n",
      " -0.3159015  -0.33823955], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31499153 -0.33256492 -0.77265745 -0.67040163 -0.33249268 -0.3662491\n",
      " -0.33055466 -0.34217823 -0.35126874 -0.31591234 -0.32078007 -0.37521654\n",
      " -0.31407598 -0.3219881  -0.32837167 -0.31912628 -0.38297307 -0.32641944\n",
      " -0.5078838  -0.47403812 -0.31593496 -0.3162213  -0.33263767 -0.40595233\n",
      " -0.33722022 -0.31395617 -0.31379625 -0.48125744 -0.36980143 -0.32012334\n",
      " -0.3257954  -0.35846323], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33064502 -0.32686976 -0.31556427 -0.8050399  -0.33910745 -0.32912183\n",
      " -0.42661723 -0.56419575 -0.33301026 -0.3161694  -0.3682934  -0.6231289\n",
      " -0.35117385 -0.31473252 -0.56969935 -0.31381908 -0.42216542 -0.32357207\n",
      " -0.3135065  -0.45375913 -0.6576363  -0.34803584 -0.38583925 -0.31407198\n",
      " -0.3171349  -0.32187536 -0.34358656 -1.1421461  -0.9035497  -0.31453547\n",
      " -0.31573433 -0.42471093], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32961047 -0.37107116 -0.32232517 -0.34235862 -0.3344437  -0.85655135\n",
      " -0.32376373 -0.34615928 -0.33118454 -0.3287123  -0.31806073 -0.46775067\n",
      " -0.3135433  -0.50722766 -0.33666694 -0.35621223 -0.3199691  -0.3151284\n",
      " -0.3434763  -0.49962854 -0.5288092  -0.31955323 -0.31367475 -0.33764693\n",
      " -0.44347805 -0.32892984 -0.32805264 -0.33316466 -0.3146965  -0.34210938\n",
      " -0.31689405 -0.32598895], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34931737 -0.53036165 -0.3159386  -0.35085544 -0.6214691  -0.3174037\n",
      " -0.3333882  -0.56711197 -0.31438088 -0.31595823 -0.3711322  -0.36880037\n",
      " -0.34408745 -0.3769199  -0.3151463  -0.31395093 -0.31616175 -0.4300609\n",
      " -0.3773554  -0.90021765 -0.5931901  -0.4147044  -0.480667   -0.32609838\n",
      " -0.37555808 -0.32226378 -0.31588748 -0.84336936 -0.33331364 -0.3450451\n",
      " -0.32947534 -0.33175883], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.39527422 -0.35660505 -0.31590694 -0.3149515  -0.52718997 -0.32648212\n",
      " -0.3143497  -0.3173552  -0.3143033  -0.31617114 -0.31629845 -0.32119465\n",
      " -0.5983258  -0.34287816 -0.33307385 -0.3134375  -0.6311972  -0.3235443\n",
      " -0.3133833  -0.3716547  -0.31552252 -0.31456506 -0.31477255 -0.36630574\n",
      " -0.32407653 -0.31340805 -0.53422517 -0.32136202 -0.40605605 -0.548767\n",
      " -0.39498577 -0.31687936], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33784738 -0.3245112  -0.31470746 -0.31848288 -0.32954428 -0.32554632\n",
      " -0.31431645 -1.0067799  -0.31408226 -0.39807448 -0.32535863 -0.3402358\n",
      " -0.35058928 -0.40517262 -0.50270295 -0.31484303 -0.3141777  -0.33834988\n",
      " -0.31351775 -0.32028252 -0.38166264 -0.48792255 -0.31724775 -0.34271824\n",
      " -0.6777818  -0.313958   -0.43387565 -0.31490967 -0.31551296 -0.8423892\n",
      " -0.31521952 -0.31380695], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31684133 -0.31679    -0.31565747 -0.3134375  -0.32577983 -0.32693717\n",
      " -0.3236591  -0.3322184  -0.37490934 -0.31406328 -0.36134258 -0.33705541\n",
      " -0.32504362 -0.38135087 -0.37817293 -0.3134924  -0.31648272 -0.3147579\n",
      " -0.41613868 -0.31439847 -0.32604676 -0.3151376  -0.32314345 -0.3547016\n",
      " -0.3653177  -0.31525102 -0.32661527 -0.40733242 -0.31456175 -0.32279176\n",
      " -0.33753544 -0.3401486 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5539595  -0.33352417 -0.31959003 -0.31624588 -0.35745972 -1.1349438\n",
      " -0.3146131  -0.3217559  -0.31654125 -0.62493044 -0.32928273 -0.31353873\n",
      " -0.34329873 -0.3193787  -0.31806707 -0.31620085 -0.31975472 -0.31979716\n",
      " -0.85052925 -0.31865972 -0.31606835 -0.31912178 -0.43772686 -0.40647328\n",
      " -0.3229725  -0.43092063 -0.3162536  -0.32077643 -0.6013653  -0.35168839\n",
      " -0.55958223 -0.3153926 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34680662 -0.46875817 -0.7468568  -0.32496428 -0.68253464 -0.37115934\n",
      " -0.3167623  -0.33384615 -0.31667373 -0.36024818 -0.46483982 -0.40979335\n",
      " -0.31530085 -0.31903547 -0.32347202 -0.35022187 -0.31624997 -1.0466815\n",
      " -0.44699746 -0.3294949  -0.3203975  -0.40640277 -0.31993517 -0.55797344\n",
      " -0.3135256  -0.39451128 -0.86876106 -0.3205548  -0.32695135 -0.31636664\n",
      " -0.3314924  -0.32955456], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31441206 -0.3570127  -0.3140201  -0.3208759  -0.32901862 -0.32085383\n",
      " -1.0232618  -0.5137799  -0.31460536 -0.45562154 -0.3782012  -0.31581604\n",
      " -0.63439804 -0.3921679  -0.8102829  -0.32738674 -0.31490237 -0.35035878\n",
      " -0.3169589  -0.9909059  -0.31355566 -0.3148157  -0.32375413 -0.36261207\n",
      " -0.3302754  -0.314028   -0.32302627 -1.2398992  -0.37829292 -0.32556894\n",
      " -0.3146052  -0.32227576], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31487817 -0.33885223 -0.31476584 -0.31343246 -0.8854039  -0.31963384\n",
      " -0.41391793 -0.36500138 -0.34637353 -0.5226103  -0.63515836 -0.31844765\n",
      " -0.9104058  -0.33947578 -0.31566182 -0.7823502  -0.31403872 -0.31954378\n",
      " -0.3134551  -1.1116824  -0.31458595 -0.425273   -0.31940305 -0.3815936\n",
      " -0.609946   -0.3260165  -0.31375095 -0.31788552 -0.321085   -0.3222615\n",
      " -0.3495438  -0.32353327], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3148103  -0.34137917 -0.8546264  -0.31419328 -0.6392465  -0.31789142\n",
      " -0.31573778 -0.35054553 -0.4177237  -0.39167637 -0.33161065 -0.37948054\n",
      " -0.31693745 -0.40161648 -0.3142105  -0.31569389 -0.33833882 -0.5988975\n",
      " -0.5132436  -0.86804235 -0.4197396  -0.38964263 -0.31413049 -0.3176006\n",
      " -0.43968877 -1.0331366  -0.4645564  -0.34747875 -0.32162684 -0.9604311\n",
      " -0.31348333 -0.31520772], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33750847 -0.33150548 -0.31557506 -0.31800896 -0.31459832 -0.34281638\n",
      " -0.31508237 -0.31605625 -0.3157804  -0.34152725 -0.5191487  -0.31599945\n",
      " -0.32202137 -0.31868345 -0.31621373 -0.33565232 -0.33519936 -0.3176815\n",
      " -0.53546643 -0.31517595 -0.36346444 -0.3447754  -0.44813842 -0.31761613\n",
      " -0.3943353  -0.32115686 -0.3172843  -0.32678062 -0.610422   -0.3605231\n",
      " -0.3236829  -0.3986805 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43447205 -0.31962284 -0.7805577  -1.0212243  -0.3284036  -0.39414185\n",
      " -0.35446486 -0.31442448 -0.31894726 -0.32427955 -0.4739054  -0.3326897\n",
      " -0.33941203 -0.3558303  -0.32305577 -0.3474325  -0.32210872 -0.3328573\n",
      " -0.36991903 -0.33946475 -0.31460997 -0.31547722 -0.32849202 -0.5521341\n",
      " -0.38122925 -0.3140342  -0.3143962  -0.3151162  -0.9068741  -0.59453595\n",
      " -0.3178732  -0.3255688 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31379172 -0.37260774 -0.34529367 -0.3146053  -0.31968495 -0.39364725\n",
      " -0.5059604  -0.3139863  -0.3466952  -0.32516015 -0.43862337 -0.31705624\n",
      " -0.3214749  -0.8389888  -0.37972474 -0.44678473 -0.31378615 -0.3654126\n",
      " -0.31610137 -0.71108127 -0.3175608  -0.36918595 -0.4146729  -0.3240037\n",
      " -0.34096438 -0.39127097 -0.5160967  -0.3134558  -0.32450768 -0.3179439\n",
      " -0.3246357  -0.39865348], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33414656 -0.31486496 -0.4230401  -0.3202402  -0.33866435 -0.34466994\n",
      " -0.3225579  -0.3154014  -0.31691435 -0.3257645  -0.4333484  -0.3151424\n",
      " -0.3175416  -0.5307006  -0.32701066 -0.39336446 -0.88133335 -0.43686172\n",
      " -0.3324778  -0.31350797 -0.31524962 -0.31429777 -0.32352152 -0.44402164\n",
      " -0.31334147 -0.48005447 -0.31429565 -0.3156074  -0.33168465 -0.42982668\n",
      " -0.31705928 -0.5926296 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3202343  -0.3402385  -0.31703764 -0.35661605 -0.32802    -0.7226783\n",
      " -0.31938764 -0.31553373 -0.31871882 -0.3362813  -0.38236135 -0.31635475\n",
      " -0.3311188  -0.38025308 -0.3160235  -0.3262419  -0.31449753 -0.31799865\n",
      " -0.4146059  -0.87854874 -0.3307418  -0.3153352  -0.37928283 -0.36055395\n",
      " -0.31436923 -0.44926804 -0.32722855 -0.34116077 -0.38379306 -0.3255663\n",
      " -0.31875107 -0.4214102 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38995627 -0.84791553 -0.31840917 -0.31484625 -0.31720555 -0.38095236\n",
      " -0.31716353 -0.33797976 -0.3148921  -0.35609686 -0.3189795  -0.32049873\n",
      " -0.31360087 -0.6743106  -0.31357133 -0.37136132 -0.3405861  -0.32185394\n",
      " -0.48560846 -0.31976184 -0.3145179  -0.55463594 -0.31355712 -0.56065094\n",
      " -0.34777546 -0.3298823  -0.31784648 -0.49060255 -0.34300208 -0.31402323\n",
      " -0.3647051  -0.31554425], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33328316 -0.9208373  -0.31441075 -0.6543223  -0.3447732  -0.3136541\n",
      " -0.816794   -0.31540793 -0.4873252  -0.3140274  -0.31389257 -0.45086187\n",
      " -0.33312526 -0.33075926 -0.32711887 -0.36120212 -0.315056   -0.41244638\n",
      " -0.4559848  -0.36754978 -0.3574729  -0.5455946  -0.32987544 -0.33497536\n",
      " -0.31461382 -0.39865506 -0.3814567  -0.33353603 -0.4510461  -0.35584015\n",
      " -0.33683506 -0.3551474 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31484458 -0.32280782 -0.36775365 -0.42646128 -0.98907393 -0.36103663\n",
      " -0.34353048 -0.32526857 -0.35392103 -0.37340823 -0.32537463 -0.51374394\n",
      " -0.32061207 -0.39092147 -0.31532913 -0.31999794 -0.35187563 -0.3159605\n",
      " -0.31491446 -0.4712893  -0.32028502 -0.32077593 -0.3432901  -0.31833252\n",
      " -0.31516683 -0.31704825 -0.3135513  -0.34145916 -0.3412277  -0.31356636\n",
      " -0.42442074 -0.3746135 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.44010162 -0.31481406 -0.31462625 -0.3253563  -0.43663636 -0.31339228\n",
      " -0.5192183  -0.31611493 -0.39417335 -0.36658454 -0.33609366 -0.569512\n",
      " -0.32778656 -0.7046697  -0.3707946  -0.31926247 -0.33618072 -0.31594816\n",
      " -0.31376263 -0.61207384 -0.36463794 -0.32283717 -0.3812807  -0.31835905\n",
      " -0.31481162 -0.3260743  -1.143971   -0.31819004 -0.627062   -0.31562114\n",
      " -0.3242642  -0.3268194 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31370062 -0.38112965 -0.3137785  -0.33195722 -0.5258856  -0.3144218\n",
      " -0.31646204 -0.34284362 -0.8747674  -0.3137201  -0.87494385 -0.42081606\n",
      " -0.4900518  -0.31830296 -0.32528466 -0.96492815 -0.31541434 -0.33596724\n",
      " -0.38866124 -0.31667432 -0.32318214 -0.33388126 -0.3141049  -0.31372917\n",
      " -0.40101156 -0.31392446 -0.31934494 -0.5017291  -0.4362977  -0.3274553\n",
      " -0.32140326 -0.31427363], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35995412 -0.49519193 -1.1211147  -0.32099923 -0.32173747 -0.34575516\n",
      " -0.49840686 -0.31327698 -0.31936148 -0.8392318  -0.4153527  -0.31945685\n",
      " -0.42273447 -0.3137884  -0.3387359  -0.72778106 -0.31329876 -0.31755385\n",
      " -0.3301297  -0.33614552 -0.3226318  -0.35455495 -0.31745517 -0.31473738\n",
      " -0.4922721  -0.32939455 -0.36572018 -0.36366716 -0.31547523 -0.36596277\n",
      " -0.3190795  -0.31357184], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31346503 -0.99146205 -0.3154834  -0.33623394 -0.31464228 -0.32014316\n",
      " -0.3810361  -0.31347948 -0.37836838 -0.3177423  -0.31370524 -0.31592312\n",
      " -0.31749076 -0.3329671  -0.33263502 -0.34040612 -0.31514952 -0.31994918\n",
      " -0.31510985 -0.3525297  -0.34810418 -0.40059566 -0.7744811  -0.34265858\n",
      " -0.7890775  -0.3324155  -0.372423   -0.31429243 -0.31946635 -0.31627473\n",
      " -0.31681624 -0.3224211 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35942525 -0.3488872  -0.67357445 -0.6936512  -0.33108652 -0.51176083\n",
      " -0.3444863  -0.38813406 -0.3534649  -0.3136108  -0.31660613 -0.3357043\n",
      " -0.38311824 -0.34003752 -0.32370126 -0.3148822  -0.31374067 -0.32418904\n",
      " -0.31579465 -0.32054216 -0.6567983  -0.31639904 -0.3445511  -0.38700378\n",
      " -0.31438515 -0.40624443 -0.31621486 -0.37891564 -0.33452117 -0.3246564\n",
      " -0.31426796 -0.6435246 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32725295 -0.3164491  -0.31904924 -0.447208   -0.32526228 -0.493393\n",
      " -0.33749774 -0.79103637 -0.34785646 -0.32498005 -0.31785437 -0.46778965\n",
      " -0.40617964 -0.31354624 -0.556412   -0.31609362 -0.8179834  -0.34267405\n",
      " -0.32274964 -0.81009233 -0.32783347 -0.31504488 -0.5629852  -0.3249238\n",
      " -0.35466424 -0.31520736 -0.5923754  -0.47168076 -0.31331027 -0.31655413\n",
      " -0.32013252 -0.31622702], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3178175  -0.33809137 -0.32564884 -0.31605253 -0.4914403  -0.3586717\n",
      " -0.33731374 -0.3137866  -0.31850454 -0.38711816 -0.3194448  -0.31550008\n",
      " -0.32011193 -0.31568024 -0.32515112 -0.31585637 -0.313794   -0.31372613\n",
      " -0.352659   -0.47996587 -0.31430584 -0.48738378 -0.3228766  -0.35591498\n",
      " -0.36558712 -0.31982556 -0.803764   -0.62839377 -0.31733298 -0.32417583\n",
      " -0.31953478 -0.31329685], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37145507 -0.31628707 -0.3240987  -0.32258344 -0.32713383 -0.31587097\n",
      " -0.31624207 -0.48361748 -0.31587332 -0.31458876 -0.91355187 -0.32442218\n",
      " -0.31546956 -0.31499824 -0.3865532  -0.31826714 -0.32518417 -0.33367258\n",
      " -0.43339568 -0.68705577 -0.6948075  -0.31617063 -0.31450588 -0.338283\n",
      " -0.3440014  -0.31614074 -0.31871492 -0.31519842 -0.33102393 -0.34276274\n",
      " -0.3155766  -0.31594327], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31337702 -0.32207105 -0.31397098 -0.42913592 -0.31418508 -0.34875044\n",
      " -0.69237787 -0.32748306 -0.35376364 -0.31347924 -0.3181132  -0.3153547\n",
      " -0.3682308  -0.31388763 -0.32867154 -0.9144124  -0.35699835 -0.44026867\n",
      " -0.35702038 -0.3173682  -0.3513652  -0.32872477 -0.3146736  -0.32652548\n",
      " -0.3161515  -0.33802345 -0.947901   -0.31416228 -0.31678843 -0.32645032\n",
      " -0.31333503 -0.42476293], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3247231  -0.31668344 -0.31549278 -0.43857664 -0.31597978 -0.3261161\n",
      " -0.39790928 -0.3224181  -0.59177107 -0.7550516  -0.3389526  -0.3148498\n",
      " -0.3455612  -0.33127338 -0.3184866  -0.3867915  -0.322558   -0.48255575\n",
      " -0.31397036 -0.61817527 -0.31953183 -0.313522   -0.3218219  -0.31791466\n",
      " -0.34229657 -0.327528   -0.31677914 -0.45668438 -0.31362742 -0.32472584\n",
      " -0.4046478  -0.32700405], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31622893 -0.31359118 -0.61545926 -0.3136309  -0.31708097 -0.337221\n",
      " -0.3597659  -0.31756884 -0.31429592 -0.32770213 -0.66751    -0.66096973\n",
      " -0.3486432  -0.32493976 -0.32636267 -0.3220598  -0.3406629  -0.31571832\n",
      " -0.3365417  -0.8537408  -0.32736441 -0.32122853 -0.31607234 -0.31617516\n",
      " -0.33441228 -0.36942977 -0.31808597 -1.0261562  -0.34605798 -0.33404592\n",
      " -0.31536442 -0.31838307], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31524634 -1.0921292  -0.3400221  -0.32550842 -0.31420547 -0.5120919\n",
      " -0.31575936 -0.3181708  -0.32584    -0.35561556 -0.35743105 -0.320851\n",
      " -0.3200786  -1.0955855  -0.3240924  -0.31367284 -0.51640725 -0.3179315\n",
      " -0.3160767  -0.41928282 -0.33395314 -0.33019158 -0.31419772 -0.32445037\n",
      " -0.31488895 -0.3546919  -0.318444   -0.32869437 -0.32811764 -0.4136313\n",
      " -0.31718853 -0.31439257], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3171755  -0.3164048  -0.5899407  -0.45652157 -0.32708958 -0.32288474\n",
      " -0.8205336  -0.3378789  -0.31737438 -0.3181981  -0.31541488 -0.33897698\n",
      " -0.3158216  -0.31452966 -0.3210499  -0.36552995 -0.31542122 -0.32667735\n",
      " -0.3184499  -0.31979033 -0.316512   -0.3247791  -0.33846903 -0.31842825\n",
      " -0.3185447  -0.31834415 -0.925531   -0.32111552 -0.7768692  -0.4836764\n",
      " -0.31344247 -0.31535748], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31432265 -0.33382934 -0.5114229  -0.32918733 -1.2566977  -0.31395844\n",
      " -0.35213175 -0.32155442 -0.32536283 -0.31857318 -0.34054217 -0.44341642\n",
      " -0.323256   -0.40350497 -0.8832903  -0.34905338 -0.46596158 -0.35033768\n",
      " -0.4927516  -0.41900092 -0.3468411  -0.31417125 -0.3167181  -0.31465\n",
      " -0.3238316  -0.31437454 -0.42183813 -0.32263    -0.31359842 -0.4218514\n",
      " -0.32582614 -0.3423972 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31387612 -0.3164717  -0.32064036 -0.31766412 -0.3175553  -0.31696326\n",
      " -0.3776524  -0.3323771  -0.35844663 -0.35537237 -0.31541792 -0.74121726\n",
      " -0.35259414 -0.34129748 -0.3200014  -0.31753674 -0.31361306 -0.3138938\n",
      " -0.34700516 -0.32842815 -0.5841794  -0.34676087 -0.32769278 -0.56598574\n",
      " -0.32932398 -0.31332353 -0.32263464 -0.31330872 -0.8341235  -0.31576943\n",
      " -0.998989   -0.34258562], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33805695 -0.3149745  -0.3720648  -0.39556038 -0.40939066 -0.9000609\n",
      " -0.346956   -0.31423673 -0.33369735 -0.43655854 -0.3159698  -0.33525383\n",
      " -0.46584174 -0.8308057  -0.33347565 -0.56577426 -0.31671533 -0.32159573\n",
      " -0.31341797 -0.33249688 -0.32442364 -0.5594456  -0.31496614 -0.3187294\n",
      " -0.31340656 -0.34328198 -0.72957325 -0.31751037 -0.73627865 -0.31842676\n",
      " -0.3133237  -0.9824472 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43462792 -0.3348722  -0.9519043  -0.31338826 -0.3707561  -0.32410723\n",
      " -0.3145415  -0.42897403 -0.33619052 -0.32178605 -0.33099055 -0.32300228\n",
      " -0.58325505 -0.31579414 -0.31403142 -0.4120018  -0.38097712 -0.33851704\n",
      " -0.31678706 -0.31416124 -0.31440473 -0.3249542  -0.32546306 -0.31488305\n",
      " -0.31684688 -0.32622194 -0.31352866 -0.4097275  -0.36256212 -0.3485828\n",
      " -0.34694323 -0.45979267], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31340352 -0.31563094 -0.3193841  -0.31525886 -0.411647   -0.3214559\n",
      " -0.31963247 -0.3144044  -0.42466775 -0.3342691  -0.3541154  -0.33671528\n",
      " -0.31665558 -0.313527   -0.34502837 -0.3137973  -0.3695063  -0.31643796\n",
      " -0.3259355  -0.32134628 -0.33968502 -0.36892813 -0.31913823 -0.31366733\n",
      " -0.73748887 -0.3196537  -0.31656253 -0.3170866  -0.43619177 -0.60207355\n",
      " -0.3183866  -0.4693131 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3380257  -0.32305813 -0.5225474  -0.32039526 -0.33539772 -0.38046986\n",
      " -0.55954814 -0.3315361  -0.3165536  -0.33912775 -0.365311   -0.47397888\n",
      " -0.320444   -0.31353927 -0.33786973 -0.33446997 -0.31361568 -0.38258693\n",
      " -0.5221646  -0.5601069  -0.48169342 -0.3256485  -0.3147226  -0.31596398\n",
      " -0.37088412 -0.31407487 -0.49459076 -0.34248245 -0.3343941  -0.31508636\n",
      " -0.32792106 -0.3133935 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4151437  -0.3137231  -0.32488987 -0.33582777 -0.32591814 -0.32980284\n",
      " -0.3214635  -0.31908938 -0.38766134 -0.31528077 -0.31467733 -0.32189724\n",
      " -0.31378388 -0.37832224 -0.61546844 -0.5251635  -0.35366386 -0.3284218\n",
      " -0.49279326 -0.31473878 -0.40280455 -0.4097481  -0.403688   -0.32840222\n",
      " -0.3640678  -0.324442   -0.31653118 -0.32889515 -1.0565552  -0.3147259\n",
      " -0.32644042 -0.3172316 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31584254 -0.37653694 -1.201364   -0.31435955 -0.31522015 -0.34693488\n",
      " -0.31399813 -0.32384753 -0.3138985  -0.3800498  -0.36269268 -0.31452417\n",
      " -0.3139836  -0.31961125 -0.34148932 -0.37352607 -0.8367008  -1.2392266\n",
      " -0.3677634  -0.3146823  -0.32056475 -0.33555686 -0.31519276 -0.31650165\n",
      " -0.31327987 -0.3139903  -0.34104764 -0.3182243  -1.2374808  -1.2013698\n",
      " -0.31468213 -0.4720257 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.353524   -0.7538508  -0.31553218 -0.31339568 -0.33026373 -0.44963795\n",
      " -0.37908497 -0.32526866 -0.42446315 -0.3194104  -0.31973013 -0.39138067\n",
      " -0.31573483 -0.3410846  -0.34694618 -0.31501275 -0.31522173 -0.31353343\n",
      " -0.34560212 -0.31343263 -0.34412447 -0.31571597 -1.2654877  -0.5055858\n",
      " -0.39161897 -0.3323907  -0.31653988 -0.32027152 -0.32668456 -0.31396773\n",
      " -0.52144146 -0.31392533], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31516683 -0.3204778  -0.42470813 -0.35652727 -0.3381434  -0.32776088\n",
      " -1.0589774  -0.3165329  -0.33986452 -0.319784   -0.33660293 -0.33164838\n",
      " -0.3148399  -0.31457925 -0.6077868  -0.69097614 -0.5157308  -0.3640326\n",
      " -0.37444758 -0.31702965 -0.3225528  -0.32502502 -0.33613282 -0.39476055\n",
      " -0.35583714 -0.34173778 -0.31507644 -0.36825907 -0.32145563 -0.3216405\n",
      " -0.3523486  -0.33282807], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33048475 -0.32102734 -0.3526868  -0.41661003 -0.3247555  -0.31761917\n",
      " -0.32765636 -0.3693515  -0.31391418 -0.45161188 -0.34733826 -0.36147138\n",
      " -0.31376326 -0.5615151  -0.31592634 -0.32896647 -0.31442425 -0.34035957\n",
      " -0.33053717 -0.31381646 -0.33195448 -0.31832212 -0.31564426 -0.37388057\n",
      " -0.31426144 -0.32817242 -0.31328562 -0.36179113 -0.34446275 -0.314925\n",
      " -0.32138267 -0.34681514], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3200727  -0.31433162 -0.3138445  -0.9663806  -0.3274809  -0.31416488\n",
      " -0.31394258 -0.52920145 -0.34088674 -0.3151957  -0.3139518  -0.3333472\n",
      " -0.33016092 -0.3156227  -0.31376585 -0.31496578 -0.3776528  -0.7671882\n",
      " -0.31687492 -0.31677046 -0.49403477 -0.31608564 -0.31382483 -0.31666824\n",
      " -0.32132182 -0.3161103  -0.3205562  -0.31881788 -0.31713516 -0.31602532\n",
      " -0.55800587 -0.32709894], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3380448  -0.4254759  -0.3524835  -0.3815924  -0.3911669  -0.37588367\n",
      " -0.3659679  -0.6691916  -0.31811053 -0.37043893 -0.32512587 -0.44617325\n",
      " -0.32685488 -0.34847268 -0.31721395 -0.35764316 -0.36599377 -0.32103676\n",
      " -0.34104958 -0.31968236 -0.31868666 -0.3169359  -0.31773144 -0.45760286\n",
      " -0.31457675 -0.3167942  -0.31571946 -0.32826754 -0.4837399  -0.33511794\n",
      " -0.40016207 -0.3159186 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32241455 -0.31403574 -0.31348908 -0.31471485 -0.45134008 -0.3147788\n",
      " -0.3614247  -0.74357855 -0.31444183 -0.4952829  -0.33091998 -0.85995245\n",
      " -0.31662908 -0.31987005 -0.47783357 -0.42074424 -0.31351626 -0.705775\n",
      " -0.32855183 -1.1321771  -0.31514734 -0.31571257 -0.31974798 -0.31364563\n",
      " -0.38126963 -0.3359282  -0.31603134 -0.3133968  -0.31346983 -0.3640636\n",
      " -0.35742903 -0.317361  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.561745   -0.3597337  -0.31371856 -0.44108653 -0.33153123 -0.31607294\n",
      " -0.31405595 -0.3198157  -0.31748495 -0.3321418  -0.46115482 -0.313985\n",
      " -0.3578469  -1.1702132  -0.31735963 -0.31715    -0.31361455 -0.31967714\n",
      " -0.3341364  -0.40924594 -0.31370506 -0.32334504 -0.49863365 -0.31738922\n",
      " -0.31704426 -0.31465036 -0.314366   -0.47057152 -0.31968477 -0.31958362\n",
      " -0.43434158 -0.31576988], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.314171   -0.31823775 -0.31665695 -0.31463453 -0.31332266 -0.33193618\n",
      " -0.32775548 -0.3163432  -0.3155822  -0.34668896 -0.3176657  -0.36838248\n",
      " -0.43167806 -1.0772971  -0.3741945  -0.36647043 -0.48436114 -0.5423191\n",
      " -0.31787747 -0.44967955 -1.1316365  -0.38022113 -0.3141036  -0.31357282\n",
      " -0.31585473 -0.84390515 -0.6852638  -0.48745114 -0.33588475 -0.3612908\n",
      " -0.34536263 -0.31983316], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33853954 -0.314115   -0.31434476 -0.33264947 -0.3135594  -0.5209329\n",
      " -1.1303378  -0.32078266 -0.6980117  -0.3277517  -0.31675512 -0.32227886\n",
      " -0.554464   -0.31764132 -0.31444216 -0.31479222 -0.39422125 -0.36415446\n",
      " -0.31467456 -0.31387413 -0.31776103 -0.46036276 -0.31888625 -0.3229506\n",
      " -0.347714   -0.3220567  -0.7184522  -0.55719966 -0.3773617  -0.36352825\n",
      " -0.31373963 -0.34508106], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37778157 -0.31656522 -0.3329783  -0.32783183 -0.31817505 -0.94025934\n",
      " -0.572319   -0.32021257 -0.3190179  -0.32279074 -0.33038178 -0.3656393\n",
      " -0.3255859  -0.31424236 -0.38257587 -0.32653037 -0.31368196 -0.3136339\n",
      " -0.3982361  -0.37691867 -0.35216337 -0.33039737 -0.32118133 -0.35048676\n",
      " -0.8306843  -0.33163625 -0.3484671  -0.32978535 -0.31399238 -0.31632233\n",
      " -0.6008512  -0.3284636 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32448646 -0.31560028 -0.3148954  -0.32196972 -0.64580226 -0.3192195\n",
      " -0.31685972 -0.3191176  -0.31674537 -0.31678852 -0.32675362 -0.32024747\n",
      " -0.31366944 -0.31382936 -0.47847843 -0.3611359  -0.39938742 -0.5314671\n",
      " -0.31395164 -0.3156352  -0.31401563 -0.32899606 -0.31489992 -0.32446328\n",
      " -0.3198262  -0.31327587 -0.44359335 -0.33249047 -0.38696212 -0.33315808\n",
      " -0.32410136 -0.37367326], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.46505368 -0.31547028 -0.32233086 -0.56891835 -0.31876373 -0.31918606\n",
      " -0.328104   -0.3142632  -0.33204597 -0.4989372  -0.48465323 -0.31348133\n",
      " -0.3161842  -0.39595467 -0.3390248  -0.32058388 -0.46094447 -0.31707793\n",
      " -0.47231722 -0.6272795  -0.31371978 -0.31519607 -0.33818692 -0.31354755\n",
      " -1.0731559  -0.32844207 -0.31727082 -0.75473046 -0.39255023 -0.3133737\n",
      " -0.5191558  -0.31983715], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31494048 -0.31403297 -0.31485304 -0.6111904  -0.31400633 -0.3201706\n",
      " -0.35574594 -0.3470001  -0.31701785 -0.31940383 -0.5943993  -0.31653953\n",
      " -0.31571865 -0.3388253  -0.36789575 -0.31641835 -0.32787254 -0.33433208\n",
      " -0.40671173 -0.32003438 -0.31354415 -0.31400257 -0.34445092 -0.31915548\n",
      " -0.34245452 -0.33170253 -0.673866   -0.3175495  -0.34282374 -0.3194849\n",
      " -0.52964437 -0.3323494 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3703735  -0.44061738 -0.48160806 -0.3181552  -0.42346236 -0.33485287\n",
      " -0.3148628  -0.37580794 -0.3585626  -0.33282167 -0.31553894 -0.32410395\n",
      " -0.32152367 -0.8825085  -0.3233211  -0.33899915 -0.8280005  -0.33058187\n",
      " -1.2986338  -0.31694978 -0.43521068 -0.31592068 -0.32456172 -0.31342557\n",
      " -0.32742497 -0.5373033  -0.3426302  -0.41074437 -0.322585   -0.3147488\n",
      " -0.32045618 -0.36991763], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33151865 -0.46237683 -0.4038704  -0.32827157 -0.31844592 -0.35416776\n",
      " -0.6750756  -0.31337032 -0.31633303 -0.314744   -0.31327575 -0.31687337\n",
      " -0.49306852 -0.31360373 -0.32715806 -0.39814356 -0.5687037  -0.31653917\n",
      " -0.31683725 -0.31386593 -0.32346666 -0.31759626 -0.3161358  -0.69789743\n",
      " -0.33406505 -0.50493896 -0.31421286 -0.31456247 -0.3182428  -0.31900704\n",
      " -0.32039094 -0.5880314 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32894236 -0.3190053  -0.31424254 -1.0002453  -0.31448394 -0.33242404\n",
      " -0.32201207 -0.53980094 -0.31755844 -0.31494933 -0.45258543 -0.3133758\n",
      " -0.44988734 -0.32283157 -0.31665227 -0.3264029  -0.48792768 -0.3340204\n",
      " -0.32121608 -0.32157975 -0.35566977 -0.31887022 -0.31356958 -0.3200825\n",
      " -0.32238302 -0.33868834 -0.31469154 -0.32919586 -0.31326896 -0.3316199\n",
      " -0.31491393 -0.34388968], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3524785  -0.31390616 -0.32595667 -0.3136729  -0.32985726 -0.32428893\n",
      " -0.31417158 -0.31512022 -0.3180847  -0.31597075 -0.31838697 -0.42862082\n",
      " -0.31684715 -0.5001025  -0.8207928  -0.315702   -0.45977995 -0.3160103\n",
      " -0.31376246 -1.2114911  -0.31415504 -0.34524488 -0.3416899  -0.34130493\n",
      " -0.33094695 -0.31412178 -0.31440023 -0.3316364  -0.50693655 -0.3152547\n",
      " -0.33016133 -0.31377527], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.0775015  -0.6133677  -0.36017334 -0.39254934 -0.35044023 -0.32800987\n",
      " -0.37669235 -0.31567937 -0.36269036 -1.1687568  -0.31355476 -0.31343853\n",
      " -0.39858985 -0.3177356  -0.403208   -0.33026278 -0.3577742  -0.31525782\n",
      " -0.3143835  -0.40872747 -0.32278252 -0.31459284 -0.35703647 -0.32342786\n",
      " -0.3149617  -0.3210966  -0.31618288 -1.1615237  -0.38559705 -1.2273097\n",
      " -0.31471458 -0.34396738], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32091603 -0.43619376 -0.31701586 -0.31818467 -0.32823706 -0.40659514\n",
      " -0.3134368  -0.32885656 -0.32616103 -0.31523997 -0.315574   -0.31751853\n",
      " -0.3643324  -0.3152513  -1.0148927  -0.5486662  -0.31347454 -0.3158101\n",
      " -0.3439895  -0.34746897 -0.54935503 -0.37035763 -0.33576155 -0.31620973\n",
      " -0.32634863 -0.3754788  -0.31651103 -0.3379375  -0.6550282  -0.31368843\n",
      " -0.3172071  -0.49758115], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31796855 -0.3134281  -0.32921085 -0.3141803  -0.48076445 -0.3258984\n",
      " -0.32589644 -0.37416053 -0.67953634 -0.5282593  -0.6024245  -0.45002964\n",
      " -0.31730172 -0.36458528 -0.3136541  -0.35321063 -0.32648352 -0.31684524\n",
      " -0.31403106 -1.0114301  -0.9722089  -0.32368878 -0.31409636 -0.31713444\n",
      " -0.31385112 -0.31454062 -0.49073473 -0.31488392 -0.4449556  -0.3159445\n",
      " -0.37562326 -0.31399763], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5141145  -0.31683862 -0.33986154 -0.32880807 -0.31660014 -0.31500068\n",
      " -0.36670658 -0.38574618 -0.32384425 -0.40873373 -0.31440273 -0.34572548\n",
      " -0.31609112 -0.31363675 -0.31553417 -0.46306205 -0.33615574 -0.31905323\n",
      " -0.45995247 -0.31445757 -0.3141002  -0.3381282  -0.3189918  -0.31540522\n",
      " -0.31422314 -0.31340605 -0.3180303  -0.39388025 -0.33416617 -0.31658286\n",
      " -0.3394509  -0.31516492], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32836995 -0.35134056 -0.32588655 -0.40119052 -0.34931368 -0.31676102\n",
      " -0.4487453  -0.33016458 -0.37884676 -0.31350058 -0.31349397 -0.3241505\n",
      " -0.3605956  -0.31580186 -0.31416672 -0.3155374  -0.52982485 -0.37627587\n",
      " -0.3619991  -0.3214175  -0.31656194 -0.31495047 -0.41073322 -0.35296047\n",
      " -0.3236509  -0.31994054 -0.33976954 -0.3162909  -0.31381097 -0.41239208\n",
      " -0.33239308 -0.33463556], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3149812  -0.31565407 -0.31457117 -0.31751373 -0.31400067 -0.31808242\n",
      " -0.31839314 -0.31333694 -0.3304858  -0.3135654  -0.5662688  -1.0301582\n",
      " -0.3143008  -0.39740092 -0.4472139  -0.3175862  -0.38367495 -0.84505725\n",
      " -0.32825184 -0.31346408 -0.34687227 -0.32122526 -0.44811207 -0.45131034\n",
      " -0.31510863 -0.3154286  -0.3135864  -0.3197666  -0.99749637 -0.32110593\n",
      " -0.47174534 -0.32462218], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31412336 -0.3212728  -0.31363258 -0.4102136  -0.3686133  -0.32279918\n",
      " -0.3135701  -0.60818166 -0.32312378 -0.35157418 -0.6734731  -0.31576484\n",
      " -0.32174057 -0.31373912 -0.3133007  -0.3171933  -0.3452075  -0.32487074\n",
      " -0.31406206 -0.34032935 -0.31469056 -0.3554271  -0.3207863  -0.48124534\n",
      " -0.31341067 -0.31891322 -0.31527868 -0.31633624 -0.3811233  -0.31335533\n",
      " -0.31866932 -0.34188157], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31546602 -0.481453   -0.35036188 -0.42107368 -0.33097908 -0.3133244\n",
      " -0.31875607 -0.32117087 -0.31623277 -0.3139439  -0.33897266 -0.33946016\n",
      " -0.34167957 -0.8829441  -0.31520718 -0.3259041  -0.32750195 -0.33383694\n",
      " -0.5009133  -0.3406701  -0.36511624 -0.3255352  -0.3142106  -0.3267615\n",
      " -0.3174366  -0.32584748 -0.33120343 -0.60678446 -0.91252756 -0.66262347\n",
      " -0.34260476 -0.6066871 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3454662  -0.31335038 -0.32898876 -0.34753406 -0.3172959  -0.3579728\n",
      " -0.36905754 -0.33251986 -0.96193516 -0.43180647 -0.40439403 -0.4211459\n",
      " -0.32757998 -0.94126177 -0.31402496 -0.31539583 -0.3206241  -0.56772363\n",
      " -0.3136657  -0.31476098 -0.3823241  -0.41396523 -0.31401834 -0.38866746\n",
      " -0.314689   -0.67439175 -0.347553   -0.35851318 -0.32000026 -0.31510836\n",
      " -0.4626153  -0.3164544 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4991632  -0.3739875  -0.31443137 -0.91491115 -0.89533186 -0.32670718\n",
      " -0.31783226 -0.31572938 -0.32742926 -1.2370901  -0.33371118 -0.32039022\n",
      " -0.37171683 -0.31376526 -0.32624653 -0.36074802 -0.32151675 -0.34072414\n",
      " -0.3364719  -0.3410339  -0.3286597  -0.31374025 -0.32511398 -0.3220385\n",
      " -0.31406718 -0.3160879  -1.0250206  -0.31622052 -0.32633772 -0.3225976\n",
      " -0.3410067  -0.5303737 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31783018 -0.31698433 -0.33790588 -0.33637828 -0.315582   -0.4639929\n",
      " -0.33343875 -0.3296704  -0.45284885 -0.31590644 -0.31670064 -0.3448037\n",
      " -0.32880577 -0.3364413  -0.32546514 -0.33705983 -0.317573   -0.3720128\n",
      " -0.3521377  -0.44604582 -0.34191564 -0.35472426 -0.3256793  -0.31774178\n",
      " -0.31472373 -0.34089625 -0.33096752 -0.32500038 -0.31482998 -0.31689352\n",
      " -0.31490976 -0.49898487], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37283084 -0.6009122  -0.3254095  -1.1139245  -0.31480342 -0.31449735\n",
      " -0.31760746 -0.3214559  -0.51272315 -0.35715708 -0.32152608 -0.31526685\n",
      " -0.3142745  -0.42562255 -0.31541452 -0.31636333 -0.4340031  -0.31539488\n",
      " -0.3139006  -0.3147003  -0.35085493 -0.31461513 -0.32052928 -0.3135492\n",
      " -0.31705552 -0.6757129  -0.35795248 -0.46580657 -0.33081508 -1.0569068\n",
      " -0.31973553 -0.31694108], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3140517  -0.3133446  -0.32063007 -0.32373697 -0.31725562 -0.4190213\n",
      " -0.32025334 -0.31915748 -0.3139862  -0.31331655 -0.31646168 -0.80867434\n",
      " -0.3144408  -0.31742698 -0.4530882  -0.31440875 -0.32070386 -0.35858932\n",
      " -0.3188261  -0.3283564  -0.41781232 -0.321177   -0.32243744 -0.32585627\n",
      " -0.31465638 -0.332864   -0.31710467 -0.40911752 -0.34584367 -0.3861142\n",
      " -0.31786644 -0.3162072 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31379122 -0.31348342 -0.31377342 -0.3157604  -0.41767886 -0.96141195\n",
      " -0.31985006 -0.7627826  -0.32538146 -0.3569393  -0.8406794  -0.49060488\n",
      " -0.3148787  -0.3162164  -0.31342462 -0.31570032 -0.31368938 -0.31600326\n",
      " -0.33856097 -0.7680272  -1.0178742  -0.3234608  -0.31627297 -0.34174344\n",
      " -0.6820741  -0.700778   -0.31738287 -0.31343386 -0.33566904 -0.31738618\n",
      " -0.3216361  -0.49201173], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.0140213  -0.31735528 -0.31628948 -0.3248673  -0.3153333  -0.35561195\n",
      " -0.32013088 -0.4808526  -0.31371194 -0.36845365 -0.31473565 -0.52752376\n",
      " -0.33502847 -0.43066823 -0.403651   -0.31367534 -0.31417698 -0.51012444\n",
      " -0.31848738 -0.31560156 -0.31710693 -0.31360775 -0.3327538  -0.3136959\n",
      " -0.31575224 -0.3459895  -0.31609973 -0.32641616 -0.31376916 -1.2349488\n",
      " -0.6474525  -0.43780643], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31748694 -0.3156253  -0.31634754 -0.32518813 -0.31456333 -0.3291087\n",
      " -0.35607514 -0.79820216 -0.3150981  -0.34599346 -0.31533277 -0.4760889\n",
      " -0.37039047 -0.31969568 -0.31503096 -0.38754594 -0.43988496 -0.38918126\n",
      " -0.32808173 -0.35222062 -0.3298133  -0.57685    -0.31610528 -0.3165609\n",
      " -0.39271516 -0.3174628  -0.31364694 -0.32819912 -0.32146144 -0.32609496\n",
      " -0.31424367 -0.31551313], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32148373 -0.385518   -0.31349447 -0.35327    -0.5656865  -0.31481928\n",
      " -0.32065716 -0.31488636 -0.42574623 -0.3137211  -0.38609338 -0.3263575\n",
      " -0.3136372  -0.31496125 -0.6454132  -0.33259818 -0.60482705 -0.34530357\n",
      " -0.47412062 -0.3216877  -0.52860475 -0.6566984  -0.34001014 -0.37964717\n",
      " -0.3569907  -0.3144198  -0.33917955 -0.31600925 -0.33208293 -0.32134783\n",
      " -0.3206768  -0.34498   ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3154025  -0.3369509  -0.32620147 -0.31506854 -0.45474467 -0.31372917\n",
      " -0.3195923  -0.31455916 -0.32275593 -0.32415515 -0.32889158 -0.31346914\n",
      " -0.3316191  -0.32176572 -0.31689075 -0.40278393 -0.31691375 -0.3171322\n",
      " -0.3248468  -0.3336755  -0.32400548 -0.3637346  -0.3295014  -0.31345206\n",
      " -0.31327027 -0.31896538 -0.3426594  -0.317472   -0.33758834 -0.40666175\n",
      " -0.31356087 -0.31710085], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3152877  -0.3132993  -0.3159605  -0.31568962 -0.3135234  -0.32294047\n",
      " -0.3354169  -0.33109123 -0.33419    -0.323242   -0.31337303 -0.315646\n",
      " -0.31952092 -0.31926057 -0.31610137 -0.3266635  -0.31395373 -0.3340489\n",
      " -0.5590948  -0.32510692 -0.3896453  -0.42783856 -0.4683304  -0.31355295\n",
      " -0.32044458 -0.31746385 -0.38293847 -0.8032104  -0.33521438 -0.3755625\n",
      " -0.35470077 -0.33598745], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31347278 -0.3161887  -0.31393525 -0.44546553 -0.31376404 -0.31439787\n",
      " -0.31523293 -0.3451631  -0.35528213 -0.313308   -0.31579733 -0.313472\n",
      " -0.3151449  -0.32412118 -0.3161052  -0.31451058 -0.3238533  -0.47908723\n",
      " -0.3147334  -0.31329903 -0.3143856  -0.3250377  -0.49923643 -0.32671458\n",
      " -0.32810003 -0.35332257 -0.51940143 -1.0027927  -0.32765722 -0.708212\n",
      " -0.4410718  -0.31371439], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31561077 -0.35611698 -0.44352695 -0.4203661  -0.5320258  -0.48676157\n",
      " -0.31334233 -0.37409666 -0.3223478  -0.31336597 -0.5379978  -0.31389683\n",
      " -0.74523175 -0.32332033 -0.65005285 -0.32017183 -0.31399754 -1.2631587\n",
      " -0.32913452 -0.48876786 -1.0856501  -0.31368625 -0.39425245 -0.33756232\n",
      " -0.32284728 -0.31371742 -0.4939162  -1.0114765  -0.31912732 -0.32187372\n",
      " -0.3156806  -0.31605533], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.42317837 -0.31333756 -0.3154148  -0.34315452 -0.8142586  -0.4783212\n",
      " -0.3261552  -0.32732067 -0.36551648 -0.32765386 -0.31692964 -0.3133272\n",
      " -0.3908094  -0.3457588  -0.3140254  -0.36521032 -0.31417257 -0.31748712\n",
      " -0.3161734  -0.32380167 -0.7638887  -0.31731856 -0.3183397  -0.31851354\n",
      " -0.324713   -0.95688534 -0.3148507  -0.31668717 -0.31356445 -0.34502363\n",
      " -0.31479898 -0.31636864], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3170359  -0.56939685 -0.32135892 -0.37200803 -0.31366786 -0.32116687\n",
      " -0.31334147 -0.314528   -0.84337306 -0.4783597  -0.6801692  -0.31699163\n",
      " -0.32635844 -0.32356155 -0.33128554 -0.34942713 -0.31390285 -0.32267687\n",
      " -0.34192437 -0.41379532 -0.3576309  -0.38601413 -0.31493247 -0.31487408\n",
      " -0.31552765 -0.31580803 -0.3289444  -0.32582682 -0.31658694 -0.31401947\n",
      " -0.35734656 -0.3139776 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31550556 -0.31423542 -0.32156152 -0.3135588  -0.3317843  -0.32496172\n",
      " -0.3174011  -0.31591773 -0.32394308 -0.4298211  -0.32159895 -0.32946074\n",
      " -0.31450328 -0.3162099  -0.31973958 -0.3164952  -0.314465   -0.3498336\n",
      " -0.31689075 -0.3453583  -0.3145314  -0.3831982  -0.31384373 -0.32581908\n",
      " -0.38501173 -0.31418535 -0.3175128  -0.31362605 -0.31487417 -0.45626545\n",
      " -0.31679305 -0.3406163 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31373015 -0.31377202 -0.31361192 -0.32929328 -0.69081813 -0.32176563\n",
      " -0.32484078 -0.5129353  -0.6285613  -0.3206339  -0.3154692  -0.9097351\n",
      " -0.3148867  -0.3141027  -0.38831148 -0.31992218 -1.1707938  -0.32246488\n",
      " -0.49222577 -0.32864565 -0.31406397 -0.34217244 -0.33319044 -0.3139424\n",
      " -0.31777778 -0.31907776 -0.3479557  -0.31624728 -0.34122393 -0.32520148\n",
      " -0.32404998 -0.3135419 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.96504486 -0.31357256 -0.4040206  -0.382165   -0.31391463 -0.34611753\n",
      " -0.3171097  -0.3137332  -0.32402283 -0.31412256 -0.33219472 -0.32919472\n",
      " -0.31910834 -0.31606373 -0.32341456 -0.31393388 -0.31830597 -0.3144346\n",
      " -0.3144184  -0.46397102 -0.31390244 -0.40561134 -0.31649166 -0.32793593\n",
      " -0.3137832  -0.3150695  -0.31421226 -0.32140905 -0.31445262 -0.38173726\n",
      " -0.3264473  -0.32916728], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6895246  -0.31498623 -0.3187762  -0.33051112 -0.39982605 -0.873109\n",
      " -0.32598996 -0.3488699  -0.32069182 -0.35797372 -0.33895287 -0.35068414\n",
      " -0.31599474 -0.31653005 -0.3136372  -0.34921086 -0.3142254  -0.31996545\n",
      " -0.36619174 -0.3281057  -0.32083872 -0.32078552 -0.87181115 -0.31372413\n",
      " -0.31921422 -0.32092312 -0.3260165  -0.39342678 -0.3161291  -0.32527563\n",
      " -0.32819858 -0.3642168 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3439148  -0.31384555 -0.5490293  -0.32011548 -0.31598276 -0.3269051\n",
      " -0.386926   -0.75785685 -0.3336626  -0.3298234  -0.31486008 -0.3145333\n",
      " -0.31398132 -0.3526486  -0.3147266  -0.3263784  -0.31460005 -0.31381264\n",
      " -0.31372586 -0.36158183 -0.31371865 -0.38793367 -0.3136208  -0.31461504\n",
      " -0.3426425  -0.31431925 -0.31550756 -0.31418937 -0.31360155 -0.35752627\n",
      " -0.33071944 -0.31954837], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3138832  -0.3218518  -0.3246252  -0.4040865  -0.31947702 -0.40087283\n",
      " -0.31389257 -0.3192319  -0.31733167 -0.31764328 -0.31653622 -0.31373137\n",
      " -0.31561363 -0.33436093 -0.31456003 -0.33416346 -0.324417   -0.36498317\n",
      " -0.32136306 -0.31511942 -0.31478488 -0.32530558 -0.5853727  -0.32375285\n",
      " -0.3263323  -0.3152444  -0.31922382 -0.3133936  -0.31711683 -0.3181551\n",
      " -0.31488097 -0.38806325], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.66151685 -0.47427583 -0.32544172 -0.4429054  -0.47517228 -0.7599118\n",
      " -0.3153681  -0.33201247 -0.315338   -0.31850168 -0.31376594 -0.33738425\n",
      " -0.36926812 -0.31555176 -0.31698036 -0.33275372 -0.39045817 -0.3137008\n",
      " -0.31326914 -0.33380663 -0.31428304 -0.3133906  -0.31424657 -0.33192393\n",
      " -0.33467916 -0.32447767 -0.32080385 -0.32931402 -0.33526245 -0.3195553\n",
      " -0.33220977 -0.31880835], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4082336  -0.31332824 -0.39531    -0.59246516 -0.31464142 -0.6050665\n",
      " -0.3148011  -0.31771913 -0.31550393 -0.92387825 -0.38559404 -0.39194432\n",
      " -0.50041765 -0.64842    -0.56940544 -0.351018   -0.325701   -0.31597266\n",
      " -0.47773117 -0.31397218 -0.31368685 -0.32198164 -0.37914094 -0.31795657\n",
      " -0.31662923 -0.31372884 -0.3349167  -0.32430306 -0.31761345 -0.3245324\n",
      " -0.34513575 -0.3403364 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3303668  -0.6002028  -0.31845763 -0.4066457  -0.31458718 -0.4755029\n",
      " -0.34715074 -0.36831394 -0.31647247 -0.31449944 -0.35317856 -0.31339088\n",
      " -0.33617833 -0.3162164  -0.3240305  -0.31363058 -0.6912699  -0.3564977\n",
      " -0.4142049  -0.31333554 -0.3215553  -0.31330654 -0.32756838 -0.36651513\n",
      " -0.3134592  -0.31374103 -0.3298695  -0.49507785 -0.3632539  -0.31425744\n",
      " -0.32724315 -0.31682658], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.44954404 -0.32032016 -0.31520468 -0.31576073 -0.3317762  -0.3186297\n",
      " -0.31336755 -0.313382   -0.3291015  -0.40878618 -0.42677492 -0.31382787\n",
      " -0.31330043 -0.31376952 -0.5298294  -0.3156133  -0.31359503 -0.3207932\n",
      " -0.41006932 -0.3438323  -0.31750524 -0.66500664 -0.36078212 -0.37793565\n",
      " -0.96110857 -0.31417203 -0.31407207 -0.3825336  -0.31385913 -0.36208656\n",
      " -0.3168516  -0.32620266], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35865635 -0.32806775 -0.39461082 -0.31362787 -1.0899541  -0.31776235\n",
      " -0.3133358  -0.60064745 -0.33492726 -0.32306987 -0.84366196 -0.31350774\n",
      " -0.31417927 -0.3211886  -0.3549031  -0.3156047  -0.34426093 -0.31534392\n",
      " -0.3978722  -0.61979806 -0.31814557 -0.31545714 -0.35543242 -0.32464486\n",
      " -0.31384677 -0.31790054 -0.928485   -0.31344306 -0.31416872 -0.34523055\n",
      " -0.31427556 -1.3073057 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3135784  -0.37427753 -0.3918143  -0.41002858 -0.3330584  -0.3810387\n",
      " -0.31774914 -0.88159984 -0.31430036 -0.33310074 -0.33055842 -0.37812606\n",
      " -0.33434856 -0.3907114  -0.31601515 -0.3162842  -0.31532478 -0.3142497\n",
      " -0.44139203 -0.32544678 -0.32896706 -0.32271975 -0.31406528 -0.35660595\n",
      " -0.31556112 -0.5639894  -0.32416835 -0.37175134 -0.3137846  -0.5921813\n",
      " -0.31542435 -0.31801337], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3150935  -0.3496902  -0.31460294 -0.31734434 -0.31401563 -0.31973577\n",
      " -0.31598336 -0.34261516 -0.3171828  -0.3617512  -0.46102688 -0.33205232\n",
      " -1.0992217  -0.31386334 -0.58214104 -0.3157785  -0.3170135  -0.33926147\n",
      " -0.34864464 -0.3204946  -0.31846908 -1.101327   -0.3205958  -0.31396434\n",
      " -0.3170724  -0.33436126 -0.3504603  -0.31530103 -0.34777868 -0.31541628\n",
      " -0.31609216 -0.34967422], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38950706 -0.314296   -0.33999687 -0.31426352 -0.32011208 -0.3336188\n",
      " -0.33381373 -0.31675136 -0.32480475 -0.31755123 -0.31773362 -0.31750202\n",
      " -0.33975452 -0.31427312 -0.39714843 -0.32348186 -0.34519932 -0.3415084\n",
      " -0.31512055 -0.35760647 -0.45773053 -0.3153913  -0.32549277 -0.31394607\n",
      " -0.3182392  -0.31357133 -0.37815416 -0.35138965 -0.33743718 -0.31355703\n",
      " -0.55311173 -0.9363749 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3172998  -0.34892243 -0.31628445 -0.44312888 -0.31740248 -0.31511688\n",
      " -0.349293   -0.31420624 -0.31711456 -0.31373495 -0.33802933 -0.3165021\n",
      " -0.31437227 -0.31487077 -0.31786695 -0.3756407  -0.31368676 -0.31373876\n",
      " -0.3527565  -0.31417385 -0.31603307 -0.36594617 -0.35689065 -0.3245841\n",
      " -0.31786764 -0.337229   -0.31440875 -0.3187191  -0.31745785 -0.31695038\n",
      " -0.33739448 -0.32815593], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31477907 -0.58265144 -0.31738442 -0.36290216 -0.31561068 -0.31778985\n",
      " -0.34002686 -0.31572077 -0.31736204 -0.38231045 -0.32655102 -0.31766248\n",
      " -0.31460756 -0.33152166 -0.6434734  -0.3256101  -0.32120684 -0.31611988\n",
      " -0.33791038 -0.3185427  -0.34670296 -0.31337476 -0.3481605  -0.31456143\n",
      " -0.3710447  -0.31444582 -0.32124376 -0.31387204 -1.1892481  -0.3147527\n",
      " -0.32106626 -0.8849623 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.42707184 -0.42906117 -0.3249667  -0.4560342  -0.5439133  -0.65888697\n",
      " -0.31356698 -0.3303309  -0.3144977  -0.31548947 -1.1434832  -1.0666962\n",
      " -0.35955006 -0.44814086 -0.33462933 -0.344401   -0.31345117 -0.31377342\n",
      " -0.3523259  -0.3135526  -0.34615833 -0.46863174 -0.31414217 -0.34845266\n",
      " -0.32602903 -1.2766185  -0.31388935 -0.31499475 -0.40522116 -0.3150506\n",
      " -0.36064297 -0.31343386], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33714297 -0.32435417 -0.34452802 -0.3153566  -0.32252517 -0.31373695\n",
      " -0.31491488 -0.31352672 -0.42771062 -0.35375893 -0.35265595 -0.31703097\n",
      " -0.3152438  -0.338982   -0.99597657 -0.31409183 -0.32391962 -0.33687583\n",
      " -0.31453878 -0.31388572 -0.31374547 -0.318131   -0.3145964  -0.33746338\n",
      " -0.31438777 -0.31459987 -0.3173992  -0.36528313 -0.34126613 -0.3236947\n",
      " -0.32530293 -0.31946948], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31666148 -0.31336135 -0.31329024 -0.32943246 -0.31681025 -0.33878502\n",
      " -0.6951391  -0.31510106 -0.3186187  -0.31391305 -0.31390357 -0.3144247\n",
      " -0.3188768  -0.31335646 -0.3179517  -0.38138214 -0.38362265 -0.31660536\n",
      " -0.37059942 -0.35128954 -0.3162709  -0.31392664 -0.3152731  -0.4182854\n",
      " -0.31644145 -0.3465907  -0.3550409  -0.3152766  -0.32782385 -0.31479082\n",
      " -0.31533784 -0.31332022], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31336728 -0.31860033 -0.31633294 -0.4278994  -0.38841584 -0.31634682\n",
      " -0.32108268 -0.315753   -0.32506678 -0.41231054 -0.31387675 -0.31831604\n",
      " -0.31702784 -0.55129695 -0.38225195 -0.3183723  -0.31484    -0.3170992\n",
      " -0.32206827 -0.34772503 -0.31862772 -0.9421866  -0.37880522 -0.4573142\n",
      " -0.3997712  -0.33771998 -0.31430864 -0.32615277 -0.3141592  -0.5436553\n",
      " -0.33350947 -0.57985723], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32001498 -0.33220986 -0.31460458 -0.31663063 -0.31437027 -0.32043973\n",
      " -0.36434963 -0.5170938  -0.31421086 -0.32288852 -0.3184448  -0.31339523\n",
      " -0.65633637 -0.31326765 -0.31328326 -0.31334662 -0.32669893 -0.3573876\n",
      " -0.32334417 -0.3151945  -0.3149121  -0.31404254 -0.31582567 -0.3671616\n",
      " -0.32380423 -0.42202377 -0.3169523  -0.3133954  -0.8294741  -0.3230178\n",
      " -0.3151482  -0.35750175], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31717083 -0.31349814 -0.3344669  -1.2815025  -0.6074958  -0.31901658\n",
      " -0.31885514 -0.31680423 -0.31407416 -0.3211137  -0.3136237  -0.31424838\n",
      " -0.33876166 -0.35535723 -0.3215264  -0.31837344 -0.5603501  -0.31985638\n",
      " -0.32750213 -0.31366587 -0.33527797 -0.31477636 -0.3158268  -0.31464446\n",
      " -0.31408888 -0.33171135 -0.31845286 -0.31705883 -0.43126068 -0.32183173\n",
      " -0.32267168 -0.33841905], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3166863  -0.3574107  -0.31969473 -0.3942362  -0.3144757  -0.34366468\n",
      " -0.31707054 -0.31391358 -0.32438883 -0.31424463 -0.32070214 -0.32095903\n",
      " -0.3450169  -0.3200354  -0.31460503 -0.31419945 -0.3188913  -0.3388902\n",
      " -0.35848203 -0.31686503 -0.76295686 -0.35897094 -0.3259978  -0.34320357\n",
      " -0.38322926 -0.31337625 -0.3133793  -0.36668923 -0.32317686 -0.33770996\n",
      " -0.37020054 -0.31723082], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33122665 -0.34503463 -0.3133969  -0.31693068 -0.39046746 -0.3190697\n",
      " -0.32245487 -0.7175479  -0.3147294  -0.33742705 -0.3133435  -0.31518945\n",
      " -0.31487748 -0.34175354 -0.3187651  -0.5910084  -0.32351202 -0.31555566\n",
      " -0.31485432 -0.32256573 -0.31458196 -0.44910526 -0.3281699  -0.35687923\n",
      " -0.31487453 -0.40479875 -0.65289354 -0.31578666 -0.32579654 -1.2471166\n",
      " -0.32414955 -0.39330798], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.672081   -0.3140747  -0.5057071  -0.34571156 -0.32820427 -0.3681847\n",
      " -0.31415612 -1.2179289  -0.51960516 -1.0883936  -0.31485713 -0.31397045\n",
      " -0.31821615 -0.32098186 -0.31330714 -0.31504226 -0.5627676  -0.65891117\n",
      " -0.37884593 -0.3287874  -0.31448942 -1.1837239  -0.31759417 -0.33228186\n",
      " -0.35690475 -0.31573945 -0.33488572 -0.31409845 -0.314614   -0.3140152\n",
      " -0.3146239  -0.31731787], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34184372 -0.34397835 -0.48113173 -0.76397574 -0.95033586 -0.31343246\n",
      " -0.33601087 -0.3133637  -0.32873935 -0.32345587 -0.3228532  -0.38459447\n",
      " -0.314096   -0.32450578 -0.41026115 -0.3137365  -0.57753813 -0.38280386\n",
      " -0.34930962 -0.4318968  -0.3196581  -0.3138311  -0.31652787 -0.9631629\n",
      " -0.31957617 -0.99979687 -0.48257118 -0.33571434 -0.31559616 -0.3954323\n",
      " -0.3665459  -0.3827802 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31648    -0.31652832 -0.3141952  -0.413093   -0.31614813 -0.3165157\n",
      " -0.43689308 -0.3147186  -0.44013372 -0.31603873 -0.43350542 -1.082542\n",
      " -0.3589105  -0.43475688 -0.4942826  -0.31358144 -0.35372597 -0.4135702\n",
      " -0.32603833 -0.32121903 -0.39043206 -0.31445733 -0.31353143 -0.31390426\n",
      " -0.3234802  -0.3140423  -0.3335585  -0.31962276 -0.31374034 -0.31426787\n",
      " -0.31552505 -0.34216964], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37483385 -0.31453773 -0.34063086 -0.31429592 -0.31478003 -0.32091707\n",
      " -0.31397602 -0.33683157 -0.5248693  -0.32477668 -0.31900808 -0.3382983\n",
      " -0.36638242 -0.4527084  -0.34354833 -0.37560868 -0.33511537 -0.31477246\n",
      " -0.31568104 -0.31376368 -0.3188868  -0.31808883 -0.31482118 -0.31404674\n",
      " -0.31760147 -0.47432858 -0.32846367 -0.5188625  -0.31474155 -0.31705737\n",
      " -0.48871794 -0.32205212], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31692737 -0.3136804  -0.32927725 -0.32328722 -0.3399358  -0.34861064\n",
      " -0.38727528 -0.31408712 -0.3518203  -0.35272658 -0.4950599  -0.3215133\n",
      " -0.31729972 -0.32118288 -0.35805964 -0.34980446 -0.31392813 -0.31745952\n",
      " -0.32298553 -0.41601562 -0.734161   -0.3241624  -0.3155714  -0.3189294\n",
      " -0.31474027 -0.31721717 -0.38490847 -0.5767497  -0.31341425 -0.3186611\n",
      " -0.40472478 -0.3133859 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.0899863  -0.3230002  -0.31347096 -0.326494   -0.31652737 -0.3263028\n",
      " -1.0910814  -0.3266425  -0.31368884 -0.3532098  -0.32246706 -0.34563512\n",
      " -0.3214177  -0.313642   -0.31413823 -0.36109468 -0.33356678 -0.3135717\n",
      " -0.3134863  -0.31572285 -0.37366545 -0.31380183 -0.32328343 -0.3640186\n",
      " -0.31689692 -0.36118573 -0.3147434  -0.32619715 -0.39630648 -0.3343244\n",
      " -0.3249555  -0.31416568], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4343208  -0.42665395 -0.31381804 -0.313982   -0.3203513  -0.34474018\n",
      " -0.39862666 -0.32582846 -0.3690142  -0.3141615  -0.608264   -0.31354764\n",
      " -0.3137568  -0.4716857  -0.3133589  -0.49122816 -0.32115436 -0.36235023\n",
      " -1.1470025  -0.3158429  -0.31910616 -0.32189724 -0.31534764 -0.52154183\n",
      " -0.33197063 -0.5294317  -1.0604582  -0.31638664 -0.35470185 -0.3158044\n",
      " -0.9616416  -0.37743598], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.52820396 -0.33387032 -0.45890325 -0.3685286  -0.3152999  -0.31430385\n",
      " -0.93472016 -0.3180695  -0.3240553  -0.31768745 -0.3148486  -0.3962877\n",
      " -0.4287415  -0.32149893 -0.313871   -0.35473245 -0.31468657 -0.33829778\n",
      " -0.53303933 -0.34107578 -0.31911588 -0.34472138 -0.31329006 -0.31364164\n",
      " -0.4397667  -0.31648088 -0.31723723 -0.4857424  -0.34791386 -0.41581154\n",
      " -0.5090965  -0.32118192], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.327608   -0.32533684 -0.32007062 -0.32391325 -0.6596828  -0.31423342\n",
      " -0.3133244  -0.32696632 -0.31382447 -0.3139159  -0.35263628 -0.46343267\n",
      " -0.43303317 -0.6695602  -0.31387785 -0.31371194 -0.314092   -0.31334686\n",
      " -0.33891788 -0.3142053  -0.42298096 -0.33476385 -0.31370682 -0.31342566\n",
      " -0.31952587 -0.553776   -0.31411013 -0.3296768  -0.32563877 -0.77387786\n",
      " -0.31636143 -0.5750171 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.328266   -0.3222717  -1.1714184  -0.32299745 -0.31415907 -0.31387663\n",
      " -0.33210242 -0.32020167 -0.31432873 -0.33196935 -0.6162382  -0.31774986\n",
      " -0.31944144 -0.31701595 -0.31747374 -0.31830963 -0.31657156 -0.31470224\n",
      " -0.31332353 -0.3273053  -0.41619104 -0.63745576 -0.31897905 -0.31522903\n",
      " -0.46740606 -0.31749606 -0.3201951  -0.9011478  -0.314918   -0.3135938\n",
      " -0.59340024 -0.32403213], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31392854 -0.33556983 -0.3319609  -0.31492168 -0.35496897 -0.3542346\n",
      " -0.31659007 -0.6712646  -0.31841713 -0.5142801  -0.3137891  -0.31566477\n",
      " -0.37134388 -0.3598374  -0.42984173 -0.32694378 -0.31467265 -0.31370515\n",
      " -0.595026   -0.3160203  -0.3165972  -0.3164259  -0.31517944 -0.35048002\n",
      " -0.43302867 -0.41204947 -0.31384522 -0.3135044  -0.31647873 -0.32470673\n",
      " -0.31506968 -0.31698468], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3937772  -0.33421493 -0.4286667  -0.31603134 -0.3132953  -0.339836\n",
      " -0.43156764 -0.39626485 -0.56022364 -0.32459366 -0.7777223  -0.3714474\n",
      " -0.31423438 -0.35584167 -0.34311914 -0.97506714 -0.3263293  -0.35602245\n",
      " -0.3144984  -0.32454827 -0.3820364  -0.31475514 -0.3492538  -0.3404509\n",
      " -0.314358   -0.482845   -1.1947378  -0.4004253  -0.33123022 -0.41375053\n",
      " -0.31421462 -0.40929922], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32297742 -0.39053652 -0.31458232 -0.45720422 -0.3159752  -0.38757145\n",
      " -0.31408226 -0.31361514 -0.31557974 -0.3153018  -0.32842025 -0.326559\n",
      " -0.38807675 -0.3751399  -0.31328318 -0.42912996 -0.31616062 -0.31447655\n",
      " -0.40361303 -0.3165153  -0.31340927 -0.34698662 -0.31759992 -0.44325227\n",
      " -0.35005987 -0.5195366  -0.31383476 -0.31747973 -0.4265299  -0.32658938\n",
      " -0.35870168 -0.33945125], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43963003 -0.31516266 -0.8280698  -0.6783921  -0.32523006 -0.315977\n",
      " -1.0904394  -0.3134956  -0.3241848  -0.65622556 -0.31960884 -0.31942505\n",
      " -0.55040103 -0.40288943 -0.37180603 -0.3148069  -0.32202873 -0.33292994\n",
      " -0.32178223 -0.31354702 -0.38220698 -0.3714446  -0.32823724 -0.39793843\n",
      " -0.3218682  -0.3381135  -0.31529617 -0.31783816 -0.3332406  -0.767372\n",
      " -0.31728896 -0.31862295], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.42375815 -0.33695328 -0.3635814  -0.3244528  -0.31342208 -0.31329572\n",
      " -0.44576025 -0.36268705 -0.5223299  -0.33289585 -0.50472426 -0.3158548\n",
      " -0.32718754 -0.31516492 -0.31733826 -0.32087797 -0.3186187  -1.1942303\n",
      " -0.5919599  -0.3295921  -0.32514274 -0.664581   -0.3133839  -0.32158676\n",
      " -0.3964922  -0.3134966  -0.31536373 -0.314354   -0.31785795 -0.3141298\n",
      " -0.32205206 -0.313411  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37687948 -0.91635257 -0.39379004 -0.31691775 -0.31662428 -0.33891565\n",
      " -0.3194428  -0.33482885 -0.31420076 -0.31385845 -0.31620565 -0.3637772\n",
      " -0.33390552 -0.31342322 -0.31340247 -0.32637057 -0.38106883 -0.33138755\n",
      " -0.31641477 -0.31362474 -0.3149551  -0.3170873  -0.7326081  -0.37798876\n",
      " -0.34950733 -1.1845009  -0.31783462 -0.50373715 -0.31692234 -0.38485566\n",
      " -0.47957918 -0.5360671 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3163916  -0.33529222 -0.63537645 -0.35449874 -0.31546384 -0.42856228\n",
      " -0.31357533 -0.33556956 -0.37959784 -0.34043682 -0.3491319  -0.33994123\n",
      " -0.738755   -0.34353262 -0.3953137  -0.32104713 -0.3133976  -1.208543\n",
      " -0.32702184 -0.3227776  -0.3199014  -0.3347136  -0.34375852 -0.5828352\n",
      " -0.32962367 -0.31497267 -0.31341362 -0.3259749  -0.45681536 -0.31349578\n",
      " -0.3351291  -0.7905624 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31582317 -0.31416237 -0.35454583 -0.31810775 -0.3919261  -0.48905674\n",
      " -0.44180962 -0.513718   -0.31618097 -0.35566935 -0.31802    -0.3223223\n",
      " -0.313342   -0.34002572 -0.31474036 -0.3293956  -0.51078993 -0.32816538\n",
      " -0.3203358  -0.34505868 -0.3475894  -0.36968473 -0.37477052 -0.32244408\n",
      " -0.3139734  -0.3180426  -0.31629342 -0.31441134 -0.5793957  -0.36497283\n",
      " -0.4695214  -0.33306965], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31949928 -0.324604   -0.3140443  -0.38765842 -1.1601883  -0.38713866\n",
      " -0.35835567 -0.3140166  -0.31553036 -0.3138445  -0.31486416 -0.33440334\n",
      " -0.31899762 -0.5504923  -0.31463495 -0.36621523 -0.33683327 -0.3711276\n",
      " -0.3263199  -0.34191808 -0.31913424 -0.5926588  -0.31654674 -0.34826225\n",
      " -0.3630764  -0.31438193 -0.35072812 -0.3603945  -0.31915304 -0.32289103\n",
      " -0.45240802 -0.3144198 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3135437  -0.31494987 -0.34225205 -0.32043663 -0.3137938  -0.47508475\n",
      " -0.3203533  -0.70885    -0.31363893 -0.33923548 -0.33154947 -0.31336868\n",
      " -0.31574467 -0.6755677  -0.47276214 -0.34179825 -0.3163107  -0.40715066\n",
      " -0.3594953  -0.34200972 -0.7295438  -0.3214559  -0.3140133  -0.3313891\n",
      " -0.3284822  -0.3159751  -0.3133766  -0.6833963  -0.5886623  -0.32059062\n",
      " -0.31788084 -0.3137811 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3161197  -0.31379992 -0.3229919  -0.31597093 -0.37466767 -0.32740134\n",
      " -0.31549573 -0.33459657 -0.31876683 -0.31334025 -0.31621903 -0.3159132\n",
      " -0.32357776 -0.31416968 -0.32688284 -0.3605203  -0.31546634 -0.37395018\n",
      " -0.33483908 -0.3149878  -0.379071   -0.322518   -0.9734441  -0.42636788\n",
      " -0.32093912 -0.7690482  -0.31443956 -0.91364837 -0.32390928 -0.35720906\n",
      " -0.31360096 -0.34988177], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33874252 -0.3135264  -0.3169399  -0.31578812 -0.40962908 -0.31452703\n",
      " -0.31379694 -0.31668302 -0.31497118 -0.38494277 -0.32271224 -0.31374225\n",
      " -0.35629746 -0.31564286 -0.3173112  -0.32990277 -0.34645143 -0.32852978\n",
      " -0.6101973  -0.36147013 -0.733524   -0.33576453 -0.6410015  -0.33139047\n",
      " -0.3146944  -0.36381382 -0.34818774 -0.31439376 -0.3210039  -0.33720416\n",
      " -0.31429636 -0.313671  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4310125  -0.3676622  -0.31397802 -0.3138567  -0.3287361  -1.2049742\n",
      " -0.31872973 -0.3157205  -0.3139358  -0.34774297 -0.33565778 -0.3275671\n",
      " -0.45253995 -0.31645265 -0.6326386  -0.32735324 -0.31961125 -0.31466463\n",
      " -0.31361854 -0.3290358  -0.31338993 -0.31848216 -0.31515378 -0.31653187\n",
      " -0.36404362 -0.31368616 -0.43436342 -0.5164133  -0.3148486  -0.3173689\n",
      " -0.3196605  -0.50912637], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31759018 -0.32006103 -0.31351155 -0.39718834 -0.3223034  -0.33952093\n",
      " -0.31363127 -0.31793237 -0.33404857 -0.31416827 -0.3152705  -0.64994264\n",
      " -0.34137356 -0.43307444 -0.31963575 -0.3232579  -0.31403017 -0.3157371\n",
      " -0.3141849  -0.31399387 -0.31407842 -0.35498148 -0.31812474 -0.38418216\n",
      " -0.9452254  -0.32299736 -0.87846416 -0.3206849  -1.2960222  -0.31446952\n",
      " -0.34096456 -0.3582573 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.44460034 -0.44230887 -0.31550416 -0.34771383 -0.31333023 -0.39611086\n",
      " -0.31587854 -0.32731354 -0.32795936 -0.43665376 -1.1949444  -0.3139317\n",
      " -0.3134619  -0.31436175 -0.31605905 -0.32464442 -0.3141433  -0.3132897\n",
      " -0.34171438 -0.4509189  -0.54974824 -0.31439012 -0.3138123  -0.3134238\n",
      " -0.3133028  -0.31971282 -0.3162701  -0.31418046 -0.31439385 -0.38972458\n",
      " -0.5904382  -0.31356156], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31962934 -0.32412118 -0.3289378  -0.3150592  -0.31434518 -0.3559119\n",
      " -0.33490655 -0.38494357 -0.3520243  -0.31440318 -0.3261366  -0.32283673\n",
      " -0.3671867  -0.31446192 -0.5566269  -0.4515922  -0.31506905 -0.49803412\n",
      " -0.36286643 -0.31466323 -0.322136   -0.31831795 -0.42499226 -0.319966\n",
      " -0.31665894 -0.56888586 -0.48561662 -0.77729064 -0.3132729  -0.32304353\n",
      " -0.31547236 -0.3158042 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.1964669  -0.3144353  -1.251199   -0.32933676 -0.39859593 -0.31333485\n",
      " -0.31330034 -0.35313073 -0.31349048 -0.38326502 -0.3516037  -0.33369583\n",
      " -0.31949106 -0.31447577 -0.3178     -0.33175045 -0.31331778 -0.70969886\n",
      " -0.3388698  -0.3137722  -0.9448962  -0.31503773 -0.31575406 -0.3163622\n",
      " -0.31808624 -0.37324083 -0.3999719  -0.3206249  -0.3224175  -0.42607647\n",
      " -0.49348232 -0.31694266], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33102155 -0.35154322 -0.31465203 -0.31329024 -0.31622052 -0.31364363\n",
      " -0.33869547 -0.31766438 -0.31525797 -0.32162184 -0.31366125 -0.31377465\n",
      " -0.37494752 -0.5473118  -0.31409672 -0.3623581  -0.42110434 -0.3133209\n",
      " -0.3860339  -0.31409478 -0.3148151  -0.3134268  -0.31355476 -0.41132745\n",
      " -0.61178696 -0.32161278 -0.6889871  -0.31383187 -0.35192695 -0.31407094\n",
      " -0.3137655  -0.31519145], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3829045  -0.41127294 -0.31373477 -0.34572986 -0.3293107  -0.3151243\n",
      " -0.3138196  -0.33064955 -0.721557   -0.4528682  -0.31412736 -0.33106178\n",
      " -0.34213352 -0.3137008  -0.31333426 -0.3143701  -0.31973794 -0.31490454\n",
      " -0.32349512 -0.33065838 -0.318594   -0.31339967 -1.0926812  -0.31716084\n",
      " -0.35195437 -0.35795173 -0.37730914 -0.31364223 -0.31382516 -0.39788336\n",
      " -0.33142683 -0.3172961 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4508492  -0.69842887 -0.33639157 -0.32650793 -0.31787312 -0.3157317\n",
      " -0.324741   -0.3163636  -1.0977387  -0.31587368 -0.32120538 -0.8637185\n",
      " -0.36877036 -0.34244418 -0.3148606  -0.32822824 -1.1654875  -0.43200964\n",
      " -0.80934465 -0.39608535 -0.31412065 -0.3334239  -0.9579197  -0.3135789\n",
      " -0.33334568 -0.31506506 -0.31400013 -0.35715127 -0.3974401  -0.34740275\n",
      " -0.31493473 -0.31400388], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4347088  -0.3380011  -0.3236749  -0.31476974 -0.32345906 -1.0334889\n",
      " -0.3405543  -0.39123607 -0.32670057 -0.34851542 -0.31420574 -0.40551472\n",
      " -0.31882107 -0.86367416 -0.32022953 -0.3199175  -0.31386498 -0.5857781\n",
      " -0.31459597 -0.6614605  -0.333304   -1.1993402  -0.4403698  -0.6142311\n",
      " -0.55503285 -0.3280474  -0.539698   -0.3266518  -0.32686383 -0.31613708\n",
      " -0.35299414 -0.31348795], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31347463 -0.39972326 -0.3443976  -0.32252067 -0.34280336 -0.31380793\n",
      " -0.3160614  -0.32526365 -0.319552   -0.3873099  -0.34227997 -0.5394767\n",
      " -0.31339926 -0.33730727 -0.3568113  -1.1609036  -0.31852934 -0.31376427\n",
      " -0.36432603 -0.31334132 -0.3336649  -1.2295862  -0.31411353 -0.3165482\n",
      " -0.32979795 -0.31342068 -0.32030925 -0.40519726 -0.40281802 -0.3696158\n",
      " -0.3163187  -0.3461474 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32091022 -0.5570521  -0.5146136  -0.47948554 -0.3166719  -0.31472722\n",
      " -0.31328988 -0.31733912 -0.44590503 -1.1162837  -0.35663307 -0.33628768\n",
      " -0.33570713 -0.31856072 -0.3133391  -0.31593084 -0.31631166 -0.33512467\n",
      " -0.3133915  -0.5697873  -0.3158629  -0.35578722 -0.7018969  -0.3416834\n",
      " -0.3539253  -0.31596503 -0.7165869  -0.40636435 -0.33436707 -0.4177774\n",
      " -0.32929474 -0.31331027], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31370366 -0.47765237 -0.3148098  -0.32298744 -0.31492594 -0.31697166\n",
      " -0.31409377 -0.31386507 -0.31515926 -0.34317195 -0.31449264 -0.31373256\n",
      " -0.32865715 -0.3197454  -0.80176044 -0.31331402 -0.31589288 -0.4384071\n",
      " -0.318661   -0.41942242 -0.3201976  -0.3139544  -0.31711352 -0.39187688\n",
      " -0.31375277 -0.32714605 -0.31333563 -0.6502711  -0.31474227 -0.3728903\n",
      " -0.37340018 -0.33566254], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31522718 -0.63099134 -0.34912947 -0.32182568 -0.35779136 -0.4419923\n",
      " -0.33215803 -0.31491837 -0.41095334 -0.31461468 -0.31654075 -0.31373668\n",
      " -0.3150694  -0.31962043 -0.31717142 -0.31361088 -0.3137149  -0.32298976\n",
      " -0.39058477 -0.3161709  -0.34990394 -0.42321068 -0.33567047 -0.37110695\n",
      " -0.3701365  -0.3180722  -0.3633766  -0.3132906  -0.31395042 -0.32934403\n",
      " -0.31559807 -0.32351083], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3136309  -0.41208217 -0.3427745  -0.35672522 -0.31465262 -0.3329202\n",
      " -0.31797487 -0.32936463 -0.32579386 -0.32420653 -0.32132968 -1.0013103\n",
      " -0.3218612  -0.33309025 -0.40010703 -0.31654075 -0.31446725 -0.4080027\n",
      " -0.31475514 -0.31393892 -0.3137966  -0.31343558 -0.3142031  -0.3152367\n",
      " -0.3157518  -0.31333032 -0.6557929  -0.3144588  -0.595762   -0.31330138\n",
      " -0.31764287 -0.33789957], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33306485 -0.31440753 -0.36688814 -0.3284843  -0.33277965 -0.32392892\n",
      " -0.3140138  -0.37070385 -0.3444717  -0.34107137 -0.4234441  -0.31589392\n",
      " -0.47409153 -0.38188872 -0.35479534 -0.4677478  -0.33668992 -0.3138608\n",
      " -0.31564972 -0.3826192  -0.4059034  -0.34971657 -0.3400517  -0.34417897\n",
      " -0.316435   -0.3144582  -0.31384695 -0.3209027  -0.37026978 -0.31438038\n",
      " -0.32273635 -0.31420782], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3326609  -0.32038972 -0.3219038  -0.3242267  -0.31580144 -0.31466812\n",
      " -0.32158944 -0.31444234 -0.34697643 -0.33226696 -0.31392184 -0.31565243\n",
      " -0.34120747 -0.45145214 -0.31831604 -0.31390113 -0.31581065 -0.4744172\n",
      " -0.31489974 -0.3161802  -0.3141009  -0.31406474 -0.3136906  -0.31800064\n",
      " -0.3287088  -0.862551   -0.4151286  -0.3255285  -0.31343043 -0.31341302\n",
      " -0.3203064  -0.31406188], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31532112 -0.3259807  -0.32328066 -0.3160893  -0.31370166 -0.31337842\n",
      " -0.316986   -0.31752235 -0.5957544  -0.3200012  -0.32581693 -0.4245767\n",
      " -0.3417414  -0.41160023 -0.3426667  -0.5712264  -0.3665581  -0.32065618\n",
      " -0.32580358 -0.36210102 -0.3285247  -0.33024445 -0.31439272 -0.3200328\n",
      " -0.3430296  -0.5949251  -0.65294206 -0.9108379  -0.9051714  -0.3282011\n",
      " -0.313771   -0.32293746], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31335732 -0.31741613 -0.48772448 -0.40733176 -0.32140827 -0.38440853\n",
      " -0.3196007  -0.3133793  -0.34920874 -0.31666407 -0.38790822 -0.31364453\n",
      " -0.3183763  -0.321392   -0.38129836 -0.4008661  -0.31447768 -0.36778557\n",
      " -0.31332466 -0.6751678  -1.111501   -0.3171894  -0.31716058 -0.33650124\n",
      " -0.3401328  -0.316127   -0.3250058  -0.31471512 -0.31719193 -0.31326914\n",
      " -0.32377872 -0.31803212], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.46811575 -0.31349415 -0.47863644 -0.34060186 -0.33468205 -0.31584385\n",
      " -0.3203307  -1.2919258  -0.65309733 -0.31364816 -0.31342086 -0.3133725\n",
      " -0.87302744 -0.3172071  -0.31896192 -0.3175416  -0.31472033 -0.3140201\n",
      " -0.31363326 -0.34660214 -0.31334686 -0.34668642 -0.3139734  -0.42336854\n",
      " -0.3134125  -0.31682804 -0.35639137 -1.0441594  -0.31568763 -0.34658927\n",
      " -0.3875483  -0.31545147], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31333554 -0.3449095  -0.6267889  -0.3135649  -0.3449198  -0.3147889\n",
      " -0.31775045 -0.31644145 -0.3193722  -0.3134281  -0.31568807 -0.50953823\n",
      " -0.7243897  -0.31329966 -0.34290048 -0.31505907 -0.5289531  -0.31352028\n",
      " -0.73106045 -0.31614006 -0.3190957  -0.31554905 -0.3151964  -0.31677333\n",
      " -0.31369644 -0.31336963 -0.34217483 -0.34636223 -0.31420052 -0.33014333\n",
      " -0.37247583 -0.51144004], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.58859634 -0.32329896 -0.4049899  -0.3143203  -0.31345433 -0.36170372\n",
      " -0.3794613  -0.31480014 -0.5102719  -0.31465864 -0.38338625 -0.4408911\n",
      " -0.313629   -0.38906404 -0.33211347 -0.31540462 -0.3135876  -0.32545352\n",
      " -0.31899813 -0.31341955 -0.35670185 -0.3236736  -0.36240515 -0.35515475\n",
      " -0.31481743 -0.31335872 -0.31947374 -0.33327323 -0.3967012  -0.34000233\n",
      " -0.3237782  -0.907145  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32226038 -0.31332615 -0.3145342  -0.34423134 -0.31890377 -0.33432066\n",
      " -0.32178319 -0.3292879  -0.32283545 -0.41095406 -0.3226236  -0.31793895\n",
      " -0.3338302  -0.32042018 -0.31388265 -0.5574199  -0.3136453  -0.51910853\n",
      " -0.34932998 -0.3132965  -0.31376708 -0.32877874 -0.564186   -0.40991536\n",
      " -0.991591   -0.31871074 -0.3206826  -0.38177064 -0.31449023 -0.31428993\n",
      " -0.32297716 -0.36649117], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.47731096 -0.74104667 -0.31486443 -0.3183188  -0.3365496  -0.75299865\n",
      " -0.3170861  -0.31363824 -0.3139323  -0.31679365 -0.31381628 -0.73958117\n",
      " -0.31326723 -0.3234042  -0.42141443 -0.3308228  -0.363517   -0.3133272\n",
      " -0.31449988 -0.31364024 -0.35731053 -0.31354895 -0.313359   -0.32194674\n",
      " -0.31507975 -0.31413564 -0.3263244  -0.3134089  -0.32010326 -0.5281477\n",
      " -0.31836626 -0.34528312], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37119249 -0.49619287 -0.33180597 -0.31710535 -0.3471465  -0.622524\n",
      " -0.33203554 -0.47290984 -0.31483155 -0.31451312 -0.3133379  -0.31460702\n",
      " -0.34092903 -0.31559086 -0.36143526 -0.32369024 -0.36941636 -1.0299847\n",
      " -0.31373754 -0.3532612  -0.31407928 -0.5389546  -0.3136148  -0.3424076\n",
      " -0.31338033 -0.31413266 -0.62776846 -0.31672043 -0.31384894 -0.31369758\n",
      " -0.3139864  -0.31413546], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3151642  -0.36276227 -0.4076476  -0.3449556  -0.31387603 -0.319461\n",
      " -0.45280105 -0.32945502 -0.3139763  -0.3177973  -0.41160458 -0.3761\n",
      " -0.31393752 -0.3153805  -0.32148242 -0.33545816 -0.34726918 -0.34875464\n",
      " -0.33205795 -0.31535208 -0.3460543  -0.3151424  -0.7617847  -0.31693953\n",
      " -0.7642259  -0.32916608 -0.33168474 -0.3135755  -0.32925177 -0.32960412\n",
      " -0.3143619  -0.36192042], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32759225 -0.31604037 -0.31406805 -0.3229417  -0.31458822 -0.32265657\n",
      " -0.31460223 -0.35736158 -0.37081146 -0.3734756  -0.35195798 -0.31347662\n",
      " -0.3204797  -0.3998067  -0.44076544 -0.3139902  -0.31678516 -0.35794464\n",
      " -0.7694032  -0.3133195  -0.35804838 -0.3135505  -0.31406885 -0.3184572\n",
      " -0.32011607 -0.31714877 -0.36654356 -0.31418562 -0.31336552 -0.41758582\n",
      " -0.31566685 -0.4680641 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3811483  -0.35823795 -0.32425877 -0.31933895 -0.31333888 -0.3216144\n",
      " -0.31467125 -0.31347734 -0.32870752 -0.34063637 -0.3853449  -0.4419592\n",
      " -0.32375595 -0.31466323 -0.33913428 -0.3178649  -0.31391907 -0.31436905\n",
      " -0.3151872  -0.3912379  -0.8799615  -0.47634444 -0.3186136  -0.3137756\n",
      " -0.32524616 -0.31617463 -0.32361037 -0.31352273 -0.47390395 -0.31571895\n",
      " -0.31855777 -0.36332843], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32626942 -0.5148823  -0.33146176 -0.31934112 -0.31385922 -0.3539418\n",
      " -0.31998244 -0.34225    -0.39316574 -0.3606937  -0.32780573 -0.3145381\n",
      " -0.3147502  -0.34279016 -0.32200152 -0.32731223 -0.32423773 -0.4173556\n",
      " -0.3679697  -0.33006802 -0.31483963 -0.31601343 -0.34347105 -0.3535388\n",
      " -0.3161808  -0.3162781  -0.61811036 -0.3287711  -0.3899804  -0.3210945\n",
      " -0.31342357 -0.3178025 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31333303 -0.36687526 -0.32822692 -0.33557716 -1.092206   -0.3262111\n",
      " -0.31330827 -1.225064   -0.56505406 -0.32654604 -0.3159119  -0.31838256\n",
      " -0.31329286 -0.35464248 -0.4056649  -0.5499234  -0.3930304  -0.3137243\n",
      " -0.3820459  -0.3175883  -0.32367772 -0.31952682 -0.36561027 -0.32346475\n",
      " -0.40551153 -0.33247182 -0.31501174 -0.579798   -0.38290945 -0.48197114\n",
      " -0.33122802 -0.3216004 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31672123 -0.34171873 -0.326891   -0.32057384 -0.4257122  -0.73544633\n",
      " -0.3140213  -0.31402564 -0.31811252 -0.33897445 -0.58323675 -0.7541431\n",
      " -0.34673533 -0.31634668 -0.34351858 -0.60980916 -0.3134653  -0.64776367\n",
      " -0.3133719  -0.31335804 -0.3244028  -0.33724296 -0.31337303 -0.31421825\n",
      " -0.31516153 -0.32502854 -0.3158122  -0.3187976  -0.3236221  -0.46209309\n",
      " -0.31408122 -0.31376576], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31392995 -0.3151496  -0.3137764  -0.31841898 -0.38030142 -0.31428024\n",
      " -0.3247903  -0.3369863  -0.4356014  -0.32551438 -0.3134124  -0.3156113\n",
      " -0.3148662  -0.40178728 -0.31395668 -0.31607288 -0.35795397 -0.3217614\n",
      " -0.31385547 -0.3148136  -0.31333888 -0.39455763 -0.31556433 -0.41659346\n",
      " -0.3147647  -0.31386316 -0.3610417  -0.3190958  -0.44786787 -0.50535953\n",
      " -0.31562763 -0.35401717], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32951847 -0.31606132 -0.3695265  -0.37187046 -0.31667328 -0.31390077\n",
      " -0.31485885 -0.31658626 -0.31373197 -0.35736752 -0.32455257 -0.319413\n",
      " -0.31471086 -0.31338105 -0.52242184 -0.321463   -0.604002   -0.733243\n",
      " -0.3463905  -0.3137461  -0.47332814 -0.36263427 -0.31502712 -0.31742775\n",
      " -0.31606427 -0.38977075 -0.46982795 -0.31395876 -0.3133157  -0.48085245\n",
      " -0.322707   -0.32660708], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31364068 -0.31327724 -0.31331927 -0.31389257 -0.31496397 -0.3191145\n",
      " -0.37499568 -0.31474853 -0.31529713 -0.48344797 -0.31945416 -0.31358194\n",
      " -0.31360853 -0.32638055 -0.39331377 -0.3171928  -0.31582862 -0.34316045\n",
      " -0.3138917  -0.35303307 -0.31453356 -0.31583506 -0.3136033  -0.33958647\n",
      " -0.31623405 -0.3356934  -0.32102647 -0.3218332  -0.3510175  -0.40512228\n",
      " -0.3696742  -1.1532288 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32206267 -0.3228982  -0.34231824 -0.31434077 -0.37157    -0.33794907\n",
      " -0.31371456 -0.34783408 -0.3500696  -0.32546282 -0.31641287 -0.3659526\n",
      " -0.41600674 -0.38185877 -0.32986045 -0.36409968 -0.32864597 -0.43808898\n",
      " -0.3688752  -0.32318205 -0.313916   -0.3163583  -0.411618   -0.32368422\n",
      " -0.33509466 -0.31327882 -0.31386158 -0.31443182 -0.31799915 -0.3143465\n",
      " -0.98612964 -0.32680416], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3796218  -0.55329084 -0.35624462 -0.41068453 -0.33977422 -0.3201862\n",
      " -0.47645867 -0.31439403 -0.31666076 -0.3137945  -0.31721404 -0.5026902\n",
      " -0.32954565 -0.80259097 -0.32691017 -0.31492952 -0.31677958 -0.32370463\n",
      " -0.31487173 -0.31389257 -0.31381264 -0.31729478 -0.3135999  -0.31788927\n",
      " -0.3158574  -0.3220645  -0.3154274  -0.31346172 -0.4391399  -0.3179452\n",
      " -0.38500482 -0.44264093], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31582028 -0.39912474 -0.32158208 -0.31355825 -0.47771978 -0.31661412\n",
      " -0.31349903 -0.3191488  -0.48917568 -0.31836027 -0.4796986  -0.761899\n",
      " -0.3253129  -0.432567   -0.31611285 -0.31534582 -0.31335098 -0.43336245\n",
      " -0.4237225  -0.55759406 -0.31422183 -0.32216167 -0.43216565 -0.3133772\n",
      " -0.3439306  -0.35743755 -0.3184272  -0.4848113  -0.76270866 -0.31382602\n",
      " -0.31350112 -0.33346415], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6537925  -0.98702705 -0.3261538  -0.3192512  -0.315      -0.31474617\n",
      " -1.0198318  -0.31359825 -0.3150922  -0.4841474  -0.31495473 -0.31987518\n",
      " -0.54503816 -0.31381664 -0.31480256 -0.31364635 -0.47271323 -0.31440377\n",
      " -0.34155428 -0.47940493 -0.51083755 -0.32050887 -0.32625258 -0.31414783\n",
      " -0.3805973  -0.37928584 -0.31374714 -0.40191615 -0.31339926 -0.31353885\n",
      " -0.31637838 -0.3875658 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35123217 -0.35748324 -0.3770943  -0.31580612 -0.3154639  -0.7175822\n",
      " -0.38526997 -0.35012874 -0.31349787 -0.52899337 -0.342155   -0.32458067\n",
      " -0.328037   -0.3135641  -0.33095142 -0.32006916 -0.88945234 -0.31460485\n",
      " -0.31712013 -0.3725504  -0.31326646 -0.33437467 -0.3831476  -0.65253955\n",
      " -0.3184208  -0.3197472  -0.39140597 -0.31577918 -0.3368801  -0.3134668\n",
      " -0.32014343 -0.3423129 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3224914  -0.31730095 -0.5631689  -0.34880957 -0.483918   -0.3443127\n",
      " -0.31473914 -0.3146904  -0.3172144  -0.31879354 -0.6052275  -0.3142126\n",
      " -0.33484566 -0.31360897 -0.34463337 -0.3136966  -0.42702532 -0.31346443\n",
      " -0.32848188 -0.32631123 -0.318332   -0.31373283 -0.3179512  -0.6864412\n",
      " -0.3566501  -0.44630313 -0.31443903 -0.37771842 -0.31489915 -0.313271\n",
      " -1.0453303  -0.33369854], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31599212 -0.35818923 -0.42540693 -0.41253334 -0.3150433  -0.3203655\n",
      " -0.45850933 -0.31404072 -0.31481805 -0.39365318 -0.33080304 -0.39825052\n",
      " -0.31361672 -0.31426895 -0.31368196 -0.31348523 -0.31569442 -0.31598276\n",
      " -0.3592901  -0.32740927 -0.31421757 -0.3166646  -0.37303898 -0.31570902\n",
      " -0.31680036 -0.9939025  -0.3166751  -0.3147794  -0.43827596 -0.31405586\n",
      " -0.31627664 -0.31684497], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33206514 -0.31621173 -0.552027   -0.3136224  -0.31529772 -0.33184516\n",
      " -0.3159732  -0.33135536 -0.31552324 -0.49481842 -0.61974037 -0.32145226\n",
      " -0.38311404 -0.31553409 -0.3289934  -0.34505093 -0.3832957  -0.69184124\n",
      " -0.3307888  -0.31514168 -0.33042976 -0.53526145 -0.33155692 -0.33865255\n",
      " -0.3146367  -0.3138492  -0.31366837 -0.3138039  -0.3132747  -0.32567707\n",
      " -0.40594938 -0.31664237], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34555876 -0.31963393 -0.31699744 -0.33227664 -0.3135187  -0.3386531\n",
      " -0.42929107 -0.37410766 -0.32234997 -0.4445528  -0.3136905  -0.3164306\n",
      " -0.3133339  -0.3688823  -0.31593537 -0.38422891 -0.31374627 -0.31478292\n",
      " -0.31327683 -1.0851088  -0.68685645 -0.48339987 -0.32778984 -0.3132641\n",
      " -0.3171426  -0.3510118  -0.34171617 -0.31336352 -0.32824126 -0.32080767\n",
      " -0.31746125 -0.3544663 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32586968 -0.31353527 -0.31352237 -0.3141944  -0.31430897 -0.31511134\n",
      " -0.3456903  -0.3133787  -0.31337878 -0.31706056 -0.31363964 -0.38035178\n",
      " -0.32344043 -0.33587548 -0.31830668 -0.3176288  -0.31336832 -0.31791624\n",
      " -0.44591433 -0.31329703 -0.31498694 -0.31332466 -0.3133704  -0.3134437\n",
      " -0.31540808 -0.3167286  -0.31901607 -0.31329075 -0.33968732 -1.0375125\n",
      " -0.31815857 -0.3281014 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31623495 -0.314481   -0.6600027  -0.32547992 -0.42584226 -0.3292245\n",
      " -0.461348   -0.3132769  -0.3869744  -0.60690045 -0.31374    -0.33358055\n",
      " -0.31979316 -0.31432143 -0.31415272 -0.3135504  -0.38397494 -0.3137743\n",
      " -0.3273149  -0.33399564 -0.3141083  -0.31682596 -0.31378788 -0.3140888\n",
      " -0.32104108 -0.3168672  -0.3185803  -0.3139977  -0.36523455 -0.319995\n",
      " -0.3136175  -0.5774813 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31602612 -0.31550375 -0.3142376  -0.3209584  -0.32991272 -0.8535248\n",
      " -0.3164287  -0.4440359  -0.32470465 -0.31565592 -0.37339503 -0.41659904\n",
      " -0.3146501  -0.31561488 -0.32328135 -0.3138884  -0.315127   -0.31465462\n",
      " -0.32233387 -0.32647586 -0.3136419  -0.34288153 -0.31491905 -0.35690343\n",
      " -0.3216074  -0.34900528 -0.35509    -0.3151223  -0.3255365  -0.54763126\n",
      " -0.6178837  -0.3394924 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31497937 -0.31786627 -0.31337738 -0.31356603 -0.31724036 -0.32269412\n",
      " -0.3137648  -0.31934053 -0.3341462  -0.34486324 -0.31797522 -0.31684038\n",
      " -0.32399637 -0.31331927 -0.6371115  -0.32357284 -0.31545913 -0.315404\n",
      " -0.31334278 -0.31586218 -0.315171   -0.3228666  -0.3183188  -0.31434405\n",
      " -0.31407583 -0.3143882  -0.32885072 -0.31331334 -0.3165529  -0.35054165\n",
      " -0.4256939  -0.5144124 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36367285 -0.45973116 -0.31924203 -1.0046587  -0.3973571  -0.31376708\n",
      " -0.3159418  -0.3297255  -0.58740115 -0.3136486  -0.32305855 -0.3153874\n",
      " -0.31326663 -0.3132843  -0.31453356 -0.31572622 -0.313914   -0.3146218\n",
      " -0.39532205 -0.32742634 -0.3140389  -0.35770068 -0.31481788 -0.32759207\n",
      " -0.32426342 -0.3151317  -0.31368625 -0.3145171  -0.5410381  -0.3499173\n",
      " -0.31356698 -0.54798245], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3449779  -1.1205732  -0.31338435 -0.3246379  -0.9701471  -0.3138069\n",
      " -0.3355734  -0.31363642 -0.31380835 -0.4877272  -0.31418926 -0.42561322\n",
      " -0.3569172  -0.32545722 -0.3480648  -0.33981386 -0.31471997 -0.3403712\n",
      " -0.34582216 -0.31791148 -0.31341118 -0.72605646 -0.33195722 -0.33305812\n",
      " -0.33450767 -0.3565854  -0.7635578  -0.38903934 -0.3812285  -0.5236764\n",
      " -0.31332082 -0.31329885], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31644154 -0.3499956  -0.35083672 -0.3284915  -0.44000307 -0.392165\n",
      " -0.31326774 -0.7485993  -0.3226197  -0.3141298  -0.3138912  -0.33539918\n",
      " -0.31574517 -0.7715205  -0.3461063  -0.70697856 -0.5889953  -0.40746534\n",
      " -0.31408843 -0.31699112 -0.33122972 -0.5667694  -0.36665338 -0.3144508\n",
      " -0.3162085  -0.3410956  -0.31516892 -0.31611007 -0.4307348  -0.31939465\n",
      " -0.3136655  -0.3193206 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34725285 -0.31380767 -0.9074934  -0.31665766 -0.3498517  -0.3337294\n",
      " -0.31354502 -0.4405856  -0.31585446 -0.3140012  -0.3133305  -0.3207863\n",
      " -0.40876555 -0.3164511  -0.32145277 -0.33190536 -0.3135539  -0.3150258\n",
      " -0.35911322 -0.85197747 -1.0316412  -0.33768836 -0.31475914 -0.31535852\n",
      " -0.31339872 -0.32508385 -0.31454715 -0.31473425 -0.3347665  -0.3157225\n",
      " -0.34242582 -0.96482265], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31415594 -0.31386557 -0.31438768 -0.31372735 -0.31351295 -0.3251518\n",
      " -0.4114638  -0.368927   -0.327633   -0.31459284 -0.32361934 -0.3187013\n",
      " -0.3160248  -0.31592643 -0.3138446  -0.31441665 -0.31647888 -0.33661848\n",
      " -0.3169433  -0.31423026 -0.31381714 -0.33463156 -0.31349596 -0.31654394\n",
      " -0.3176544  -0.31395146 -0.31440178 -0.3146     -0.3499531  -0.34056142\n",
      " -0.32132846 -0.3143862 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.40081117 -0.3133391  -0.33194214 -0.5165083  -0.3145802  -0.32565665\n",
      " -0.31378806 -0.3825752  -0.3137027  -0.31641164 -0.32269204 -0.32291234\n",
      " -0.33637506 -0.34040046 -0.3134557  -0.31524312 -0.31948578 -0.89099616\n",
      " -0.32103452 -0.3151555  -0.31380776 -0.7821624  -0.31476888 -0.37864488\n",
      " -0.31437707 -0.31365758 -0.31446707 -0.3134239  -0.33657414 -0.33755568\n",
      " -0.33878943 -0.3168212 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38394392 -0.31336066 -0.35623252 -0.4147244  -0.31735596 -0.3354961\n",
      " -0.31356853 -0.4768601  -0.31353003 -0.35451958 -0.73999673 -0.4256295\n",
      " -0.4635591  -0.3495574  -0.32101807 -0.31641468 -0.3506843  -0.3147802\n",
      " -0.36434698 -0.31695265 -0.31630263 -0.34150285 -0.42310613 -0.3158194\n",
      " -0.40256563 -0.31464478 -0.31365156 -0.3444303  -0.64296424 -0.3152479\n",
      " -0.31558886 -0.32594723], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3159922  -0.3141843  -0.320831   -0.34234297 -0.35281163 -0.48146746\n",
      " -0.31636333 -0.31415975 -0.917298   -0.3147561  -0.31334966 -0.31360164\n",
      " -0.31404063 -0.35307413 -0.3132905  -0.31529522 -0.33704162 -0.3138863\n",
      " -0.31344125 -0.31351757 -1.266864   -0.31392455 -0.3965134  -0.31773075\n",
      " -0.31486842 -0.31663054 -0.3133393  -0.3136025  -0.31916025 -0.38919103\n",
      " -0.35592526 -1.0765865 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32019603 -0.31560513 -0.39734426 -0.3141547  -0.3147541  -0.39675033\n",
      " -1.272264   -0.46412557 -0.31728098 -0.31404376 -0.34271282 -0.32682884\n",
      " -0.44134724 -0.31481883 -0.31441614 -0.3177134  -0.38001254 -0.31331533\n",
      " -0.31539506 -0.44770014 -0.3184358  -0.3212293  -0.53395486 -0.54484\n",
      " -0.38120937 -0.35164085 -0.34270325 -0.31539    -0.5499165  -0.40260723\n",
      " -0.313887   -0.3175161 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3157589  -0.31460005 -0.31980133 -0.31433362 -0.9709563  -0.47045112\n",
      " -0.31329894 -0.32334027 -1.3088557  -0.3135552  -0.315001   -0.3281191\n",
      " -0.32987586 -0.32355222 -0.31482214 -0.31331044 -0.58066535 -0.37671664\n",
      " -0.3160712  -0.31637257 -0.37620002 -0.3263852  -0.31427276 -0.319547\n",
      " -0.935608   -0.3138966  -0.31331593 -0.31706873 -0.55960846 -0.33654365\n",
      " -0.9123024  -1.0145304 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.316835   -0.31418684 -0.31336212 -0.3138189  -0.32636052 -0.32430154\n",
      " -0.31761613 -0.3286693  -0.32072914 -0.3192628  -0.3139633  -0.31610268\n",
      " -1.2327334  -0.31481493 -0.36509225 -0.31512594 -0.6647043  -0.47684893\n",
      " -0.36879948 -0.31907013 -0.31329712 -0.31929606 -0.3738722  -0.31423846\n",
      " -0.35039976 -0.4391037  -0.34755334 -0.35265145 -0.32035148 -0.31858766\n",
      " -0.4332626  -0.31990805], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31330234 -0.42059973 -0.32033244 -0.31567067 -0.32502872 -0.31335682\n",
      " -0.3134171  -0.3232867  -0.31480858 -0.32045463 -0.33586773 -1.1700462\n",
      " -0.3146664  -0.6093823  -0.60947394 -0.3385082  -0.31751227 -0.31463608\n",
      " -0.33957002 -0.48001957 -0.6095712  -0.35660437 -0.31373143 -0.31576684\n",
      " -0.3145466  -0.33223858 -0.31353763 -0.3160175  -0.3132978  -0.31502122\n",
      " -0.31981847 -0.31372935], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.313527   -0.37167102 -0.6183383  -0.8922534  -1.1549022  -0.61455405\n",
      " -0.31801096 -0.4099027  -0.3165859  -0.4694355  -0.325838   -0.6302179\n",
      " -0.31421077 -0.31483537 -0.31337267 -0.43069544 -0.3539262  -0.31399003\n",
      " -0.31618974 -0.31486225 -0.31350303 -0.31492168 -1.2641147  -0.31330323\n",
      " -0.32189474 -0.31345823 -0.32231125 -0.34998628 -0.3171828  -0.32395402\n",
      " -0.31334558 -0.35150093], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3138296  -0.31368285 -0.33869106 -0.31816977 -0.3135405  -0.31365496\n",
      " -0.313954   -0.3140859  -0.33079857 -0.31390476 -0.31344596 -0.31390634\n",
      " -0.3142799  -0.36328    -0.31351626 -0.5498107  -0.35875905 -0.3268218\n",
      " -0.32048655 -0.32409412 -0.57632405 -0.37136996 -0.594447   -0.3551281\n",
      " -0.31347567 -0.34544197 -0.31867757 -0.31350094 -0.3212945  -0.31970495\n",
      " -0.34702158 -0.3226872 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34086376 -0.3135417  -0.31494117 -0.35185108 -0.31818432 -0.5953164\n",
      " -0.35858032 -0.36469316 -0.33545512 -0.3136487  -0.35553452 -0.3134018\n",
      " -0.3135065  -0.40884978 -0.31567782 -0.47371793 -0.3207535  -0.31922105\n",
      " -0.31338006 -0.39013714 -0.39609313 -0.32000953 -0.33830762 -0.52982044\n",
      " -0.34025377 -0.32416135 -0.32508117 -0.31484407 -0.3187696  -0.31552523\n",
      " -0.32221574 -0.31362072], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3191171  -0.40367687 -0.4147282  -0.31427354 -0.32499495 -0.31382552\n",
      " -0.3155479  -0.4199664  -0.34081146 -0.31344098 -0.3148994  -0.37571955\n",
      " -0.35383216 -0.3134972  -0.891424   -0.4713675  -0.3165531  -0.31386882\n",
      " -0.31805572 -0.31935844 -0.3277644  -0.3164634  -0.34813786 -0.3134293\n",
      " -0.3133177  -0.7625531  -0.36935496 -0.35508874 -0.3137798  -0.31377152\n",
      " -0.3600641  -0.31723577], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31896597 -0.41553345 -0.32248864 -0.32039827 -0.50593305 -0.3180465\n",
      " -0.3176648  -0.3159457  -0.33858994 -0.31466308 -0.3225641  -0.31419188\n",
      " -0.31432474 -0.31361595 -0.54324543 -0.3823934  -0.34667438 -0.3132824\n",
      " -0.31371698 -0.3210614  -0.3212908  -0.3747775  -0.31402898 -0.31334686\n",
      " -0.34092438 -0.7462983  -0.3182054  -0.33031172 -0.31410733 -0.4045897\n",
      " -0.31671298 -0.37861508], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31516212 -0.323038   -1.0866064  -0.80016625 -0.31427824 -0.31576362\n",
      " -0.40764475 -0.31356907 -0.58036697 -0.3160181  -0.3134396  -0.6542667\n",
      " -0.3195309  -0.57731164 -0.31671566 -0.3590656  -0.32160768 -0.31410158\n",
      " -0.35547227 -0.31855446 -0.34557706 -0.31686997 -0.33302173 -0.3144475\n",
      " -0.32306227 -0.3888569  -0.36570588 -0.31381473 -0.37424484 -0.83789945\n",
      " -0.4496308  -0.3236314 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31403017 -0.32031244 -0.53348947 -0.36608207 -0.3179033  -0.32977274\n",
      " -0.32604557 -0.3133292  -0.32840633 -0.80284345 -0.3233286  -0.31345475\n",
      " -0.3234476  -0.31371924 -0.31457117 -0.32971367 -1.0943432  -0.3165859\n",
      " -0.3160118  -0.3245481  -0.31576213 -0.31484094 -0.3681606  -0.33414382\n",
      " -0.3576249  -0.32096678 -0.31950465 -0.32232526 -0.32452258 -1.2370882\n",
      " -0.3377698  -0.3273236 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.2421556  -0.6121047  -0.34226406 -0.31697965 -0.31355104 -0.31939638\n",
      " -0.31520668 -0.39092848 -0.3137846  -0.31539434 -0.313829   -0.43366924\n",
      " -0.45665967 -0.3188138  -0.31337363 -0.3138522  -0.31401318 -0.31539062\n",
      " -0.31332213 -0.33241206 -0.32006457 -0.35245746 -0.3157224  -0.39210293\n",
      " -0.32597932 -0.32532445 -0.32898164 -0.31352097 -0.40101123 -0.31455976\n",
      " -0.3185733  -0.3132932 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3149632  -0.31628734 -0.3224074  -0.48489654 -0.3185059  -0.3256064\n",
      " -0.3791907  -0.33078846 -0.32376784 -0.31449458 -0.36486152 -0.34276256\n",
      " -0.3226292  -0.3183517  -0.31404883 -0.4239273  -0.31332326 -0.540148\n",
      " -0.3154852  -0.3141114  -0.53504956 -0.3156698  -0.31456378 -0.31353047\n",
      " -0.3523367  -0.3139512  -1.1030393  -0.34175912 -0.3154736  -0.31334487\n",
      " -0.313789   -0.56871724], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33488506 -0.37009993 -0.3247791  -0.3138021  -0.35887653 -0.32780528\n",
      " -0.31333965 -0.3141878  -0.31332797 -0.32566535 -0.31664333 -0.3317058\n",
      " -0.31537643 -0.31337214 -0.3254009  -0.7198218  -0.39441276 -0.33336514\n",
      " -0.33811817 -0.31377822 -0.31347087 -0.52828944 -0.31481022 -0.32662103\n",
      " -0.32544792 -0.31351957 -0.31379443 -0.31350407 -0.3147292  -0.35314077\n",
      " -0.33561856 -0.36852705], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.313564   -0.3144808  -0.31334618 -0.31968027 -0.7802881  -0.3171394\n",
      " -0.3137952  -0.31366393 -0.31847063 -0.31464845 -0.31419772 -0.33191136\n",
      " -0.3138546  -0.3181799  -0.31713644 -0.32319257 -0.33446673 -0.31384042\n",
      " -0.32148683 -0.3138156  -0.31852195 -0.34047192 -0.3152412  -0.33182257\n",
      " -0.33515394 -0.31383702 -1.1015124  -0.31672522 -0.38497767 -0.31395626\n",
      " -0.3152848  -0.314522  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32768178 -0.31477726 -0.3136156  -0.3152192  -0.7735061  -0.5395993\n",
      " -0.31708252 -0.3214845  -0.3133996  -0.35574085 -0.31636423 -0.3142307\n",
      " -0.36301222 -0.31672904 -0.31399623 -0.3947253  -0.32239047 -0.31342503\n",
      " -0.4152476  -0.38351655 -0.3153874  -0.3133576  -0.43248487 -0.3133656\n",
      " -0.31451747 -0.31500354 -0.44586158 -0.41340336 -0.359377   -0.33232296\n",
      " -0.38067004 -0.5982312 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3414421  -0.581919   -0.32746905 -0.31679946 -0.37749    -0.44894752\n",
      " -0.347598   -0.31339133 -0.39493823 -0.32441097 -0.3142543  -0.3144843\n",
      " -0.34877357 -0.31671688 -0.5545798  -0.4960368  -0.32129934 -0.31390688\n",
      " -0.32092848 -0.31596762 -0.5947246  -0.31441066 -0.3210078  -0.31401348\n",
      " -0.31383893 -0.3272097  -0.31559086 -1.2770963  -0.31561825 -0.4529435\n",
      " -0.31349143 -0.31825587], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3217594  -0.35952762 -0.36236367 -0.3138243  -0.31420782 -0.37283546\n",
      " -0.557243   -0.32322595 -0.3221057  -0.31398228 -0.31616306 -0.3368446\n",
      " -0.34887904 -0.31785083 -0.31498066 -0.31349945 -0.31710726 -0.9259467\n",
      " -0.43209285 -0.32854676 -0.6936511  -0.31824157 -0.31626916 -0.34369215\n",
      " -0.31370646 -0.31328136 -0.32241154 -0.38418272 -0.55050266 -0.33600464\n",
      " -0.31823212 -0.7773746 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3136182  -0.3136622  -0.31522885 -0.32044977 -0.3142901  -0.31328806\n",
      " -0.31335464 -0.32436693 -0.31859502 -0.35277075 -0.8395785  -0.32624912\n",
      " -0.31389084 -0.31545654 -0.31403863 -0.32509935 -1.1007292  -0.31335717\n",
      " -0.31870374 -1.0837452  -0.31984115 -0.34182334 -0.33036044 -0.77104986\n",
      " -0.4816711  -0.31582037 -0.3472658  -0.47540766 -0.35675582 -0.31409246\n",
      " -0.34748498 -0.41171768], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31346017 -0.34846923 -0.54519546 -0.32847083 -0.3135668  -0.31938937\n",
      " -0.32707316 -0.3142348  -0.3133352  -1.276703   -0.3157976  -0.31750178\n",
      " -0.32437944 -0.36405307 -0.31344134 -0.7040901  -0.31336832 -0.3156751\n",
      " -0.3280217  -0.33956397 -0.31388456 -0.3135304  -0.37243056 -0.3133012\n",
      " -0.6467627  -0.3336193  -0.31409028 -0.46139264 -0.3240474  -0.3135602\n",
      " -0.31808305 -0.697678  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.46965057 -0.31352296 -0.3133834  -0.34418124 -0.37754828 -0.31417516\n",
      " -1.0625718  -0.9556341  -0.7796315  -0.32233328 -0.5293348  -0.3399397\n",
      " -0.3137867  -0.32051015 -0.31371856 -0.3133237  -0.3693651  -0.31398898\n",
      " -0.31706032 -0.31533226 -0.52812666 -0.9139526  -0.3615693  -0.31359258\n",
      " -0.31387568 -0.32478547 -0.37173712 -0.31369418 -0.32909453 -0.313562\n",
      " -0.32558736 -0.3277018 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3834483  -0.3219507  -0.3363151  -0.34592322 -0.31328064 -0.31468606\n",
      " -0.33349258 -0.3215419  -0.42961657 -0.32455197 -0.38092273 -0.32622582\n",
      " -0.48042873 -0.31756884 -0.31340632 -0.32520777 -1.3094392  -0.3287215\n",
      " -0.31572276 -0.31551713 -0.31959757 -0.31600267 -0.3135925  -0.31467804\n",
      " -0.35485235 -0.4678645  -0.45816588 -0.53405786 -0.3132946  -0.31367317\n",
      " -0.31635752 -0.47227073], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31541035 -0.3175441  -0.48761168 -0.3135453  -0.31326592 -0.32141355\n",
      " -0.75443256 -0.31436443 -0.3175121  -0.8903097  -0.3795852  -0.31395066\n",
      " -0.31846648 -0.40960217 -0.40174875 -0.34285724 -0.31420034 -0.31847957\n",
      " -0.31716847 -0.31418204 -0.6682185  -0.31459877 -0.31401747 -0.31340474\n",
      " -0.4291759  -0.3209335  -0.31721717 -0.31914613 -0.31380793 -0.3535995\n",
      " -0.31335026 -0.3138459 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31809127 -0.3242848  -0.3282592  -0.31339464 -0.3168982  -0.34010193\n",
      " -0.3134837  -0.32492363 -0.3270949  -0.35210437 -0.3327679  -0.32540435\n",
      " -0.41203701 -0.38643184 -0.31696975 -0.32632008 -0.3174556  -0.31809354\n",
      " -0.3227304  -0.31426755 -0.32324123 -0.3140495  -0.334935   -0.3139168\n",
      " -0.8544179  -0.60302114 -0.31333092 -0.43074024 -0.3278145  -0.31359947\n",
      " -0.31386018 -0.31974298], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31337878 -0.33451486 -0.3201256  -0.31625152 -0.31327438 -0.4096949\n",
      " -0.3175962  -0.31392464 -0.3709204  -0.33296335 -0.31807566 -0.3161397\n",
      " -0.7108685  -0.40439016 -0.32075238 -0.32715076 -0.3134504  -0.35874262\n",
      " -0.31385818 -0.3226286  -0.37330723 -0.31359893 -0.33187535 -0.31338295\n",
      " -0.3147367  -0.33279783 -1.2465812  -0.3605715  -0.31393266 -0.46865797\n",
      " -0.364117   -0.3525633 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31412476 -0.47126415 -0.31326967 -0.33435896 -0.37935755 -0.35266778\n",
      " -0.3250295  -0.3137953  -0.31401223 -0.33640537 -0.31327552 -0.31693295\n",
      " -0.31852084 -0.32004216 -0.3144459  -0.6486344  -0.33433688 -0.36723113\n",
      " -0.32156083 -0.3132791  -0.31714287 -0.31334233 -0.31388125 -0.3145085\n",
      " -0.476802   -0.33064193 -0.38983786 -0.31365559 -0.6034547  -1.1566641\n",
      " -0.3136161  -0.3238965 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31354928 -0.31808206 -0.31547654 -0.3228394  -0.3133406  -0.31654996\n",
      " -1.2877295  -0.46751338 -0.31515414 -0.31921178 -0.3292535  -1.3036897\n",
      " -0.32635468 -0.32892898 -0.3241423  -0.31464452 -0.3203834  -0.3912314\n",
      " -0.33183283 -0.31368598 -0.31379634 -0.31441355 -0.31351706 -0.33840248\n",
      " -0.31482163 -0.3148573  -0.31597233 -0.31502408 -0.3463607  -0.3299553\n",
      " -0.42013496 -0.33049607], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.8218106  -0.31326655 -0.31516656 -0.31447056 -1.3115392  -0.35434294\n",
      " -0.38540545 -0.3137803  -0.37234646 -0.31444198 -0.3835505  -0.3149443\n",
      " -0.32526666 -0.329137   -0.31399736 -0.3149845  -0.32411402 -0.36625853\n",
      " -0.31390148 -0.31342182 -0.32241333 -0.31336623 -0.31364912 -0.31724364\n",
      " -0.3360548  -0.33630395 -0.31612885 -0.34310022 -0.34813002 -0.32161078\n",
      " -0.31530488 -0.41654348], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.64156187 -0.31330016 -0.34550408 -0.31337565 -0.33267125 -0.5797559\n",
      " -0.3134572  -0.313587   -0.32188118 -0.315546   -0.3801672  -0.31751263\n",
      " -0.35939854 -0.31542286 -0.3695204  -0.3137486  -0.314971   -0.31851268\n",
      " -0.31395903 -0.55342776 -0.3369641  -0.31817383 -0.3234066  -1.0452255\n",
      " -0.36860406 -0.35243827 -0.31851935 -0.5265567  -0.55652314 -0.31379426\n",
      " -0.31493542 -0.31716144], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.314313   -0.35187876 -0.31352454 -0.31370768 -0.31390756 -0.32678285\n",
      " -0.3134898  -0.32678294 -0.41434065 -0.3464826  -0.31340316 -0.42241517\n",
      " -0.31362396 -0.31370905 -0.84064645 -0.32972294 -0.3136966  -0.31332046\n",
      " -0.31327122 -0.3198865  -0.48326203 -0.3383668  -0.31485495 -0.31338245\n",
      " -0.31471702 -0.31381106 -0.32634854 -0.3167319  -0.31395835 -0.31363547\n",
      " -0.73446274 -0.3162106 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.44865733 -0.3373654  -0.3153461  -0.3133242  -0.32928872 -0.31815666\n",
      " -0.31436443 -0.37897193 -0.3149529  -0.3145125  -0.31713316 -0.31565702\n",
      " -0.3292631  -0.31679192 -0.34418824 -0.32407084 -0.3221798  -0.31327462\n",
      " -0.31406823 -0.31390244 -0.31534845 -0.32192463 -0.31476906 -0.31374547\n",
      " -0.31348175 -0.3134605  -0.31334957 -0.31356707 -0.34578654 -0.6081866\n",
      " -0.3189612  -0.31422123], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31329513 -0.3142356  -0.3140058  -0.41266686 -0.31536087 -0.31823885\n",
      " -0.3175127  -0.3314994  -0.31339446 -1.1089518  -0.4023567  -0.31525528\n",
      " -0.31500322 -0.38765234 -0.31772903 -0.31374225 -0.3185986  -0.34181517\n",
      " -0.37390393 -0.3156653  -0.3612381  -0.3141803  -1.2174774  -0.31338617\n",
      " -0.36269566 -0.31331107 -0.3231343  -0.31433004 -0.31970426 -0.31446323\n",
      " -0.31382638 -0.3137352 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3204965  -0.3153159  -0.31953174 -0.31543297 -0.31859797 -0.38590586\n",
      " -0.37154895 -0.31588566 -1.1316087  -0.34889638 -0.31676248 -0.31721693\n",
      " -0.48715198 -0.3195954  -0.32947534 -0.44730908 -0.32458687 -0.3135857\n",
      " -0.3161955  -0.3195748  -0.31417263 -0.313694   -0.31448752 -0.34409827\n",
      " -0.31592485 -0.31434137 -0.31539923 -0.44193164 -1.1875151  -0.3318413\n",
      " -0.37158743 -0.31402645], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31334993 -0.31426442 -0.3170095  -0.7474073  -0.3196445  -0.31554922\n",
      " -0.3229339  -0.4198157  -0.3237794  -0.31645614 -0.3133521  -1.0971957\n",
      " -0.31417724 -0.31373563 -0.32224786 -0.34398115 -0.31976148 -0.4227643\n",
      " -0.31390625 -0.3136695  -0.31343156 -0.32839853 -0.3143013  -0.31364816\n",
      " -0.51340187 -0.37590277 -0.3134923  -0.32949787 -0.31349918 -1.1058363\n",
      " -0.5412764  -0.31966764], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.313512   -0.31349325 -0.31452468 -0.3433031  -0.324016   -0.37473625\n",
      " -0.31768867 -0.3263864  -0.32392532 -0.31652302 -0.5868207  -0.3227853\n",
      " -0.31394064 -0.31391802 -0.31538495 -0.37431043 -0.33343783 -0.31656158\n",
      " -0.6081192  -0.31340483 -0.3135391  -0.31412232 -0.7975453  -0.31444347\n",
      " -0.3133676  -0.316404   -0.3229624  -0.318266   -0.313964   -0.31843302\n",
      " -0.3230468  -0.31352758], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.38225788 -0.3720007  -0.3324166  -0.31470248 -0.31876388 -0.3160841\n",
      " -0.3133651  -0.32432565 -0.3145616  -0.3180886  -0.47879893 -0.3153067\n",
      " -0.319008   -0.32934874 -0.31535476 -0.5349699  -0.31411856 -0.3174811\n",
      " -0.31390235 -0.31489235 -0.42815712 -0.3133658  -0.31404638 -0.31722838\n",
      " -0.31984505 -0.31365976 -0.5087767  -0.3133122  -0.3177055  -0.38905412\n",
      " -0.42766157 -0.31352848], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.326968   -0.3200283  -0.31352323 -0.33311093 -0.32557154 -0.3433175\n",
      " -0.34092903 -0.31438804 -0.3142376  -0.33366215 -0.3135788  -0.3317993\n",
      " -0.31326216 -0.49906176 -0.31388143 -0.6388443  -0.34972045 -0.3137467\n",
      " -0.3388336  -0.33192942 -0.3152185  -0.3238853  -0.31387246 -0.32654405\n",
      " -0.31352255 -0.31372586 -0.31450891 -0.41156113 -0.31338617 -0.32494673\n",
      " -0.33126387 -0.3138262 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31678063 -0.32077444 -0.36383155 -0.31823385 -0.72913086 -0.31353545\n",
      " -0.3774869  -0.3147863  -0.31336868 -0.31533644 -0.31352514 -0.31363693\n",
      " -0.31654924 -0.3158157  -0.40201887 -0.35923582 -0.31330574 -0.31362805\n",
      " -0.32183155 -1.0646524  -0.3378631  -0.31433326 -0.3196925  -0.32889318\n",
      " -0.31394404 -0.8119137  -1.008467   -0.40793225 -0.3227998  -0.31453583\n",
      " -0.32192236 -0.36972362], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32452577 -0.31348202 -0.3323831  -0.3142104  -0.31461582 -0.42626694\n",
      " -0.31406283 -1.3035578  -0.31414652 -0.32225323 -0.31632555 -1.2810414\n",
      " -0.31638578 -0.8590351  -0.3141279  -0.31386507 -0.31849432 -0.66509914\n",
      " -0.31596082 -0.32258976 -0.3431953  -0.31411797 -0.3986926  -0.35153526\n",
      " -0.3403699  -0.3139275  -1.2458286  -0.47100636 -0.42269495 -0.66661453\n",
      " -0.3138309  -0.31441805], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3139457  -0.31436488 -0.31536156 -0.33928356 -0.3262894  -0.32315865\n",
      " -0.31579047 -0.3134532  -0.31435242 -0.31339934 -0.31847185 -0.324462\n",
      " -0.3304177  -0.31753206 -0.3181178  -0.31481344 -0.31936797 -0.31794485\n",
      " -0.31458178 -0.3607009  -0.32184383 -0.32804835 -0.32112125 -0.31434563\n",
      " -0.31333652 -0.3555457  -0.3208356  -0.57005626 -0.31856436 -0.47923058\n",
      " -0.53642726 -0.3198221 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4738229  -0.31481048 -0.31412718 -0.31972167 -0.7334601  -0.31962484\n",
      " -0.31393012 -0.3146267  -0.31360233 -0.31609938 -0.31410447 -0.31380934\n",
      " -0.3513455  -0.31326774 -0.32794666 -0.6965598  -0.31514838 -0.33756596\n",
      " -0.33391532 -0.38393638 -1.2862673  -0.31809646 -0.31347653 -0.76615584\n",
      " -0.8603437  -0.31465775 -0.31622764 -0.34192672 -0.3384939  -0.3247144\n",
      " -1.0939052  -0.7663027 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31368354 -0.3231601  -0.32583335 -0.32629007 -0.32385874 -0.35012773\n",
      " -0.31640747 -0.31402323 -0.39506665 -0.3154954  -0.3147278  -0.31416488\n",
      " -0.34106365 -0.3138533  -0.3202753  -0.31361523 -0.32125005 -0.34649694\n",
      " -0.35477436 -0.50382966 -0.32176694 -0.3134781  -0.44396776 -0.32546556\n",
      " -0.31951806 -0.33466226 -0.34026778 -0.340389   -0.31374452 -0.3158702\n",
      " -1.1174029  -0.31360286], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31356993 -0.3135534  -0.31397194 -0.3484253  -0.32332715 -0.33354074\n",
      " -0.37260157 -0.32058752 -0.31407058 -0.61369455 -0.32392505 -0.31490305\n",
      " -0.313302   -0.3402223  -0.31342137 -0.31346887 -0.31341815 -0.31327194\n",
      " -0.92645186 -0.3135188  -0.32497334 -0.3139362  -0.36301205 -0.34542805\n",
      " -0.50434124 -0.32849717 -0.31566536 -0.3148291  -0.31428155 -0.4117859\n",
      " -0.31534845 -0.31329173], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3156294  -0.3138035  -0.32603127 -0.3338606  -1.0435989  -0.31389433\n",
      " -0.31377333 -0.31344324 -0.50401187 -0.42203653 -0.35042185 -0.3421533\n",
      " -0.31390408 -0.32500875 -0.31459954 -0.31366184 -0.7141623  -0.32163602\n",
      " -1.0838902  -0.32984662 -0.40841255 -0.3181232  -0.3134842  -0.34741524\n",
      " -0.44113737 -0.32199374 -0.3136161  -0.33952534 -0.4758593  -0.32191744\n",
      " -0.3181053  -0.31413555], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31330794 -0.34775063 -0.33178878 -0.32922903 -0.31395972 -0.35723925\n",
      " -0.31383657 -0.33028626 -0.32717457 -0.3142853  -0.3149289  -0.31497526\n",
      " -0.3132898  -0.3133595  -0.37231368 -0.31369713 -0.348349   -0.3148104\n",
      " -0.4794522  -0.41897506 -0.31350476 -0.3134185  -0.3134368  -0.4762359\n",
      " -0.3377342  -1.2598529  -0.31624258 -0.313625   -0.33124042 -0.3135809\n",
      " -0.31341806 -0.31867686], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31472504 -0.53180766 -0.32482508 -0.6165994  -0.3184643  -0.31437096\n",
      " -0.31373093 -0.31336954 -0.40840802 -0.31382343 -0.31334925 -0.3220074\n",
      " -0.43382218 -0.3132633  -0.3134064  -0.31329477 -0.31339255 -0.3138343\n",
      " -0.31521598 -0.33035618 -0.31365043 -0.31338173 -0.34992057 -0.3135139\n",
      " -0.31333485 -0.32159048 -0.42503518 -0.31388354 -0.31563938 -0.74609643\n",
      " -0.32001212 -0.747917  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32685685 -0.31341198 -0.3138458  -0.3423961  -0.3140558  -0.38467035\n",
      " -0.3201237  -1.3059527  -0.329591   -0.4939282  -0.38219804 -0.31769884\n",
      " -0.35170692 -0.31395495 -0.3138007  -0.3142787  -0.37247056 -0.32040098\n",
      " -0.43507797 -0.31356707 -0.31406257 -0.314243   -0.33203197 -1.088356\n",
      " -0.33238754 -0.33244702 -0.3200619  -0.3179661  -0.31537724 -0.31368572\n",
      " -0.31339663 -0.32238838], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3235618  -0.49658334 -0.37174895 -0.31713358 -0.4123194  -0.34720296\n",
      " -0.314055   -0.3143781  -0.3502423  -0.3248275  -0.3144808  -0.3339651\n",
      " -0.39121994 -0.31545132 -0.35089037 -0.3134442  -0.38831922 -0.3143035\n",
      " -0.32807934 -0.32144612 -0.31339282 -0.36133558 -0.3372181  -0.31706196\n",
      " -0.36910462 -0.34945336 -0.33790177 -0.31332144 -0.32166186 -0.32557118\n",
      " -0.31513152 -0.31372944], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34102526 -0.314298   -0.8090425  -0.32295904 -0.3146145  -0.3420793\n",
      " -0.31884396 -0.3139372  -0.31468648 -0.3133569  -0.32251367 -0.31341434\n",
      " -0.75626004 -0.31336674 -0.3151216  -0.31482702 -0.3372066  -0.31336194\n",
      " -0.31395206 -0.3240581  -0.31930637 -0.34611028 -0.8905703  -0.32361072\n",
      " -0.3133821  -0.31411865 -0.9358872  -0.41140836 -0.4007247  -0.31353316\n",
      " -0.31867236 -0.31562024], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.40932527 -0.4526726  -0.4298274  -0.32545435 -0.31354344 -0.3140995\n",
      " -0.65383565 -0.31910264 -0.3137013  -0.5763062  -0.32578725 -0.31370923\n",
      " -0.3399942  -0.31551453 -0.3823303  -0.36457998 -0.4342232  -0.33442226\n",
      " -0.38489386 -1.0304451  -0.32207936 -0.55298215 -0.42722607 -0.47135174\n",
      " -0.315858   -0.47665045 -0.31532216 -0.31355304 -0.31396714 -0.3134774\n",
      " -0.32257688 -0.31367204], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6144048  -0.32081795 -0.3133806  -0.33153483 -0.3139241  -0.31356627\n",
      " -0.34556693 -0.31950992 -0.31357265 -0.3226387  -0.63684857 -0.3185413\n",
      " -0.31487626 -0.31341136 -0.31863266 -0.3155754  -0.31428015 -0.7045834\n",
      " -0.314898   -0.37049037 -0.3142469  -0.88970053 -0.3170675  -0.42620787\n",
      " -0.3169748  -0.31333435 -0.3190775  -0.31549522 -1.1581885  -1.1633782\n",
      " -0.43050838 -0.32173055], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33640146 -0.31362864 -0.3778167  -0.3633557  -0.31327942 -0.33254766\n",
      " -0.4418757  -0.35197827 -0.32194793 -1.1697605  -0.31331202 -0.31338608\n",
      " -0.31588817 -0.31340614 -0.31549418 -0.31946516 -0.9554586  -0.31376183\n",
      " -0.3222914  -0.3135953  -0.3224908  -0.3153213  -0.3133739  -0.45107877\n",
      " -0.3206203  -0.31728142 -0.31393525 -0.3373021  -0.31476375 -0.31932822\n",
      " -0.4630477  -0.434477  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3149222  -0.3962866  -0.31404212 -0.32560492 -0.31340292 -0.313514\n",
      " -0.49976698 -0.37335753 -0.32771596 -0.31335637 -0.3138715  -0.31440178\n",
      " -0.31365183 -0.41944367 -0.3207184  -0.40295976 -0.318512   -0.3138643\n",
      " -0.55890316 -0.31575823 -0.32120416 -0.31326592 -0.3150929  -0.33481145\n",
      " -0.32096377 -0.32128888 -0.3198861  -1.1105751  -0.38213736 -0.31513315\n",
      " -0.35641724 -0.3209981 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3190679  -0.31493777 -0.3293709  -0.508657   -0.31456256 -0.34840143\n",
      " -0.32513964 -0.33561736 -0.3440887  -0.42766866 -0.31825048 -0.40236357\n",
      " -1.0710238  -0.31361604 -0.31329808 -0.31520015 -0.38152704 -0.31334007\n",
      " -0.32822487 -0.45096958 -0.31874767 -0.3142966  -0.3150146  -0.31717923\n",
      " -0.36483    -0.7965462  -0.5440539  -0.3213964  -0.31335378 -0.37557405\n",
      " -0.3271659  -0.31376716], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37091777 -0.31410995 -0.31382978 -0.3754467  -0.31789333 -0.31690636\n",
      " -0.3134253  -0.31671107 -0.56767094 -0.31723568 -0.33063352 -0.3388827\n",
      " -0.31954223 -0.3133507  -0.31360173 -0.3254646  -0.31420112 -0.3518592\n",
      " -0.31398088 -0.31359118 -0.31782427 -0.31433833 -0.33811927 -0.31404915\n",
      " -0.3133297  -0.8289261  -0.38850564 -0.41858467 -0.38767645 -0.32848576\n",
      " -0.3454866  -0.31409767], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34914327 -0.4210621  -0.37164277 -0.3140481  -0.3521398  -0.4301262\n",
      " -0.82868975 -0.43524507 -0.31395668 -0.3135506  -0.32853013 -0.31362882\n",
      " -0.35739025 -0.3138782  -0.3164531  -0.32217756 -0.3355635  -0.54850394\n",
      " -0.31356975 -0.3212213  -0.31435233 -0.32011926 -0.31389555 -0.32138526\n",
      " -0.41920257 -0.31329975 -0.31485695 -0.31336448 -0.85134155 -0.33138517\n",
      " -0.3135992  -0.313625  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36119628 -0.3155226  -0.3133373  -0.34991956 -0.49965647 -0.40828368\n",
      " -0.31339622 -0.31382143 -0.31962746 -0.7670152  -0.7801107  -0.31390008\n",
      " -0.32941324 -0.34297484 -0.33848363 -0.31782064 -1.1719204  -0.4906234\n",
      " -0.43479508 -0.47190797 -0.3135471  -0.38234183 -1.0357096  -0.33993495\n",
      " -0.31711206 -0.38288394 -0.31692496 -0.31515986 -0.31730512 -0.31364024\n",
      " -0.31704912 -0.42645195], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3145233  -0.3242472  -0.34295395 -0.36879665 -0.3187164  -0.5040644\n",
      " -0.31342217 -0.4625853  -0.3338307  -0.3174451  -0.3314216  -0.7810013\n",
      " -0.3193995  -0.3132681  -0.9950622  -0.31361967 -0.31362787 -0.32230115\n",
      " -0.35910183 -1.0086062  -0.3229637  -0.36371455 -0.3879768  -0.31959635\n",
      " -0.3134206  -0.31349903 -0.52297944 -0.3140732  -0.31493527 -0.3142289\n",
      " -0.32202    -0.32686943], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31345972 -0.31393272 -0.4229769  -0.31347245 -0.3136546  -0.32393533\n",
      " -0.4092697  -0.3164386  -0.34996393 -0.31788814 -0.31721807 -0.31451353\n",
      " -0.31326932 -0.47601306 -0.3136324  -0.31636828 -0.322425   -0.36607\n",
      " -0.31912228 -0.31335142 -0.3685516  -0.31746453 -0.31378493 -0.4166616\n",
      " -0.5150064  -0.33453533 -0.5539868  -0.4785722  -0.3316614  -1.1435041\n",
      " -0.34767812 -0.3150574 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31681347 -0.44323832 -0.63328165 -0.45112097 -0.44603407 -0.31497544\n",
      " -0.50520474 -0.45254433 -0.31709704 -0.39820856 -0.3135547  -0.31695387\n",
      " -0.42959073 -0.3214903  -0.34238267 -0.31862563 -0.3310989  -0.31352273\n",
      " -0.9743285  -0.31503546 -0.31686965 -0.31356862 -0.33006048 -0.44679448\n",
      " -0.92909795 -0.31353405 -0.5810556  -0.43839148 -0.3137447  -0.31622756\n",
      " -0.31372237 -0.3224427 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31445357 -0.31330383 -0.31541914 -0.31350076 -0.32970166 -0.37715897\n",
      " -0.3142994  -0.31374955 -0.3136782  -0.31668603 -0.45923498 -0.31327307\n",
      " -0.3584618  -0.31373233 -0.3137109  -0.3145259  -0.31413102 -0.3145769\n",
      " -0.31591338 -0.3134485  -0.31374148 -0.31360948 -0.31396773 -0.3140032\n",
      " -0.40649772 -0.50686914 -0.31519267 -0.3308246  -0.74845695 -0.6542852\n",
      " -0.32145357 -0.31378728], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4457713  -0.38018006 -0.31772658 -0.361107   -0.3373772  -0.947019\n",
      " -0.4006251  -0.37766784 -0.3804396  -0.78911626 -0.81436074 -0.3142787\n",
      " -0.3141946  -0.33335644 -0.31638542 -0.319689   -0.3720367  -0.31327778\n",
      " -0.31461504 -0.34344527 -0.32662067 -0.3326125  -0.31895047 -0.36573547\n",
      " -0.5122629  -0.43472546 -0.313514   -0.44695598 -0.31387064 -0.31340334\n",
      " -0.31479725 -0.32446846], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3389499  -0.3804815  -0.9684713  -0.39300546 -0.9806887  -0.7320329\n",
      " -0.33586484 -0.31344777 -0.32688352 -0.31430638 -1.2073479  -0.33337516\n",
      " -0.4720828  -0.5334493  -0.35399693 -0.3181552  -0.31328517 -1.0763528\n",
      " -0.33887827 -0.32595116 -0.31447595 -0.31423342 -0.3181804  -0.31343925\n",
      " -0.3206683  -0.31370723 -0.31390852 -0.31460553 -0.34866735 -0.3172861\n",
      " -0.31341797 -0.320431  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31327498 -0.36601865 -0.3250884  -0.31489035 -0.3194732  -0.3136466\n",
      " -0.31556025 -0.3141514  -0.31338617 -0.331794   -0.31362385 -0.31337965\n",
      " -0.34370813 -0.31685287 -0.31394893 -0.33353785 -0.3719934  -0.31453216\n",
      " -0.46656772 -0.31416306 -0.3764013  -0.3133617  -0.32686332 -0.36582792\n",
      " -0.32114673 -0.3140849  -0.3376612  -0.33605832 -0.3379649  -0.38015357\n",
      " -0.8230573  -0.31419405], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36289355 -0.31562468 -0.72711134 -0.3227923  -0.4164071  -0.31379816\n",
      " -0.5076551  -0.31432414 -0.31399012 -0.41802025 -0.31371108 -0.31521207\n",
      " -0.34290573 -0.3143976  -0.31353822 -0.31380042 -0.31504086 -0.33790094\n",
      " -0.54508436 -0.36303172 -0.31855923 -0.31375462 -0.43075582 -0.31430689\n",
      " -0.31645855 -0.3148251  -0.36865616 -0.32354903 -0.3730113  -0.31433457\n",
      " -0.4794678  -0.36674318], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32207105 -0.40289468 -0.31340057 -0.31360784 -0.31570572 -0.31408426\n",
      " -0.31348795 -0.39365584 -0.31423044 -0.3137926  -0.33298004 -0.313833\n",
      " -0.32421893 -0.32909557 -0.31413695 -0.34145644 -0.8273468  -0.3150682\n",
      " -0.87862355 -0.31955037 -0.31334653 -0.56986076 -0.31665635 -0.313779\n",
      " -0.39387447 -0.3206067  -0.31950682 -0.32739344 -0.31381193 -0.32786593\n",
      " -0.3342865  -0.5678209 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35771343 -0.3137278  -0.31326565 -0.9645109  -0.3140255  -0.31687745\n",
      " -0.31403697 -0.39894038 -0.5391511  -0.313308   -0.31359485 -0.31601056\n",
      " -0.97808367 -0.33050078 -0.3134876  -0.3478101  -0.31945884 -0.43631428\n",
      " -0.31390172 -0.88864017 -0.35623193 -0.80508655 -0.46941084 -0.31536233\n",
      " -1.0810568  -0.31493065 -0.31791538 -0.31377202 -0.31371865 -0.31601918\n",
      " -1.1459736  -0.43985105], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32425308 -0.31328326 -0.35153097 -0.31388804 -0.31337598 -0.58815575\n",
      " -0.35629088 -0.31558782 -0.3135525  -0.3264774  -0.42826837 -0.3198486\n",
      " -0.31475776 -0.31327698 -0.34898275 -0.3359381  -0.3542192  -0.32890597\n",
      " -0.40046716 -0.31479907 -0.3231918  -0.31389162 -0.31365234 -0.31345755\n",
      " -0.31816316 -0.3231414  -0.31350243 -0.38842934 -0.33054438 -0.3134451\n",
      " -0.33411533 -0.31334662], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33123976 -0.34609222 -0.31439847 -0.34638458 -0.31380844 -0.3506968\n",
      " -0.9445573  -0.37722453 -0.31374276 -0.31424543 -0.31481814 -0.35427618\n",
      " -0.319303   -0.3149316  -0.31827408 -0.31462896 -0.32621902 -0.31389067\n",
      " -0.31544513 -0.33699796 -0.31459534 -0.32791927 -0.31342304 -0.3517071\n",
      " -0.32892236 -0.31334844 -0.32004344 -0.3133258  -1.2985034  -0.3149604\n",
      " -0.31943572 -0.3138803 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31439552 -0.36316353 -0.32829356 -0.3142464  -0.3194313  -0.3605434\n",
      " -0.3953395  -0.3519444  -0.33312374 -0.31332856 -0.31592816 -0.31434363\n",
      " -0.32193673 -0.36706638 -0.31326437 -0.6427223  -0.33958018 -0.34944984\n",
      " -0.31476524 -0.31959143 -0.31595093 -0.31340116 -0.35872674 -0.95342577\n",
      " -0.3335638  -0.41523546 -0.31438854 -0.41339928 -0.3176551  -0.45769948\n",
      " -0.31341362 -0.31389433], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32579464 -0.32363158 -0.4384906  -0.31804305 -0.31384206 -0.31327733\n",
      " -0.31352463 -0.31365392 -0.31334227 -0.4241788  -0.37538308 -0.31415722\n",
      " -0.31363258 -0.33520788 -0.31681937 -0.43771654 -0.31988096 -0.32526967\n",
      " -0.31799984 -0.5691553  -0.36097205 -0.31470066 -0.3149523  -0.31645232\n",
      " -0.33625498 -0.50296223 -0.3151569  -0.32088256 -0.39366123 -0.31351757\n",
      " -0.3371621  -0.31497893], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31422156 -0.41015998 -0.3141312  -0.8092569  -0.5734177  -0.31748867\n",
      " -0.33089104 -0.3164094  -0.338991   -0.31332657 -0.9227694  -0.3222616\n",
      " -0.31489992 -0.5741977  -0.31404498 -0.31930542 -0.3133148  -0.34798643\n",
      " -0.32706827 -0.34812203 -0.3154753  -0.85575783 -0.319591   -0.3236816\n",
      " -0.5285835  -0.40459466 -0.31516397 -0.3134354  -0.61021024 -0.5253916\n",
      " -0.31455323 -0.32795328], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4839716  -0.32456815 -0.4259071  -0.33253866 -0.31383747 -0.31724426\n",
      " -0.31617358 -0.31425074 -0.44280303 -0.59376097 -0.31396914 -0.38580188\n",
      " -0.317541   -0.31500807 -0.5038754  -0.3307507  -0.31615117 -0.31526756\n",
      " -0.33290303 -0.31345093 -0.31369373 -0.4417054  -0.31343123 -0.35394672\n",
      " -0.3222723  -0.31903338 -0.31450152 -0.31631905 -0.31528687 -0.3346109\n",
      " -0.313968   -0.31350797], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.36410698 -0.32279357 -0.40463617 -0.31894466 -0.3916304  -0.3925156\n",
      " -0.32305837 -0.32457316 -0.38132465 -0.3165939  -0.3237318  -0.4028296\n",
      " -0.32209498 -0.44743055 -0.31449136 -0.31340823 -0.31670612 -0.9139613\n",
      " -0.3132689  -0.42537382 -0.4313849  -0.31498137 -0.31537843 -0.31331524\n",
      " -0.33068046 -0.32816598 -0.3386748  -0.365381   -0.32495207 -0.3133602\n",
      " -0.3280736  -0.31997517], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31620184 -0.32806155 -0.31332526 -0.31626463 -0.48809084 -0.31336647\n",
      " -0.3190416  -0.31468344 -0.34799755 -0.31332865 -0.37871623 -0.316502\n",
      " -0.31354877 -0.318084   -0.34239817 -0.3862607  -0.31346068 -0.31459954\n",
      " -0.3601405  -0.35932022 -0.47082698 -0.31364328 -0.31403106 -0.31532514\n",
      " -0.45372853 -0.5398488  -0.31334287 -0.31387612 -0.3347411  -0.31394657\n",
      " -0.32528502 -0.31338078], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3346283  -0.6662226  -0.33390176 -0.3570001  -0.32040477 -0.5398934\n",
      " -0.31413832 -0.32034394 -0.35509107 -0.31361836 -0.3630253  -1.043908\n",
      " -0.31425536 -0.31859624 -0.48997262 -0.31505454 -0.84951895 -0.3134308\n",
      " -0.42253432 -0.3136047  -0.42878515 -0.31535557 -0.31338    -0.82841396\n",
      " -0.46297103 -0.32829288 -0.31408036 -0.3142343  -0.31384948 -0.38972676\n",
      " -0.31392124 -0.3177653 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32504594 -0.31447038 -0.33280843 -0.31689057 -0.4030036  -0.31401756\n",
      " -0.32398936 -0.313409   -0.3153987  -0.31351477 -0.34042427 -0.3273309\n",
      " -0.31358492 -0.3391171  -0.31835386 -0.57240444 -0.33612585 -0.31491125\n",
      " -0.513125   -0.31410682 -0.31441918 -0.31417856 -0.32955575 -0.32290414\n",
      " -0.3145723  -0.35548514 -0.31339037 -0.31678176 -0.31533757 -0.77188647\n",
      " -0.48554832 -0.3275292 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32390702 -0.3642791  -0.3138864  -0.3139459  -0.3136704  -0.4644844\n",
      " -0.34155244 -0.36684486 -0.44111377 -0.31679574 -0.32955799 -0.34572008\n",
      " -0.38230807 -0.39585966 -0.94065654 -0.35447925 -0.3139227  -0.31854364\n",
      " -0.31386515 -0.3217449  -0.48702022 -0.5423358  -0.31327176 -0.3136041\n",
      " -0.31558478 -0.5235394  -0.31332493 -0.31760138 -0.32280427 -0.3745034\n",
      " -0.31362727 -0.33034495], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32046    -0.31561556 -0.33326846 -0.31627533 -0.3702832  -0.3665115\n",
      " -0.31360486 -0.52738476 -0.32310006 -0.31466725 -0.31808528 -0.31462094\n",
      " -0.3679242  -0.31694388 -0.3152993  -0.31364417 -0.35306147 -0.3136627\n",
      " -0.46619207 -0.31603646 -0.31429872 -0.3297484  -0.34064883 -0.31355652\n",
      " -0.31426755 -0.31552652 -0.33258867 -0.9665804  -0.77135766 -0.31865302\n",
      " -0.31398898 -0.31457743], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3181968  -0.31768963 -0.47575036 -0.3133196  -0.3134124  -0.3156358\n",
      " -0.31329286 -0.31356418 -0.31593478 -0.31361473 -0.8198246  -0.35682616\n",
      " -0.4067143  -0.4775427  -0.3202028  -0.3212932  -0.3196148  -0.3757017\n",
      " -0.34699166 -0.32593456 -1.2124574  -0.31348577 -0.33641976 -0.3618577\n",
      " -0.31338888 -0.31982315 -0.36832005 -0.7594083  -0.31501374 -0.45450717\n",
      " -0.31656045 -0.3135033 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32885802 -0.33586943 -0.31329563 -0.3142483  -0.31543225 -0.31440717\n",
      " -0.3403603  -0.31672826 -0.31483048 -0.3319022  -0.31332266 -0.32255107\n",
      " -0.48245993 -0.31355375 -0.3138291  -0.31464392 -0.31410474 -0.31725955\n",
      " -0.32922664 -0.31462434 -0.31388596 -0.3436448  -0.3142854  -0.32569808\n",
      " -0.31950238 -0.31573537 -0.3154174  -0.31441554 -0.33211535 -0.54203856\n",
      " -0.31332964 -0.4533405 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33855152 -0.320833   -0.3136589  -0.317059   -0.31898522 -0.32530224\n",
      " -0.32120416 -1.0462433  -0.5045393  -0.31453687 -0.31424072 -0.83129585\n",
      " -0.3147633  -0.32587054 -0.31844765 -0.49833515 -0.33825818 -0.5205404\n",
      " -0.3594915  -0.31333572 -0.31352168 -0.31330705 -0.32682273 -0.31379068\n",
      " -0.31343603 -0.31662637 -0.46305102 -0.32094526 -0.33179158 -0.42699903\n",
      " -0.3149267  -0.34323376], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32028735 -0.33068886 -0.31381595 -0.32686985 -0.31335604 -0.39709267\n",
      " -0.31327856 -0.33022594 -0.31404534 -0.3136188  -0.3213507  -0.3358235\n",
      " -0.5058042  -0.33560476 -0.5015557  -0.34715328 -0.31352934 -0.323678\n",
      " -0.31346148 -0.31450754 -0.31432274 -0.31413484 -0.3170229  -0.31377763\n",
      " -0.31414068 -0.31340727 -0.43061733 -0.3411068  -0.3133175  -0.31720963\n",
      " -0.3187841  -0.31622565], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3589343  -0.314483   -0.31711316 -0.36905515 -0.31430307 -0.3463308\n",
      " -0.5730497  -0.31332552 -0.31388047 -0.324843   -0.31858394 -0.32037267\n",
      " -0.33086842 -0.3588004  -0.33015987 -0.3253761  -0.31440988 -0.316951\n",
      " -0.35571972 -0.3137446  -0.31340134 -0.31637585 -0.31327873 -0.315278\n",
      " -0.3143297  -0.31839937 -0.3270533  -0.31515962 -0.3878413  -0.32192937\n",
      " -0.31343952 -0.3326163 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31545714 -0.33533126 -0.31339288 -0.32580978 -0.31462175 -0.3139997\n",
      " -0.3233576  -0.31363022 -0.31682456 -0.31470162 -0.33948785 -0.6881822\n",
      " -0.31531563 -0.31688553 -0.33078143 -0.32355326 -0.31929687 -0.31332403\n",
      " -0.31380722 -0.32959658 -1.1838763  -0.31434834 -0.32664767 -0.7310296\n",
      " -0.31332344 -0.34106237 -0.31354502 -0.32989    -0.3133542  -0.323661\n",
      " -0.3445624  -0.31504348], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3137358  -0.3175757  -0.32002866 -0.7487186  -0.3150976  -0.4995013\n",
      " -0.3183684  -0.31329983 -0.31560826 -0.38662907 -0.31569085 -0.39681053\n",
      " -0.34355915 -0.31541348 -0.31510255 -0.31601977 -0.31411517 -0.5686353\n",
      " -0.31537148 -0.33590037 -0.3413828  -0.31724063 -0.48788214 -0.34413958\n",
      " -0.31351453 -0.39423573 -0.3378841  -0.31578413 -0.31359625 -0.31691834\n",
      " -0.31522205 -0.37022746], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31825683 -0.3267128  -0.3144917  -0.32182413 -0.3553847  -0.32216287\n",
      " -0.31378093 -0.3247036  -0.34341973 -0.39310032 -0.32150257 -0.3356\n",
      " -0.31538305 -0.4030819  -0.35692835 -0.32202226 -0.32963806 -0.31328458\n",
      " -0.31513596 -0.31478456 -0.31390408 -0.6025849  -0.31351984 -0.31634387\n",
      " -0.31515446 -0.32293704 -0.31392926 -0.32136416 -0.31406745 -0.31374016\n",
      " -0.9617939  -0.37756503], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31364354 -0.31335306 -0.35577133 -0.3151083  -0.31333888 -0.32461417\n",
      " -0.31331533 -0.3132648  -0.31348786 -1.1253346  -0.32235247 -0.3224226\n",
      " -0.3225154  -0.49506477 -0.31570154 -0.59066117 -0.31345442 -0.31331787\n",
      " -0.3135499  -1.2226609  -0.3193179  -0.34067553 -0.3182858  -0.3134166\n",
      " -0.31326514 -0.31442755 -0.3171642  -0.42289215 -0.31419405 -0.31342372\n",
      " -0.3134706  -0.3138579 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3134138  -0.31342286 -0.34504804 -0.31332082 -0.3195023  -0.3135966\n",
      " -0.36974734 -0.3179832  -0.3265149  -0.5813767  -0.3151957  -0.31394362\n",
      " -0.3375054  -0.3137731  -0.3133244  -0.3161289  -0.32186475 -0.3135457\n",
      " -0.34238604 -0.3461645  -0.31960285 -0.342643   -0.3140476  -0.34298068\n",
      " -0.47937837 -0.31361228 -0.33978152 -0.31511238 -0.31368762 -0.62326056\n",
      " -0.3742664  -0.31330183], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31703705 -0.536951   -0.31399152 -0.31333303 -0.37588164 -0.32928547\n",
      " -0.6014184  -0.315006   -0.33251894 -0.32081112 -0.31405467 -0.37242407\n",
      " -0.3906285  -0.31520024 -0.31362543 -0.3479174  -0.32209957 -0.31421512\n",
      " -0.31334653 -1.2896017  -0.3133352  -0.7792103  -0.51051116 -0.31708923\n",
      " -0.31401902 -0.31959236 -0.33435443 -0.3135789  -0.3817722  -0.31339732\n",
      " -0.3148653  -0.3160395 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34143695 -0.31359956 -0.38277376 -0.31705433 -0.33780223 -0.3148385\n",
      " -0.3268334  -0.31329417 -0.31339532 -0.3132675  -0.47451863 -0.3133412\n",
      " -0.48728096 -0.31339577 -0.3297694  -0.31626552 -0.31381115 -0.31350702\n",
      " -0.35995537 -0.7675868  -0.31531364 -0.5838145  -0.31773043 -0.31328648\n",
      " -0.32479596 -0.31514108 -0.3270172  -0.3209324  -0.3326592  -0.32196376\n",
      " -0.31337702 -0.3266894 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34771097 -0.502573   -1.1075544  -0.8491811  -0.32355198 -0.31965828\n",
      " -0.31654203 -0.6534867  -0.31429714 -0.55736613 -0.31334218 -0.31397375\n",
      " -0.3544786  -0.3807028  -0.3141932  -0.3544856  -0.34637538 -0.50608116\n",
      " -0.31338567 -0.33714256 -0.3135466  -0.31529772 -0.6415648  -0.31537592\n",
      " -0.3148874  -0.31406876 -0.31939638 -0.32184651 -0.3134375  -0.43585145\n",
      " -0.9041267  -0.37094072], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31355834 -0.3188405  -0.3135081  -0.31448483 -0.31520796 -0.31380028\n",
      " -0.33502847 -0.3133074  -0.31640002 -0.3132648  -0.3895617  -0.3288715\n",
      " -0.31431577 -0.6844983  -0.32775822 -0.3139733  -0.3544178  -0.35393977\n",
      " -0.31342041 -0.31460127 -0.31522858 -1.3046803  -0.31442964 -0.31468275\n",
      " -0.3132945  -0.31416813 -0.31330794 -0.3314382  -0.314736   -0.31429365\n",
      " -0.3223028  -0.37199527], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33501196 -0.31504104 -0.3137987  -0.31326532 -0.3142019  -0.3171255\n",
      " -0.48765787 -0.32256964 -0.31328815 -0.31327724 -0.36548382 -0.31706977\n",
      " -1.1138518  -0.7038902  -0.31643197 -1.2642555  -0.31358692 -0.31754977\n",
      " -0.31408703 -0.3138357  -0.3134821  -0.35328892 -0.35115924 -0.31343323\n",
      " -0.3152965  -0.33082142 -0.7462765  -0.64044833 -0.31328136 -0.31659007\n",
      " -0.32655978 -0.31370392], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32197508 -0.37296575 -0.31343907 -0.31367213 -0.36788717 -0.45410225\n",
      " -0.3137393  -0.32022598 -0.4354841  -0.35569066 -0.43196228 -0.31372386\n",
      " -0.3266807  -0.5737027  -0.3175416  -0.31464374 -0.31380156 -0.46725366\n",
      " -0.4318372  -0.3136392  -0.31699234 -0.31334043 -0.32353756 -0.3141829\n",
      " -0.3251041  -0.39365232 -0.31665644 -0.31671914 -0.42486763 -0.31629166\n",
      " -0.3381363  -0.4336088 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3168626  -0.31399482 -0.3135183  -0.3134856  -0.39301455 -0.31400126\n",
      " -0.31471974 -0.31677958 -0.31358194 -0.32281715 -0.31400737 -0.3211654\n",
      " -0.31383806 -0.31379294 -0.31464922 -0.31633693 -0.31402913 -0.31948215\n",
      " -0.31476435 -0.3153867  -0.38257587 -0.37937793 -0.3491356  -0.31357464\n",
      " -0.31485233 -0.3135222  -0.31413615 -0.31395513 -0.36004952 -0.37373224\n",
      " -0.3144373  -0.3244608 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33279818 -0.33403516 -0.36452144 -0.31334487 -0.3177376  -0.33176595\n",
      " -0.3152084  -1.2499529  -0.33148736 -0.3470606  -0.3179754  -1.1016822\n",
      " -0.31351236 -0.3135403  -0.31343278 -0.36690152 -0.32360512 -0.31925884\n",
      " -0.3146454  -0.3139802  -0.31418517 -0.44030994 -0.4229066  -0.37079608\n",
      " -0.43344468 -0.33734792 -0.32869267 -0.31492412 -0.313304   -0.34975952\n",
      " -0.34041044 -0.5399196 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34605747 -0.3139667  -0.4874454  -1.0756745  -0.3133183  -0.31337127\n",
      " -0.36851493 -0.31428853 -0.332528   -0.33937576 -0.31409732 -0.31532773\n",
      " -0.31368902 -0.37784842 -0.8246517  -0.31367606 -0.31358987 -0.4394174\n",
      " -0.31386515 -0.32191986 -0.3634293  -0.3147795  -0.31330374 -0.3359357\n",
      " -0.31329966 -1.297762   -0.31342494 -0.5960189  -0.46614933 -0.3142724\n",
      " -0.42286366 -0.31374225], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.349647   -0.3139295  -0.3137279  -0.31655064 -0.73993814 -0.5371156\n",
      " -0.31962043 -0.748558   -0.31345162 -0.3150126  -0.31884873 -0.3477129\n",
      " -0.31335437 -0.32262695 -0.8841888  -0.31415218 -1.1896613  -0.42708468\n",
      " -0.57336164 -0.31384903 -0.39453834 -0.3135478  -0.31346685 -0.31337467\n",
      " -0.31619114 -0.31740528 -0.31543523 -0.31500068 -0.3341598  -0.31328848\n",
      " -0.31340325 -0.3138339 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.313359   -0.31938106 -0.32624876 -0.318008   -0.31341434 -0.35432503\n",
      " -0.31336403 -0.31411326 -0.31349692 -0.31871977 -0.31489062 -0.3315659\n",
      " -0.3132845  -0.31328762 -0.3373192  -0.3239686  -0.31407475 -0.3208515\n",
      " -0.31347522 -0.32311103 -0.31665036 -0.31339836 -0.3335591  -0.93979377\n",
      " -0.412471   -0.31436488 -0.3861454  -0.51392335 -0.31362143 -0.36246836\n",
      " -0.3160109  -1.2655048 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3132974  -0.31495962 -1.1810361  -0.31481335 -0.32276785 -0.31379226\n",
      " -0.31341842 -0.38887998 -0.31835482 -0.32211763 -0.37804544 -0.3200445\n",
      " -0.50993514 -0.8187058  -0.31519797 -0.32122457 -0.31349805 -0.3137102\n",
      " -0.32760155 -0.35565683 -0.33130044 -0.31341457 -0.31504738 -0.32179907\n",
      " -0.91682667 -0.3276566  -0.3294352  -0.32590538 -0.3134457  -0.3136796\n",
      " -0.33158958 -0.41844898], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3134179  -0.38113812 -0.31500807 -0.6607885  -0.31326216 -0.31595823\n",
      " -0.48024672 -0.32072714 -0.3418687  -0.3166711  -0.34703514 -0.31453216\n",
      " -0.3136785  -0.31785542 -0.3209278  -0.3467478  -0.32796437 -0.31355226\n",
      " -0.31404272 -0.31405336 -0.3139836  -0.3168176  -0.38882875 -0.31717065\n",
      " -0.31357926 -0.3134335  -1.2551244  -0.31332177 -0.350954   -0.36395267\n",
      " -0.32875094 -0.3141259 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33307546 -0.41755003 -0.31388283 -0.31328413 -0.6874915  -0.31826586\n",
      " -0.32476953 -0.31374973 -0.31636012 -0.59914994 -0.3501984  -0.45683068\n",
      " -0.31336483 -0.341887   -0.43370277 -0.44508505 -0.31963775 -0.43152753\n",
      " -0.54513884 -0.31339622 -0.31547627 -0.35075608 -0.73484844 -0.31328946\n",
      " -0.31337094 -0.31341684 -0.32289016 -0.31375295 -0.32852677 -0.32004398\n",
      " -0.31381035 -0.31351784], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31919464 -0.32225037 -0.3140032  -0.31328622 -0.34685498 -1.0176948\n",
      " -0.31811643 -0.31474635 -0.32117096 -1.2985257  -0.3135234  -0.33075327\n",
      " -0.39129934 -0.3405108  -0.33900195 -0.32232413 -0.3133136  -0.7087754\n",
      " -0.48759228 -0.33981267 -0.33068517 -0.3962951  -0.31338906 -0.31823462\n",
      " -0.31436062 -0.3256015  -0.31357342 -0.31330976 -0.3132946  -0.31379807\n",
      " -0.34334725 -0.31435007], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32032162 -0.34386086 -0.31404793 -0.313285   -1.003083   -0.372503\n",
      " -0.35867143 -0.3408746  -0.3144011  -0.31522536 -1.1494371  -0.47134423\n",
      " -0.318728   -0.31510314 -0.33744824 -0.7639569  -0.61782134 -0.31713262\n",
      " -0.36131185 -0.87144566 -0.31794953 -0.31937006 -0.38864517 -0.32589042\n",
      " -0.31380934 -0.3158341  -0.3134971  -0.31433293 -0.35694563 -0.31377447\n",
      " -0.3135539  -0.3975274 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31401607 -0.31331393 -0.31556165 -0.5345476  -0.32346088 -0.31514257\n",
      " -0.3141492  -0.73198766 -0.31394082 -0.32630512 -0.3133983  -0.35456923\n",
      " -0.31328675 -0.33722723 -0.32955232 -0.33604595 -0.3158089  -0.31349143\n",
      " -0.31917167 -0.31374773 -0.3189602  -0.31327787 -0.31974903 -0.36539257\n",
      " -0.38065448 -0.86068    -0.3136776  -0.31339175 -0.31655324 -0.39864033\n",
      " -0.31337702 -0.3350674 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31828874 -0.3317141  -0.31365392 -0.32309532 -0.40729338 -0.31954268\n",
      " -0.3189327  -0.3140067  -0.3139444  -0.3182022  -0.31366315 -0.32237387\n",
      " -0.32932407 -0.33059192 -0.3137283  -0.31342557 -0.31852344 -0.32534596\n",
      " -0.3146829  -0.31331098 -0.32450208 -0.31384912 -0.32865638 -0.6158834\n",
      " -0.315064   -0.31858748 -0.38770127 -0.31615013 -0.31401476 -0.3316872\n",
      " -0.32693502 -0.32533926], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.2392211  -0.31358457 -0.32905936 -0.3959289  -0.39511868 -0.31577483\n",
      " -0.31764182 -0.32383218 -0.37975857 -0.32279503 -0.3172109  -0.314296\n",
      " -0.335751   -0.31340265 -0.3327815  -0.5474207  -0.31583375 -0.31329545\n",
      " -0.53439105 -1.1379474  -0.3148714  -0.34888056 -0.3137689  -0.3245974\n",
      " -0.3145434  -0.31338033 -0.31341407 -1.2994986  -0.36074054 -0.34830675\n",
      " -0.40726346 -0.31346276], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31368867 -0.47034505 -0.36242604 -0.40935424 -0.3144338  -0.31334174\n",
      " -0.391638   -0.3135121  -0.32029057 -0.31370297 -0.31367022 -0.32207692\n",
      " -0.31332883 -0.34787178 -0.37264755 -0.32666978 -0.38201174 -0.32660288\n",
      " -0.37483895 -0.31334785 -0.3377097  -0.32711947 -0.40716106 -0.32073846\n",
      " -0.3174844  -0.31705752 -0.32015988 -0.31337553 -0.3132966  -0.3135823\n",
      " -0.36033067 -0.33684587], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3147205  -0.3142105  -0.3289723  -0.3177232  -0.3134842  -0.3133527\n",
      " -0.31658417 -0.31429967 -0.3138903  -0.3142289  -0.3305348  -0.32046023\n",
      " -0.31538436 -0.3197298  -0.31868517 -0.32969183 -0.31340396 -0.31338844\n",
      " -0.35455218 -0.31716648 -0.32252032 -0.31415594 -0.31488895 -0.31347382\n",
      " -0.31366515 -0.31334087 -0.3132944  -0.31482178 -0.3833882  -0.42385477\n",
      " -0.35632527 -0.32069945], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32177204 -0.31407547 -0.38154966 -0.34279186 -0.3140356  -0.32909608\n",
      " -0.3135391  -0.43246862 -0.3475259  -0.31397846 -0.65570647 -0.31363517\n",
      " -0.38984334 -0.3142241  -0.32708192 -0.33018327 -0.31677455 -0.31666806\n",
      " -0.31771532 -0.3134936  -0.36091405 -0.3243947  -0.31523928 -0.3138082\n",
      " -0.3281307  -0.53555113 -0.4525733  -0.3136311  -0.31704754 -0.38430586\n",
      " -0.31760418 -0.31374076], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31358868 -0.3139748  -0.31827658 -0.31327638 -0.31328258 -0.34627858\n",
      " -0.31438386 -0.3136438  -0.31327003 -0.32615072 -0.31362727 -0.6134887\n",
      " -0.31502277 -0.31431377 -0.3408963  -0.31328997 -0.3134598  -0.5919819\n",
      " -0.31837612 -0.8111007  -0.35396782 -0.44781396 -0.63966554 -0.44673812\n",
      " -0.31419006 -0.31361192 -0.37832215 -0.31391925 -0.31384033 -0.31818\n",
      " -0.40459338 -0.4051618 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4052339  -0.3133257  -0.48438376 -0.31532878 -0.31340718 -0.42861664\n",
      " -0.31342983 -0.32575917 -0.3549373  -0.31371212 -0.31547368 -0.47280288\n",
      " -0.3134369  -0.31416166 -0.34017795 -0.31434616 -0.32383013 -0.31349343\n",
      " -0.31687677 -0.3161192  -0.3230621  -0.31340796 -0.31451243 -0.31988382\n",
      " -0.3243616  -0.31328213 -0.31343314 -0.31834066 -0.31917575 -0.31352445\n",
      " -0.33366728 -0.35759056], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31703106 -0.31465212 -0.35500616 -0.3985841  -0.81748587 -0.4767007\n",
      " -0.49938476 -0.31385714 -0.31337756 -0.31368214 -0.31574336 -0.3132863\n",
      " -0.31420416 -0.32569256 -0.3153805  -0.7918432  -0.38605538 -0.33567235\n",
      " -0.3465214  -0.31645283 -0.32185516 -0.36151814 -0.3139188  -0.32790852\n",
      " -0.31327343 -0.36776495 -0.9854395  -0.33223173 -0.3136007  -0.62025213\n",
      " -0.5881417  -0.335331  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3228627  -0.33026698 -0.31648827 -0.31585202 -0.31402817 -0.31630567\n",
      " -0.3306499  -0.3135201  -0.32672918 -0.3704692  -0.36549225 -0.31704634\n",
      " -0.31391558 -0.3361562  -0.35597387 -1.0144506  -0.7332975  -0.46455234\n",
      " -0.33032095 -0.31451598 -0.5255026  -0.3299626  -0.3143183  -0.4095295\n",
      " -0.4478379  -0.31457448 -0.35312688 -0.3133901  -0.3140239  -0.3457841\n",
      " -0.32961586 -0.31511185], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33672875 -0.3858955  -0.3294004  -0.31358755 -0.32007262 -0.6902133\n",
      " -1.3110317  -0.35155663 -0.31514612 -1.1647089  -1.124652   -0.31479988\n",
      " -0.31349918 -0.31611067 -0.31380975 -0.3223483  -0.47191766 -0.3137966\n",
      " -0.31575674 -0.3149443  -0.32286316 -0.33705568 -0.31601307 -0.31842807\n",
      " -0.34942016 -0.31359702 -0.31408748 -0.3196129  -0.31375986 -0.31346434\n",
      " -0.3218715  -0.31401435], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5183031  -0.3136927  -0.31349832 -0.32645494 -0.33322838 -0.31832403\n",
      " -0.3611787  -0.31392238 -0.31387386 -0.9165689  -0.31513777 -0.32891214\n",
      " -0.31418875 -0.32019943 -0.36623597 -0.3698562  -0.3145393  -0.31630984\n",
      " -0.31406024 -0.31793904 -0.35808772 -0.69027185 -0.31416777 -0.31361908\n",
      " -0.31390843 -0.3143975  -0.3138649  -0.31942576 -0.41795722 -0.31433126\n",
      " -0.3156358  -0.31358877], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31330296 -0.31347418 -0.3132708  -0.75549734 -0.31868702 -0.31402043\n",
      " -0.39022702 -0.34100237 -0.3142827  -0.31423873 -0.31461954 -0.33320045\n",
      " -0.32463622 -0.5844294  -0.98972803 -0.31520423 -0.3135756  -0.31538826\n",
      " -0.31617844 -0.31343734 -0.3143802  -0.88100624 -0.31435537 -0.31360373\n",
      " -0.3231597  -0.32662886 -0.32066435 -0.5497968  -0.31331524 -0.31327552\n",
      " -0.3324306  -0.3269328 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3136999  -0.31333336 -0.3134281  -0.31600863 -0.3446348  -0.33122408\n",
      " -0.31735858 -0.32504913 -0.31410262 -0.31484652 -0.32263163 -0.31834638\n",
      " -0.4928572  -0.36805928 -0.31388935 -0.67602414 -0.31369922 -0.3536073\n",
      " -0.34724113 -0.31345683 -0.49821985 -0.32314932 -0.31523448 -0.35330164\n",
      " -0.3302939  -0.43692118 -0.88173914 -0.3414422  -0.3136756  -0.32661793\n",
      " -0.32345742 -0.57013005], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31649905 -0.31334826 -0.3151836  -0.37945607 -0.31598935 -0.31453452\n",
      " -0.38730505 -0.45396265 -0.32982314 -0.31493387 -0.3134098  -0.3553413\n",
      " -0.33078948 -0.3793648  -0.3208882  -0.31374705 -0.33923805 -0.3251046\n",
      " -0.32529327 -0.31346574 -0.31339473 -0.40835288 -0.42593834 -0.34108323\n",
      " -0.31342462 -0.3137823  -0.313281   -0.3134604  -0.32942516 -0.3136913\n",
      " -0.34344527 -0.83660483], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31349126 -0.3279282  -0.8242861  -0.31375775 -0.33104825 -0.3239567\n",
      " -0.3137134  -0.33599442 -0.55450994 -0.65931475 -0.34447676 -0.33939683\n",
      " -0.3433662  -0.31342113 -0.5943071  -0.3639886  -0.3133493  -0.31355163\n",
      " -0.40306246 -0.34223503 -0.31417263 -0.33847395 -0.31335056 -0.31943762\n",
      " -0.32370645 -0.45590556 -0.3850835  -0.31335282 -0.4184597  -0.3370185\n",
      " -0.3803737  -0.31506765], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3136027  -0.3265123  -0.31347314 -0.31376263 -0.9383886  -0.31407547\n",
      " -0.31407815 -0.3139594  -0.32479924 -0.32118228 -0.32031667 -0.31353587\n",
      " -0.950161   -0.3136865  -0.3168647  -0.5227517  -0.31450728 -0.35848778\n",
      " -0.32434806 -0.3151302  -0.48855865 -0.31509498 -0.77116346 -0.32803133\n",
      " -0.5915256  -0.31476757 -1.2016108  -0.32903004 -0.31409976 -0.7436938\n",
      " -0.4188877  -0.31551775], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31769666 -0.3142307  -0.3574267  -0.31400868 -0.37784284 -0.3140335\n",
      " -0.942894   -0.31769136 -0.3132627  -0.8877616  -0.31382325 -0.3139608\n",
      " -0.3436187  -0.63232577 -0.31404254 -0.33219153 -0.32780755 -0.31738383\n",
      " -0.3263071  -0.34777153 -0.3216923  -0.34627387 -0.6363497  -0.31517848\n",
      " -0.82090294 -0.3142759  -0.31377387 -0.31447098 -0.3136122  -0.33108488\n",
      " -0.31395903 -0.31612092], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31642085 -0.31735015 -0.31534722 -0.31577197 -0.32375672 -0.33073896\n",
      " -0.31460214 -0.6803305  -0.3187965  -0.984573   -0.32549226 -0.31329912\n",
      " -0.45945758 -0.33698595 -0.80690795 -0.3135172  -0.3140901  -0.31849933\n",
      " -0.32998574 -0.3143458  -0.32406825 -0.3626572  -0.31347078 -0.31836522\n",
      " -0.31341407 -0.35517263 -0.38002566 -0.3231547  -0.31616777 -0.6246979\n",
      " -0.3522517  -0.31343654], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31879276 -0.32042503 -0.3137553  -0.37985128 -0.3355354  -0.313285\n",
      " -0.31474826 -0.3558287  -0.31349343 -0.4960869  -0.39896894 -0.31822377\n",
      " -0.3586288  -0.31610292 -0.31334078 -0.31363082 -0.3212365  -0.31516796\n",
      " -0.9648663  -0.31620103 -0.33405137 -0.32904986 -0.31328213 -0.31372926\n",
      " -0.3435375  -0.31412265 -0.32414135 -0.3944127  -0.31504688 -0.32640344\n",
      " -0.3135552  -0.3134769 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3866136  -0.31331438 -0.313434   -0.31595963 -0.32126078 -0.33240873\n",
      " -0.34183866 -0.31516144 -0.3256831  -0.313612   -0.3136284  -0.31362316\n",
      " -0.31349352 -0.31771767 -0.45443225 -0.31498927 -0.31343028 -0.32659075\n",
      " -0.32946908 -0.39331892 -0.3235253  -0.31348777 -0.33726484 -0.3563645\n",
      " -0.49207667 -0.32692495 -0.31364685 -0.3688252  -0.31744388 -0.3265971\n",
      " -0.4110109  -0.31408036], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.313669   -0.3139786  -0.31352514 -0.3132696  -0.3247914  -0.31915376\n",
      " -0.36153442 -0.31896546 -0.32974437 -0.32276493 -0.31337094 -0.3132803\n",
      " -0.314245   -0.31362212 -0.44885325 -0.41715452 -0.93501276 -0.58447254\n",
      " -0.3206253  -0.31702498 -0.43806276 -0.3181889  -0.3289469  -0.3179557\n",
      " -0.91028404 -0.31330374 -0.8358506  -0.31578127 -0.3160772  -0.31589732\n",
      " -0.33015087 -0.31705752], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32018065 -0.32605588 -0.52894294 -0.36069435 -0.31370288 -0.3153792\n",
      " -0.3158361  -0.33175105 -0.31667364 -0.31722108 -0.49482554 -0.3320949\n",
      " -0.33036962 -0.31345326 -0.31573224 -0.5692841  -0.33977056 -0.31758004\n",
      " -1.0970664  -0.3524639  -0.31356603 -0.3138493  -0.31329826 -0.31402898\n",
      " -0.3386122  -0.3142926  -0.5337007  -0.32920718 -0.44664654 -0.32241273\n",
      " -0.3152298  -0.31417865], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34750044 -0.3133739  -0.31350476 -0.33595395 -0.34194696 -0.31434518\n",
      " -0.31357047 -0.8975811  -0.9795656  -0.3139458  -0.32598853 -0.31341955\n",
      " -0.3162287  -0.3203994  -1.1346292  -0.3911852  -0.34420693 -0.31331003\n",
      " -0.31982237 -0.3276925  -0.31475782 -0.31394738 -0.3380792  -0.31594318\n",
      " -0.31331462 -0.31363997 -0.31437966 -0.32606304 -0.34089175 -0.41780674\n",
      " -0.31848997 -0.31606966], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.2671815  -0.40038952 -0.3371843  -0.31561956 -0.31334427 -0.3145849\n",
      " -0.3138473  -0.3148119  -0.31339836 -0.34015977 -0.31382892 -0.31344178\n",
      " -0.3882852  -0.3163173  -0.31462026 -0.31839624 -1.3077776  -0.36796555\n",
      " -0.31421363 -0.31326646 -0.31497544 -0.36821073 -0.34634528 -0.3132857\n",
      " -0.32948065 -0.3768943  -0.31372797 -0.3132688  -0.37254277 -0.34954548\n",
      " -0.31341633 -0.3133162 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31993258 -0.46358895 -0.31341556 -0.31561816 -0.3155861  -0.3135086\n",
      " -0.31426388 -0.31340447 -0.33211663 -0.31352273 -0.32936645 -0.315054\n",
      " -0.313361   -0.31360096 -0.3141128  -0.31338513 -0.5639246  -0.31440032\n",
      " -0.31440789 -0.31416237 -0.31389067 -0.31425256 -0.34324738 -0.31339636\n",
      " -0.32638323 -0.31383345 -0.31326425 -0.31391174 -0.31374696 -0.5550323\n",
      " -0.33225977 -0.32664502], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32236776 -0.31871742 -0.7649963  -0.46230012 -0.41768327 -0.36580387\n",
      " -0.31462932 -0.5290462  -0.31333634 -0.40699595 -0.5274488  -0.31654543\n",
      " -0.31327167 -0.3133155  -0.3163558  -0.31873608 -0.32159573 -0.31849283\n",
      " -0.31433493 -0.31507775 -0.32690647 -0.3134138  -0.31394884 -0.31550828\n",
      " -0.31397516 -0.3269916  -0.32506385 -0.34724072 -0.34431642 -0.31329268\n",
      " -0.33984348 -0.31948265], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33440247 -0.32869482 -0.7927137  -0.313762   -0.3175909  -0.31368884\n",
      " -0.3138748  -0.31933758 -0.31340465 -0.31341764 -0.31522363 -0.31523588\n",
      " -0.32668552 -0.31340533 -0.3134389  -0.45792446 -1.2281929  -0.38510823\n",
      " -0.3586756  -0.34762308 -0.31684887 -0.3137966  -0.3259991  -0.32341576\n",
      " -0.32360485 -0.31331864 -0.3190897  -0.33141717 -0.31500754 -0.3135091\n",
      " -0.6065196  -0.32886094], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3139532  -0.3683927  -0.31366977 -0.5319494  -0.3134225  -0.64561063\n",
      " -0.3133108  -0.31330732 -0.31372622 -0.31518388 -0.31616437 -0.34518582\n",
      " -0.31328395 -0.31577832 -1.0338998  -0.3163412  -0.31353387 -0.3140516\n",
      " -1.1036233  -0.32431185 -0.31534374 -0.31345093 -0.3140294  -0.3138891\n",
      " -0.32026806 -1.3013957  -0.31521466 -0.32195657 -0.3146577  -0.38171774\n",
      " -0.31643677 -0.31359005], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.3092322  -0.31326705 -0.3136845  -0.33958215 -0.32811487 -0.45187837\n",
      " -0.49388695 -0.4534633  -0.3190159  -0.31388527 -0.31386566 -0.3165556\n",
      " -0.32779816 -0.31326532 -1.1672535  -0.37615272 -0.32968557 -0.31903037\n",
      " -0.3819216  -0.49664044 -0.31510654 -0.3160155  -0.40817115 -0.36359033\n",
      " -0.3313843  -0.31443346 -0.31380785 -0.33322582 -0.3133352  -0.46049702\n",
      " -0.36995924 -0.31327072], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.74515426 -0.33614537 -0.31536877 -0.36803338 -0.31504044 -0.35774085\n",
      " -0.3935603  -0.33027846 -0.6485182  -0.31803688 -0.31472754 -0.3166005\n",
      " -0.31355965 -0.31788865 -0.33577767 -0.31380445 -0.34862536 -0.31469476\n",
      " -0.33279032 -0.33195156 -0.31450868 -0.314591   -0.3234363  -0.32216036\n",
      " -0.3153038  -0.31382647 -0.31876737 -0.3952585  -0.50626063 -0.3135254\n",
      " -0.31449264 -0.3135788 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3166823  -0.34091514 -0.3489322  -0.31881624 -0.32320085 -0.313619\n",
      " -0.36572802 -0.32992506 -0.33820954 -0.37792715 -0.32935905 -0.3266562\n",
      " -0.31346172 -0.31357795 -0.31394082 -0.3157352  -0.3135499  -0.3184409\n",
      " -0.31401217 -0.91622996 -0.3296187  -0.31536958 -0.31471092 -0.31577986\n",
      " -0.34687388 -0.31409392 -0.31385094 -0.31331253 -0.34526584 -0.31374887\n",
      " -0.31344885 -0.3150059 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31991455 -0.31436044 -0.3538772  -0.31413466 -0.31743    -0.3143168\n",
      " -0.32511967 -0.3137851  -0.31424123 -0.3178052  -0.32960618 -0.3132871\n",
      " -0.645863   -0.43252757 -0.31404376 -0.3182694  -0.31656924 -0.32026088\n",
      " -0.31661883 -0.31327498 -0.31506288 -0.31328154 -0.3134565  -0.33102572\n",
      " -0.31337598 -0.42609382 -0.32852024 -0.31348673 -0.31576136 -0.31499666\n",
      " -0.31376666 -0.37571895], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31430542 -0.5463908  -0.38644207 -0.3301453  -0.31358877 -0.31381273\n",
      " -0.32023108 -0.32092    -0.46121314 -0.31465298 -0.31357569 -0.32543164\n",
      " -0.3759151  -0.31458595 -0.31339046 -0.39360252 -0.3133012  -0.3447597\n",
      " -0.7027228  -0.31330907 -0.31507227 -0.32991743 -0.31400067 -0.31395894\n",
      " -0.3296626  -0.35020012 -0.33017898 -0.3198666  -0.31476218 -0.3575541\n",
      " -0.31370592 -0.3141839 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.603249   -0.34948304 -0.43111598 -0.31424865 -0.31346914 -0.31450692\n",
      " -0.31367674 -0.31904987 -0.3678176  -0.3133793  -0.58884823 -0.31953382\n",
      " -0.3871649  -0.31754586 -0.32018653 -0.31330252 -0.36502397 -0.33731553\n",
      " -0.37354174 -0.34011796 -0.5200412  -0.3428766  -0.3141384  -0.31634188\n",
      " -0.3171005  -0.3154047  -0.32811376 -0.37648836 -0.31350118 -0.3137032\n",
      " -0.31366307 -0.31331307], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31440648 -0.313342   -0.51712847 -0.3280976  -0.33258757 -0.49408364\n",
      " -0.31612962 -0.44806075 -0.3312138  -0.313735   -0.32151508 -0.31341806\n",
      " -0.31479734 -0.3253193  -0.31390643 -0.4028794  -0.31375575 -0.3168904\n",
      " -0.32579842 -1.2090778  -0.3505488  -0.69297755 -0.31379807 -0.31461233\n",
      " -0.32006344 -0.31420913 -0.33900696 -0.3137851  -0.31351697 -0.32685196\n",
      " -0.4109407  -0.3510589 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33367088 -0.31327108 -0.31380287 -0.32186553 -0.315364   -0.3149965\n",
      " -0.34744707 -0.31813014 -0.3137954  -0.31412363 -0.31329364 -0.37774497\n",
      " -0.3174373  -0.3135121  -0.32519683 -0.31332937 -0.3161588  -0.31415662\n",
      " -0.552392   -0.3428802  -0.31730312 -0.6248416  -0.3143573  -0.3273296\n",
      " -1.0161808  -0.31387535 -0.3478196  -0.32599068 -0.31536722 -0.31364548\n",
      " -0.3133753  -0.31473094], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3132714  -1.127286   -0.32496583 -0.31437358 -0.31538635 -0.9601295\n",
      " -0.34574977 -0.31369722 -0.31733626 -0.31327358 -0.69154936 -0.31345892\n",
      " -0.32277423 -0.31363982 -0.31372803 -0.3133387  -0.31341937 -0.32568172\n",
      " -0.48066744 -0.31388456 -0.49034035 -0.7521976  -0.31933045 -0.31476507\n",
      " -0.3259443  -0.3141023  -0.3255296  -0.31395817 -0.31371978 -0.4334909\n",
      " -0.31350312 -0.31588644], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3134302  -0.31625423 -0.31587896 -0.31353483 -0.32356283 -0.31545705\n",
      " -0.31393388 -0.31623998 -0.3138574  -0.31334513 -0.31354764 -0.31396836\n",
      " -0.45450035 -0.31334713 -0.31357315 -0.3147748  -0.31341556 -0.32157776\n",
      " -0.35688123 -0.31375846 -0.34743544 -0.31638098 -0.3133739  -0.37594524\n",
      " -0.3354523  -0.33053625 -0.31464237 -0.37450603 -0.44048494 -0.31791562\n",
      " -0.3158501  -0.3135072 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.7439797  -0.35358468 -0.3132973  -0.3248673  -0.3152833  -0.3379046\n",
      " -0.31461746 -0.34972423 -0.3449453  -0.33895677 -0.3134172  -0.3146435\n",
      " -1.1592873  -0.31360608 -0.43232208 -0.3134252  -0.31398177 -0.4878659\n",
      " -0.31590176 -0.31379226 -0.31757718 -0.36167982 -1.3055898  -0.313306\n",
      " -0.31329757 -0.3141689  -0.3136987  -0.37892446 -0.31330165 -0.5516333\n",
      " -0.31335333 -0.3261519 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32467535 -0.35882416 -0.32045454 -0.39161986 -0.3207492  -0.33105466\n",
      " -0.3135999  -0.7962619  -0.42538545 -0.31359068 -0.3132811  -0.31555957\n",
      " -0.3241168  -0.33019328 -0.31557748 -0.31454653 -0.32557583 -0.35082567\n",
      " -0.31450796 -0.3285756  -0.36902162 -0.3220713  -0.3167695  -1.1478401\n",
      " -0.32051933 -0.3312187  -0.3141573  -0.31394485 -0.7665597  -0.3136534\n",
      " -0.3454785  -0.34363574], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31428304 -0.31497204 -0.31337312 -0.3133075  -0.35321772 -0.3420534\n",
      " -0.3133292  -0.5526218  -0.31363302 -0.315046   -0.35388815 -0.4698395\n",
      " -0.31328964 -0.31410247 -0.40929914 -0.31406546 -0.31359023 -0.31600204\n",
      " -0.3275511  -0.31783035 -0.31332335 -0.3165897  -0.6253855  -1.1508453\n",
      " -0.3356484  -0.31749493 -0.3172809  -0.31516865 -0.31331646 -0.36862567\n",
      " -0.32240143 -0.8968363 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3141023  -0.36580774 -0.32088283 -0.31328824 -0.33178595 -0.31343278\n",
      " -0.5520549  -0.31329033 -0.31424928 -0.3163033  -0.31569058 -0.4380503\n",
      " -0.31327683 -0.5508924  -0.31512785 -0.44256857 -0.3148158  -0.31344578\n",
      " -0.3188288  -0.31327543 -0.31332248 -0.46377409 -0.31333223 -0.4036542\n",
      " -0.3205171  -0.31712446 -0.4682952  -0.31339046 -0.31327358 -0.31338033\n",
      " -0.3235204  -0.31336632], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31328142 -0.31550688 -0.3133258  -0.4583869  -0.31507862 -0.3143412\n",
      " -0.3140267  -0.3153667  -0.31392637 -0.3149483  -0.3349885  -0.31778282\n",
      " -0.31574735 -0.31598943 -0.33209133 -0.31454462 -0.31343532 -0.31619167\n",
      " -0.5604791  -0.6198609  -0.31391576 -0.3232181  -0.31511647 -0.6609789\n",
      " -0.4054691  -0.31327003 -0.31477708 -0.31739667 -0.32546556 -0.31341293\n",
      " -0.31395346 -0.32471412], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32131144 -0.31838116 -0.34826872 -0.31348577 -0.32756934 -0.31361365\n",
      " -0.32073128 -0.33537915 -0.35926247 -0.33518162 -0.3242498  -0.37903708\n",
      " -0.3134705  -0.31365636 -0.31990036 -0.33083573 -0.315722   -0.34443426\n",
      " -0.37825435 -0.34767157 -0.349381   -0.33183214 -0.3269749  -0.3135019\n",
      " -0.3306654  -1.0495634  -0.31852257 -0.4050552  -0.31326532 -0.31531268\n",
      " -0.34502473 -0.31946066], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5099435  -0.61167437 -0.32459918 -0.95984304 -0.32914034 -0.31331542\n",
      " -0.31337145 -0.3136785  -0.31336448 -0.33218452 -0.31567398 -0.31893218\n",
      " -0.3133387  -0.31709546 -0.31485286 -0.31356925 -0.31506193 -0.32332104\n",
      " -0.31328404 -0.93185735 -0.31680164 -0.31362325 -0.31346583 -0.31836754\n",
      " -0.32160163 -0.5508367  -0.31333938 -0.31467387 -0.3133961  -0.3277448\n",
      " -0.3501158  -0.31663325], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34090066 -0.31381264 -0.3134137  -1.2395893  -0.7107331  -0.36332694\n",
      " -0.63172966 -0.31742704 -0.5515227  -0.3182387  -0.3175928  -0.31369278\n",
      " -0.5822176  -0.34359145 -0.40247324 -0.3293791  -0.31352627 -0.32763323\n",
      " -0.3139674  -0.32646984 -0.38552043 -0.31380758 -0.3996547  -0.31339672\n",
      " -0.5440631  -0.3135121  -0.31327933 -0.9438949  -0.35510477 -0.31328344\n",
      " -0.3320009  -0.9327913 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5959586  -0.32541648 -0.31707835 -0.41293555 -0.35064837 -0.31478637\n",
      " -0.3143035  -0.32793877 -0.42489427 -0.31353047 -0.31332597 -0.58596665\n",
      " -0.31526268 -0.33947697 -0.3301412  -0.31386995 -0.3717963  -0.3179903\n",
      " -0.31359485 -0.3151001  -0.31751105 -0.4909165  -0.3133575  -0.31414896\n",
      " -0.3133109  -0.31452885 -0.31453532 -0.31434834 -0.31449586 -0.31891555\n",
      " -0.50091565 -0.31694692], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31334713 -0.48769447 -0.31343228 -0.36453438 -0.31326523 -0.36539918\n",
      " -0.3133089  -0.3230722  -0.3394442  -0.3139566  -0.31505758 -0.99388766\n",
      " -0.31348386 -0.3212434  -0.32104644 -0.3230574  -0.34711155 -0.3269565\n",
      " -0.6521373  -0.3135687  -0.32522267 -0.31364956 -0.31365052 -0.5972104\n",
      " -0.31542957 -0.3170439  -0.4561353  -0.34012815 -0.34231138 -0.3556285\n",
      " -0.3285168  -0.38704085], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32484508 -0.31350964 -0.31326845 -0.56564146 -0.40437782 -0.32002026\n",
      " -0.3144737  -0.31331638 -0.3351917  -0.8772022  -0.3146808  -0.31390017\n",
      " -0.3610195  -0.31461033 -0.31553477 -0.3136703  -0.32443804 -0.3872548\n",
      " -0.3145743  -0.31741196 -0.33528838 -0.32622778 -0.31835714 -0.3134423\n",
      " -0.56237906 -0.3159718  -0.31336606 -0.31389678 -0.3132708  -0.31540704\n",
      " -0.3139675  -0.31433144], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33062953 -0.3164459  -0.31491697 -0.3137033  -0.3147635  -1.1079152\n",
      " -0.31532633 -0.42782316 -0.31575188 -0.31333172 -0.31854206 -0.31750393\n",
      " -0.3167584  -0.422041   -0.3195632  -0.31425667 -0.31558147 -0.32067445\n",
      " -0.31373763 -0.43303996 -0.3169061  -0.3292671  -0.31518492 -0.35917258\n",
      " -0.31940833 -0.36138284 -0.38581517 -0.33032045 -0.3183105  -0.31349945\n",
      " -0.31326488 -0.31740466], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3278453  -0.3136588  -0.41659194 -0.3155007  -0.31417167 -0.337408\n",
      " -0.3505817  -0.34597138 -0.31368572 -0.39453304 -0.3134308  -0.3138121\n",
      " -0.31850767 -0.32266304 -0.3135296  -0.39799824 -0.31944108 -0.31415272\n",
      " -0.31339097 -0.31546375 -0.31756303 -0.31566024 -0.33861136 -0.31985706\n",
      " -0.31346625 -0.31369904 -0.34508544 -0.36108887 -0.5736278  -0.31457013\n",
      " -0.46534085 -0.31476018], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.319329   -0.31725138 -0.31328222 -0.31332073 -0.31327942 -0.31331882\n",
      " -0.44240767 -0.32753918 -0.3142858  -0.31431663 -0.31332874 -0.47175026\n",
      " -0.3142301  -0.36109868 -0.39678857 -0.31544018 -0.32117113 -0.31381324\n",
      " -0.33309844 -0.41208163 -0.3226019  -0.31409392 -0.39018562 -0.316021\n",
      " -0.31653675 -0.31776997 -0.3133089  -0.3206529  -0.31593615 -0.35243055\n",
      " -0.36271083 -0.3154375 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3138439  -0.31389982 -0.3161098  -0.31506538 -0.31343463 -0.4236795\n",
      " -0.33223498 -0.391501   -0.32643405 -0.32288033 -0.31420833 -0.40684056\n",
      " -0.3142898  -0.31492472 -0.3206254  -0.31362283 -0.37382698 -0.31334278\n",
      " -0.31332806 -0.37073708 -0.31793445 -0.31346503 -0.3143855  -0.4660371\n",
      " -0.33406836 -0.32503974 -0.458141   -0.98757446 -0.9398739  -0.31814495\n",
      " -0.34386864 -0.31767818], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3152586  -0.3136493  -0.3217373  -0.31720346 -0.31453687 -0.31984088\n",
      " -0.315324   -0.31330332 -0.31616828 -0.31341606 -0.31497997 -0.45495403\n",
      " -0.4395208  -0.47158265 -0.31675735 -0.31404987 -0.3705424  -0.3245231\n",
      " -0.31399414 -0.3168554  -0.3133976  -0.3142496  -0.31364277 -0.31348306\n",
      " -0.31344265 -0.5225258  -0.31953037 -0.46358395 -0.31346267 -0.85837615\n",
      " -0.31761986 -0.6925918 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31433997 -0.31375393 -0.32205135 -0.5573881  -0.31582204 -0.3163968\n",
      " -0.31680268 -0.31390443 -0.3158275  -0.36926672 -0.31336525 -0.9590107\n",
      " -0.313495   -0.31456393 -0.3450427  -0.31395867 -0.31377736 -0.6127466\n",
      " -0.31660068 -0.31638646 -0.31904727 -0.3141467  -0.31336343 -0.3224301\n",
      " -0.6855875  -0.31342095 -0.43590102 -0.32932138 -0.364963   -0.3143868\n",
      " -0.39191845 -0.3229026 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31455445 -0.3222274  -0.3135836  -0.3133509  -0.3147468  -0.31686053\n",
      " -0.98288697 -0.31373242 -0.42488056 -0.32287574 -0.35156134 -0.317411\n",
      " -0.32300815 -0.31366724 -0.31383294 -0.31552052 -0.34487742 -0.4253726\n",
      " -0.31774786 -0.31975725 -0.3144808  -0.31328136 -0.31375045 -0.31404454\n",
      " -0.31457117 -0.3225894  -0.31593207 -0.31326967 -0.3275384  -0.32626545\n",
      " -0.31535044 -0.4968492 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31389344 -0.3611055  -0.31414947 -0.40758306 -1.1885471  -0.31387743\n",
      " -0.31371027 -0.32415637 -0.439834   -0.31351575 -0.31929556 -0.3214659\n",
      " -0.46819526 -0.31332275 -0.3154379  -0.47036797 -0.3350909  -0.31356514\n",
      " -0.31350103 -0.4336972  -0.3184808  -0.35671136 -0.31362683 -0.31861672\n",
      " -0.31582117 -0.3169127  -0.43820214 -0.45316935 -0.9111054  -0.3133237\n",
      " -0.31330296 -0.31673113], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31350783 -0.4525404  -0.31568867 -0.3150407  -0.31351173 -0.34993714\n",
      " -0.31357569 -0.4675511  -0.3241235  -0.31741804 -0.4038451  -0.32904968\n",
      " -0.31346244 -0.31387544 -0.3168158  -0.3211982  -0.49692485 -0.31339473\n",
      " -0.31354868 -0.3728429  -0.5400419  -0.35455292 -0.31337407 -0.31461033\n",
      " -0.3145133  -0.39933577 -0.31820625 -0.31401417 -0.31454617 -0.31805015\n",
      " -0.31411552 -0.7633529 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31368667 -0.31550217 -0.313411   -0.31584245 -0.31492516 -0.31408304\n",
      " -0.3132871  -0.60302645 -0.31336057 -0.31330252 -0.5279803  -0.9283029\n",
      " -0.31394815 -0.31346154 -0.31365907 -0.3715884  -0.3221185  -0.3140524\n",
      " -0.3418749  -0.31424004 -0.3132804  -0.32783365 -0.46334326 -0.31503704\n",
      " -0.31531373 -0.31402096 -0.31584576 -0.4670256  -0.35644796 -0.31643736\n",
      " -0.31355825 -0.31362098], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31362307 -0.3362319  -0.32069027 -0.34612334 -0.3428409  -0.43523768\n",
      " -0.32463804 -0.31332815 -0.318936   -0.31330532 -0.3521336  -0.3136494\n",
      " -0.7797936  -0.31333607 -0.34510848 -0.32201326 -0.31349397 -0.32384822\n",
      " -0.31661665 -0.31374878 -0.31448185 -0.31361464 -0.36772922 -0.3150167\n",
      " -0.34645993 -0.5577092  -0.31729642 -0.32531437 -0.36327064 -0.92427063\n",
      " -0.44176608 -0.31513977], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31620017 -0.31389678 -0.31339324 -0.3136295  -0.94790566 -0.40162596\n",
      " -0.31345615 -0.32566905 -0.3305438  -0.3136303  -0.31400275 -0.31727335\n",
      " -0.31334096 -0.6081143  -0.31658494 -0.32440433 -0.3329666  -0.31428444\n",
      " -0.43487936 -0.31424412 -0.96359265 -0.31907222 -0.5555591  -0.4024394\n",
      " -0.52858996 -0.40356836 -0.33858874 -0.54230547 -0.36383137 -0.8128058\n",
      " -0.31820843 -0.31888053], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31364208 -0.34642243 -0.32086673 -0.3137833  -0.43966758 -0.31652936\n",
      " -0.31335732 -0.31357116 -0.31467307 -0.60963404 -0.3149022  -0.4161321\n",
      " -0.31352967 -0.31504887 -0.3207171  -0.31372327 -0.34709615 -0.31692728\n",
      " -0.36366963 -0.588727   -0.46414384 -0.33369222 -0.31400877 -0.4155145\n",
      " -0.317899   -0.31400022 -0.31487566 -0.3143614  -0.31467143 -0.40755704\n",
      " -0.31360358 -0.31678984], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33917606 -0.31329092 -0.68226844 -0.31411657 -0.31442425 -0.31417045\n",
      " -0.65064794 -0.31370986 -0.4110871  -0.31344074 -0.3244613  -0.31568876\n",
      " -0.31481996 -0.3669786  -0.36148757 -0.3803984  -0.31394413 -0.31635144\n",
      " -0.31780225 -0.31346443 -0.46226728 -0.32993758 -0.31627405 -0.31376848\n",
      " -0.3132763  -0.3133583  -0.3161597  -0.3779984  -0.3133664  -0.31387326\n",
      " -0.34800798 -0.31406492], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31653187 -0.45148158 -0.32456136 -0.32525092 -0.31392175 -0.32787424\n",
      " -0.31331813 -0.41658214 -0.31437498 -0.3441829  -0.31356376 -0.31701428\n",
      " -0.3132776  -0.37331337 -0.32122475 -0.31333992 -0.31349283 -0.31330827\n",
      " -0.5868314  -0.31348315 -0.3190094  -0.31350476 -0.77865076 -0.31333077\n",
      " -0.31380305 -0.4418563  -0.31365705 -0.31968823 -0.31708202 -0.6017264\n",
      " -0.31414407 -0.3159327 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3133088  -0.34207577 -0.31354058 -0.31859383 -0.3142067  -0.38893026\n",
      " -0.3437153  -0.31326243 -0.33447886 -0.33396894 -0.70192444 -0.35104236\n",
      " -0.31584418 -0.9176341  -0.3188854  -0.31341693 -0.31613657 -0.5434222\n",
      " -0.31330225 -0.31697097 -0.3181799  -0.31382167 -0.31368598 -0.3142126\n",
      " -0.3166019  -0.31533426 -0.31405813 -0.33308494 -0.31618783 -0.3168348\n",
      " -0.31697643 -0.31333354], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3230595  -0.31893393 -0.3138305  -0.7594359  -0.40563112 -0.32694042\n",
      " -0.3139633  -0.3138798  -0.3166448  -0.31430697 -0.31419528 -0.3140584\n",
      " -0.31347835 -0.3203634  -0.3504561  -0.3133108  -0.31354877 -0.3440882\n",
      " -0.31457743 -0.32700655 -0.38825002 -0.77584684 -0.31396174 -0.31492376\n",
      " -0.38798591 -0.330019   -0.3167182  -0.33525008 -0.313617   -0.318439\n",
      " -0.3135384  -0.33777517], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.47086516 -0.390352   -0.35702237 -0.31363285 -0.3336357  -0.7345644\n",
      " -0.31340075 -0.320733   -0.3188698  -0.3142658  -0.35038942 -0.3136426\n",
      " -0.32598937 -0.36018556 -0.36458686 -0.40851521 -1.2683843  -0.32727545\n",
      " -0.34613568 -0.31967923 -0.32719898 -0.31327176 -0.31390965 -0.6492033\n",
      " -0.3133163  -0.31936762 -0.31519493 -0.32332215 -0.31345746 -0.35204735\n",
      " -0.3191106  -0.31333023], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3339644  -0.3262037  -1.1928949  -0.32167283 -0.31367806 -0.36596128\n",
      " -0.31342417 -0.3314882  -0.3152244  -0.31611067 -0.3148893  -0.3863595\n",
      " -0.3139816  -0.33637422 -0.3157898  -0.3697777  -0.34000808 -0.36751562\n",
      " -0.35513368 -0.3359248  -0.4196988  -0.5937656  -0.3292076  -0.32133573\n",
      " -0.32217565 -0.3166877  -0.31336805 -0.31374922 -0.31390792 -0.31367013\n",
      " -0.31338698 -1.1469145 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31363946 -0.31982243 -0.31494778 -0.31341493 -0.3940933  -0.37671658\n",
      " -0.31331235 -0.31340456 -0.3302322  -0.37029687 -0.33431023 -0.3393705\n",
      " -0.31854355 -0.31628567 -0.6030308  -0.3258332  -0.42085224 -0.35896853\n",
      " -0.3136188  -0.33261484 -0.31328884 -0.31339157 -0.35141674 -0.5034709\n",
      " -0.31335568 -0.31329146 -0.32295775 -0.336662   -0.31993163 -0.31330323\n",
      " -0.31329128 -0.4899177 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.289083   -0.35410434 -0.5221693  -0.33516535 -0.31565955 -0.3255061\n",
      " -0.31453782 -0.3954843  -0.7082896  -0.31566536 -0.31359068 -0.75917566\n",
      " -0.38806883 -0.315071   -0.3135308  -0.31525347 -0.31810132 -0.31328318\n",
      " -0.31659755 -0.31411308 -0.31403297 -0.31356853 -0.32284468 -0.31427398\n",
      " -0.31712604 -0.32464045 -0.331586   -0.4920863  -0.31335124 -0.31348926\n",
      " -0.31368145 -0.8808583 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3633858  -0.8042991  -0.31331778 -0.31967533 -0.31376857 -0.3139222\n",
      " -0.71802574 -0.31918538 -0.31341642 -0.32267797 -0.31786704 -0.32020903\n",
      " -0.31359005 -0.31335506 -1.2170318  -0.31620938 -0.3142806  -0.31336248\n",
      " -0.31361872 -0.31406066 -0.31337553 -0.3170227  -0.3156312  -0.31359783\n",
      " -0.31341615 -0.5740096  -0.314026   -0.44405854 -0.60856086 -0.31655446\n",
      " -0.31329137 -1.2042458 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31762916 -0.32351702 -0.31352472 -0.31341755 -0.3146213  -0.3261333\n",
      " -0.3243779  -0.41324583 -0.3139822  -0.31411734 -0.31675476 -0.54097563\n",
      " -0.31464034 -0.31326208 -0.31427476 -0.31626865 -0.31502226 -1.0686474\n",
      " -0.97995365 -0.44069633 -0.315957   -0.31335646 -0.3136527  -0.46465924\n",
      " -0.3366894  -0.3136168  -0.31364164 -0.318661   -0.31362396 -0.37878054\n",
      " -0.33678356 -0.5014388 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31381682 -0.33446315 -0.32327807 -0.31336832 -0.31326932 -0.31965646\n",
      " -0.31391132 -0.317007   -0.33162272 -0.38862512 -0.43023023 -0.32122543\n",
      " -0.31891608 -0.7497838  -0.31419927 -0.31337702 -0.32694584 -0.42115146\n",
      " -0.5628146  -0.3145945  -0.31967768 -0.31330356 -0.47759974 -0.3437727\n",
      " -1.0196147  -1.2927977  -0.3731438  -0.34492376 -0.334407   -0.31769067\n",
      " -0.3403648  -0.52452534], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31332842 -0.3388861  -0.3133101  -0.44501996 -0.32382736 -0.35969958\n",
      " -0.35683852 -0.32762045 -0.31840545 -1.1177157  -0.33434802 -0.32232708\n",
      " -0.31399179 -0.33061427 -0.4022828  -0.31348142 -0.32094476 -0.3263962\n",
      " -0.32551628 -0.32220495 -0.31828603 -0.3134302  -0.3137986  -0.31382203\n",
      " -0.33127835 -0.46111882 -0.3388844  -1.0416247  -0.3142477  -0.31431854\n",
      " -0.3297975  -0.31342793], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31425536 -0.3679337  -0.3211201  -0.32150662 -0.31424657 -1.1701273\n",
      " -0.31330305 -0.5472432  -0.3229731  -0.3136965  -0.3158655  -1.0084738\n",
      " -0.32691085 -0.31372073 -0.31373546 -0.3272243  -0.32131022 -0.90604293\n",
      " -0.31335157 -0.31359494 -0.3575281  -0.31547165 -0.3140166  -0.32433996\n",
      " -0.31431532 -0.31326827 -0.31890672 -0.31910506 -0.31487036 -0.3285315\n",
      " -0.31534207 -0.31521213], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31698373 -0.31346765 -0.40161783 -0.3159942  -0.3401912  -0.31345135\n",
      " -0.32623878 -0.3139578  -0.3138054  -0.32266012 -0.3151671  -1.0010872\n",
      " -0.3733786  -0.31333354 -0.31431994 -0.42427    -0.3995509  -0.31406936\n",
      " -0.58428305 -0.31336126 -0.31521398 -0.3170907  -0.3270165  -0.33266562\n",
      " -0.313334   -0.31410062 -0.31346452 -0.32183564 -0.31999558 -0.32042208\n",
      " -0.31327385 -0.3501163 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31326827 -0.3710855  -0.32899392 -0.3308819  -0.3139256  -0.31466708\n",
      " -0.3133047  -0.31347644 -0.38191378 -0.31351557 -0.31326896 -0.31340152\n",
      " -0.32306236 -0.31799144 -0.3353194  -0.3669343  -0.31939396 -0.31421435\n",
      " -0.31401572 -0.31548443 -0.31347322 -0.31341502 -0.32849494 -0.31780103\n",
      " -0.315352   -0.34787574 -0.3213027  -0.31327003 -0.31420052 -0.32460073\n",
      " -0.31361768 -0.3142807 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3325585  -0.31326225 -0.3138372  -0.33654708 -0.32602862 -0.33039457\n",
      " -0.31431073 -0.7361971  -0.31589347 -0.31583107 -0.33023724 -0.32110387\n",
      " -0.31342602 -0.31396043 -0.3465369  -0.31459534 -0.3219602  -0.31361392\n",
      " -0.3398371  -0.32210708 -0.3218149  -0.31422994 -0.31637898 -0.31377143\n",
      " -0.31334975 -0.31754118 -0.31377423 -0.384858   -0.3158762  -0.32355946\n",
      " -0.31790477 -0.3133902 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32839733 -0.38959152 -0.31476933 -0.3138297  -0.31455028 -0.33804584\n",
      " -0.31680495 -0.41990733 -0.31328884 -0.3136039  -0.36909974 -1.2720077\n",
      " -0.31412676 -0.3165966  -0.41824403 -0.31911692 -0.31481203 -0.32986516\n",
      " -0.35703155 -0.39783144 -0.31751087 -0.34757844 -0.3286931  -0.38768116\n",
      " -0.3132626  -0.31835863 -0.31361723 -0.3224004  -0.31342232 -0.39164308\n",
      " -0.31339836 -0.31496987], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31345022 -0.31363457 -0.45476925 -0.31344813 -0.3190794  -0.41282606\n",
      " -0.32211322 -0.40020826 -0.3137669  -0.40242106 -0.31326723 -0.31343636\n",
      " -0.31366655 -0.31469962 -0.31356943 -0.31342268 -0.31346226 -0.31349677\n",
      " -0.33035213 -1.2114959  -0.31359172 -0.31337756 -0.31452894 -0.31362987\n",
      " -0.3218467  -0.6201858  -0.31794825 -1.284802   -0.35727528 -1.07299\n",
      " -0.35630983 -0.31327665], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32630986 -0.6075545  -0.31346008 -0.323847   -0.33135828 -0.31385\n",
      " -0.3533013  -0.31326306 -0.9006707  -0.39450526 -0.31329644 -0.38967687\n",
      " -0.366503   -0.31449056 -0.31334794 -0.31357116 -0.314298   -0.32290605\n",
      " -1.2698438  -0.31393158 -0.31461388 -0.3136067  -0.3851304  -0.31331927\n",
      " -0.3134104  -0.49996    -0.31370828 -0.72097313 -0.31660676 -0.3136804\n",
      " -0.3303386  -0.3213965 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.324341   -0.31332543 -0.31356803 -0.3135444  -0.33280766 -0.3132627\n",
      " -0.57587135 -0.33171812 -0.3267584  -0.31350258 -0.31805882 -0.36943653\n",
      " -0.33382356 -0.31340212 -0.37326807 -0.31674355 -0.3133589  -0.35957727\n",
      " -0.33008447 -0.31340787 -0.3136391  -0.43228698 -0.3284661  -0.31443268\n",
      " -0.48496908 -0.31381193 -0.3133006  -0.3198008  -0.3160025  -0.32243526\n",
      " -0.31336397 -0.31333467], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3132777  -0.32232198 -0.31327987 -0.31676334 -0.31379974 -0.31900558\n",
      " -0.3309455  -0.3162251  -0.32075202 -1.1779301  -0.31331253 -0.36379302\n",
      " -0.31337214 -0.32025275 -0.7690978  -0.39538187 -0.31369373 -1.2787069\n",
      " -0.38478506 -0.36248338 -0.3309395  -0.31939587 -0.71839017 -0.8671757\n",
      " -0.3139072  -0.3133204  -0.31436497 -0.31339237 -0.3244856  -0.3166025\n",
      " -0.31464958 -0.9968944 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31449354 -0.31348133 -0.31340405 -0.3135588  -0.31328171 -0.3338396\n",
      " -0.31380722 -0.32375395 -0.31511846 -0.31349972 -0.31453243 -0.31330776\n",
      " -0.31419945 -0.3919075  -0.31555617 -0.5295616  -0.33377385 -0.31375635\n",
      " -0.34945202 -0.55444896 -1.0957332  -0.31343037 -0.43760064 -0.31391028\n",
      " -0.3154666  -0.31339166 -0.31357482 -0.349717   -0.31342915 -0.3312376\n",
      " -0.31386244 -0.3134586 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3147455  -0.32256496 -0.3139854  -0.36903363 -0.31396383 -0.31411308\n",
      " -0.3158701  -0.36490422 -0.313291   -0.31416368 -0.3160128  -0.31344134\n",
      " -0.37572208 -0.3137954  -0.32559055 -0.31388074 -0.31348515 -0.3133569\n",
      " -0.31334618 -0.31578717 -0.45127374 -0.31337145 -0.3137515  -0.32402593\n",
      " -0.3146702  -0.31505305 -0.31331995 -0.37754232 -0.3147259  -0.3134931\n",
      " -0.31468952 -0.315717  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31524187 -0.31345406 -0.34999233 -0.3136993  -0.32407895 -0.31637257\n",
      " -0.31605992 -0.5223702  -0.3136877  -0.31372517 -0.41039836 -0.63715804\n",
      " -0.32883698 -0.31369182 -0.31361836 -0.31803352 -0.31326556 -0.7859165\n",
      " -0.31359616 -0.35858172 -0.32658532 -0.3352328  -0.31335002 -0.3139148\n",
      " -0.3290351  -0.31411996 -0.32384872 -0.3753119  -0.3134133  -0.31326827\n",
      " -0.41834745 -0.33883613], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34763098 -0.31451407 -0.31761372 -0.37451136 -0.3160825  -0.31507236\n",
      " -0.31358248 -0.3132634  -0.3311402  -0.32814166 -0.39248502 -0.46791956\n",
      " -0.52443933 -0.31764278 -0.39035684 -0.3755065  -0.31361637 -0.3671265\n",
      " -0.31335813 -0.39761344 -0.31480622 -0.34788558 -0.31327683 -0.32778373\n",
      " -0.525067   -0.3262277  -0.3165345  -0.31801432 -0.3134497  -0.31390494\n",
      " -0.3227511  -0.3217849 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32023266 -0.31328273 -0.41428566 -0.31356105 -0.3190346  -0.31430045\n",
      " -0.3223681  -0.3137245  -0.31337067 -0.31999975 -0.32171863 -0.44296005\n",
      " -0.3140558  -0.31370682 -0.3137013  -0.31799543 -0.7349789  -0.3629531\n",
      " -1.1048517  -0.31392264 -0.31396452 -0.32740822 -0.3144957  -0.3273454\n",
      " -0.33447638 -0.5012139  -0.31328952 -0.31347924 -0.3202111  -0.31406936\n",
      " -1.2025912  -0.3138001 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31352296 -0.31647587 -0.31795007 -0.37828803 -0.3151757  -0.6019179\n",
      " -0.32449985 -0.31370306 -0.32122758 -0.32500488 -0.3133108  -0.314108\n",
      " -0.3358259  -0.31326288 -0.3135898  -0.35007867 -0.31339306 -0.36931303\n",
      " -0.36124748 -0.31770352 -0.3154152  -0.31326854 -0.31544244 -0.31438342\n",
      " -0.34636214 -0.31326497 -0.32117528 -0.34035498 -0.31474364 -0.3139788\n",
      " -0.31519186 -0.6593772 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3146949  -0.31372744 -0.32305303 -0.9401089  -1.136714   -0.33544362\n",
      " -0.32589585 -0.32468054 -0.31345084 -0.32905963 -0.31539923 -0.31336012\n",
      " -0.31429315 -0.5289587  -0.334431   -0.50028175 -0.3179601  -0.31354415\n",
      " -0.39746293 -0.3150753  -0.33057684 -0.31718698 -0.3144441  -0.82711077\n",
      " -0.31336248 -0.37792274 -0.35371828 -0.3212741  -0.31592798 -0.31621304\n",
      " -0.37440264 -0.40962005], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31603184 -0.32243603 -0.32325476 -0.31460163 -0.31610963 -0.313271\n",
      " -1.0626671  -0.31522483 -0.31544802 -0.31367928 -0.3133922  -0.31422043\n",
      " -0.31543845 -0.31620556 -0.8458811  -0.31629393 -0.31327245 -0.33606368\n",
      " -0.3178137  -0.3132676  -0.5062473  -0.3288454  -0.31341475 -0.31683558\n",
      " -0.3135722  -0.33480626 -0.31335682 -0.31970114 -0.31652728 -0.31420714\n",
      " -0.3280772  -0.31791937], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33128503 -0.31448692 -0.31369573 -0.3138013  -0.31522006 -0.31358004\n",
      " -0.31576684 -0.313533   -0.3132811  -0.31347603 -0.4003356  -0.318332\n",
      " -0.4852541  -0.32948595 -0.31378528 -0.31575406 -0.38821056 -1.162161\n",
      " -0.34047067 -0.4728643  -0.32892126 -0.31451452 -0.3167801  -0.31403932\n",
      " -0.6919711  -0.3138439  -0.3243036  -0.31459796 -0.3133042  -0.31788734\n",
      " -0.31336275 -0.37205657], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32007712 -0.317323   -0.55862606 -0.3133237  -0.31361854 -0.31571224\n",
      " -0.35053477 -0.31354085 -0.323009   -0.693107   -0.31419006 -0.31398603\n",
      " -0.31329215 -0.33933163 -0.31421375 -0.4893661  -0.31384286 -0.31921023\n",
      " -0.31342915 -0.3388128  -0.32545987 -0.5635192  -0.31346574 -1.2878454\n",
      " -0.31415382 -0.31417176 -0.31342173 -0.31954205 -0.31909752 -0.4645898\n",
      " -0.31983683 -0.31340274], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31960312 -0.31475002 -0.31329834 -0.31330505 -0.4327875  -0.414385\n",
      " -0.6777951  -0.3142066  -0.31402105 -0.3132648  -0.3156241  -0.32437867\n",
      " -0.31678253 -0.3133311  -0.31431437 -0.3152265  -0.35296205 -0.31339577\n",
      " -0.32018185 -0.315961   -0.31327367 -0.31330907 -0.3138222  -0.31379023\n",
      " -0.4544772  -0.31818128 -0.3215022  -0.3140348  -0.3155934  -0.50904036\n",
      " -0.9932993  -0.31585827], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.92812836 -0.31367734 -0.31522703 -0.3605951  -0.34302187 -0.4502967\n",
      " -0.34754592 -1.1471019  -1.0435641  -0.9592844  -0.31335682 -0.32145107\n",
      " -0.3137102  -0.32910964 -0.31993258 -0.32547003 -0.31470728 -0.31414443\n",
      " -0.3141163  -0.34232238 -0.31561974 -0.3141022  -0.3165497  -0.31457543\n",
      " -0.31333318 -0.31347984 -0.34057567 -0.3160844  -0.3189561  -0.34449324\n",
      " -0.31348413 -0.31328127], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-1.0319278  -0.34473705 -0.31367072 -0.5811225  -0.3140531  -0.40921998\n",
      " -0.3135836  -0.3537911  -0.31467482 -0.3753368  -0.33042917 -0.3133026\n",
      " -0.3211336  -0.31353107 -0.32451284 -0.3144394  -0.44193545 -0.71233577\n",
      " -0.31402922 -0.31333318 -0.35136035 -0.34209338 -0.32714605 -1.1385355\n",
      " -0.323337   -0.3181419  -0.3133176  -0.86301875 -0.32064122 -0.31582028\n",
      " -0.31828648 -0.31363842], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35412294 -0.3211222  -0.56929475 -0.4432215  -0.3146174  -0.53556395\n",
      " -0.33806214 -0.31492943 -0.35927346 -0.32525417 -0.3137656  -0.33939633\n",
      " -0.31344187 -0.65850043 -0.31473356 -0.31376907 -0.33254072 -0.31384233\n",
      " -0.31335604 -0.31683248 -0.3134383  -0.31545913 -0.31443164 -0.31508473\n",
      " -0.31326678 -0.31411552 -0.3134755  -0.3142099  -0.316441   -0.32348073\n",
      " -0.3146616  -0.3140463 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31327263 -0.31366742 -0.5617015  -0.32132596 -0.34031284 -0.3166123\n",
      " -0.3161767  -0.3142752  -0.31382734 -0.32099482 -0.32536447 -0.31764138\n",
      " -0.3133345  -0.31374347 -0.31771377 -0.4988168  -0.363006   -0.32383978\n",
      " -0.3135717  -0.3317365  -0.35281563 -0.33799312 -0.31327438 -0.31724948\n",
      " -0.3137649  -1.1298456  -0.32136825 -0.3141331  -0.3134897  -0.31605002\n",
      " -0.31457978 -0.31419328], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31903988 -0.31690568 -0.31401703 -0.42011312 -0.31539348 -0.3174661\n",
      " -0.31405804 -0.43745333 -0.3135818  -0.37225336 -0.31329808 -0.31512386\n",
      " -0.3290061  -0.36168364 -0.31366366 -1.0838614  -0.31495282 -0.3566466\n",
      " -0.3147641  -0.3297874  -0.32642037 -0.31350905 -0.32228053 -0.42320132\n",
      " -0.31336972 -0.32085168 -0.31710935 -0.31328788 -0.3150254  -1.1019964\n",
      " -0.4730477  -0.31365705], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3135216  -0.31358546 -0.3310669  -0.3133969  -0.3148035  -0.36051762\n",
      " -1.2059245  -0.31331116 -0.33063412 -0.31331027 -1.3046043  -0.96769357\n",
      " -0.32154292 -0.33283663 -0.31388682 -0.31373215 -0.3544831  -1.1221725\n",
      " -0.32251385 -0.54805046 -0.31341878 -0.3182023  -0.31856668 -0.3149973\n",
      " -0.32763565 -0.31827348 -0.31358302 -0.31426597 -0.31328404 -0.3132966\n",
      " -0.41244093 -0.401     ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31657365 -0.46776962 -0.31366932 -0.3464999  -0.3135282  -0.31527174\n",
      " -0.32908237 -0.31653917 -0.31398943 -0.39684653 -0.31822595 -0.44300857\n",
      " -0.3454498  -0.32063925 -1.2018604  -0.31410664 -0.37288463 -0.3138769\n",
      " -0.32859817 -0.3442642  -0.32909155 -0.31364694 -1.0576979  -0.31362438\n",
      " -0.31434572 -0.35269517 -0.35564077 -1.2426361  -0.31588906 -0.39750475\n",
      " -0.40133864 -0.3731205 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31326765 -0.31503817 -0.32245082 -0.3173005  -0.31687155 -0.3137744\n",
      " -0.34793964 -0.31357038 -0.31498623 -0.3145012  -0.46409228 -0.31343323\n",
      " -0.31423002 -0.31776616 -0.31374156 -0.32768452 -0.5966434  -0.3133569\n",
      " -0.3232991  -0.31348515 -0.31336743 -0.38091302 -0.31483692 -0.31871092\n",
      " -0.3148687  -0.35874897 -0.31680757 -0.31823117 -0.3425641  -0.6605368\n",
      " -0.31328326 -0.31348056], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31760755 -0.31347305 -0.51163375 -0.3183131  -0.31596082 -0.31355\n",
      " -0.32556087 -0.313925   -0.31342015 -0.31344578 -0.44524646 -0.31360704\n",
      " -0.3140611  -0.31656453 -0.3185692  -0.32455283 -1.2705603  -0.3136691\n",
      " -0.3133873  -0.31357464 -0.31333372 -0.31882715 -0.5932729  -0.31354466\n",
      " -0.3152933  -0.31350136 -0.3133148  -0.31329328 -0.35888246 -0.31401014\n",
      " -0.31511047 -0.6749165 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31333083 -0.31365505 -0.31399447 -0.33270827 -0.36118558 -0.32063535\n",
      " -0.42174023 -0.40596923 -0.34758484 -0.3246146  -0.313871   -0.31347793\n",
      " -0.3146872  -0.31751227 -0.31463653 -0.31327036 -0.31337634 -0.3384235\n",
      " -0.39084172 -0.3140235  -0.73018974 -0.3185451  -0.3134606  -0.40861806\n",
      " -0.31328693 -1.2181748  -0.3190346  -0.31351784 -0.3138581  -0.32727152\n",
      " -0.41831505 -0.31340867], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3207105  -0.31375802 -0.3137689  -0.31630322 -0.32405403 -0.3137642\n",
      " -0.31345972 -0.34068182 -0.5609987  -0.31793082 -0.3355111  -0.31332475\n",
      " -0.43793136 -0.31327003 -0.31326985 -0.31389415 -0.39606777 -0.31327194\n",
      " -0.31328607 -1.2993267  -0.31326252 -0.31329703 -0.32234597 -0.7481882\n",
      " -0.3138527  -0.4186435  -0.313384   -0.32503518 -0.31398046 -0.31330016\n",
      " -0.5787044  -0.31329703], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31346172 -0.31352872 -0.31388196 -0.35057986 -0.6603637  -0.33004394\n",
      " -0.31336954 -0.31380853 -0.32642633 -0.31463793 -0.31809118 -0.31511882\n",
      " -0.32052773 -0.33532307 -0.44869182 -0.33839583 -0.3137485  -0.31426048\n",
      " -0.32035717 -0.3152525  -0.32814708 -0.33026415 -0.3140409  -0.31487775\n",
      " -0.31545687 -0.3134733  -0.83222973 -0.31328675 -0.35254937 -0.5496602\n",
      " -0.31327036 -0.31871352], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31435695 -0.3215114  -0.3162008  -0.31445628 -0.4537252  -0.9164702\n",
      " -0.31347287 -0.34914753 -0.3153392  -0.38241827 -0.31374025 -0.31341764\n",
      " -0.34755266 -0.31384432 -0.31326216 -0.31327647 -0.33064356 -0.31718722\n",
      " -0.3148485  -0.31369966 -0.3300178  -0.32307425 -1.1799532  -0.3132859\n",
      " -0.32565925 -0.3267518  -0.31450823 -0.42348236 -0.31497544 -0.31388327\n",
      " -0.3166177  -0.31802517], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.6153383  -0.3179753  -0.8380923  -0.31329083 -0.33868495 -0.3134633\n",
      " -0.31566486 -0.31333554 -0.3147576  -0.31409314 -0.31782454 -0.31326723\n",
      " -0.31343776 -0.31326392 -0.31327516 -0.37002295 -0.3140551  -0.3143136\n",
      " -0.987216   -0.3133393  -0.55874664 -0.31482708 -0.31933644 -0.31338137\n",
      " -0.3135439  -0.3133535  -0.31330216 -0.32002267 -0.32219017 -0.38091776\n",
      " -0.5527812  -0.31466368], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34544027 -0.31812388 -0.31327933 -0.3175475  -0.3137176  -0.31538355\n",
      " -0.3160308  -0.31440517 -0.31769744 -0.31436217 -0.3622255  -0.31349587\n",
      " -0.33423582 -0.32679316 -0.3179328  -0.3138378  -0.31470641 -0.31746852\n",
      " -0.31384382 -0.3659956  -0.3135274  -0.31326696 -0.31576422 -0.3186324\n",
      " -0.31397367 -0.3159026  -0.31342548 -0.6567147  -0.3133859  -0.31516474\n",
      " -0.31332597 -0.31327212], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31476924 -0.31464532 -0.31559956 -0.3373185  -0.31352967 -0.31629333\n",
      " -0.314298   -0.39203566 -0.31423742 -0.3595916  -0.31340283 -0.31637594\n",
      " -0.313683   -0.32092935 -0.3133447  -0.34884784 -0.31417716 -0.33240557\n",
      " -0.31711075 -0.33033448 -0.31348786 -0.31438828 -0.31340492 -0.31852126\n",
      " -0.3134287  -0.31544086 -0.31869715 -0.31344464 -0.31761587 -0.31360313\n",
      " -0.31492063 -0.33655626], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31355235 -0.31342843 -0.31360784 -0.3169899  -0.31329852 -0.31373528\n",
      " -1.0773187  -0.32607567 -0.41491857 -0.52570677 -0.31369984 -0.33649707\n",
      " -0.31353778 -0.31356984 -0.31352645 -0.31394598 -0.4088421  -0.31394458\n",
      " -1.2138956  -0.31861377 -0.31336623 -0.3167464  -0.31646073 -0.31503147\n",
      " -0.3133638  -0.31326565 -0.3144601  -1.3047863  -0.3134592  -0.31572127\n",
      " -0.32044214 -0.968768  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.313748   -0.3133495  -0.32344016 -0.3147708  -0.32931033 -0.31559303\n",
      " -0.33260724 -0.3132626  -0.3151123  -0.95617515 -0.33590972 -0.351433\n",
      " -0.31358448 -0.38311565 -0.32068717 -0.3667549  -0.32275593 -0.4769609\n",
      " -0.3589578  -0.31367856 -0.33810824 -0.31336135 -0.37381813 -0.31443852\n",
      " -0.722042   -0.31327227 -0.7657292  -0.3134267  -0.3132796  -0.31379703\n",
      " -0.31629047 -0.31623703], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31500086 -0.3133562  -0.3208657  -0.31326836 -0.31355068 -0.3411461\n",
      " -0.31505042 -0.3391319  -0.31546888 -0.31383526 -0.3145768  -1.2330141\n",
      " -0.31350625 -0.36862978 -0.3160768  -0.31326705 -0.31356812 -0.33911118\n",
      " -0.32228518 -0.3148124  -0.47190264 -0.32461262 -0.442792   -0.33460385\n",
      " -0.31339568 -0.31387028 -0.3147936  -0.31349325 -0.31366393 -0.53745735\n",
      " -0.31333485 -0.31410524], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31351897 -0.32570675 -0.31368518 -0.43458253 -0.3132797  -0.31454018\n",
      " -0.43540937 -0.3140713  -0.3304205  -0.3224002  -0.33801267 -0.3153387\n",
      " -0.31614935 -0.32435203 -0.33352947 -0.31522596 -0.31573954 -0.4412959\n",
      " -0.3178675  -0.32129434 -0.31375775 -0.5049524  -0.3139888  -0.3138574\n",
      " -0.31461093 -0.68908536 -0.3188867  -0.31700057 -0.32220417 -0.4133772\n",
      " -1.0937326  -0.31328544], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31514204 -0.31403446 -0.31338662 -1.1855876  -0.4331004  -0.45398992\n",
      " -0.3141258  -0.32178327 -0.7436811  -0.31339708 -0.32190734 -0.32410914\n",
      " -0.32006276 -0.3142463  -0.34000936 -0.31351453 -0.3144629  -0.3884014\n",
      " -0.31342757 -0.31789628 -0.31680632 -0.31773874 -0.31328273 -0.31441832\n",
      " -1.0347617  -0.31338704 -0.38841924 -0.31401336 -0.6181305  -0.3134272\n",
      " -0.32141137 -0.31855977], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31436932 -0.32264292 -0.3668076  -0.63425374 -0.31419015 -0.43558583\n",
      " -0.31329545 -0.3304803  -0.31690195 -0.32855123 -0.45636192 -1.0127378\n",
      " -0.3180445  -0.33965167 -0.31335333 -0.31434065 -0.31648377 -0.37853175\n",
      " -0.33364305 -0.33308607 -0.3132667  -0.3134273  -0.33425972 -0.32875693\n",
      " -0.49108925 -0.324041   -0.31328952 -0.32140005 -0.31369033 -0.3161176\n",
      " -0.34546727 -0.34767932], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32764176 -0.35577703 -0.3167029  -0.31458423 -0.3135234  -0.57519794\n",
      " -0.3148265  -0.31345093 -0.32012957 -0.4084978  -0.3134387  -0.31369197\n",
      " -0.34069726 -0.32798144 -0.31421    -0.33475575 -0.31398186 -0.31336266\n",
      " -0.31387115 -0.3150646  -0.31492132 -0.316038   -0.31484666 -0.3132986\n",
      " -0.32070506 -0.31397715 -0.32520828 -0.3159313  -0.31695637 -0.32003903\n",
      " -0.41707706 -0.3134469 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31432414 -0.31555793 -0.31346154 -0.35011607 -0.44627964 -0.31348437\n",
      " -0.4063345  -0.33823165 -0.40646297 -0.3137352  -0.31356165 -0.3134485\n",
      " -0.34162596 -0.33934504 -0.4080815  -0.37002832 -0.31354013 -0.3135167\n",
      " -0.31374922 -0.33762065 -0.3604315  -0.3814427  -0.31374496 -0.32138216\n",
      " -0.3133121  -0.33598155 -0.31605643 -0.32232448 -0.3132905  -0.3186181\n",
      " -0.31430262 -0.3218403 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3133922  -0.31344002 -0.31332842 -0.31665    -0.5542084  -0.3134633\n",
      " -0.31545871 -0.31365794 -0.34417844 -0.31331393 -0.5225969  -1.2778683\n",
      " -0.35574988 -0.31397113 -0.3132709  -0.3223097  -0.31873727 -0.31340754\n",
      " -0.3140328  -0.31353927 -0.33148974 -0.31517065 -0.31937838 -0.31470126\n",
      " -0.31472147 -0.3153358  -0.31733    -0.313271   -0.3198671  -0.6061356\n",
      " -0.31473494 -0.3872942 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31345493 -0.3135892  -0.37122458 -0.3135971  -0.41933724 -0.31335723\n",
      " -0.31553155 -0.31610233 -0.31339723 -0.31342602 -0.9769066  -0.4626554\n",
      " -0.31395546 -0.40947387 -0.31326488 -0.31370243 -0.31456053 -0.31755444\n",
      " -0.3135987  -0.3633851  -0.40814817 -0.31333223 -0.313679   -0.31744233\n",
      " -0.32138363 -0.75601804 -0.39615402 -0.32009047 -0.9411211  -0.33328032\n",
      " -0.31358805 -0.67697537], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4667691  -0.3639018  -0.38608658 -0.3177554  -0.3145584  -0.9497929\n",
      " -0.31785977 -0.3134869  -0.31363162 -0.3385898  -0.314648   -0.34014988\n",
      " -0.32455334 -0.8733641  -0.31343123 -0.5462519  -0.31354633 -0.31343105\n",
      " -0.31496406 -0.3133589  -0.4528756  -0.3164267  -0.31441918 -0.31749144\n",
      " -0.3387202  -0.31327575 -0.31346485 -0.32540244 -0.3135023  -0.31329545\n",
      " -0.31490558 -0.31332615], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31939828 -0.31387454 -0.31372648 -0.32459635 -0.3598618  -0.3223467\n",
      " -0.3133766  -0.3137143  -0.31340927 -0.3228579  -0.31459552 -0.332456\n",
      " -0.31336483 -0.3143612  -0.336198   -0.31384695 -0.31329355 -0.31502104\n",
      " -0.32912955 -0.31484085 -0.31675196 -0.36249018 -0.3239448  -0.31338295\n",
      " -0.3133129  -1.2946239  -0.34455785 -0.556359   -0.33667016 -0.31401607\n",
      " -0.36762193 -0.74404335], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.45447645 -0.31662133 -0.31344795 -0.31339464 -0.43141827 -0.31360984\n",
      " -0.6665144  -0.3133988  -0.31474245 -0.31353247 -0.31667164 -0.31414765\n",
      " -0.33205196 -0.35582438 -0.31500137 -0.31391704 -0.35542515 -0.31598762\n",
      " -0.31340805 -1.2623777  -0.31394145 -0.34082493 -0.31507757 -1.1208609\n",
      " -0.3133855  -0.3134464  -0.313671   -0.31397218 -0.37787503 -0.35384363\n",
      " -1.0306134  -0.31415173], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32146317 -0.4357203  -0.31489983 -0.35531846 -0.31330225 -0.4065876\n",
      " -0.31337425 -0.6130046  -0.31359684 -1.2594655  -0.3199008  -0.31841627\n",
      " -0.43755    -0.36144257 -0.31497997 -0.37797356 -0.3644611  -0.3214011\n",
      " -0.31383762 -0.41188776 -0.31525493 -0.31611258 -0.3157723  -0.39138383\n",
      " -0.31872392 -0.35447565 -0.3149122  -1.1278158  -0.35608    -0.31569573\n",
      " -0.31523815 -0.31969345], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3203653  -0.5691112  -0.5702117  -0.3376847  -0.36512268 -0.31355947\n",
      " -0.8038423  -0.31464106 -0.3146166  -0.31639808 -0.3133969  -0.31340998\n",
      " -0.31478837 -0.31471494 -0.31648818 -0.31358433 -0.49693754 -0.3135073\n",
      " -0.3194997  -0.3139242  -0.32147905 -0.3133405  -0.3343978  -0.31411847\n",
      " -0.33297163 -0.31330654 -0.31329635 -0.38982219 -0.9888994  -0.31328014\n",
      " -0.31409428 -0.31773752], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.58007956 -0.31598258 -0.3132742  -0.31434563 -0.31433004 -0.32421377\n",
      " -0.31662327 -0.3335118  -1.2774377  -0.31393144 -0.3205132  -0.3138386\n",
      " -0.31342757 -1.1593041  -1.1928442  -0.3138884  -0.91820776 -0.36773178\n",
      " -0.31728262 -0.31617534 -0.31330365 -0.3512736  -0.315426   -0.32431573\n",
      " -0.31370062 -0.31377187 -0.3172297  -0.31511152 -0.31334653 -0.3158833\n",
      " -0.31616473 -0.34611288], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.324802   -0.3285837  -0.31344187 -0.31366125 -0.32637832 -0.31508428\n",
      " -0.46890745 -0.31337267 -0.31507114 -0.3151778  -0.3189327  -0.31329182\n",
      " -0.31374094 -0.33596724 -0.61337763 -0.31336403 -0.33623055 -1.1544182\n",
      " -0.31590348 -0.33469972 -0.37819678 -0.31352898 -0.3139628  -0.3734474\n",
      " -0.31328902 -0.31753397 -0.33777714 -0.32836232 -0.3137297  -0.31346\n",
      " -0.3137447  -0.3261327 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.35008314 -0.3137245  -0.31353405 -0.5922635  -0.31948802 -0.3203172\n",
      " -0.31387264 -0.3259523  -0.31527573 -0.76475465 -0.6341801  -0.31342226\n",
      " -0.3173269  -0.31712335 -0.3137852  -0.3307531  -0.3136203  -0.31391382\n",
      " -0.3188334  -0.6254021  -0.31338802 -0.31677508 -0.3133285  -0.31838438\n",
      " -0.31338078 -0.31454    -0.31838247 -0.54288334 -0.3145609  -0.31443685\n",
      " -0.31717274 -0.3149516 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31384414 -0.44958627 -0.3134375  -0.3153048  -0.31337547 -0.3165074\n",
      " -0.34017506 -0.3134307  -0.32922825 -0.32520112 -0.34931535 -0.31407374\n",
      " -0.34214044 -0.31934702 -0.34196728 -0.31570962 -0.41465685 -0.31405875\n",
      " -0.31328964 -0.31326365 -1.1660421  -0.31399274 -0.52984196 -0.31476063\n",
      " -0.3184532  -0.3135134  -0.31685323 -0.31356436 -0.34967792 -0.32277727\n",
      " -0.89694166 -0.44262546], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31343427 -0.31335595 -0.31339192 -0.3171156  -0.31439805 -0.33081707\n",
      " -0.31434467 -0.5782948  -0.31403828 -0.33034477 -0.31492114 -0.3293791\n",
      " -0.32238984 -0.317944   -0.32518658 -0.3909605  -0.34818792 -0.32270217\n",
      " -0.32176313 -0.32341862 -0.34645826 -0.3366734  -0.37327313 -0.31444958\n",
      " -0.31663957 -0.37363937 -0.3133521  -0.31729192 -0.33727765 -1.2036977\n",
      " -0.3145507  -0.31656462], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31445923 -0.3174194  -0.31349188 -0.32915956 -0.31328154 -0.31353047\n",
      " -0.3386008  -0.31956077 -0.31524944 -0.31352568 -0.31336656 -0.31469685\n",
      " -0.31393945 -0.3195625  -0.31583047 -0.31337163 -0.31482562 -0.31354755\n",
      " -0.33646065 -0.5369693  -0.36882675 -0.3157525  -0.3139161  -0.31344885\n",
      " -0.3196917  -0.31328702 -0.3180648  -0.313779   -0.35928392 -0.31329033\n",
      " -0.3141251  -0.750371  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3132965  -0.43665993 -0.3149937  -0.31723505 -0.31344438 -0.31655836\n",
      " -0.38873154 -0.33987013 -1.1010772  -0.3136426  -0.41310924 -0.31483066\n",
      " -0.31337094 -0.36389342 -0.31331334 -0.31374556 -0.31337163 -0.34383264\n",
      " -0.31343848 -0.31336126 -0.37705186 -0.32161415 -0.36537272 -0.31328014\n",
      " -0.31342217 -0.31342444 -0.37221515 -0.31339568 -0.33128142 -0.3133725\n",
      " -0.35422933 -0.31341407], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.5499935  -0.33495805 -0.96224916 -0.31426388 -0.3148893  -0.3134605\n",
      " -0.33000004 -0.31369844 -0.3142073  -0.3644726  -0.32880113 -0.3138365\n",
      " -0.31408975 -1.3081996  -0.3757432  -0.31389597 -0.3156486  -0.6084287\n",
      " -0.32321674 -0.3133447  -0.8024231  -0.39979425 -0.31326208 -0.3325537\n",
      " -0.31753927 -0.3133849  -0.31958145 -0.3193722  -0.4868072  -0.3146997\n",
      " -0.31731302 -0.4943637 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32916066 -0.3502774  -0.3136204  -0.32295293 -0.33259553 -0.31333214\n",
      " -0.32155496 -0.31381473 -0.3172109  -0.4046334  -1.1071236  -0.31383267\n",
      " -0.33637702 -0.34231174 -0.3132627  -0.32464132 -0.34316763 -0.31541532\n",
      " -0.31747139 -0.3240512  -0.3286556  -0.3902576  -0.57911885 -0.31373894\n",
      " -0.31347287 -0.33634627 -0.31336257 -0.31384206 -0.31406248 -0.887926\n",
      " -0.31334147 -0.32174388], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3597311  -0.31726283 -0.76861525 -0.50081307 -0.31882507 -0.3415222\n",
      " -0.34389475 -0.3140975  -0.99764353 -1.0210674  -0.31438568 -0.49635744\n",
      " -0.3145233  -0.36051232 -0.3596243  -0.31362057 -0.31505567 -0.317644\n",
      " -0.31733063 -0.6709478  -0.32784155 -0.31375408 -0.3983858  -0.31844887\n",
      " -0.48684227 -0.31375653 -0.31493002 -0.31344604 -0.31876197 -0.31328136\n",
      " -0.56673396 -0.33782765], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3327279  -0.3186037  -0.3221109  -0.3851471  -0.31344604 -0.31983474\n",
      " -0.31735745 -0.35813013 -0.31502843 -0.3136546  -0.32589024 -0.31513768\n",
      " -0.31876647 -0.35151336 -0.31327498 -0.31450468 -0.3871538  -0.39406338\n",
      " -0.33923268 -0.45217535 -0.41419023 -0.3345226  -0.31356514 -0.3158216\n",
      " -0.518202   -0.31346244 -0.314376   -0.35874712 -0.31326896 -0.3135667\n",
      " -0.6835045  -0.34817824], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32425877 -0.31351453 -0.3133257  -0.31372762 -0.5098738  -0.38148546\n",
      " -0.3137359  -0.31326678 -0.32052296 -0.31615576 -0.7222901  -0.31363833\n",
      " -0.31405708 -0.96775025 -0.40349334 -0.3134247  -0.71687424 -0.31460834\n",
      " -0.31790844 -0.31330872 -0.3135552  -0.3135298  -0.3414555  -0.32065776\n",
      " -0.5691855  -0.31372237 -0.31329146 -0.3140072  -0.78090787 -0.31680286\n",
      " -1.0811505  -1.0002942 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31701967 -0.31368965 -0.713809   -0.31616855 -0.3221084  -0.316506\n",
      " -0.3204598  -0.31582874 -0.32858163 -0.31345126 -0.31513637 -0.3136898\n",
      " -0.34364623 -0.3367598  -0.3137134  -0.3326298  -0.31338263 -0.31673548\n",
      " -0.33024907 -0.31326312 -0.31632808 -0.3133169  -0.31958944 -0.313474\n",
      " -0.92416644 -0.58948034 -0.3163479  -0.32291856 -0.31816933 -0.31803238\n",
      " -0.35386807 -0.32183477], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4744715  -0.31550887 -0.3339709  -0.34740412 -0.31355163 -0.31712013\n",
      " -0.31701958 -0.52375805 -0.32243752 -0.32398367 -0.69048166 -0.4918335\n",
      " -0.3137682  -0.31353614 -0.5340056  -0.3135884  -0.31449535 -0.32131618\n",
      " -0.31418562 -0.31650427 -0.36860555 -0.78841734 -0.3133101  -0.3140106\n",
      " -0.3561497  -0.31361836 -0.31354702 -0.38030297 -0.3475377  -0.3157922\n",
      " -0.3612111  -0.31587097], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.4283205  -0.3141635  -0.31336066 -0.31991595 -0.31346905 -0.31453383\n",
      " -0.3135519  -1.0195777  -0.3135071  -0.33633727 -0.314973   -0.31339777\n",
      " -0.41237757 -0.3421108  -0.3133995  -0.315892   -0.3150462  -0.31348106\n",
      " -0.313673   -0.3135755  -0.31519344 -0.32125932 -0.3884064  -0.41706592\n",
      " -0.32019284 -0.51586694 -0.3145414  -0.313485   -0.38155806 -0.32628465\n",
      " -0.3370372  -0.34247458], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31465882 -0.34684253 -0.36017585 -0.3930551  -0.32774636 -0.40203825\n",
      " -0.3139139  -0.31327814 -0.31381088 -0.3151817  -0.33057126 -0.31505567\n",
      " -0.32202587 -0.31326565 -0.31330496 -0.3622196  -0.31943145 -0.31886408\n",
      " -0.32072473 -1.0577765  -0.3134842  -0.31635144 -0.50834334 -0.3134043\n",
      " -0.31403497 -0.31592876 -0.31387535 -0.31352    -0.3252931  -0.31840786\n",
      " -0.3132858  -0.31332386], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32729575 -0.31445217 -0.31468308 -0.31331804 -0.43053177 -0.31393212\n",
      " -0.3366683  -0.31360322 -0.33429044 -0.31326294 -0.31326932 -0.31822258\n",
      " -0.31450692 -0.32904068 -0.31358927 -0.42050526 -0.31523588 -0.34743452\n",
      " -0.31423837 -0.39009976 -0.31466272 -0.4021437  -0.31922445 -0.3179033\n",
      " -0.3267451  -0.31328142 -0.344489   -0.31407103 -0.55524784 -0.3306284\n",
      " -0.32840154 -0.6176446 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3513162  -0.3135695  -0.9645529  -0.7288362  -0.37532294 -0.31347618\n",
      " -0.31644526 -0.31329408 -0.3133799  -0.6404344  -0.31353003 -0.31379852\n",
      " -0.31365758 -0.39770195 -0.3292359  -0.31485173 -0.31352803 -0.3652056\n",
      " -0.31986964 -0.54352    -0.31397986 -0.32308495 -0.3138742  -0.32096645\n",
      " -0.3139059  -0.31380427 -0.53213984 -0.31337738 -0.31339994 -0.41387632\n",
      " -0.8588885  -0.31396297], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32374293 -0.3162571  -0.3209731  -0.38317344 -0.31342426 -0.33041212\n",
      " -0.3132777  -0.32882214 -0.34262496 -1.2771487  -0.31423062 -0.34688288\n",
      " -0.31340858 -0.31396914 -0.3138454  -0.31458414 -0.40564495 -0.3239748\n",
      " -0.31361297 -0.38424644 -0.313514   -0.3528025  -0.31327593 -1.0957983\n",
      " -0.31341425 -0.9024122  -0.31450763 -0.35303795 -0.31329876 -0.3154994\n",
      " -0.31402817 -0.52793306], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.41131008 -0.34259924 -0.3135723  -0.31359458 -0.31608635 -0.3191818\n",
      " -0.31328937 -0.33231843 -0.31469187 -0.31344414 -0.5255139  -0.6633217\n",
      " -0.4552799  -0.35254368 -0.31961447 -0.39958274 -0.313929   -0.32907575\n",
      " -0.31378928 -0.31659338 -0.31672817 -0.31387776 -0.31373075 -1.0070763\n",
      " -0.33022764 -0.31600055 -0.45521837 -0.31340674 -0.31802398 -0.31351975\n",
      " -0.31364793 -0.31359345], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31573102 -0.3174334  -0.38048542 -1.0007961  -0.31350946 -0.31333172\n",
      " -0.5194718  -0.31351486 -0.3754559  -0.7675855  -0.31791833 -0.3132838\n",
      " -0.33564577 -0.3158542  -0.36020535 -0.31327593 -0.31345928 -0.37596038\n",
      " -0.56410027 -0.31877446 -0.315275   -0.32268903 -0.32846025 -0.31338087\n",
      " -0.31409088 -0.31370986 -0.31333956 -0.31413025 -0.53872406 -0.31357726\n",
      " -0.37327677 -0.3638695 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32180306 -0.3148303  -0.31336397 -0.41803116 -0.3147492  -0.3134234\n",
      " -0.34922943 -0.3139864  -0.31331995 -0.3588792  -0.31334513 -0.3222768\n",
      " -0.32331577 -0.31376386 -0.31326896 -0.384611   -0.31343576 -0.36712164\n",
      " -0.38534033 -0.3336603  -0.32187226 -0.32103348 -0.32762894 -0.31638706\n",
      " -0.31462687 -0.32979262 -0.47057644 -0.31749701 -0.3678527  -0.38285393\n",
      " -0.32828066 -0.41165403], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3186884  -0.43316922 -0.3190652  -0.69165045 -0.7372942  -0.31772503\n",
      " -0.31797495 -0.6537789  -0.3590324  -0.36185724 -0.31345457 -0.31347907\n",
      " -0.31328988 -0.516709   -0.31333223 -0.31643355 -0.3178151  -0.43984827\n",
      " -0.3407238  -0.31916067 -0.31601012 -0.31506297 -0.31345224 -0.31326663\n",
      " -0.31466872 -0.7837528  -0.3133182  -0.42986253 -0.3136506  -0.31381193\n",
      " -0.50091404 -0.31338704], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.37114537 -0.331442   -0.3133671  -0.3309235  -0.3132791  -0.31346226\n",
      " -0.340952   -0.31466272 -0.314294   -0.31331053 -0.3295772  -0.4869546\n",
      " -0.31402364 -0.31366977 -0.7138827  -0.31330007 -0.34212047 -0.3160627\n",
      " -0.5254293  -0.7290175  -0.32021925 -0.3225243  -0.31592494 -0.32310972\n",
      " -0.3272879  -0.5994951  -0.31391132 -0.3132633  -0.32862693 -0.35051027\n",
      " -0.329116   -0.31368843], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31508654 -0.3134916  -0.32377335 -0.31401286 -0.31327933 -0.31645864\n",
      " -0.32360786 -0.31473616 -0.31376177 -0.34144422 -0.32121634 -0.31481797\n",
      " -0.31700796 -0.5299474  -0.31357387 -0.35436073 -0.3195644  -0.6437553\n",
      " -0.31326425 -0.32213187 -0.36099234 -0.31494743 -0.31670403 -0.31327873\n",
      " -0.32056814 -0.31347567 -0.31417498 -0.31979674 -0.31333748 -0.3161862\n",
      " -0.31701022 -0.31643128], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31383154 -0.38842174 -0.3132831  -0.85649097 -0.31327227 -0.31344858\n",
      " -0.5322242  -0.4989041  -0.4165184  -0.3249933  -0.3142942  -0.41738215\n",
      " -0.31992304 -0.32964683 -0.31981915 -0.313844   -0.3969232  -0.34026363\n",
      " -0.39003834 -0.47286445 -0.31880662 -0.3256392  -0.31503513 -0.3231805\n",
      " -0.3139119  -0.83997965 -0.32406947 -0.38780296 -0.35109437 -0.31326687\n",
      " -0.31332874 -0.32494655], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.91622365 -0.31332743 -0.33558327 -0.3133121  -0.3134293  -0.31402844\n",
      " -0.40848392 -0.3135985  -0.35037726 -0.317042   -0.98926604 -0.3393824\n",
      " -0.946897   -0.31338382 -0.31332475 -0.31663126 -0.31532615 -0.31393752\n",
      " -0.31758648 -0.3135018  -1.1375139  -0.6173382  -0.31814408 -0.33789483\n",
      " -0.31566998 -0.3132924  -0.31427747 -0.3239972  -0.31585464 -0.31424168\n",
      " -0.31337    -0.3137818 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33474568 -0.31808668 -0.3139269  -0.31633502 -0.3159996  -0.33860642\n",
      " -0.31546807 -0.31489235 -0.32618752 -0.31841022 -1.0082667  -0.3167577\n",
      " -0.31714922 -1.2437177  -0.31990504 -0.3205335  -0.3153494  -0.31635508\n",
      " -0.31349248 -0.3411324  -0.31327036 -0.31564346 -1.0458481  -0.6267147\n",
      " -0.3197348  -0.31332728 -0.3254332  -0.31864166 -0.8260485  -0.31387657\n",
      " -0.3183002  -0.44511616], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31603873 -0.31426233 -0.31412622 -0.31443852 -0.3176643  -0.43224627\n",
      " -0.31375054 -0.31446445 -0.31326845 -1.0230577  -0.31443417 -0.3135032\n",
      " -0.31361446 -0.31370097 -0.31354284 -0.31376508 -0.32975584 -0.31655923\n",
      " -0.31583098 -0.3438875  -0.32275534 -0.43922117 -0.31344473 -0.3275031\n",
      " -0.31404325 -1.107931   -0.33007762 -0.32356852 -0.33365765 -0.31848252\n",
      " -0.3133915  -0.3164325 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31357396 -0.33318013 -0.36865634 -0.31363738 -0.31413478 -0.31334853\n",
      " -0.45254618 -0.31468806 -0.3203841  -0.31366873 -0.31380454 -0.31346643\n",
      " -0.34001064 -0.37644482 -0.41327107 -0.35686696 -0.3169574  -0.36147562\n",
      " -0.8477392  -0.313424   -0.31335768 -0.37840053 -0.31377664 -0.31343767\n",
      " -0.31635857 -0.3190511  -0.31335437 -0.31555063 -0.31403393 -0.3313088\n",
      " -0.3601707  -0.32625213], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.32919618 -0.3258072  -0.3139445  -0.32179123 -0.35246208 -0.32247448\n",
      " -0.45651644 -0.31350502 -0.31332058 -0.31337643 -0.31346503 -0.38573995\n",
      " -0.32322663 -0.31470397 -0.31830037 -0.31341797 -0.31414792 -0.31497318\n",
      " -0.3164716  -0.31540662 -0.31327018 -0.31330347 -0.31809786 -0.31496447\n",
      " -0.31329808 -0.31341344 -0.41005865 -0.31342828 -0.3193594  -0.35200116\n",
      " -0.50961185 -0.3350503 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3230998  -0.3187541  -0.39363277 -0.31357604 -0.31357482 -0.31498832\n",
      " -0.38168478 -0.3583246  -0.31339055 -0.9972803  -0.3382257  -0.31620115\n",
      " -0.3134545  -0.32408464 -0.3132681  -0.6980335  -0.3134633  -0.32763633\n",
      " -0.31780753 -0.35561237 -0.32658327 -0.32223898 -0.32693157 -0.31927752\n",
      " -0.3167055  -0.31347376 -0.3823088  -0.3495885  -0.31992996 -0.5161183\n",
      " -0.3304661  -0.3234082 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3134124  -0.3572425  -0.7448496  -0.8112174  -0.31423724 -0.31426546\n",
      " -1.099537   -0.31526816 -0.31448665 -0.31636927 -0.31856868 -0.31338173\n",
      " -0.3132728  -0.31507933 -0.31328824 -0.31382203 -0.31338173 -0.43294254\n",
      " -0.31348106 -0.3135823  -0.314819   -0.31349728 -0.32048023 -0.3134219\n",
      " -0.3358916  -0.5548886  -0.3408787  -0.313319   -0.53475606 -0.3311491\n",
      " -0.3135004  -0.6461895 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.42664725 -0.3133439  -0.31394833 -0.31524128 -0.31637865 -0.3233339\n",
      " -0.98026633 -0.31326294 -0.3900485  -0.32483524 -0.31562304 -0.31631434\n",
      " -0.35288182 -0.32873195 -0.31346783 -0.3138     -0.31827158 -0.317169\n",
      " -0.3198821  -0.39099258 -0.345619   -0.31345013 -0.32409644 -0.3132878\n",
      " -0.3135993  -0.31367457 -0.7212623  -0.32925922 -0.31441152 -0.32383123\n",
      " -0.317096   -0.31393823], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3138628  -0.31471345 -0.3146488  -0.647788   -0.33880252 -0.31329042\n",
      " -0.31352273 -0.34689847 -0.31394276 -0.31344986 -0.3717987  -0.31385052\n",
      " -0.31746852 -0.3132757  -0.49638706 -0.60257316 -0.45116884 -0.32652575\n",
      " -0.31329373 -0.40289253 -0.31734166 -0.34626982 -0.35325533 -0.44681585\n",
      " -0.3133366  -0.31326506 -0.3192895  -0.3132761  -0.31400797 -0.32503888\n",
      " -0.42599392 -0.31493405], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33468017 -0.31348786 -0.31483632 -0.34099406 -0.3181598  -0.31331742\n",
      " -0.31341904 -0.32367375 -0.31667373 -0.40973884 -0.32426515 -0.31357986\n",
      " -1.2150989  -0.31355268 -0.3132783  -0.33432263 -0.3132749  -0.35622594\n",
      " -0.3519798  -0.31408036 -0.43130267 -0.31331682 -0.31354937 -0.31354362\n",
      " -0.31356958 -0.31335855 -0.38446787 -0.313319   -0.31329703 -0.31485373\n",
      " -0.31329346 -0.3402924 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31401652 -1.2930198  -0.3156737  -0.3172843  -0.31402844 -0.33322242\n",
      " -0.3185029  -0.31332928 -0.324902   -0.31420982 -0.31585592 -0.3349653\n",
      " -0.3449366  -0.36659926 -0.3212816  -0.34719142 -0.32365695 -0.41932046\n",
      " -0.32856986 -0.3132675  -0.3671388  -0.31353787 -0.7598781  -0.3202754\n",
      " -0.3139511  -0.37021035 -0.36038095 -0.31597614 -0.31521833 -0.42719167\n",
      " -0.33387083 -0.390858  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31357533 -0.3848005  -0.88300854 -0.35229656 -0.3931408  -0.31365705\n",
      " -0.31336004 -0.3512779  -0.31378475 -0.33295098 -0.31409523 -0.31382918\n",
      " -0.3208912  -0.32024044 -0.3149973  -0.31435537 -1.0211064  -0.35057867\n",
      " -0.3603379  -0.32187176 -0.38983285 -0.31330732 -1.1620662  -0.31356558\n",
      " -0.3137886  -0.3133841  -0.3133021  -0.33267605 -0.31328607 -0.31341362\n",
      " -0.3141096  -0.31384635], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3135067  -0.3317442  -0.32722992 -0.3133922  -0.37004817 -0.31587428\n",
      " -0.31588298 -0.31342173 -0.32277846 -0.31419128 -0.3134403  -0.3133805\n",
      " -0.32166955 -0.31681865 -0.3375789  -0.36177862 -0.3382137  -0.31360966\n",
      " -0.32034558 -0.38061106 -0.31450728 -0.31764    -0.4791205  -0.31466925\n",
      " -0.31339046 -0.5568601  -0.31375077 -0.31434554 -0.31593424 -0.3457377\n",
      " -0.31568223 -0.32986712], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31337398 -0.3133277  -0.3316567  -0.313399   -1.2536054  -0.32409713\n",
      " -0.32368127 -0.3152037  -1.0399843  -0.31366786 -0.31524217 -0.31510568\n",
      " -0.3215011  -0.31916735 -0.58476746 -0.3154799  -0.33010796 -0.43650654\n",
      " -0.3138048  -0.3225021  -0.31351957 -0.31334364 -0.31704146 -0.31442145\n",
      " -0.3244795  -0.31336945 -0.3179864  -0.32003593 -0.31696463 -0.31332222\n",
      " -1.263907   -0.3136229 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.33108172 -0.31480318 -0.3547709  -0.3310402  -0.31333554 -0.31358737\n",
      " -0.3794247  -0.31372222 -0.31435835 -0.45165035 -0.32450855 -0.31743747\n",
      " -0.31580055 -0.316988   -0.31467134 -0.31390268 -0.31330356 -0.4616771\n",
      " -0.3135858  -0.3132884  -0.313266   -0.3135     -0.33600098 -0.35480428\n",
      " -0.9713644  -0.31338227 -0.32912672 -0.31414878 -0.31338748 -0.3140773\n",
      " -0.77402055 -0.3215432 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.799338   -0.31354117 -0.31328186 -0.31382203 -0.3197144  -0.32603395\n",
      " -0.31463277 -0.3149355  -0.32288152 -0.3138276  -0.3132634  -0.3218294\n",
      " -0.31341746 -0.3171323  -0.34205714 -0.31384224 -0.31341556 -0.3134619\n",
      " -0.3163093  -0.31469136 -0.3190392  -0.35936    -0.31349578 -0.32865843\n",
      " -0.31371883 -0.3132661  -0.3136149  -0.5018357  -0.36038288 -0.32557902\n",
      " -0.38742152 -0.31353813], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31801113 -0.48372594 -0.33408594 -1.1579962  -0.32699913 -0.356985\n",
      " -1.1299875  -0.3702259  -0.33027196 -0.31851944 -0.3312834  -0.31549087\n",
      " -0.35846612 -0.31620234 -0.31695336 -0.31337842 -0.31326184 -0.31356522\n",
      " -0.80705047 -0.31335306 -0.32517272 -0.32719228 -0.31380627 -0.3159975\n",
      " -0.31509706 -0.313264   -0.50826705 -0.331778   -0.3223796  -0.34453994\n",
      " -1.2400262  -0.313298  ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31363562 -0.3133772  -0.3278826  -0.31612772 -0.32248104 -0.31332064\n",
      " -0.31386307 -0.45541432 -0.3333531  -0.31617445 -0.3133455  -0.31498814\n",
      " -0.3247504  -0.33539826 -0.3231407  -0.345124   -0.31334704 -0.31421617\n",
      " -0.729988   -0.32397237 -1.2894794  -0.3136243  -0.8620101  -0.314022\n",
      " -0.3134105  -0.32137102 -0.5935855  -0.7881479  -0.32340506 -0.3139675\n",
      " -0.4362377  -0.3143928 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31409454 -0.31342244 -0.41509724 -0.319884   -0.32942954 -0.31422365\n",
      " -0.3519791  -0.31428233 -0.35824347 -0.3132762  -0.3134238  -0.32074228\n",
      " -0.3197769  -0.31650904 -0.31340003 -0.42646137 -0.31334686 -0.37107703\n",
      " -0.42701676 -0.77043587 -0.31490934 -0.31381166 -0.31330985 -0.31739017\n",
      " -0.31363317 -0.31334826 -0.31355086 -0.3132634  -0.31684715 -0.33699805\n",
      " -0.31333852 -0.38722438], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31593147 -0.3727567  -0.31341493 -0.31349945 -0.31410366 -0.31730866\n",
      " -0.41926685 -0.3133603  -0.31350815 -0.5538992  -0.31714922 -0.32175666\n",
      " -0.31327438 -0.5389599  -0.3148171  -0.31427756 -0.3161509  -0.31340107\n",
      " -0.31327865 -0.32341802 -0.37435445 -0.38336658 -0.31775713 -0.31520876\n",
      " -0.31366673 -0.31579632 -0.31713897 -0.33193257 -0.3461457  -0.3158228\n",
      " -1.3009953  -0.35294747], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.43567112 -0.3141534  -0.334222   -0.31445393 -0.31365827 -0.31543532\n",
      " -0.3272301  -0.313399   -0.3132675  -0.3135025  -0.31358877 -0.6801024\n",
      " -0.32874122 -0.31808242 -0.31351566 -0.31362152 -0.55958176 -0.31671906\n",
      " -0.31329685 -0.313833   -0.31347916 -0.3133657  -0.31338644 -0.63861525\n",
      " -0.31326193 -0.3309235  -0.31847993 -0.3177364  -0.313625   -0.31567502\n",
      " -0.31389537 -0.32027584], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.45935923 -0.31664583 -0.3156619  -0.313359   -0.31337172 -0.34165466\n",
      " -0.35470897 -0.31468222 -0.31635484 -0.31328797 -0.3163244  -0.31634814\n",
      " -1.021368   -0.313422   -0.53687227 -0.39022774 -0.3257034  -0.31366923\n",
      " -0.42831832 -0.5941738  -0.3133277  -0.31344238 -0.42679664 -0.31760788\n",
      " -0.31451225 -0.31326243 -0.6117058  -0.3534767  -0.39259514 -0.3150031\n",
      " -0.32021552 -0.3141587 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3132728  -0.31550914 -0.31331438 -0.39509177 -0.31435302 -0.3838416\n",
      " -0.3135636  -1.1576979  -0.313819   -0.38364822 -0.3228938  -0.31645846\n",
      " -0.32448906 -0.38904652 -0.31367734 -0.32196817 -0.33695728 -0.31626162\n",
      " -0.31980693 -0.67123723 -0.38586202 -0.84584844 -0.31367928 -0.45460153\n",
      " -0.31923363 -0.3204759  -0.315444   -0.32468683 -0.31416184 -0.9137409\n",
      " -0.4664461  -0.3170222 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.324293   -0.3148136  -0.31385314 -0.3133542  -0.3672676  -0.35615128\n",
      " -0.31570268 -0.32120138 -0.3470337  -0.31891763 -0.31541374 -0.3271524\n",
      " -0.472427   -0.31361315 -0.31348473 -0.31507254 -0.31567737 -0.3310693\n",
      " -0.31387657 -0.3142855  -0.32008812 -0.31591442 -0.32170084 -0.3135356\n",
      " -0.31328607 -0.38980523 -0.31492376 -0.31788242 -0.31403497 -0.42035884\n",
      " -0.33580393 -0.74461484], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3303794  -0.31357273 -0.32324097 -0.31349275 -0.32102847 -0.31697878\n",
      " -0.32044214 -0.4332762  -0.31415    -0.45123547 -0.45239764 -0.31863803\n",
      " -0.315139   -0.3204424  -0.31391445 -0.3137838  -0.3655388  -0.31592417\n",
      " -0.31337693 -0.3144252  -0.5195222  -0.31412962 -0.7077795  -0.3141608\n",
      " -0.3635566  -0.32025006 -0.31326392 -0.31463775 -0.3137297  -0.31581047\n",
      " -0.77586603 -0.31899944], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31342137 -0.32630864 -0.36822435 -0.3493551  -0.31326872 -0.3133893\n",
      " -0.3134179  -0.5185118  -0.39491832 -0.31345737 -0.31331682 -0.32333967\n",
      " -0.32045564 -0.3133542  -0.31340927 -0.3138832  -1.0204122  -0.3138373\n",
      " -1.23673    -0.5337327  -0.5196668  -0.40427327 -0.31534642 -0.31443712\n",
      " -0.34777144 -0.31373763 -0.40872264 -0.3237167  -1.0478988  -0.33101287\n",
      " -0.3365005  -0.31342906], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34034583 -0.3133012  -0.3411213  -0.3267782  -0.32873547 -0.41441774\n",
      " -0.35044408 -0.31352115 -0.31355852 -0.32665232 -0.31332648 -0.31327915\n",
      " -0.87445116 -0.3249436  -0.35364997 -0.3135668  -0.31368458 -0.33246335\n",
      " -0.32430807 -0.31396478 -0.3362072  -0.33562624 -0.31341416 -0.31363335\n",
      " -0.3140012  -0.31694716 -0.3136636  -0.3151223  -0.31542236 -0.46097577\n",
      " -0.35121605 -0.38606316], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3854674  -0.5965524  -0.31369695 -0.31453148 -0.33903295 -0.31345275\n",
      " -0.83704805 -1.2877816  -0.31547    -0.31373936 -0.3156173  -0.33067423\n",
      " -0.31340405 -0.31348175 -0.31371778 -0.3136195  -0.32093176 -1.1996543\n",
      " -0.34302112 -0.31332126 -0.3137263  -0.3168843  -0.52215683 -0.44370183\n",
      " -0.31430236 -0.31342426 -0.32865867 -0.31418717 -0.31609225 -0.3253806\n",
      " -0.31326637 -0.3167319 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.34346235 -0.31376934 -0.31677577 -0.3135181  -0.38015723 -0.31437463\n",
      " -0.3132912  -0.31329423 -0.31620175 -0.44337445 -0.72180474 -0.32918513\n",
      " -0.31501293 -0.3142159  -0.31430045 -0.41382417 -0.328181   -0.3133487\n",
      " -0.31890768 -0.3134767  -0.34144017 -0.31338114 -0.32788312 -0.31394276\n",
      " -0.31327018 -0.43511918 -0.31349552 -0.31350955 -0.34511253 -0.31805918\n",
      " -0.31547156 -0.32951236], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3702386  -1.0224811  -0.32044154 -0.31339368 -0.32690492 -0.3151618\n",
      " -1.1767498  -0.31385314 -0.31329268 -0.31342915 -0.47389176 -1.2628455\n",
      " -0.3133974  -1.0219833  -1.0629678  -0.31379163 -0.31494665 -0.7607995\n",
      " -0.3134105  -0.31384224 -0.31331933 -0.31330732 -0.3210639  -0.3162756\n",
      " -0.31354362 -0.31328928 -0.3138204  -0.31454557 -0.3135804  -0.31642452\n",
      " -0.8313173  -0.31338975], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31423783 -0.3295477  -0.31351557 -0.40766996 -0.3961143  -0.31458396\n",
      " -0.4010652  -0.53990126 -0.3936334  -0.31412137 -0.313656   -0.31348073\n",
      " -0.3132824  -0.31549042 -0.31367543 -0.49478513 -0.31327865 -0.31337833\n",
      " -0.3140192  -0.31489697 -0.3404252  -0.31813627 -0.31966    -0.3135418\n",
      " -0.3203649  -0.31465036 -0.3145346  -0.8940027  -0.31491828 -0.82550275\n",
      " -0.3143943  -0.3141951 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31363887 -0.62613803 -0.31701282 -0.31690985 -0.31369296 -0.32395065\n",
      " -0.3235576  -0.3200012  -0.31326732 -0.31841558 -0.3136593  -0.31781143\n",
      " -0.31382257 -0.40540072 -0.3134586  -0.3148759  -0.31884032 -0.33312663\n",
      " -0.3172415  -0.3132843  -0.32891738 -0.32800308 -0.31485173 -0.34421486\n",
      " -0.31795508 -0.326526   -0.32029998 -0.33370787 -0.32861328 -0.3425461\n",
      " -0.31490812 -0.32516935], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31602758 -0.32127497 -0.3153206  -0.31382334 -0.31421965 -0.3153928\n",
      " -0.31638438 -0.9106684  -1.0961945  -0.82245755 -0.35040033 -0.32769173\n",
      " -0.31359452 -1.2920191  -0.42635328 -0.3134625  -0.3134281  -0.31424177\n",
      " -0.3226199  -0.3427624  -0.3166039  -0.9334253  -0.31469482 -0.34695402\n",
      " -0.4692803  -0.5727701  -0.42498937 -0.31336814 -0.31365374 -0.3141007\n",
      " -0.31538236 -0.31346992], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31331864 -0.31340587 -0.31667572 -0.3365211  -0.36456567 -0.32188746\n",
      " -0.32714346 -0.31358352 -0.31516275 -0.31436938 -0.3136657  -0.31702766\n",
      " -1.0742592  -0.3137161  -0.3855865  -0.35081583 -0.3139943  -0.31330782\n",
      " -0.3139797  -0.34577405 -0.66253495 -0.5750568  -0.3905395  -0.31333345\n",
      " -0.31328467 -0.3137621  -0.32613522 -0.31880245 -0.3133338  -0.7994623\n",
      " -0.40785795 -0.34560212], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3137312  -0.41402793 -0.3317324  -0.33196962 -0.31862816 -0.3282827\n",
      " -0.3138393  -0.3133122  -0.3435862  -0.7465614  -0.39721102 -0.31526303\n",
      " -0.31338906 -0.3133507  -1.2928004  -0.31327122 -0.31341362 -0.35272056\n",
      " -0.37905282 -0.3133785  -0.34051952 -0.3137924  -0.31360477 -0.44495994\n",
      " -0.3263692  -0.31753343 -0.322325   -0.31959713 -0.31820428 -0.3215839\n",
      " -0.31404847 -0.3132633 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.8168846  -0.313266   -0.31788224 -0.70697606 -0.31523937 -0.31354824\n",
      " -0.33067757 -0.31386697 -0.31327814 -0.33793783 -0.31442538 -0.3133488\n",
      " -0.3199967  -0.32740822 -0.39097694 -0.31883156 -0.31628776 -0.3135689\n",
      " -0.3135369  -0.4477099  -0.31351453 -0.3132661  -0.3295194  -0.57812524\n",
      " -0.313806   -0.92894673 -0.31365496 -0.3162026  -0.49495068 -0.31648418\n",
      " -0.3139796  -0.31355625], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.59645414 -0.313317   -0.59515923 -0.31336266 -0.3141438  -0.31784979\n",
      " -0.31603342 -0.32424775 -0.31424874 -0.31355888 -0.3221391  -0.58157647\n",
      " -0.31423488 -0.31344885 -0.31455088 -0.85268605 -0.3207087  -0.35462475\n",
      " -0.3133868  -0.34183806 -0.32317436 -0.31462565 -0.3134652  -0.46144357\n",
      " -0.31507045 -0.3242355  -0.31653708 -0.32023862 -0.31703252 -0.34650713\n",
      " -0.31332892 -0.92624456], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3140787  -0.31434432 -0.3133725  -1.0534822  -0.31334358 -0.32165432\n",
      " -0.31328675 -0.3133109  -0.31379113 -0.3149957  -0.32196862 -0.31528547\n",
      " -0.31362057 -0.31446028 -0.3249816  -0.31877568 -0.31759244 -0.314372\n",
      " -0.3153801  -0.3132857  -0.32032803 -0.32345018 -0.31441483 -0.31420746\n",
      " -0.31811816 -0.94254327 -0.31343767 -0.38141382 -0.31331933 -0.31530112\n",
      " -1.1758902  -0.31327996], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31800818 -0.31887084 -0.31377745 -0.31334007 -0.31406265 -0.31466943\n",
      " -0.32183382 -0.31354955 -0.33353168 -0.31389293 -0.31411117 -0.32036185\n",
      " -0.31327176 -0.33209568 -0.31378773 -0.3132646  -0.31340343 -0.31326216\n",
      " -0.3340636  -0.3164717  -0.73252785 -0.5123663  -0.315724   -0.35067967\n",
      " -0.40617868 -0.3973377  -0.45652103 -0.35442597 -0.31445312 -0.31705225\n",
      " -0.34049994 -0.43142703], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31386673 -0.31404394 -0.51776826 -0.31397653 -0.31327212 -0.31512213\n",
      " -0.31332144 -0.33260176 -0.32860616 -0.35561672 -0.3132911  -0.31547245\n",
      " -0.31436974 -0.37576008 -0.31333068 -0.31389207 -0.37366816 -0.32480502\n",
      " -0.32108328 -0.33047318 -0.44620377 -0.31467003 -0.31464192 -0.31340772\n",
      " -0.31995258 -0.3405944  -0.31331918 -0.9936693  -0.31515378 -0.31986\n",
      " -0.3134185  -0.3208536 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31586385 -0.31349415 -0.33340666 -0.31450215 -0.31374955 -0.31330243\n",
      " -0.3263054  -0.33122116 -0.31535122 -0.31328154 -0.31568232 -0.3132634\n",
      " -0.313953   -0.36486864 -0.31344962 -0.31796116 -0.31380898 -0.31444392\n",
      " -0.32154664 -1.038718   -0.31326932 -0.31385767 -0.3153     -0.31575406\n",
      " -0.3139497  -0.39563632 -0.3143633  -0.34684405 -0.31357428 -0.31504235\n",
      " -0.32747173 -0.32832918], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31327227 -0.3152351  -0.3169338  -0.39181727 -0.34642917 -0.31406894\n",
      " -0.3275987  -0.7440394  -0.40393648 -0.3133787  -0.33429864 -0.31436557\n",
      " -0.31327212 -0.31387562 -0.3135264  -0.7637031  -0.3814984  -0.3133894\n",
      " -0.3153065  -0.31340203 -0.31647143 -0.31333765 -1.2035288  -0.31330687\n",
      " -0.32516342 -0.3756659  -0.9894469  -0.3259029  -0.3139459  -1.2937922\n",
      " -0.32931447 -0.31648976], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.61933637 -0.6257243  -0.31462747 -0.32290804 -0.3139903  -0.32041723\n",
      " -0.4974029  -0.89029205 -0.4288013  -0.3137588  -0.31329006 -0.3135268\n",
      " -0.32404006 -0.31831977 -0.31370085 -0.31729355 -0.35874996 -0.31330243\n",
      " -0.48102844 -0.35589728 -0.33272108 -0.31400806 -0.31667936 -0.31346208\n",
      " -0.31818172 -0.31987283 -0.31408522 -0.31637725 -0.45415306 -0.42754465\n",
      " -0.31347775 -0.31901157], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31391078 -0.3152959  -0.31354678 -0.31412283 -0.31335908 -0.3133734\n",
      " -0.32755    -0.314166   -0.31955063 -0.9570601  -0.3174977  -0.31654724\n",
      " -0.3138069  -0.33515716 -0.4411982  -0.31513673 -0.315668   -0.8197075\n",
      " -0.31520006 -0.3160302  -0.9244474  -0.3136353  -0.31399718 -0.31432274\n",
      " -0.35804206 -0.31327525 -0.32330862 -0.6292774  -0.31403968 -0.31374487\n",
      " -0.34950286 -0.31540477], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31354117 -0.53050613 -0.33407706 -0.4681977  -0.31357116 -0.31408626\n",
      " -0.3145657  -0.33162552 -0.32583636 -0.31431264 -0.44094893 -0.32471773\n",
      " -0.66608584 -1.0265139  -0.32712704 -0.60179174 -0.3160654  -0.35077453\n",
      " -0.31342113 -0.35010347 -0.31375647 -0.31535453 -0.35807106 -0.31367144\n",
      " -0.3140515  -0.3133041  -0.3132986  -0.59896713 -0.3133345  -0.55311596\n",
      " -0.31802613 -0.3139439 ], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.3134085  -0.31893063 -0.32317573 -0.31355834 -0.3157218  -0.35133702\n",
      " -0.33320984 -0.3133495  -0.31334096 -0.31327227 -0.31793472 -0.31345546\n",
      " -0.3132884  -0.31674954 -0.31329513 -0.31483084 -0.31479144 -0.80715173\n",
      " -0.34969473 -0.31329626 -0.33424112 -0.31447306 -0.31746906 -0.32797158\n",
      " -0.31990436 -0.33905268 -0.31977975 -0.39261544 -0.39275926 -0.4562814\n",
      " -0.60140806 -0.46423706], shape=(32,), dtype=float32)\n",
      "The rewards are: tf.Tensor(\n",
      "[-0.31340057 -0.3207638  -0.3133705  -0.31326532 -0.315642   -0.3187124\n",
      " -0.3154832  -0.3132627  -0.31387857 -1.1422584  -0.313399   -0.44421533\n",
      " -0.31364694 -0.3134851 ], shape=(14,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model using policy_gradient REINFORCEMENT LEARNING Technique\n",
    "# NAME: policy_gradient\n",
    "# PARAMETERS:Call the policy_gradient function with the following parameters:\n",
    "#            X_train_vectors: Training input data (features)\n",
    "#            y_train: Training target labels\n",
    "#            model: The trained neural network model\n",
    "#            Adam(learning_rate): Adam optimizer with specified learning rate\n",
    "#            epochs: Number of training epochs\n",
    "#            batch_size: Batch size for training\n",
    "#            gamma: Discount factor for rewards\n",
    "# PURPOSE: This is used to call the function named policy_gradient with the provided arguments as input parameters.The purpose of this line of code is to invoke the policy_gradient function and pass in the required input parameters for it to train the model with the reinforcement technique . \n",
    "# PRECONDITION: X_train_lstm, y_train, model2, epochs, batch_size, gamma, and learning_rate should be appropriately defined and initialized before this function call.\n",
    "# POSTCONDITION: The model's weights and biases being updated based on the policy gradient algorithm, the function is designed to update the model's parameters during training.\n",
    "\n",
    "policy_gradient(X_train_lstm, y_train, model2, optimizer, epochs=1, batch_size=32, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a503b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## LSTM_Q-Learning ###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32746b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Q-learning function\n",
    "# Define Q-LEARNING Technique for LSTM model\n",
    "# NAME: q_learning\n",
    "# PURPOSE: to implement the Q-learning technique for training a LSTM model (model) using given input data (x) and target labels (y) with a specified optimizer (optimizer). The algorithm is trained for a given number of epochs (epochs) and batch size (batch_size), and uses a discount factor (gamma) for computing the Q-values and rewards. The Q-values and rewards are used to modify the loss function and update the model's weights. The code also includes the visualization of reward and loss histograms for analysis. \n",
    "#          The purpose of this code is to define the Q-learning function for a LSTM model, which can be used for reinforcement learning tasks.\n",
    "# INVARIANTS: Calculates the length of the input data (x) using shape() method.length is an integer variable representing the number of rows in the input data x, used to determine the batch sizes and loop iterations in the training process.\n",
    "#             The input data y should be a numpy array of target labels for each sample in x.\n",
    "#             The model should be a neural network model implemented using TensorFlow.\n",
    "#             The optimizer should be an instance of a TensorFlow optimizer (e.g. Adam optimizer).\n",
    "#             Epochs should be an integer specifying the number of times to iterate over the input data.\n",
    "#             batch_size should be an integer specifying the size of each batch during training.\n",
    "#             gamma should be a float specifying the discount factor for future rewards in the Q-learning algorithm.\n",
    "#             The training process involves iterating over the input data in batches of size batch_size, and for each batch:\n",
    "#             The logits (raw output) of the model for the input data x_batch are computed using model(x_batch).\n",
    "#             The log probabilities of the logits are computed using tf.math.log(tf.clip_by_value(logits, 1e-10, 1.0)).\n",
    "#             One-hot encoded labels are created from the target labels y_batch using tf.one_hot() method.\n",
    "#             The maximum Q-value for each sample in the batch is computed using tf.reduce_max(logits, axis=1).\n",
    "#             The maximum Q-value is used as the reward and is converted to a numpy array using q_values.numpy().\n",
    "#             The policy gradient loss is computed by multiplying the log probabilities with the one-hot encoded labels and taking the negative mean using tf.reduce_mean(tf.reduce_sum(labels * log_probs, axis=1) * rewards).\n",
    "#             The gradients of the policy gradient loss with respect to the model's trainable weights are computed using tape.gradient().\n",
    "#             The gradients are applied to the optimizer using optimizer.apply_gradients() to update the model's weights.\n",
    "#             The average reward for the current batch is computed and used as a baseline.\n",
    "#             The model loss is computed by multiplying the policy gradient loss with the average reward and the discount factor (gamma).\n",
    "#             The gradients of the model loss with respect to the model's trainable weights are computed using tape.gradient().\n",
    "#             The gradients are applied to the optimizer using optimizer.apply_gradients() to update the model's weights.\n",
    "#             The rewards and losses for each epoch are stored in epoch_rewards and epoch_losses, respectively.\n",
    "#             After training, the reward and loss histograms for all epochs are plotted using plt.hist().\n",
    "\n",
    "\n",
    "def q_learning(x, y, model, optimizer, epochs, batch_size, gamma):#class to define the Q-Learning technique\n",
    "    length = x.shape[0] #Iterates over each epoch.\n",
    "    for epoch in range(epochs):\n",
    "        epoch_rewards = [] #empty lists that are likely intended to store the rewards for each epoch during the training of a neural network.\n",
    "        epoch_losses = [] #empty lists that are likely intended to store the losses for each epoch during the training of a neural network.\n",
    "        for batch_start in range(0, length, batch_size): #It is used to iterate over the input data (x) in batches of size batch_size during the training process. It starts from the beginning of the input data and increments in steps of batch_size until it reaches the end of the data. \n",
    "            batch_end = min(batch_start + batch_size, length) #It calculates the ending index (batch_end) of the current batch during the iteration over the input data (x) in batches. It ensures that the ending index does not exceed the total length of the data (length) to avoid accessing data beyond the available range. \n",
    "            x_batch = x[batch_start:batch_end] #Extracting a batch of data from the array 'x' using the start and end indices of the batch\n",
    "            y_batch = y[batch_start:batch_end] #Extracting a batch of labels from the array 'y' using the start and end indices of the batch\n",
    "            \n",
    "            with tf.GradientTape() as tape: #tf.GradientTape() is a TensorFlow API that provides a mechanism for automatic differentiation, which is a key technique used in machine learning optimization algorithms, such as gradient descent. It allows you to compute gradients of a computation with respect to its input variables, which can then be used to update the values of those variables during optimization.\"tape\" refers to a mechanism provided by TensorFlow that records operations for the purpose of computing gradients. The tape acts as a context within which computations are recorded, and these computations can later be used to compute gradients using the tape.gradient() method.\n",
    "                logits = model(x_batch) #Passing the batch of input data 'x_batch' through the model to obtain logits.Logits are the output of the model before applying any activation function, typically used for classification tasks Logits represent the raw, unnormalized scores for each class, which can be used for further processing or prediction.'model' is the trained model that takes 'x_batch' as input and produces logits as output.\n",
    "                log_probs = tf.math.log(tf.clip_by_value(logits, 1e-10, 1.0)) # calculates the log probabilities by taking the natural logarithm (tf.math.log()) of the model's predicted logits (logits). The tf.clip_by_value() function is used to clip the logits to a specific range to avoid numerical instability. In this case, the minimum value is set to 1e-10 and the maximum value is set to 1.0. The resulting log probabilities are stored in the log_probs variable.\n",
    "                labels = tf.one_hot(y_batch, depth=output_dim) #Converting the batch of labels 'y_batch' into one-hot encoding using 'tf.one_hot' function One-hot encoding represents categorical labels as binary vectors with a single '1' and remaining '0's.'y_batch' is the input tensor containing the batch of labels to be converted to one-hot encoding.'output_dim' specifies the depth of the one-hot encoding, which should be equal to the number of classes in the classification task\n",
    "                q_values = tf.reduce_max(logits, axis=1) # Compute the maximum Q-value for each sample in the batch\n",
    "                rewards = q_values.numpy() # Use the maximum Q-value as the reward\n",
    "                loss = -tf.reduce_mean(tf.reduce_sum(labels * log_probs, axis=1) * rewards) # Modify the loss function to include the reward\n",
    "                grads = tape.gradient(loss, model.trainable_weights)  #grads typically refers to the computed gradients of the loss function with respect to the trainable weights of a machine learning model.The tape.gradient() function in TensorFlow is used to compute the gradients of a given function (in this case, the loss function) with respect to a list of variables (in this case, the model.trainable_weights). These gradients can then be used in an optimization algorithm, such as gradient descent, to update the model weights and improve the model's performance during training.Compute the gradients of the loss with respect to the trainable weights of the model.loss: The computed loss value.model.trainable_weights: List of trainable weights of the model\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights)) #It applies the computed gradients (grads) to update the model weights (model.trainable_weights) using an optimizer. The zip() function is used to create pairs of gradients and corresponding model weights, which are then passed to the apply_gradients() method of the optimizer to perform the weight update step. This step is a key part of the optimization process in training machine learning models, as it helps to adjust the model weights based on the gradients of the loss function, with the goal of minimizing the loss and improving the model's performance.\n",
    "            print(\"The rewards are:\", rewards) #prints the rewards\n",
    "            epoch_rewards.append(rewards) #appends the rewards obtained by the network during the current epoch to the epoch_rewards list. This allows us to keep track of the rewards obtained by the network during each epoch of training.\n",
    "            epoch_losses.append(loss.numpy())  # appends the loss obtained by the network during the current epoch to the epoch_losses list. This allows us to keep track of the loss obtained by the network during each epoch of training.The numpy() method is used to extract the numerical value of the TensorFlow loss object, which is a symbolic representation of the loss function used to train the network. This numerical value is then appended to the epoch_losses list.\n",
    "    \n",
    "                \n",
    "    # Plot reward histogram\n",
    "    plt.hist(epoch_rewards, bins=20) #creates a histogram plot of the distribution of the rewards obtained by the network during training, using 20 bins. This allows us to visualize how often the network obtained rewards in different ranges, which can provide insight into its overall performance.\n",
    "    plt.title(\"Reward Histogram Q-Learning NN\") # sets the title of the plot to \"Reward Histogram Q-Learning NN\", which describes the type of algorithm used and the type of data being plotted.\n",
    "    plt.xlabel(\"Reward\") #sets the x-axis label to \"Reward\", which describes the meaning of the values being plotted on the x-axis.\n",
    "    plt.ylabel(\"Frequency\") #sets the y-axis label to \"Frequency\", which describes the number of occurrences of rewards in each bin.\n",
    "    plt.show() #displays the plot on the screen. This allows us to see the distribution of the rewards obtained by the network during training and gain insights into its performance.\n",
    "    \n",
    "    # Plot loss histogram \n",
    "    plt.hist(epoch_losses, bins=20) # creates a histogram plot of the distribution of the losses obtained by the network during training, using 20 bins. This allows us to visualize how often the network had a certain level of loss during the training process, which can provide insights into how well the network is learning and improving over time.\n",
    "    plt.title(\"Loss Histogram Q-Learning NN\") #sets the title of the plot to \"Loss Histogram Q-Learning NN\", which describes the type of algorithm used and the type of data being plotted.\n",
    "    plt.xlabel(\"Loss\") # sets the x-axis label to \"Loss\", which describes the meaning of the values being plotted on the x-axis.\n",
    "    plt.ylabel(\"Frequency\") #sets the y-axis label to \"Frequency\", which describes the number of occurrences of losses in each bin.\n",
    "    plt.show() # displays the plot on the screen. This allows us to see the distribution of the losses obtained by the network during training and gain insights into its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48c48b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "#Use the same parameters as for policy_gradient LSTM model as above\n",
    "#input_dim = X_train_vectors.shape[1]\n",
    "#output_dim = len(np.unique(y_train))\n",
    "\n",
    "# Reshape the data for LSTM input\n",
    "#X_train_lstm = np.reshape(X_train_vectors.toarray(), (X_train_vectors.shape[0], 1, X_train_vectors.shape[1]))\n",
    "#X_test_lstm = np.reshape(X_test_vectors.toarray(), (X_test_vectors.shape[0], 1, X_test_vectors.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3e49544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model and define the optimizer\n",
    "# Name: Neural Network model\n",
    "# Purpose: to define and create a LSTM neural network or classification model for a given dataset.\n",
    "# Invariants: The input_dim variable contains the number of features in the input data.\n",
    "#             The output_dim variable contains the number of classes in the target variable.\n",
    "#             The inputs variable is an input layer that takes a 3-dimensional input of shape (number of samples, 1, input_dim).\n",
    "#             The x variable is a hidden layer that applies a Long Short-Term Memory (LSTM) operation with 64 units and a Rectified Linear Unit (ReLU) activation function to the input.\n",
    "#             The model3 variable is a Keras Model that takes inputs as input and x as output.\n",
    "#             The optimizer variable is an Adam optimizer with a learning rate of 0.001 that is used to optimize the model during training.\n",
    "\n",
    "inputs = Input(shape=(1, input_dim,)) #creates an input layer in Keras with 3 dimensions, defined by the shape parameter. The first dimension is set to 1, indicating that each input sample will have a single time step. The second dimension is set to input_dim, indicating the number of features in each time step. The inputs variable stores this input layer, which will be used as the input to the subsequent layers in the model.\n",
    "x = LSTM(32, activation='relu')(inputs) # creates a Long Short-Term Memory (LSTM) layer in Keras with 64 units and the ReLU activation function. The inputs variable is passed as the input to this layer. The LSTM layer is a type of recurrent neural network layer that is commonly used for processing sequential data, such as text or time series data. The output of the LSTM layer is stored in the x variable and will be used as input to the subsequent layer in the model.\n",
    "x = Dense(output_dim, activation='softmax')(x) #creates a dense layer with output_dim number of units and the softmax activation function. The x variable is passed as the input to this layer. The purpose of this layer is to perform the final classification of the input data, with each unit representing a different class. The output of the dense layer will be a probability distribution over the different classes, with the sum of the probabilities equal to 1. The output of this layer is stored in the x variable and will be used as the output of the model.\n",
    "model3 = Model(inputs=inputs, outputs=x) # creates a Keras Model object that specifies the input and output layers of the neural network. The inputs variable represents the input layer of the model, which takes as input a tensor of shape (batch_size, 1, input_dim). The x variable represents the output layer of the model, which is the output of the last dense layer with softmax activation. The Model constructor takes two arguments: the input tensor and the output tensor. These tensors define the input and output of the model and all the layers in between. The resulting model3 object can be used to train and evaluate the neural network.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # initializes an instance of the Adam optimizer from the Keras API with a learning rate of 0.001. The Adam optimizer is a popular gradient descent optimization algorithm that is commonly used in deep learning.\n",
    "#optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001) #RMSprop optimizer\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # is an important line of code in the process of building a deep learning model using Keras. It compiles the model by specifying the loss function, optimizer, and metrics to be used during training.In particular, the loss parameter specifies the loss function that the model will use to evaluate its performance on the training data. In this case, the 'categorical_crossentropy' loss function is used, which is commonly used for multiclass classification problems.The optimizer parameter specifies the optimization algorithm that will be used to adjust the weights of the model during training in order to minimize the loss function. Here, the optimizer variable is passed in, which should be an instance of a pre-defined optimizer class from Keras, such as Adam or RMSprop.Finally, the metrics parameter specifies the evaluation metrics that will be used to monitor the model's performance during training and testing. In this case, 'accuracy' is the metric used, which is commonly used for classification problems.Overall, model.compile is a crucial step in the process of building and training a deep learning model, as it sets up the model for optimization by specifying the necessary components for the training process.\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy']) #loss:mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fcce7dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rewards are: [0.5015963  0.5010962  0.50025403 0.5002769  0.50064456 0.50001943\n",
      " 0.500169   0.5011169  0.5001677  0.5002142  0.5001276  0.5000235\n",
      " 0.50028896 0.5002861  0.5008515  0.500551   0.5008875  0.5002846\n",
      " 0.500448   0.500543   0.50001305 0.5003037  0.5000944  0.5007639\n",
      " 0.5009596  0.50093544 0.500536   0.5008638  0.50148994 0.5007094\n",
      " 0.50047964 0.5006105 ]\n",
      "The rewards are: [0.50103396 0.5002012  0.5006951  0.5009573  0.5007132  0.50031626\n",
      " 0.5002106  0.50156003 0.5023263  0.5001407  0.50141156 0.500062\n",
      " 0.5003131  0.5019356  0.5008604  0.50040495 0.50157934 0.50000316\n",
      " 0.5007609  0.50099206 0.50113964 0.50100577 0.50211716 0.50138444\n",
      " 0.50107676 0.5010752  0.5000351  0.50039566 0.50012743 0.50108486\n",
      " 0.5006831  0.50214523]\n",
      "The rewards are: [0.5011547  0.501001   0.50024706 0.5017034  0.5010142  0.50033087\n",
      " 0.50219256 0.5022765  0.50142586 0.5009932  0.5013283  0.501351\n",
      " 0.50117874 0.5018372  0.50163966 0.50059474 0.50007045 0.50261384\n",
      " 0.5005911  0.5001678  0.5017154  0.5000846  0.5021957  0.5015026\n",
      " 0.50042236 0.50084263 0.5020302  0.50176585 0.5009705  0.50190693\n",
      " 0.5004951  0.5010789 ]\n",
      "The rewards are: [0.50269604 0.50075054 0.5018308  0.5026522  0.5031517  0.5022519\n",
      " 0.5027283  0.50149953 0.5019345  0.50129384 0.5011342  0.5019772\n",
      " 0.5011681  0.50204223 0.50181633 0.5024323  0.50185716 0.5024455\n",
      " 0.5012579  0.5014056  0.50303453 0.5012058  0.50059384 0.5017223\n",
      " 0.5014686  0.5017952  0.50319225 0.50244486 0.5023112  0.50115865\n",
      " 0.50174123 0.50235194]\n",
      "The rewards are: [0.50222147 0.5015936  0.50442123 0.50102186 0.50184476 0.50342125\n",
      " 0.50264484 0.5022969  0.5023916  0.5013347  0.50372577 0.5005329\n",
      " 0.50266683 0.50235426 0.50343674 0.5015899  0.50272757 0.50235915\n",
      " 0.5038022  0.5019579  0.50269175 0.50045955 0.5043439  0.5035064\n",
      " 0.5021569  0.5024651  0.50132173 0.5031508  0.5035169  0.50250995\n",
      " 0.5026501  0.50276595]\n",
      "The rewards are: [0.50099516 0.5025064  0.5035801  0.5018698  0.50342196 0.5023542\n",
      " 0.50269717 0.50247806 0.50063866 0.5023218  0.5012326  0.50210863\n",
      " 0.5036336  0.5010897  0.5030635  0.5045346  0.5037913  0.5012007\n",
      " 0.5020028  0.5025903  0.5010263  0.50320846 0.5035373  0.5022792\n",
      " 0.5017869  0.50355077 0.5008971  0.5020629  0.5025625  0.5018874\n",
      " 0.5034615  0.50277936]\n",
      "The rewards are: [0.5030814  0.50336415 0.5003922  0.5014033  0.50294787 0.5024208\n",
      " 0.5030029  0.5014037  0.5031144  0.5017464  0.501457   0.50187385\n",
      " 0.5025533  0.50402015 0.5035246  0.5017378  0.50283885 0.50141656\n",
      " 0.5033133  0.5014315  0.5003744  0.50176936 0.50208807 0.50163907\n",
      " 0.50447273 0.5016061  0.5012056  0.50192386 0.50273556 0.5021725\n",
      " 0.50334215 0.5010802 ]\n",
      "The rewards are: [0.5022185  0.50233483 0.50276035 0.5016233  0.50262874 0.50370514\n",
      " 0.501934   0.5000935  0.50238484 0.5023635  0.50167936 0.50247\n",
      " 0.5034936  0.50082034 0.50149584 0.50229985 0.50099695 0.501545\n",
      " 0.501304   0.5019608  0.5012813  0.5027724  0.500261   0.5026429\n",
      " 0.50333    0.5011841  0.5034066  0.5038815  0.5025285  0.50276214\n",
      " 0.50214833 0.5031568 ]\n",
      "The rewards are: [0.5029629  0.5027404  0.503635   0.50165933 0.50173295 0.5029232\n",
      " 0.50107396 0.5023889  0.5017784  0.50310206 0.50244886 0.50241023\n",
      " 0.5021339  0.5009721  0.50076747 0.5007266  0.5026344  0.5007714\n",
      " 0.5028748  0.50112695 0.5029855  0.5026963  0.50285757 0.5011799\n",
      " 0.50106674 0.5014913  0.50205094 0.50355625 0.50072175 0.5008496\n",
      " 0.50121534 0.5017117 ]\n",
      "The rewards are: [0.5025142  0.50243086 0.5007551  0.50103647 0.5043614  0.50096077\n",
      " 0.5024678  0.5023901  0.50343734 0.5008872  0.50185573 0.5006822\n",
      " 0.50108784 0.5023704  0.5021668  0.5010234  0.5039143  0.5032558\n",
      " 0.5029429  0.50206244 0.5007007  0.5004997  0.5020288  0.50183916\n",
      " 0.5001728  0.5022329  0.50227183 0.5020718  0.50387305 0.50310445\n",
      " 0.5015037  0.5021536 ]\n",
      "The rewards are: [0.5020165  0.50199115 0.5010378  0.5021875  0.5056968  0.5023101\n",
      " 0.5019823  0.50116783 0.5010018  0.5028118  0.50172293 0.50101936\n",
      " 0.5018584  0.5043181  0.501235   0.5045624  0.5010609  0.50176966\n",
      " 0.50151086 0.5014579  0.50160575 0.5007492  0.5014588  0.5019587\n",
      " 0.5009279  0.50132954 0.5036393  0.5002884  0.50003844 0.5018508\n",
      " 0.50094664 0.5008935 ]\n",
      "The rewards are: [0.5009927  0.50213766 0.50191015 0.50321496 0.5013374  0.5026063\n",
      " 0.50019205 0.5044809  0.501865   0.50410855 0.5012742  0.50178194\n",
      " 0.503146   0.5003253  0.5022595  0.5007131  0.50274265 0.50185883\n",
      " 0.50155145 0.5031137  0.50205016 0.50169396 0.50134844 0.5022374\n",
      " 0.5024867  0.5031864  0.502674   0.50189817 0.50295764 0.5011031\n",
      " 0.50289255 0.5003172 ]\n",
      "The rewards are: [0.5011553  0.5007746  0.50185174 0.5030519  0.50180966 0.50161654\n",
      " 0.501897   0.5001802  0.5000631  0.50043154 0.50229406 0.50057715\n",
      " 0.5008152  0.5006454  0.5045187  0.5016955  0.5015716  0.5005404\n",
      " 0.5039174  0.50126195 0.50139076 0.5013404  0.50079423 0.5012086\n",
      " 0.50264245 0.5005141  0.50143284 0.500316   0.50211346 0.50088793\n",
      " 0.50174034 0.50261825]\n",
      "The rewards are: [0.5014078  0.5019617  0.50156784 0.500707   0.5004872  0.501117\n",
      " 0.5002964  0.50309145 0.5010608  0.50342256 0.5033666  0.5021831\n",
      " 0.50127226 0.50264764 0.5005268  0.5008762  0.5037221  0.5031366\n",
      " 0.50230145 0.5042414  0.50429416 0.5001631  0.50263685 0.5022221\n",
      " 0.5007463  0.5015529  0.5016186  0.50034726 0.50026447 0.50218505\n",
      " 0.50162274 0.5001838 ]\n",
      "The rewards are: [0.50255454 0.5015418  0.5013032  0.5001209  0.50087714 0.5017318\n",
      " 0.50044256 0.50247276 0.5023     0.5003343  0.5019686  0.5019614\n",
      " 0.50029594 0.50067437 0.5020621  0.5006611  0.5024697  0.50357443\n",
      " 0.5007628  0.5009077  0.50200695 0.50250226 0.50021267 0.50060725\n",
      " 0.50157356 0.5028837  0.5004092  0.50335205 0.5027272  0.50239176\n",
      " 0.5014458  0.5014195 ]\n",
      "The rewards are: [0.50026435 0.5038934  0.5005835  0.501453   0.50067776 0.50253284\n",
      " 0.50370204 0.50118226 0.50144994 0.50350034 0.50071603 0.50149703\n",
      " 0.5030727  0.501013   0.5023478  0.5010162  0.5050093  0.5001344\n",
      " 0.5014641  0.50080067 0.50119656 0.5002559  0.50073206 0.50005597\n",
      " 0.5006601  0.50141394 0.5009922  0.50443125 0.50309867 0.50567776\n",
      " 0.5028023  0.5028332 ]\n",
      "The rewards are: [0.5008359  0.501001   0.50041217 0.50125045 0.50127834 0.5002469\n",
      " 0.5032395  0.50024337 0.5007448  0.503195   0.50394744 0.50313383\n",
      " 0.50015503 0.50456107 0.5019432  0.5021859  0.503584   0.5020948\n",
      " 0.5003624  0.50236565 0.50062245 0.5030779  0.50256455 0.5035674\n",
      " 0.50269896 0.5002022  0.5037376  0.5005178  0.50293213 0.5017549\n",
      " 0.50083697 0.50098467]\n",
      "The rewards are: [0.50205034 0.50308776 0.50196064 0.5015454  0.5006237  0.5026013\n",
      " 0.501675   0.50584376 0.5028012  0.5028532  0.5021362  0.50483334\n",
      " 0.5028872  0.50154924 0.50100094 0.5008185  0.501341   0.50169015\n",
      " 0.5001405  0.50045556 0.5024568  0.50281143 0.5009429  0.50304663\n",
      " 0.5001697  0.5052718  0.50116944 0.50151765 0.500489   0.50109357\n",
      " 0.5013554  0.5025954 ]\n",
      "The rewards are: [0.5024787  0.50115275 0.5026397  0.5032773  0.5010614  0.50272\n",
      " 0.50057447 0.5015292  0.504009   0.5046079  0.504979   0.5051294\n",
      " 0.5016834  0.5020864  0.50058275 0.5025564  0.5036557  0.50087255\n",
      " 0.5036291  0.5007941  0.5012896  0.5020424  0.5016369  0.505043\n",
      " 0.5024386  0.50348115 0.5016494  0.50107527 0.503715   0.5009135\n",
      " 0.50269073 0.5002565 ]\n",
      "The rewards are: [0.5014657  0.50285226 0.5011855  0.5004166  0.50085014 0.50176215\n",
      " 0.50542766 0.5041974  0.5007982  0.5011977  0.5022194  0.5047229\n",
      " 0.5000966  0.50379544 0.50193727 0.50153565 0.50496817 0.50541574\n",
      " 0.5014165  0.5045733  0.5070202  0.50008774 0.5004959  0.50136256\n",
      " 0.5027021  0.50407284 0.5048432  0.5041902  0.5043268  0.50058144\n",
      " 0.50009423 0.50162923]\n",
      "The rewards are: [0.5025791  0.501685   0.5038019  0.50439495 0.5008899  0.50135666\n",
      " 0.5013857  0.50100875 0.5042605  0.5034189  0.5011334  0.50116825\n",
      " 0.5053774  0.50066006 0.500086   0.5047341  0.502117   0.5026234\n",
      " 0.5007024  0.50081676 0.5020798  0.5022803  0.5003783  0.5052957\n",
      " 0.50072217 0.5003936  0.50289893 0.5064364  0.5006217  0.5071022\n",
      " 0.5009272  0.50685   ]\n",
      "The rewards are: [0.5027717  0.50378007 0.5010867  0.50326    0.50435436 0.50278026\n",
      " 0.5002546  0.5035141  0.50005955 0.50408465 0.50115    0.50074995\n",
      " 0.5027242  0.50598186 0.5077458  0.5005828  0.502274   0.503747\n",
      " 0.5021568  0.5006791  0.5023727  0.5030352  0.50046754 0.50083196\n",
      " 0.50081736 0.50262433 0.5041169  0.50109434 0.50408703 0.50577873\n",
      " 0.50419235 0.5018998 ]\n",
      "The rewards are: [0.50141245 0.5000871  0.5071185  0.5000877  0.5038944  0.50354123\n",
      " 0.5056898  0.5039681  0.50216496 0.5026156  0.5067431  0.5069701\n",
      " 0.50021636 0.50071776 0.504867   0.5013808  0.50511223 0.50667804\n",
      " 0.5013736  0.5009202  0.50235814 0.50035834 0.50007856 0.50354517\n",
      " 0.5020451  0.50161606 0.5023741  0.5004418  0.5018363  0.50285566\n",
      " 0.5060614  0.5012977 ]\n",
      "The rewards are: [0.50568765 0.5012443  0.5048218  0.5040136  0.50420773 0.50020444\n",
      " 0.5065995  0.5037001  0.50338316 0.5055223  0.5045538  0.50226265\n",
      " 0.5006463  0.50407326 0.5048092  0.50433517 0.50111127 0.50125206\n",
      " 0.5048264  0.5052994  0.5003758  0.5031002  0.50205624 0.50059056\n",
      " 0.5040825  0.50526905 0.506262   0.50034875 0.50828916 0.50661\n",
      " 0.5037217  0.50618863]\n",
      "The rewards are: [0.5074729  0.504255   0.5092511  0.50680095 0.5031621  0.50558233\n",
      " 0.5067345  0.50223225 0.50423336 0.5017628  0.5053376  0.5017098\n",
      " 0.5074572  0.50552285 0.5009092  0.50696874 0.500889   0.50141823\n",
      " 0.5033048  0.5085659  0.5044132  0.50593126 0.50629437 0.50697523\n",
      " 0.5078835  0.5023707  0.5024824  0.5041726  0.5013409  0.5027931\n",
      " 0.50137377 0.50082535]\n",
      "The rewards are: [0.5076946  0.50085837 0.50172055 0.50532204 0.50662553 0.5046193\n",
      " 0.507239   0.50411147 0.50274664 0.50808424 0.5008652  0.5092744\n",
      " 0.50222677 0.5030595  0.50261176 0.5014571  0.50477415 0.5004264\n",
      " 0.50569403 0.50171125 0.50132954 0.5028719  0.5008567  0.50298893\n",
      " 0.50031775 0.5052553  0.50660133 0.50358474 0.5043463  0.5059944\n",
      " 0.5065286  0.5036467 ]\n",
      "The rewards are: [0.5056208  0.5038924  0.50042355 0.5073069  0.5055122  0.5049587\n",
      " 0.50503415 0.5044719  0.50079685 0.5015969  0.5061474  0.5006284\n",
      " 0.5044141  0.5021665  0.5074704  0.5019946  0.50736195 0.5030028\n",
      " 0.5031093  0.50009394 0.5084629  0.50485325 0.504369   0.50186443\n",
      " 0.5029285  0.50020105 0.5015554  0.5001641  0.5038692  0.50310546\n",
      " 0.5005298  0.5016076 ]\n",
      "The rewards are: [0.5028098  0.50062263 0.5095376  0.502284   0.5006122  0.5046138\n",
      " 0.5044195  0.50045395 0.50825804 0.50102025 0.50525224 0.50366575\n",
      " 0.50577945 0.5018766  0.5054397  0.5043772  0.50860375 0.5049291\n",
      " 0.50707954 0.5054667  0.50719905 0.50537205 0.5099716  0.50591797\n",
      " 0.50292456 0.50172204 0.5036784  0.50618535 0.50012237 0.5063159\n",
      " 0.5015288  0.5029022 ]\n",
      "The rewards are: [0.5036564  0.5047503  0.51091844 0.5092712  0.500927   0.5072109\n",
      " 0.5035368  0.5003986  0.5028071  0.506872   0.5080949  0.5036681\n",
      " 0.50071317 0.5042568  0.50345075 0.5046606  0.5019297  0.505117\n",
      " 0.5009972  0.5050375  0.5092856  0.5002926  0.5100859  0.5093279\n",
      " 0.5085522  0.505886   0.5070082  0.50044525 0.5001583  0.5075085\n",
      " 0.50555855 0.5011205 ]\n",
      "The rewards are: [0.5009707  0.5078053  0.50575745 0.5016897  0.5027592  0.5062141\n",
      " 0.5105024  0.50191003 0.5054304  0.50830597 0.51253647 0.5021447\n",
      " 0.5109877  0.50663716 0.50689787 0.5060385  0.5041107  0.5097514\n",
      " 0.5080528  0.5079788  0.50377244 0.5077247  0.5108449  0.50796014\n",
      " 0.50666124 0.50202155 0.5012764  0.5059976  0.5065622  0.504501\n",
      " 0.5011678  0.5063028 ]\n",
      "The rewards are: [0.507293   0.5091242  0.50654167 0.50292075 0.5080228  0.5060881\n",
      " 0.50670683 0.5012521  0.5025058  0.5004297  0.5049325  0.5123217\n",
      " 0.50307715 0.5138738  0.50762165 0.5044111  0.5015791  0.5006157\n",
      " 0.5082116  0.50497323 0.5090829  0.50550437 0.50573397 0.5043965\n",
      " 0.51355034 0.5057767  0.5085212  0.50233173 0.50524765 0.5084143\n",
      " 0.50283897 0.50920844]\n",
      "The rewards are: [0.50726336 0.5041567  0.5003638  0.50550205 0.5069031  0.5018334\n",
      " 0.504714   0.5038376  0.506293   0.5003842  0.50779235 0.5013327\n",
      " 0.5119386  0.50617754 0.5059006  0.5013795  0.5009175  0.504544\n",
      " 0.51050997 0.5065881  0.50317085 0.51107264 0.5101562  0.50374675\n",
      " 0.50462145 0.5120145  0.5112501  0.5083932  0.5040553  0.5031148\n",
      " 0.5063303  0.5059426 ]\n",
      "The rewards are: [0.51541024 0.5025475  0.5041319  0.5045312  0.50498605 0.5042428\n",
      " 0.51143605 0.5011428  0.5000851  0.5113086  0.50133044 0.5108811\n",
      " 0.503932   0.50213075 0.5074333  0.51142323 0.51115584 0.511816\n",
      " 0.50540257 0.50027084 0.5060622  0.50896996 0.5026288  0.50790995\n",
      " 0.5040246  0.5034804  0.50842476 0.5126033  0.50388265 0.50169396\n",
      " 0.5028047  0.5104587 ]\n",
      "The rewards are: [0.50175774 0.5004795  0.5141556  0.5046134  0.50610805 0.5095995\n",
      " 0.5133129  0.5042248  0.51332724 0.5036614  0.5148575  0.50471795\n",
      " 0.50831735 0.5099705  0.51252306 0.50377387 0.51386607 0.50243413\n",
      " 0.51001644 0.5020986  0.5108635  0.50372595 0.50514656 0.51122415\n",
      " 0.50774693 0.5090158  0.50278634 0.504255   0.50106966 0.51173747\n",
      " 0.5051405  0.50228167]\n",
      "The rewards are: [0.50853497 0.5054926  0.5039782  0.508854   0.5030116  0.51177114\n",
      " 0.509565   0.51194596 0.5070383  0.5050855  0.5123792  0.5060849\n",
      " 0.5019816  0.5167852  0.5001747  0.5005434  0.5116551  0.50936854\n",
      " 0.5076248  0.5122625  0.5157168  0.50083387 0.5025709  0.50570256\n",
      " 0.5136097  0.51338315 0.5045731  0.50936484 0.50541943 0.50542414\n",
      " 0.5032864  0.5042375 ]\n",
      "The rewards are: [0.50452787 0.5121935  0.50747305 0.50753194 0.51286924 0.50448084\n",
      " 0.51264864 0.51519173 0.5085129  0.5018916  0.5164214  0.50149417\n",
      " 0.51077306 0.5130043  0.50439066 0.50256354 0.50273573 0.5053748\n",
      " 0.5171792  0.51277226 0.5001246  0.5131505  0.50672257 0.5004111\n",
      " 0.51206356 0.5098384  0.5169324  0.50120556 0.505823   0.50326675\n",
      " 0.51105905 0.5062997 ]\n",
      "The rewards are: [0.5117851  0.50538546 0.5140338  0.5129121  0.5144362  0.5110043\n",
      " 0.5110624  0.5087165  0.5035659  0.500317   0.5036366  0.50016415\n",
      " 0.5007173  0.5089923  0.5067254  0.516133   0.50686467 0.5001281\n",
      " 0.50755334 0.50619775 0.5026476  0.50677097 0.5147015  0.50559014\n",
      " 0.5033193  0.5169305  0.5095699  0.5029929  0.5173607  0.5052078\n",
      " 0.51218784 0.50793815]\n",
      "The rewards are: [0.5036534  0.5105386  0.50077623 0.5184175  0.5095807  0.5002717\n",
      " 0.5076571  0.50607216 0.5135425  0.5101629  0.51482207 0.5169906\n",
      " 0.50576013 0.51716    0.50325555 0.5142851  0.5094273  0.5015184\n",
      " 0.50093096 0.5148963  0.51086134 0.5116357  0.5128572  0.50261664\n",
      " 0.5150296  0.5099407  0.5024534  0.5072559  0.5174096  0.5146206\n",
      " 0.50508034 0.50106406]\n",
      "The rewards are: [0.5108906  0.5031738  0.5121572  0.5014269  0.5023762  0.50474775\n",
      " 0.50142866 0.50541055 0.50924575 0.50818735 0.5114466  0.51071745\n",
      " 0.50105494 0.51465815 0.5149829  0.5040951  0.5023246  0.5205432\n",
      " 0.51301974 0.50904924 0.5053223  0.5018289  0.501828   0.5028444\n",
      " 0.5013568  0.5054709  0.51567984 0.5054424  0.50289506 0.5108182\n",
      " 0.5061133  0.51379883]\n",
      "The rewards are: [0.5091311  0.5095512  0.51193565 0.5186988  0.50294954 0.5195984\n",
      " 0.5186467  0.5155438  0.5006882  0.50492567 0.5159321  0.5008013\n",
      " 0.519332   0.50561434 0.50104094 0.5114092  0.5216125  0.5188418\n",
      " 0.5035744  0.5183248  0.5008891  0.5149129  0.5044535  0.5077859\n",
      " 0.5155242  0.5078433  0.5104436  0.51566416 0.516187   0.5024602\n",
      " 0.52095675 0.5033975 ]\n",
      "The rewards are: [0.50917864 0.50152177 0.5088064  0.50113446 0.50637335 0.5054354\n",
      " 0.5031203  0.5057473  0.51505876 0.50868195 0.509697   0.50591093\n",
      " 0.5043511  0.5105227  0.519623   0.5072258  0.5004434  0.5157316\n",
      " 0.51620054 0.5181492  0.5053324  0.5156286  0.5216701  0.51973325\n",
      " 0.5154144  0.50416666 0.50096625 0.50879043 0.51847315 0.5087198\n",
      " 0.5188277  0.5106288 ]\n",
      "The rewards are: [0.5041728  0.50236726 0.5166814  0.5026825  0.5179323  0.5190576\n",
      " 0.5157386  0.5046738  0.5065235  0.51269776 0.5053036  0.5134368\n",
      " 0.5187891  0.50625235 0.5109561  0.50926536 0.5014523  0.5084459\n",
      " 0.5123291  0.5075992  0.5048615  0.5021322  0.51228774 0.5025692\n",
      " 0.5009408  0.5041465  0.5121097  0.5007986  0.52174056 0.5151766\n",
      " 0.51335543 0.5036862 ]\n",
      "The rewards are: [0.5066458  0.5075277  0.51269895 0.50144917 0.51234025 0.5089037\n",
      " 0.50684893 0.5142076  0.50378036 0.5074919  0.5071832  0.5102253\n",
      " 0.51549083 0.5085397  0.51604754 0.5066304  0.5257243  0.51256406\n",
      " 0.5025893  0.51415753 0.50680375 0.51639247 0.51845217 0.51426315\n",
      " 0.51182353 0.50311154 0.5158073  0.5015631  0.5204047  0.52064\n",
      " 0.5223972  0.51658314]\n",
      "The rewards are: [0.50390697 0.51014656 0.50311416 0.51503056 0.51074076 0.51474863\n",
      " 0.50784487 0.5035333  0.50479436 0.51347715 0.50581855 0.511746\n",
      " 0.50453585 0.5096217  0.52144575 0.50590664 0.50074404 0.51325506\n",
      " 0.521269   0.5124718  0.5207918  0.51089907 0.5022433  0.51283675\n",
      " 0.511269   0.5033051  0.5112486  0.5000261  0.5098882  0.5138268\n",
      " 0.52376336 0.5062245 ]\n",
      "The rewards are: [0.50206393 0.5025417  0.5037791  0.5076411  0.5095616  0.5004041\n",
      " 0.52804744 0.511962   0.5020474  0.51558197 0.50837654 0.5060624\n",
      " 0.51299083 0.5001505  0.5119854  0.5141323  0.50919265 0.5123899\n",
      " 0.5089719  0.51266474 0.51280606 0.5262815  0.50173324 0.5046695\n",
      " 0.5123291  0.5024053  0.5190345  0.5094538  0.50005126 0.50525546\n",
      " 0.5168842  0.50284624]\n",
      "The rewards are: [0.5153448  0.51465356 0.5076676  0.5116352  0.5069364  0.51659334\n",
      " 0.516253   0.5017339  0.51927364 0.5184643  0.514268   0.50204605\n",
      " 0.52358896 0.51245356 0.5125641  0.52373475 0.5022639  0.52469385\n",
      " 0.50305367 0.5227078  0.53124934 0.50856954 0.51662064 0.52356917\n",
      " 0.5016456  0.51183283 0.5195555  0.5197291  0.52606297 0.5089704\n",
      " 0.51220506 0.50851536]\n",
      "The rewards are: [0.5036902  0.5013737  0.5207575  0.50269043 0.5150699  0.5118993\n",
      " 0.5105017  0.5065036  0.52012736 0.51491576 0.5202024  0.5053598\n",
      " 0.50149137 0.50084114 0.5228734  0.5112719  0.5014353  0.5029651\n",
      " 0.5152545  0.52071965 0.501873   0.5161268  0.5030394  0.51755095\n",
      " 0.5241957  0.5266899  0.5021207  0.51144075 0.51500857 0.5172229\n",
      " 0.517807   0.5054539 ]\n",
      "The rewards are: [0.52053195 0.51817554 0.51519465 0.5281658  0.50120455 0.51523715\n",
      " 0.52743435 0.5131862  0.5154953  0.50219554 0.5209492  0.525771\n",
      " 0.50201344 0.507352   0.5063996  0.5058388  0.5022419  0.51372004\n",
      " 0.5104749  0.52274275 0.5206922  0.50938797 0.5154847  0.5201333\n",
      " 0.511287   0.50601333 0.51604533 0.5156764  0.5202439  0.5079509\n",
      " 0.5050318  0.51051676]\n",
      "The rewards are: [0.5023014  0.50434965 0.51317006 0.5220274  0.5168039  0.5240979\n",
      " 0.5216624  0.5288989  0.50111645 0.50273013 0.5297147  0.5055104\n",
      " 0.51647323 0.51107246 0.5060802  0.5229773  0.52498394 0.5075619\n",
      " 0.5176548  0.5204568  0.5053466  0.500181   0.5071363  0.5000443\n",
      " 0.50188714 0.50037503 0.51788867 0.50281405 0.51054496 0.5053395\n",
      " 0.5098665  0.5114743 ]\n",
      "The rewards are: [0.5048061  0.50286275 0.51502573 0.5278645  0.5092846  0.52151585\n",
      " 0.50297505 0.50477254 0.5182523  0.5194393  0.5025649  0.5223316\n",
      " 0.5264079  0.5004714  0.5076276  0.51019496 0.52716416 0.5137091\n",
      " 0.5058017  0.5060999  0.5114416  0.5201806  0.5313321  0.50460976\n",
      " 0.50070906 0.5253888  0.5131485  0.51069874 0.5016923  0.5034567\n",
      " 0.51719207 0.50767887]\n",
      "The rewards are: [0.5193482  0.503745   0.5309339  0.5230882  0.52108264 0.50172347\n",
      " 0.5274583  0.5011439  0.5075479  0.51903105 0.5222685  0.5117323\n",
      " 0.5165339  0.5289788  0.5072475  0.52169764 0.5168755  0.5067021\n",
      " 0.5017392  0.505074   0.5040932  0.5099495  0.5256417  0.5106382\n",
      " 0.50361437 0.5090044  0.51293314 0.52552634 0.52039176 0.5021551\n",
      " 0.5269352  0.5246221 ]\n",
      "The rewards are: [0.5041805  0.50894266 0.5169779  0.51197064 0.51803    0.5154476\n",
      " 0.5018149  0.5059287  0.51768374 0.523061   0.5202909  0.507984\n",
      " 0.50650156 0.51586807 0.5227761  0.53347206 0.52211684 0.50515956\n",
      " 0.5259728  0.51527184 0.514033   0.5081535  0.5086291  0.5012939\n",
      " 0.50893426 0.53152317 0.5244751  0.5245317  0.5015615  0.52467096\n",
      " 0.50505894 0.52231884]\n",
      "The rewards are: [0.5120185  0.5304866  0.52079827 0.5002043  0.5105103  0.5042194\n",
      " 0.5182799  0.5278499  0.51792693 0.50649154 0.52576935 0.52046347\n",
      " 0.5047714  0.5130577  0.5107109  0.50352883 0.5276667  0.50946695\n",
      " 0.5014142  0.52845705 0.5115906  0.5089806  0.5013277  0.5269342\n",
      " 0.50356585 0.527306   0.52126384 0.52665836 0.5041105  0.5017947\n",
      " 0.5205541  0.5072772 ]\n",
      "The rewards are: [0.5063838  0.5123759  0.52139354 0.5191058  0.51649785 0.5088573\n",
      " 0.50964093 0.5320853  0.5054497  0.50714165 0.5028017  0.50872046\n",
      " 0.5073713  0.5008056  0.5172224  0.50007886 0.52428126 0.51971775\n",
      " 0.50300974 0.50152385 0.53200525 0.5253629  0.50097835 0.50065184\n",
      " 0.5139672  0.51483184 0.5181559  0.52315897 0.5103113  0.52959263\n",
      " 0.5211069  0.5324919 ]\n",
      "The rewards are: [0.51063246 0.51910305 0.53401303 0.50454366 0.50752544 0.5064828\n",
      " 0.5251011  0.52535397 0.52200174 0.51729006 0.51196295 0.52050686\n",
      " 0.52392846 0.51096356 0.51230323 0.51509285 0.51669234 0.50910074\n",
      " 0.5112638  0.5341481  0.51750994 0.5309334  0.5237424  0.5118309\n",
      " 0.50351    0.509317   0.52269197 0.50537497 0.5356328  0.5023541\n",
      " 0.5029195  0.5108593 ]\n",
      "The rewards are: [0.51470923 0.5245277  0.5269693  0.53358483 0.5323747  0.5348681\n",
      " 0.5056673  0.5297903  0.5201374  0.51685286 0.5257862  0.52655643\n",
      " 0.50961614 0.51327646 0.50008607 0.5155273  0.5061801  0.5023132\n",
      " 0.50522107 0.54003406 0.5042287  0.50207144 0.5283637  0.5197644\n",
      " 0.52197725 0.53040576 0.51819915 0.50937885 0.5180948  0.5145854\n",
      " 0.5073255  0.5110228 ]\n",
      "The rewards are: [0.5165679  0.52275217 0.5016326  0.5002866  0.52155584 0.50291824\n",
      " 0.5031177  0.5353627  0.52886194 0.509869   0.52953947 0.5002291\n",
      " 0.5034966  0.52415025 0.50426364 0.50192076 0.505209   0.51427495\n",
      " 0.50060916 0.5245376  0.51753783 0.5160511  0.5057766  0.50341207\n",
      " 0.5153652  0.5036598  0.5085146  0.50300646 0.5118314  0.50701505\n",
      " 0.51414263 0.5152883 ]\n",
      "The rewards are: [0.5089896  0.5086952  0.5193097  0.5150543  0.5060296  0.53270614\n",
      " 0.5250006  0.53407955 0.5335461  0.5039862  0.500569   0.5387793\n",
      " 0.51768154 0.5011066  0.5121352  0.5225707  0.51003087 0.5247305\n",
      " 0.5031653  0.5019526  0.50723577 0.51994973 0.50716096 0.52081025\n",
      " 0.525134   0.5002248  0.5100215  0.5248852  0.5015944  0.53124714\n",
      " 0.547882   0.5236473 ]\n",
      "The rewards are: [0.52780646 0.5301353  0.50582385 0.5134582  0.50933707 0.5443545\n",
      " 0.5224781  0.5166657  0.5161804  0.5254912  0.5057232  0.5350104\n",
      " 0.50041217 0.5272018  0.5184067  0.5030734  0.50857127 0.51637965\n",
      " 0.5113878  0.542862   0.5097595  0.5139132  0.5334873  0.53086317\n",
      " 0.5057008  0.51535773 0.5199989  0.5091737  0.52798164 0.54046375\n",
      " 0.53444695 0.5354956 ]\n",
      "The rewards are: [0.52382475 0.5066299  0.53088516 0.5260096  0.505984   0.5203858\n",
      " 0.5167017  0.5044003  0.5343252  0.5377286  0.51785594 0.5263077\n",
      " 0.51468235 0.5288392  0.50473577 0.5180922  0.5319757  0.5232282\n",
      " 0.5030572  0.50789773 0.5299515  0.51047385 0.5306046  0.50706583\n",
      " 0.5009455  0.50270927 0.5214027  0.5185601  0.51475275 0.5021813\n",
      " 0.5308208  0.53073275]\n",
      "The rewards are: [0.5247112  0.5182763  0.52192044 0.53801084 0.52748483 0.51589984\n",
      " 0.5210691  0.52472436 0.5258019  0.5226989  0.5344533  0.50796056\n",
      " 0.5366502  0.5020158  0.52938694 0.53175235 0.5125915  0.50469327\n",
      " 0.5018022  0.5048915  0.52973324 0.5126444  0.526169   0.5194052\n",
      " 0.54160005 0.52960837 0.5060825  0.53058124 0.50890976 0.50255114\n",
      " 0.5414566  0.51456   ]\n",
      "The rewards are: [0.50454885 0.5146504  0.5392342  0.5221748  0.50605714 0.5160529\n",
      " 0.5198912  0.51611525 0.5151543  0.5427777  0.5317955  0.51067376\n",
      " 0.5108879  0.51419187 0.5080252  0.515367   0.53136593 0.52511495\n",
      " 0.5062861  0.50677687 0.5024909  0.5030591  0.5139507  0.5233662\n",
      " 0.5306335  0.5019718  0.51330596 0.50420886 0.52552825 0.5131359\n",
      " 0.50160325 0.52186394]\n",
      "The rewards are: [0.5012338  0.5129741  0.51062024 0.5120537  0.5295454  0.5046753\n",
      " 0.51703924 0.50330555 0.514406   0.519104   0.5346977  0.5351366\n",
      " 0.5211864  0.50404286 0.5251015  0.5422839  0.536178   0.5216422\n",
      " 0.5005648  0.5169381  0.5220583  0.53064275 0.5542428  0.5256651\n",
      " 0.5111444  0.5324417  0.5172071  0.53281575 0.5014668  0.50242174\n",
      " 0.5013995  0.5108701 ]\n",
      "The rewards are: [0.5111959  0.5206131  0.51617855 0.51209813 0.5012225  0.5084575\n",
      " 0.50864595 0.5041345  0.5077801  0.50830615 0.5140469  0.530286\n",
      " 0.5161501  0.54905254 0.54113173 0.5006328  0.51220304 0.5381475\n",
      " 0.50026786 0.50377196 0.5144364  0.533164   0.51653254 0.52096117\n",
      " 0.51423347 0.5237004  0.50880164 0.5251711  0.5371763  0.5203695\n",
      " 0.5476257  0.52609175]\n",
      "The rewards are: [0.5341493  0.5214394  0.521198   0.5334138  0.5173074  0.53810436\n",
      " 0.54073703 0.5299749  0.5352581  0.54170555 0.5170409  0.5496841\n",
      " 0.5505529  0.5258306  0.5329505  0.50370777 0.5270299  0.50076675\n",
      " 0.5369594  0.5353438  0.54456097 0.5273427  0.53059804 0.51673776\n",
      " 0.50138694 0.50169265 0.5065304  0.53291947 0.5185581  0.5112716\n",
      " 0.531042   0.53970385]\n",
      "The rewards are: [0.54160625 0.50124943 0.5313417  0.5159189  0.5241597  0.5057073\n",
      " 0.52543247 0.5547536  0.5498966  0.5427189  0.5103978  0.5355063\n",
      " 0.5071369  0.5028536  0.506894   0.5439154  0.52381533 0.54941237\n",
      " 0.5304157  0.52153146 0.5412697  0.5151552  0.5058868  0.5113812\n",
      " 0.5162799  0.5140432  0.5002565  0.51034087 0.5119127  0.5175275\n",
      " 0.5087351  0.53634554]\n",
      "The rewards are: [0.53489435 0.5093051  0.51530457 0.5091098  0.5021863  0.50167966\n",
      " 0.5041843  0.5096105  0.5100754  0.5060593  0.53126794 0.5290937\n",
      " 0.5406635  0.5352577  0.5029382  0.5252581  0.5067434  0.50050634\n",
      " 0.50129527 0.5173121  0.5485365  0.507698   0.5217832  0.52737194\n",
      " 0.50974846 0.5396437  0.52795625 0.5155379  0.5121861  0.5065554\n",
      " 0.5363796  0.5229353 ]\n",
      "The rewards are: [0.51631606 0.51120454 0.50045913 0.5122442  0.5612707  0.5071769\n",
      " 0.528869   0.5116674  0.5381321  0.5020636  0.5203486  0.5219761\n",
      " 0.51399225 0.53918076 0.5548589  0.5106509  0.50483984 0.53876555\n",
      " 0.52436936 0.5181177  0.5063605  0.5190791  0.512614   0.5145296\n",
      " 0.5188394  0.5146919  0.5066956  0.52527064 0.50034934 0.54296935\n",
      " 0.5319369  0.5216007 ]\n",
      "The rewards are: [0.5395329  0.513634   0.52201205 0.5206711  0.51148933 0.50588983\n",
      " 0.5285623  0.5283632  0.5115586  0.54111814 0.5234541  0.51814544\n",
      " 0.5268653  0.53758156 0.5007166  0.5149681  0.51958495 0.5490716\n",
      " 0.50413156 0.5137517  0.50293475 0.53476745 0.5197765  0.5066827\n",
      " 0.5092308  0.53258234 0.5155843  0.5430312  0.52876544 0.52197653\n",
      " 0.5011694  0.5020646 ]\n",
      "The rewards are: [0.510255   0.52424365 0.5271124  0.5518525  0.5186317  0.5009852\n",
      " 0.5177985  0.55927855 0.5420028  0.539235   0.53295004 0.5325091\n",
      " 0.5191487  0.50528467 0.54424304 0.54888994 0.5234971  0.50443804\n",
      " 0.53589433 0.55176806 0.5224656  0.52419686 0.53384495 0.5119348\n",
      " 0.502675   0.5248978  0.53701246 0.52210104 0.54261094 0.5264585\n",
      " 0.5259561  0.5244678 ]\n",
      "The rewards are: [0.50806403 0.5026021  0.50701696 0.55265576 0.5160484  0.5245751\n",
      " 0.50928074 0.517978   0.5246281  0.5397652  0.53839    0.502133\n",
      " 0.53773504 0.5557117  0.56108487 0.52191716 0.502367   0.53838944\n",
      " 0.5179451  0.50808877 0.5539062  0.5050282  0.5174228  0.52220833\n",
      " 0.5313504  0.50921214 0.55881727 0.5029932  0.55048096 0.50197905\n",
      " 0.54489785 0.5238264 ]\n",
      "The rewards are: [0.54335576 0.51433635 0.516065   0.50410265 0.5063486  0.51271796\n",
      " 0.5188343  0.5172476  0.53488433 0.5078593  0.50827307 0.5459775\n",
      " 0.5553917  0.5137303  0.515542   0.51254594 0.50670934 0.5379904\n",
      " 0.5370208  0.5158906  0.5205769  0.53179073 0.51514    0.53161335\n",
      " 0.5260409  0.521793   0.5092587  0.5218264  0.53250015 0.5462764\n",
      " 0.5024958  0.525049  ]\n",
      "The rewards are: [0.52668047 0.5157834  0.5096167  0.5238361  0.5073172  0.5116388\n",
      " 0.5310075  0.5134902  0.5096033  0.5287917  0.51156896 0.5371746\n",
      " 0.5059812  0.5372532  0.5073904  0.5098435  0.5090112  0.50461817\n",
      " 0.5153548  0.512132   0.53511804 0.53930813 0.5113613  0.5477035\n",
      " 0.51090336 0.50339407 0.5271485  0.541875   0.5006981  0.54754484\n",
      " 0.5200746  0.5424403 ]\n",
      "The rewards are: [0.5057972  0.51144844 0.55513674 0.55690753 0.5687142  0.5390636\n",
      " 0.51088977 0.53687584 0.5367693  0.5480204  0.5437729  0.50603473\n",
      " 0.5001799  0.50328034 0.5440137  0.51227105 0.5446469  0.54426694\n",
      " 0.5101946  0.5351236  0.5259864  0.5372613  0.50727737 0.5059301\n",
      " 0.5337883  0.56263644 0.5208651  0.54927355 0.5600842  0.545974\n",
      " 0.5023402  0.50305295]\n",
      "The rewards are: [0.5614131  0.52431434 0.5400672  0.5295984  0.548358   0.5248925\n",
      " 0.50488335 0.5307291  0.5090202  0.56265163 0.5187901  0.5041267\n",
      " 0.51518166 0.511152   0.5040299  0.53775233 0.5571622  0.5017874\n",
      " 0.53674865 0.5071916  0.5233979  0.50429815 0.58100766 0.54266053\n",
      " 0.501449   0.53156376 0.5351822  0.54624814 0.51011705 0.5137232\n",
      " 0.5184119  0.5079174 ]\n",
      "The rewards are: [0.50113726 0.55824083 0.5516283  0.5614719  0.5004573  0.5386825\n",
      " 0.5301487  0.54545623 0.5223116  0.508891   0.5332883  0.52222854\n",
      " 0.50542736 0.5290428  0.50756156 0.55257493 0.51064074 0.52697086\n",
      " 0.50486434 0.56622165 0.55543023 0.5351776  0.51442933 0.52064234\n",
      " 0.5265487  0.5207719  0.5075449  0.54263026 0.5065452  0.5080267\n",
      " 0.5036054  0.5473669 ]\n",
      "The rewards are: [0.53662324 0.5112342  0.5049302  0.5352456  0.50587016 0.50451237\n",
      " 0.5066705  0.5478803  0.52049327 0.5299338  0.5055842  0.53039306\n",
      " 0.50358564 0.52269834 0.51739305 0.5341545  0.54478145 0.5121442\n",
      " 0.5027607  0.51385224 0.5536614  0.5153091  0.5225124  0.54003316\n",
      " 0.52211124 0.5315967  0.5362905  0.5144987  0.5539766  0.5238214\n",
      " 0.5070015  0.5421039 ]\n",
      "The rewards are: [0.54264635 0.54254425 0.5562014  0.5006772  0.5341186  0.500587\n",
      " 0.50582826 0.5088512  0.5017528  0.51091033 0.5403638  0.5420346\n",
      " 0.53664666 0.5091744  0.53534883 0.5284963  0.5165885  0.5087343\n",
      " 0.52300537 0.5552025  0.5272875  0.5103819  0.5074097  0.5025857\n",
      " 0.5097587  0.50674236 0.55470896 0.54020035 0.5436343  0.5369824\n",
      " 0.5278853  0.54806167]\n",
      "The rewards are: [0.56614983 0.5194129  0.53959966 0.51145065 0.5530298  0.5384982\n",
      " 0.54856706 0.5259818  0.5310349  0.5174502  0.5269303  0.503341\n",
      " 0.5006412  0.5453013  0.5032643  0.5033457  0.5059833  0.5068628\n",
      " 0.5001816  0.5157315  0.538284   0.50857997 0.5628348  0.5023539\n",
      " 0.52257615 0.5410797  0.5358821  0.5446527  0.5410489  0.5240901\n",
      " 0.56055176 0.511708  ]\n",
      "The rewards are: [0.55597275 0.53930765 0.5317837  0.55118495 0.5162521  0.57018185\n",
      " 0.54239005 0.5427834  0.5555692  0.517101   0.54249376 0.5507496\n",
      " 0.5006445  0.55990875 0.5547255  0.5112173  0.5226858  0.53275424\n",
      " 0.52249146 0.54164207 0.50445175 0.5055516  0.5096193  0.5788803\n",
      " 0.558556   0.5062636  0.50877887 0.5175736  0.5027869  0.5538161\n",
      " 0.5528248  0.5212137 ]\n",
      "The rewards are: [0.50922024 0.53359616 0.56817067 0.5112668  0.50050133 0.5614801\n",
      " 0.5524084  0.5448582  0.5121112  0.5279895  0.5577776  0.54093564\n",
      " 0.53192115 0.55655336 0.5013061  0.53212464 0.5582109  0.52572936\n",
      " 0.56672543 0.5245911  0.545465   0.54264855 0.52572113 0.5314001\n",
      " 0.52170444 0.5111804  0.52539736 0.5327126  0.5374487  0.5214467\n",
      " 0.5224656  0.50105923]\n",
      "The rewards are: [0.52390015 0.50300217 0.5184737  0.5015103  0.5127727  0.5376393\n",
      " 0.50649124 0.55880654 0.5309591  0.5119304  0.5121148  0.5339255\n",
      " 0.5025126  0.50009644 0.5003961  0.50676787 0.55447376 0.5725424\n",
      " 0.5364533  0.5370558  0.5002698  0.50687385 0.5490726  0.55001444\n",
      " 0.52778184 0.5522479  0.5731637  0.5155056  0.53702474 0.5406429\n",
      " 0.53881335 0.51174146]\n",
      "The rewards are: [0.52443045 0.51087785 0.5047196  0.5647405  0.53702146 0.50788546\n",
      " 0.5281781  0.5226203  0.54392606 0.5329286  0.5065106  0.5045043\n",
      " 0.524846   0.5297691  0.503391   0.55854785 0.5416807  0.54079807\n",
      " 0.52484477 0.52225447 0.51065814 0.50938296 0.5560275  0.50618845\n",
      " 0.56645    0.5279294  0.52745456 0.53344625 0.5288366  0.5519413\n",
      " 0.50593233 0.50529593]\n",
      "The rewards are: [0.5000783  0.54300374 0.5351554  0.5401752  0.5163521  0.55908793\n",
      " 0.50136083 0.55852306 0.5496445  0.5557479  0.53205556 0.51553196\n",
      " 0.54698485 0.56717014 0.56154484 0.52712196 0.54922545 0.52235025\n",
      " 0.5001731  0.5013116  0.5144022  0.5388013  0.50302535 0.5101626\n",
      " 0.55397487 0.53419995 0.5024438  0.55290186 0.53526497 0.56491727\n",
      " 0.5252889  0.530548  ]\n",
      "The rewards are: [0.5206794  0.52314276 0.5122813  0.52381307 0.55598927 0.5590898\n",
      " 0.54293734 0.5099764  0.54483795 0.5454919  0.5007916  0.5141811\n",
      " 0.54538816 0.5295917  0.5721076  0.56461316 0.557647   0.5160375\n",
      " 0.55375    0.52267367 0.5090868  0.50726575 0.5567548  0.5091407\n",
      " 0.5260884  0.5033673  0.568768   0.56593686 0.5500362  0.5728022\n",
      " 0.5333178  0.5124836 ]\n",
      "The rewards are: [0.5243052  0.51908183 0.51120746 0.55299556 0.50315714 0.5129042\n",
      " 0.5143099  0.5411532  0.5692557  0.53236115 0.5251554  0.5057552\n",
      " 0.5303123  0.50103116 0.50288934 0.55454236 0.5407641  0.51292986\n",
      " 0.53006744 0.5450675  0.5129858  0.52047837 0.55597246 0.55728066\n",
      " 0.56641924 0.5548842  0.51601136 0.5728988  0.5311552  0.55638564\n",
      " 0.559551   0.57124037]\n",
      "The rewards are: [0.5295169  0.51283693 0.5236555  0.5078182  0.50846666 0.5349129\n",
      " 0.5082202  0.56524044 0.5536667  0.53764945 0.5067316  0.55608356\n",
      " 0.5584398  0.502539   0.522532   0.5286023  0.56868047 0.5604657\n",
      " 0.5199617  0.5684251  0.562413   0.5281366  0.5571475  0.5490147\n",
      " 0.53153026 0.54509854 0.5417553  0.5252049  0.5235156  0.58098286\n",
      " 0.531753   0.5549488 ]\n",
      "The rewards are: [0.55716336 0.5410092  0.5313318  0.5091812  0.5391702  0.50400364\n",
      " 0.5169868  0.55556434 0.5079326  0.5094276  0.5212762  0.55995125\n",
      " 0.5064766  0.524271   0.54442984 0.5006935  0.552766   0.5017161\n",
      " 0.51643544 0.50886375 0.5254323  0.54120445 0.5087224  0.5142884\n",
      " 0.5440988  0.5358256  0.5102656  0.5061143  0.54448867 0.50135183\n",
      " 0.55773497 0.533784  ]\n",
      "The rewards are: [0.52977586 0.5601987  0.52969927 0.54152876 0.5424666  0.5259256\n",
      " 0.5340163  0.5532501  0.5018758  0.5413215  0.5072192  0.51944035\n",
      " 0.5049506  0.5216931  0.5759123  0.5160583  0.57722205 0.5416227\n",
      " 0.54441166 0.50598216 0.50556505 0.5157851  0.5245048  0.5573151\n",
      " 0.52157366 0.5602509  0.50401115 0.51462084 0.5378425  0.5011632\n",
      " 0.54850966 0.52359277]\n",
      "The rewards are: [0.53299475 0.5569945  0.502178   0.54427093 0.5219055  0.53800654\n",
      " 0.5592034  0.5464754  0.5396365  0.50177103 0.50201356 0.5152327\n",
      " 0.54609644 0.5503265  0.5602949  0.5669329  0.51887846 0.5685156\n",
      " 0.53598464 0.5516805  0.54994977 0.5011154  0.51161575 0.5071997\n",
      " 0.51752365 0.50239474 0.58097327 0.5030064  0.5582583  0.5557646\n",
      " 0.57940257 0.56761557]\n",
      "The rewards are: [0.5036583  0.5082602  0.5886229  0.56865    0.5545796  0.5260445\n",
      " 0.5084622  0.5525466  0.5539029  0.5356343  0.55796576 0.50998837\n",
      " 0.582655   0.56691504 0.5751292  0.54228055 0.5258268  0.5686199\n",
      " 0.5425239  0.53065455 0.53244513 0.5378383  0.5510504  0.5798485\n",
      " 0.5478209  0.5584368  0.51600164 0.5046731  0.5253881  0.51489323\n",
      " 0.5547326  0.50102234]\n",
      "The rewards are: [0.5026559  0.51672155 0.55283374 0.5046322  0.5073104  0.5673699\n",
      " 0.540436   0.5773727  0.5103433  0.5539368  0.50167036 0.56474555\n",
      " 0.5071353  0.5016031  0.5801563  0.50987893 0.5733077  0.5801704\n",
      " 0.56392133 0.5119923  0.5716752  0.5050897  0.5482366  0.5780398\n",
      " 0.5591969  0.5803305  0.51537603 0.5165617  0.5582054  0.53163457\n",
      " 0.50363636 0.52008516]\n",
      "The rewards are: [0.56188655 0.56797355 0.53890663 0.51613057 0.50497097 0.5302061\n",
      " 0.57021546 0.5033957  0.5335565  0.5753917  0.5858614  0.5442912\n",
      " 0.50920606 0.5437099  0.5998832  0.5753917  0.5582888  0.5392399\n",
      " 0.56066555 0.5601738  0.55235267 0.5292661  0.5108286  0.53071755\n",
      " 0.52639866 0.5207031  0.5525704  0.5915414  0.51579666 0.5718175\n",
      " 0.56791    0.53081644]\n",
      "The rewards are: [0.57241803 0.5436976  0.51213455 0.5300859  0.52013755 0.5111139\n",
      " 0.52938944 0.52915204 0.5005364  0.5755958  0.5055765  0.55628973\n",
      " 0.53188735 0.5026405  0.5393266  0.58966106 0.5093917  0.5340293\n",
      " 0.53364027 0.5029867  0.5221304  0.59185076 0.51368    0.53591645\n",
      " 0.5145783  0.5247029  0.51621395 0.5092591  0.5007189  0.54451656\n",
      " 0.5713905  0.5403488 ]\n",
      "The rewards are: [0.5055388  0.5004517  0.55966365 0.6014204  0.54918855 0.5010774\n",
      " 0.5300126  0.5620367  0.5642615  0.57552814 0.539025   0.5772387\n",
      " 0.53561234 0.5471075  0.5180665  0.5482168  0.54981345 0.5737526\n",
      " 0.5479961  0.5476088  0.5334888  0.55347884 0.521695   0.5601736\n",
      " 0.5626114  0.56097525 0.5746452  0.52590317 0.56639045 0.55427724\n",
      " 0.5616733  0.51357985]\n",
      "The rewards are: [0.6040081  0.55376285 0.5798669  0.51877594 0.5813079  0.5039893\n",
      " 0.5036004  0.50329596 0.5214281  0.5316441  0.5774157  0.5876\n",
      " 0.5216296  0.5389202  0.5148442  0.52640635 0.50195056 0.5748887\n",
      " 0.5568133  0.522867   0.6000337  0.50871974 0.52949417 0.5236395\n",
      " 0.5343714  0.5354775  0.52580434 0.5135414  0.5295087  0.5663238\n",
      " 0.60142237 0.5990692 ]\n",
      "The rewards are: [0.5723454  0.5764715  0.5000711  0.5373549  0.5636423  0.6032793\n",
      " 0.5904747  0.5798682  0.56509286 0.53449595 0.59439945 0.5099094\n",
      " 0.53468764 0.5568456  0.50312895 0.50285316 0.6014808  0.6031847\n",
      " 0.5615096  0.5134694  0.5160636  0.5256302  0.56489444 0.5680145\n",
      " 0.5167978  0.51438427 0.60415924 0.5637193  0.51891404 0.51347345\n",
      " 0.5665555  0.56909925]\n",
      "The rewards are: [0.51761144 0.5232532  0.5562458  0.5084041  0.5427724  0.5322449\n",
      " 0.5659041  0.50231373 0.510451   0.5876971  0.5751998  0.5423634\n",
      " 0.5616878  0.56059635 0.5853644  0.589289   0.509318   0.5153867\n",
      " 0.50385934 0.5010957  0.57363105 0.5800534  0.52258635 0.50115496\n",
      " 0.5651228  0.5097531  0.56689686 0.50139505 0.50335497 0.5098971\n",
      " 0.5986374  0.53909993]\n",
      "The rewards are: [0.5408926  0.5110668  0.51435405 0.5426436  0.53538483 0.5593316\n",
      " 0.5488131  0.5354243  0.5910445  0.5288615  0.5034665  0.5156411\n",
      " 0.52049017 0.5659876  0.5095271  0.57588565 0.56068605 0.6031687\n",
      " 0.5260019  0.52171105 0.53697777 0.5065408  0.50972587 0.6297299\n",
      " 0.52011627 0.56931335 0.590048   0.50289977 0.5354691  0.5223869\n",
      " 0.5236134  0.5508085 ]\n",
      "The rewards are: [0.53095365 0.583381   0.533419   0.5899926  0.54112875 0.55299073\n",
      " 0.50594705 0.5145136  0.5385698  0.5365597  0.6014279  0.54433894\n",
      " 0.5068589  0.5022789  0.5763394  0.5097211  0.5364839  0.56569296\n",
      " 0.60098135 0.50748485 0.59122103 0.55728245 0.5938521  0.5076635\n",
      " 0.51201004 0.5958626  0.5112371  0.5924524  0.5299442  0.56532454\n",
      " 0.52446336 0.5557494 ]\n",
      "The rewards are: [0.5628893  0.508988   0.5593985  0.54101473 0.5847509  0.58140475\n",
      " 0.5508889  0.6045892  0.547608   0.5165838  0.64278907 0.54854476\n",
      " 0.5480716  0.5006196  0.54605776 0.5677594  0.5933031  0.59862846\n",
      " 0.56220704 0.50607467 0.6205689  0.5264298  0.52773815 0.5073478\n",
      " 0.53006893 0.5138417  0.5100628  0.5491379  0.5530366  0.5304556\n",
      " 0.5599863  0.506542  ]\n",
      "The rewards are: [0.53862816 0.5560693  0.5788039  0.5088956  0.52692086 0.513951\n",
      " 0.5765917  0.5273048  0.5251073  0.5577007  0.5941152  0.5516661\n",
      " 0.58764017 0.56220317 0.5718404  0.58792156 0.56669766 0.5647476\n",
      " 0.53769803 0.53625715 0.5028366  0.53150904 0.61531734 0.60176146\n",
      " 0.51241696 0.501916   0.5729622  0.5556039  0.50393075 0.61785656\n",
      " 0.56352824 0.51574403]\n",
      "The rewards are: [0.5060102  0.52618545 0.526036   0.592258   0.57806474 0.50971365\n",
      " 0.5856488  0.50687116 0.54754454 0.51847404 0.528855   0.5655626\n",
      " 0.5224344  0.53087133 0.53228635 0.5891491  0.5715651  0.5578563\n",
      " 0.5124517  0.5591842  0.55788136 0.5156728  0.6112123  0.60145456\n",
      " 0.5213597  0.5632741  0.5828371  0.6210493  0.52068686 0.52871937\n",
      " 0.52454525 0.5356389 ]\n",
      "The rewards are: [0.5376006  0.5440453  0.53615314 0.553702   0.5563155  0.5433941\n",
      " 0.57573843 0.5030412  0.5732142  0.5728234  0.5249907  0.50456566\n",
      " 0.52106607 0.55524683 0.5432751  0.50675464 0.53421646 0.50483847\n",
      " 0.6044259  0.5702176  0.5463164  0.6053167  0.50969285 0.51301086\n",
      " 0.5004949  0.51195014 0.6139511  0.5688112  0.6003107  0.51849926\n",
      " 0.591947   0.5206894 ]\n",
      "The rewards are: [0.5072838  0.5116206  0.50253314 0.5091362  0.50429225 0.543235\n",
      " 0.5094415  0.52755415 0.57864195 0.51256883 0.5840351  0.6063333\n",
      " 0.5085057  0.531061   0.55542415 0.5921088  0.53384167 0.5381627\n",
      " 0.529457   0.5062115  0.526112   0.5455985  0.5582438  0.5705542\n",
      " 0.5703397  0.5083598  0.5427749  0.55051976 0.5359414  0.59930634\n",
      " 0.5088858  0.5675795 ]\n",
      "The rewards are: [0.5409462  0.56709146 0.51247    0.50539666 0.5744091  0.59678805\n",
      " 0.54452926 0.6155777  0.597301   0.51374316 0.57498616 0.57366616\n",
      " 0.50796676 0.6064044  0.6060556  0.6034953  0.50500757 0.572338\n",
      " 0.5612238  0.5707756  0.5058012  0.58102435 0.5037039  0.5971404\n",
      " 0.51399624 0.53040963 0.59792817 0.5000691  0.56913525 0.52379847\n",
      " 0.5109732  0.5035412 ]\n",
      "The rewards are: [0.5088706  0.5119183  0.5160918  0.5436768  0.549665   0.5468887\n",
      " 0.50267386 0.6120458  0.5017546  0.51234376 0.5054331  0.6056806\n",
      " 0.51052463 0.58488333 0.53398496 0.6129661  0.5737932  0.61117744\n",
      " 0.5090433  0.50887024 0.5826704  0.5489294  0.52516705 0.5077426\n",
      " 0.55142164 0.5420905  0.5164029  0.5228343  0.52988327 0.59598637\n",
      " 0.53497905 0.55104226]\n",
      "The rewards are: [0.522665   0.50407535 0.57929325 0.5030498  0.616803   0.5095726\n",
      " 0.5159262  0.54393256 0.56755245 0.6161927  0.51900154 0.597489\n",
      " 0.5280278  0.56948304 0.56595784 0.51415294 0.508958   0.5699835\n",
      " 0.5727808  0.5248921  0.5807755  0.6311056  0.5141537  0.5274316\n",
      " 0.5411745  0.5559495  0.5834086  0.56297493 0.528221   0.51791584\n",
      " 0.6056888  0.54267126]\n",
      "The rewards are: [0.56045896 0.50337106 0.5416013  0.5452616  0.5809402  0.54480755\n",
      " 0.5260352  0.58662695 0.5099036  0.5942064  0.55289614 0.533188\n",
      " 0.5854421  0.5353745  0.6108784  0.58307713 0.51509666 0.5794291\n",
      " 0.52032447 0.5831441  0.5238159  0.5863287  0.5870522  0.52460265\n",
      " 0.5737309  0.55628866 0.5156149  0.56938237 0.56852514 0.53105783\n",
      " 0.55129725 0.5121396 ]\n",
      "The rewards are: [0.5017573  0.5291334  0.59160036 0.5249254  0.58818984 0.5458452\n",
      " 0.5360021  0.5400979  0.5317797  0.5013839  0.5151218  0.5744834\n",
      " 0.6005105  0.5069887  0.51301664 0.50691164 0.544441   0.53083736\n",
      " 0.5722394  0.6204137  0.53631365 0.51928633 0.6378375  0.5718738\n",
      " 0.533016   0.60926527 0.50409794 0.5845433  0.50638384 0.6393089\n",
      " 0.58665985 0.5210232 ]\n",
      "The rewards are: [0.5391508  0.57930017 0.5035126  0.5214998  0.59221286 0.5036377\n",
      " 0.6069785  0.5349447  0.5897914  0.500074   0.53173846 0.5209117\n",
      " 0.5756275  0.58612794 0.5074487  0.59646654 0.52692294 0.5077743\n",
      " 0.50325644 0.5249262  0.5769717  0.5597439  0.5062686  0.5366\n",
      " 0.5397459  0.51174086 0.5062764  0.58936113 0.58118236 0.50372744\n",
      " 0.60501343 0.51903397]\n",
      "The rewards are: [0.57922745 0.5122325  0.58436555 0.5909078  0.5718437  0.5734014\n",
      " 0.5815478  0.51052237 0.5302425  0.5473979  0.5738787  0.5750378\n",
      " 0.5130144  0.5650992  0.506755   0.59830993 0.5383322  0.5126233\n",
      " 0.5028715  0.58501303 0.5280782  0.50145495 0.52466875 0.50058967\n",
      " 0.5109206  0.5166927  0.56078416 0.501967   0.5230291  0.54347175\n",
      " 0.5260445  0.5003591 ]\n",
      "The rewards are: [0.556679   0.63173044 0.5050279  0.5724432  0.51097333 0.59236693\n",
      " 0.5780572  0.566937   0.50023556 0.60502756 0.6236513  0.5004951\n",
      " 0.55905455 0.59721667 0.5304619  0.5193643  0.5134599  0.6194854\n",
      " 0.552297   0.63440067 0.51075965 0.50418097 0.53864735 0.54528093\n",
      " 0.5208331  0.5433948  0.5459985  0.601158   0.5340642  0.58619887\n",
      " 0.5345482  0.5564359 ]\n",
      "The rewards are: [0.5298509  0.56395423 0.5680766  0.50711846 0.55765295 0.5689906\n",
      " 0.56497383 0.55981183 0.50357234 0.53520954 0.63822377 0.5481306\n",
      " 0.5014288  0.58054453 0.5163286  0.56149024 0.5368396  0.6330427\n",
      " 0.6249852  0.5109383  0.52169234 0.5355971  0.51815283 0.5605057\n",
      " 0.5627816  0.5765375  0.5975397  0.5349176  0.52401567 0.53105456\n",
      " 0.57804275 0.5097435 ]\n",
      "The rewards are: [0.5015769  0.5171815  0.5749085  0.54672974 0.5470962  0.5246148\n",
      " 0.53986377 0.5095164  0.56081396 0.6044578  0.6139826  0.6035334\n",
      " 0.5044298  0.5801361  0.5249056  0.59952056 0.54212224 0.6148582\n",
      " 0.59535515 0.5332601  0.6032759  0.525816   0.54882246 0.5286849\n",
      " 0.55123514 0.64161736 0.6155151  0.51650476 0.52621084 0.59657484\n",
      " 0.5196983  0.5882779 ]\n",
      "The rewards are: [0.61339015 0.5563586  0.5507892  0.51711243 0.50289327 0.5369105\n",
      " 0.5282227  0.5491439  0.57371366 0.5610278  0.56671685 0.5922514\n",
      " 0.6035472  0.56782097 0.5821486  0.5311796  0.5269372  0.62947434\n",
      " 0.5511747  0.5317621  0.5712731  0.56493825 0.5863093  0.5095287\n",
      " 0.5176964  0.6269113  0.60182184 0.60422695 0.58509755 0.54087245\n",
      " 0.55763125 0.54110384]\n",
      "The rewards are: [0.54831874 0.57863265 0.5572696  0.52411914 0.51050436 0.5436821\n",
      " 0.56270903 0.5347841  0.6450108  0.5811858  0.50388086 0.5509105\n",
      " 0.5474124  0.5072614  0.53428143 0.56731397 0.53440404 0.5948003\n",
      " 0.51131964 0.5025307  0.5501733  0.6233275  0.50244296 0.5016784\n",
      " 0.5136458  0.51953954 0.51355743 0.52558273 0.5084816  0.5341826\n",
      " 0.5825672  0.53279006]\n",
      "The rewards are: [0.52300847 0.56825775 0.5871609  0.576147   0.53888947 0.526705\n",
      " 0.57471246 0.5416597  0.5537519  0.56420654 0.62303466 0.5798454\n",
      " 0.5202145  0.5233773  0.5711119  0.5544064  0.5552395  0.5143293\n",
      " 0.544784   0.57406396 0.58698565 0.58831525 0.52389705 0.5397489\n",
      " 0.6259387  0.50714225 0.5515913  0.5288758  0.52148825 0.5124632\n",
      " 0.53161955 0.51482296]\n",
      "The rewards are: [0.63255155 0.55233824 0.6269655  0.53786814 0.50427955 0.60466117\n",
      " 0.56716925 0.54984725 0.5289812  0.58203745 0.5996473  0.56398135\n",
      " 0.52057153 0.5095458  0.50846595 0.5480425  0.61887074 0.50286835\n",
      " 0.5963383  0.51537323 0.59628457 0.5752804  0.5009253  0.614001\n",
      " 0.5374988  0.5195141  0.51562256 0.5361855  0.5248149  0.59347296\n",
      " 0.554753   0.5317693 ]\n",
      "The rewards are: [0.6110475  0.5784018  0.58541304 0.5291166  0.6128724  0.5229535\n",
      " 0.57521003 0.61266035 0.5178517  0.5116802  0.5168189  0.5912428\n",
      " 0.52366275 0.6132222  0.54483235 0.5085289  0.5911972  0.5231052\n",
      " 0.5009213  0.5425977  0.5067844  0.5783187  0.5402079  0.6093852\n",
      " 0.52172965 0.5402821  0.6499346  0.56798524 0.5163714  0.50048983\n",
      " 0.5684334  0.53409857]\n",
      "The rewards are: [0.5464711  0.5015299  0.5470592  0.5382134  0.57493865 0.5317002\n",
      " 0.5323958  0.60057724 0.6135326  0.5274997  0.5027588  0.5905744\n",
      " 0.5844885  0.5228253  0.5103762  0.58900326 0.50410575 0.5285844\n",
      " 0.508107   0.6080698  0.58530855 0.5953427  0.629803   0.6189583\n",
      " 0.5696658  0.642609   0.56396043 0.59532744 0.5154965  0.5062648\n",
      " 0.5711577  0.575291  ]\n",
      "The rewards are: [0.50395435 0.5457325  0.5618877  0.51123863 0.5163408  0.6635525\n",
      " 0.5273919  0.57597864 0.53543216 0.57041824 0.55996925 0.57917595\n",
      " 0.52323836 0.6051558  0.61798024 0.58310914 0.57050556 0.61897063\n",
      " 0.5239395  0.5114198  0.5014134  0.5083255  0.62169266 0.55557925\n",
      " 0.50635415 0.6347256  0.6099666  0.6775597  0.6054787  0.57152575\n",
      " 0.5179541  0.54124564]\n",
      "The rewards are: [0.5573326  0.5003413  0.5192717  0.50131917 0.50052977 0.5421648\n",
      " 0.5253736  0.6105219  0.543113   0.6302309  0.54773813 0.52090716\n",
      " 0.5451284  0.51548535 0.6127858  0.620274   0.6039128  0.6470688\n",
      " 0.5244691  0.5766139  0.5905473  0.53218037 0.54812706 0.643048\n",
      " 0.6138198  0.67531765 0.5304374  0.51152253 0.576874   0.6108135\n",
      " 0.58566284 0.5767346 ]\n",
      "The rewards are: [0.5855044  0.57545215 0.55814123 0.50764775 0.5129722  0.5115794\n",
      " 0.5199196  0.5338783  0.51258177 0.55985236 0.5778072  0.501523\n",
      " 0.6511393  0.5074239  0.50024307 0.567789   0.54929376 0.6021528\n",
      " 0.56416553 0.5760781  0.5290838  0.5732281  0.5741662  0.60783845\n",
      " 0.57953554 0.5656856  0.53364533 0.53852445 0.6419371  0.64242864\n",
      " 0.5289704  0.5246009 ]\n",
      "The rewards are: [0.62376004 0.54182816 0.5021864  0.57866603 0.5503086  0.6172677\n",
      " 0.59800655 0.61734843 0.5837685  0.6430356  0.5345972  0.56605834\n",
      " 0.52814084 0.60775864 0.6432168  0.52190334 0.56292176 0.5710007\n",
      " 0.5098283  0.54787225 0.58500725 0.5072889  0.5705223  0.58471996\n",
      " 0.5553487  0.5899484  0.52793944 0.58767146 0.54137313 0.59998214\n",
      " 0.5082687  0.6234072 ]\n",
      "The rewards are: [0.5377203  0.5162768  0.5697512  0.5126195  0.5459996  0.61839455\n",
      " 0.51967925 0.64097166 0.545857   0.5714294  0.51806116 0.5443124\n",
      " 0.6019853  0.5259151  0.55588347 0.5518582  0.6403067  0.50584257\n",
      " 0.52823937 0.5111594  0.50747824 0.58635354 0.54996777 0.534569\n",
      " 0.6497947  0.5222845  0.5911762  0.5207241  0.53978086 0.5954067\n",
      " 0.5820558  0.5709085 ]\n",
      "The rewards are: [0.5877155  0.6032158  0.58049476 0.6008315  0.61511457 0.60143363\n",
      " 0.633228   0.5256648  0.617117   0.50319785 0.60338664 0.5344784\n",
      " 0.57087576 0.64068013 0.50111824 0.62039495 0.6069656  0.56743556\n",
      " 0.5458191  0.5750496  0.5412181  0.5374377  0.53013283 0.59285176\n",
      " 0.501864   0.6227849  0.55288756 0.5031976  0.5120308  0.58524454\n",
      " 0.54242593 0.5580817 ]\n",
      "The rewards are: [0.62609774 0.54676837 0.5345426  0.63157177 0.53575075 0.5483044\n",
      " 0.56380254 0.5404413  0.51247895 0.6310045  0.60026443 0.54124844\n",
      " 0.52146655 0.5882845  0.523987   0.536063   0.5053918  0.582648\n",
      " 0.6236462  0.5893016  0.6112089  0.65815896 0.5037724  0.5727146\n",
      " 0.53588504 0.5918111  0.61345685 0.5757033  0.60587233 0.5523219\n",
      " 0.5857181  0.5166222 ]\n",
      "The rewards are: [0.5316751  0.52580476 0.6177409  0.5811224  0.5736828  0.5762734\n",
      " 0.5581932  0.55083835 0.57614887 0.58658177 0.5469471  0.54211605\n",
      " 0.66981226 0.51355094 0.56876665 0.6641578  0.5788816  0.6363538\n",
      " 0.5204867  0.5802263  0.6031331  0.64871335 0.56490445 0.5848686\n",
      " 0.5458256  0.5797712  0.6045337  0.6343397  0.59940493 0.563028\n",
      " 0.6536467  0.61129236]\n",
      "The rewards are: [0.5710818  0.5217856  0.59386957 0.61397976 0.5300332  0.5020914\n",
      " 0.6265836  0.5223128  0.60644805 0.6012042  0.5790571  0.5274692\n",
      " 0.5497592  0.54927325 0.5162287  0.60839516 0.5568478  0.57270736\n",
      " 0.6119405  0.5902992  0.5352661  0.5616654  0.5595965  0.57109123\n",
      " 0.5476103  0.6477634  0.64723855 0.5250076  0.50155807 0.56137985\n",
      " 0.5308297  0.5878559 ]\n",
      "The rewards are: [0.57755655 0.51921755 0.50779504 0.5269309  0.59331805 0.52680945\n",
      " 0.58352906 0.6099221  0.5895768  0.50288373 0.5976997  0.5242466\n",
      " 0.5715592  0.5037602  0.6062728  0.5982747  0.6174538  0.59699714\n",
      " 0.5532198  0.6241663  0.5070784  0.6421247  0.59872425 0.59580755\n",
      " 0.5181998  0.6049388  0.5635328  0.580078   0.565117   0.57457507\n",
      " 0.5668238  0.6100184 ]\n",
      "The rewards are: [0.51501215 0.5411098  0.61651355 0.5131729  0.5253955  0.5040019\n",
      " 0.56932265 0.56343174 0.6057343  0.51695865 0.5660949  0.52762145\n",
      " 0.57934785 0.5491994  0.53898346 0.5469808  0.5280283  0.622867\n",
      " 0.62280554 0.58449554 0.56331676 0.5887355  0.5830715  0.6444888\n",
      " 0.5968061  0.5528413  0.53367513 0.56080776 0.6572095  0.55619264\n",
      " 0.50686574 0.6594548 ]\n",
      "The rewards are: [0.61612415 0.52533406 0.5449909  0.5246676  0.5681424  0.5945997\n",
      " 0.57755303 0.5985356  0.53043854 0.57153356 0.51721793 0.553122\n",
      " 0.6261317  0.6595936  0.5861693  0.5789456  0.6376163  0.5194654\n",
      " 0.6034616  0.5799821  0.536721   0.5919861  0.5735016  0.512417\n",
      " 0.5323381  0.5206879  0.5937435  0.5944883  0.5854794  0.52422917\n",
      " 0.63919383 0.6048876 ]\n",
      "The rewards are: [0.52063423 0.60439175 0.50245243 0.51294684 0.52975655 0.61319685\n",
      " 0.5378161  0.55332166 0.55531555 0.55104953 0.5157329  0.5688601\n",
      " 0.5288298  0.6396464  0.585517   0.5187976  0.63168544 0.509263\n",
      " 0.529705   0.5239346  0.58424073 0.52703273 0.56699926 0.545746\n",
      " 0.6378442  0.541099   0.5456583  0.5310969  0.51857144 0.50440943\n",
      " 0.5171944  0.5813877 ]\n",
      "The rewards are: [0.5899614  0.55010474 0.5163533  0.5999459  0.524211   0.50324523\n",
      " 0.5602992  0.55145186 0.570052   0.5239387  0.58006966 0.6033696\n",
      " 0.5787717  0.6223261  0.5097732  0.61646485 0.59795076 0.6111903\n",
      " 0.50764436 0.5078785  0.51418865 0.5398082  0.5345757  0.6683615\n",
      " 0.55919856 0.5064057  0.62062573 0.52366865 0.5226464  0.5410977\n",
      " 0.6167578  0.5402244 ]\n",
      "The rewards are: [0.5988875  0.5549043  0.5338806  0.5558349  0.5092106  0.6054553\n",
      " 0.5412012  0.62046975 0.5755929  0.5855384  0.5376581  0.55129725\n",
      " 0.5403717  0.58807176 0.52187437 0.5562665  0.61802685 0.5251589\n",
      " 0.5271562  0.6132444  0.5591811  0.5704522  0.50134856 0.6133078\n",
      " 0.5456815  0.51415086 0.52482396 0.518583   0.6051461  0.50500566\n",
      " 0.52420986 0.5029113 ]\n",
      "The rewards are: [0.51179713 0.5449476  0.6144563  0.5003802  0.589329   0.50590557\n",
      " 0.5605735  0.633647   0.5036689  0.58709997 0.5927337  0.5404172\n",
      " 0.5289069  0.6701127  0.64579695 0.51216644 0.5897159  0.5051964\n",
      " 0.60842055 0.52413535 0.60995156 0.51246357 0.54634947 0.658643\n",
      " 0.5760009  0.502996   0.6336034  0.613414   0.64402187 0.5147739\n",
      " 0.5650725  0.53615   ]\n",
      "The rewards are: [0.55434155 0.64218235 0.6374211  0.5036966  0.5730665  0.53817344\n",
      " 0.5467344  0.55607146 0.5658089  0.6799063  0.55584484 0.58375823\n",
      " 0.67430943 0.56094766 0.5620707  0.585922   0.5825824  0.515377\n",
      " 0.5147173  0.58082396 0.61286336 0.6996689  0.61056226 0.55728745\n",
      " 0.57089347 0.5871726  0.62486    0.5662274  0.6061516  0.54268366\n",
      " 0.6018669  0.52583486]\n",
      "The rewards are: [0.54062426 0.54851747 0.625491   0.50492185 0.55165637 0.60121274\n",
      " 0.6256265  0.5643985  0.6026542  0.5483854  0.60708106 0.50071603\n",
      " 0.5448669  0.65229756 0.5200308  0.61983913 0.5891434  0.5766588\n",
      " 0.64955664 0.6153997  0.59867287 0.6252861  0.5289991  0.6508293\n",
      " 0.53056425 0.58040583 0.5912101  0.5232523  0.5222539  0.5679416\n",
      " 0.62079144 0.55216897]\n",
      "The rewards are: [0.5033667  0.5831762  0.5242052  0.5409657  0.623182   0.60362834\n",
      " 0.58981025 0.5150736  0.53014475 0.53047705 0.6537322  0.53006333\n",
      " 0.6786965  0.5576715  0.6610627  0.563134   0.6628561  0.5642299\n",
      " 0.5206206  0.6423907  0.541793   0.50724375 0.5133418  0.6235031\n",
      " 0.56312346 0.53956664 0.5214882  0.5334255  0.6043293  0.6570376\n",
      " 0.5237471  0.67363995]\n",
      "The rewards are: [0.52735037 0.5232567  0.60542816 0.5607     0.51654536 0.5633751\n",
      " 0.52523196 0.64167076 0.5432229  0.64095044 0.5584081  0.5681501\n",
      " 0.55561405 0.59995115 0.5561843  0.5458092  0.5205548  0.53153974\n",
      " 0.5352075  0.5803286  0.5129956  0.51019204 0.52428836 0.5212706\n",
      " 0.5732832  0.6029287  0.589846   0.5913925  0.6038648  0.55394834\n",
      " 0.5006005  0.50067914]\n",
      "The rewards are: [0.57518333 0.54510903 0.5017407  0.5412977  0.56640095 0.62903345\n",
      " 0.534561   0.61773217 0.5195833  0.58330405 0.5077943  0.50759673\n",
      " 0.5334809  0.5873448  0.62220764 0.51138586 0.5881449  0.5272699\n",
      " 0.625377   0.6183481  0.6460917  0.58133084 0.59217215 0.6919524\n",
      " 0.5831946  0.5262503  0.54624224 0.66735804 0.6253934  0.5080515\n",
      " 0.58307403 0.5822893 ]\n",
      "The rewards are: [0.54113483 0.5731341  0.5612147  0.56254256 0.70161307 0.5768195\n",
      " 0.67639494 0.500531   0.57755476 0.6329526  0.7056186  0.62746036\n",
      " 0.596442   0.5581847  0.56371105 0.6105099  0.6280457  0.59243685\n",
      " 0.5534157  0.57988393 0.5699369  0.5114994  0.571128   0.6013249\n",
      " 0.6791763  0.68899673 0.56409794 0.6092913  0.60491353 0.56726193\n",
      " 0.5329239  0.6832796 ]\n",
      "The rewards are: [0.5875592  0.5439645  0.56869537 0.66375947 0.58517444 0.5928219\n",
      " 0.5629717  0.59201205 0.6582051  0.5418483  0.5479122  0.5948923\n",
      " 0.57747155 0.65123916 0.6518719  0.6476747  0.60241634 0.5150721\n",
      " 0.5557157  0.60416496 0.6076236  0.57785463 0.5394579  0.54106474\n",
      " 0.5462483  0.60629827 0.6388395  0.5816844  0.66613173 0.5090402\n",
      " 0.5844502  0.57042444]\n",
      "The rewards are: [0.6034273  0.6314827  0.5559013  0.6721018  0.5904657  0.6352728\n",
      " 0.5033633  0.6182253  0.5612501  0.61772794 0.6075576  0.63537806\n",
      " 0.54237896 0.5925317  0.54230636 0.5316123  0.5681443  0.6128608\n",
      " 0.52090263 0.6373964  0.6485027  0.5261744  0.6445088  0.6316314\n",
      " 0.60180604 0.5214245  0.6381105  0.50675935 0.5590549  0.623146\n",
      " 0.574494   0.5939353 ]\n",
      "The rewards are: [0.5204788  0.6275781  0.60659903 0.7306736  0.50698185 0.6619134\n",
      " 0.5869096  0.5424998  0.6659747  0.51494664 0.6096282  0.6255847\n",
      " 0.5068947  0.50574845 0.56016695 0.5080301  0.62086487 0.6416894\n",
      " 0.59088284 0.5865637  0.5230003  0.56242955 0.6164234  0.6486115\n",
      " 0.51815605 0.54147506 0.663691   0.5850645  0.6344541  0.5241981\n",
      " 0.5829791  0.5684027 ]\n",
      "The rewards are: [0.5794746  0.58145094 0.55783314 0.5770937  0.50097495 0.61044914\n",
      " 0.52162486 0.57644993 0.6375528  0.6054203  0.6207347  0.6521274\n",
      " 0.628288   0.58315074 0.5598015  0.643489   0.58205056 0.53893614\n",
      " 0.6159008  0.5338512  0.60512286 0.54756147 0.5222187  0.5277243\n",
      " 0.58989525 0.55038804 0.62479883 0.6031833  0.55577636 0.7387478\n",
      " 0.63494265 0.67159736]\n",
      "The rewards are: [0.54363775 0.5165814  0.51709825 0.6776733  0.66289073 0.6430386\n",
      " 0.61263853 0.6485189  0.5997356  0.5763634  0.5750665  0.579058\n",
      " 0.5165265  0.63372886 0.6489533  0.52710485 0.53876275 0.6222712\n",
      " 0.5297201  0.6477683  0.5897113  0.5674528  0.50984806 0.62540853\n",
      " 0.6540244  0.69109476 0.61544514 0.5699241  0.56357145 0.6917743\n",
      " 0.56837386 0.6173799 ]\n",
      "The rewards are: [0.5268784  0.67715764 0.6784422  0.56921583 0.5874804  0.60671824\n",
      " 0.5704824  0.5636705  0.57191193 0.6075887  0.5791945  0.58800584\n",
      " 0.5966237  0.53770214 0.61583954 0.5924334  0.5391313  0.5787721\n",
      " 0.58971435 0.58051896 0.61903894 0.52908635 0.65678275 0.575936\n",
      " 0.5318043  0.61504126 0.61829644 0.5118673  0.5642858  0.55538386\n",
      " 0.5856594  0.72545683]\n",
      "The rewards are: [0.5919584  0.59852827 0.58893377 0.531529   0.60357314 0.54822755\n",
      " 0.50120836 0.5729718  0.5382075  0.60559034 0.58282197 0.59538186\n",
      " 0.62090325 0.62657297 0.5309118  0.6525124  0.6630284  0.6076471\n",
      " 0.580836   0.65304315 0.5496761  0.501099   0.506273   0.651096\n",
      " 0.6200235  0.5847782  0.5299684  0.5072719  0.58113813 0.5795377\n",
      " 0.6853989  0.64911795]\n",
      "The rewards are: [0.5155748  0.6097875  0.61063963 0.5216399  0.541494   0.68379074\n",
      " 0.55313677 0.69358873 0.62099177 0.6055348  0.5821325  0.64350265\n",
      " 0.55351776 0.5236628  0.6488973  0.54128605 0.5462821  0.62696165\n",
      " 0.6276663  0.54825854 0.542231   0.6427705  0.65681285 0.6875056\n",
      " 0.5031217  0.5688047  0.5174059  0.53667474 0.6181407  0.6811729\n",
      " 0.5199003  0.5688497 ]\n",
      "The rewards are: [0.6122101  0.62988335 0.5226583  0.655779   0.5517698  0.58289987\n",
      " 0.56567687 0.669098   0.59615225 0.5288809  0.6013619  0.5980528\n",
      " 0.6334269  0.5464914  0.550311   0.5044751  0.5043451  0.5064499\n",
      " 0.5005003  0.5998156  0.60686976 0.60151595 0.6193901  0.55565673\n",
      " 0.63765955 0.51672584 0.50142914 0.5076426  0.51294667 0.6295095\n",
      " 0.65039325 0.54484653]\n",
      "The rewards are: [0.6093527  0.6227967  0.6034283  0.6236475  0.552258   0.5264131\n",
      " 0.60600173 0.5910636  0.5873169  0.59147877 0.6829057  0.5099528\n",
      " 0.72623193 0.5833813  0.5792642  0.57097614 0.6033608  0.5085988\n",
      " 0.5968177  0.56991506 0.5784489  0.7017852  0.53633356 0.6313735\n",
      " 0.5130463  0.5918936  0.5131702  0.6049876  0.6021398  0.52756685\n",
      " 0.5976597  0.5189422 ]\n",
      "The rewards are: [0.6668721  0.6133567  0.6838685  0.56094706 0.51445454 0.67156625\n",
      " 0.6223092  0.6814702  0.62371886 0.5786799  0.5265578  0.5972666\n",
      " 0.5614555  0.57989323 0.5922514  0.6150008  0.6278906  0.5257508\n",
      " 0.58763695 0.5937873  0.65721685 0.50375116 0.67811775 0.61406434\n",
      " 0.62774056 0.5101806  0.61683786 0.6409022  0.6932125  0.5263128\n",
      " 0.63389826 0.5794391 ]\n",
      "The rewards are: [0.5044012  0.5803026  0.63838476 0.5869049  0.5765021  0.7190308\n",
      " 0.52918416 0.5502796  0.6992299  0.6628665  0.6335597  0.71358633\n",
      " 0.6009399  0.6632124  0.6321542  0.5544453  0.5206613  0.57220083\n",
      " 0.5323542  0.6313428  0.6446806  0.6152927  0.6599599  0.62414354\n",
      " 0.54100794 0.71786433 0.52441955 0.67192924 0.58572435 0.53925455\n",
      " 0.67696625 0.51868   ]\n",
      "The rewards are: [0.64923817 0.5494176  0.5168738  0.60108715 0.68287987 0.5592416\n",
      " 0.54455197 0.55820936 0.7216404  0.69429886 0.5785514  0.56424487\n",
      " 0.67353624 0.580815   0.763848   0.54691666 0.722538   0.67278016\n",
      " 0.5049576  0.60848945 0.5458226  0.5836689  0.5979901  0.6631925\n",
      " 0.58296293 0.6072845  0.6213243  0.5442692  0.6147881  0.5865094\n",
      " 0.64222085 0.54906654]\n",
      "The rewards are: [0.5347159  0.6929676  0.51491386 0.6787994  0.56010634 0.5058205\n",
      " 0.5408343  0.5831855  0.50160104 0.61515975 0.5918852  0.7105317\n",
      " 0.62092507 0.60003793 0.6861038  0.64711773 0.5782998  0.6791309\n",
      " 0.6045242  0.65799654 0.61939806 0.5820456  0.6859146  0.5524768\n",
      " 0.52268964 0.54910463 0.5279819  0.51691985 0.6338712  0.53457606\n",
      " 0.507468   0.6339069 ]\n",
      "The rewards are: [0.7535627  0.60686773 0.5104123  0.5076181  0.5933012  0.5078163\n",
      " 0.6196197  0.65146506 0.5415728  0.5221219  0.5293936  0.58443373\n",
      " 0.6837984  0.62210804 0.7503342  0.70915276 0.56759936 0.6718063\n",
      " 0.5040154  0.551183   0.71798074 0.57423276 0.74867016 0.51314807\n",
      " 0.6711019  0.6461388  0.70559746 0.58041406 0.5956261  0.61893344\n",
      " 0.5294976  0.52271426]\n",
      "The rewards are: [0.60138726 0.677028   0.58875656 0.649309   0.5987192  0.60467046\n",
      " 0.50097495 0.6186155  0.53316426 0.5527613  0.5136493  0.55442625\n",
      " 0.55518514 0.5740462  0.6747754  0.67910606 0.7521215  0.5847456\n",
      " 0.54316413 0.5165226  0.535116   0.603479   0.6593411  0.67784554\n",
      " 0.6510762  0.6638     0.5604535  0.63079184 0.6179404  0.604596\n",
      " 0.61121935 0.5141215 ]\n",
      "The rewards are: [0.5713887  0.5228794  0.620838   0.61210835 0.5752211  0.5239178\n",
      " 0.53642035 0.5833526  0.5192421  0.57700443 0.63247335 0.6735304\n",
      " 0.5197533  0.59205323 0.5477787  0.6524452  0.6341049  0.5524351\n",
      " 0.626269   0.6218334  0.66851246 0.54177123 0.6745102  0.7033126\n",
      " 0.51016325 0.5145609  0.5300663  0.6692432  0.54714733 0.64001775\n",
      " 0.7529811  0.545088  ]\n",
      "The rewards are: [0.6175421  0.6219407  0.5153474  0.558013   0.6534237  0.5737672\n",
      " 0.6147328  0.6064427  0.55141234 0.6019241  0.7698531  0.6853298\n",
      " 0.5686171  0.5910001  0.5178366  0.5932601  0.51938194 0.6938676\n",
      " 0.6968455  0.59704006 0.5947598  0.77553135 0.50609785 0.56608623\n",
      " 0.5469471  0.5061114  0.646348   0.6292252  0.56850165 0.61017716\n",
      " 0.5528204  0.55346423]\n",
      "The rewards are: [0.66672164 0.728875   0.6930554  0.5090892  0.52756405 0.50902176\n",
      " 0.5502938  0.58182055 0.516816   0.5110161  0.6481788  0.57627165\n",
      " 0.6625376  0.57377166 0.5705596  0.74100554 0.6831935  0.52845615\n",
      " 0.60833675 0.62090474 0.59013796 0.70196337 0.6282007  0.5822978\n",
      " 0.5250058  0.6655393  0.60335    0.5640873  0.6102858  0.66069\n",
      " 0.58954173 0.7202681 ]\n",
      "The rewards are: [0.5097241  0.52080625 0.58493924 0.71010476 0.50978947 0.61634254\n",
      " 0.63900673 0.5404762  0.6810881  0.6744519  0.6407264  0.57506543\n",
      " 0.6371126  0.7372826  0.7215332  0.6581152  0.6385706  0.51216716\n",
      " 0.5788709  0.5987121  0.5680953  0.6179266  0.6065111  0.55093247\n",
      " 0.6457856  0.5281431  0.5115075  0.61745876 0.55677927 0.70588565\n",
      " 0.55897063 0.60073054]\n",
      "The rewards are: [0.52419055 0.68543166 0.50461566 0.6062357  0.666584   0.6204248\n",
      " 0.5901363  0.68931127 0.6048227  0.5245125  0.5251912  0.56253535\n",
      " 0.5613725  0.6076708  0.63184756 0.6652378  0.55007327 0.6080788\n",
      " 0.5690528  0.50151855 0.6279373  0.5332003  0.51597613 0.51985\n",
      " 0.56719726 0.55932856 0.718637   0.5252351  0.54028255 0.6335441\n",
      " 0.5665918  0.6537792 ]\n",
      "The rewards are: [0.6648779  0.546294   0.5676354  0.7072785  0.6946748  0.56003416\n",
      " 0.52663004 0.64903176 0.5900985  0.6532338  0.5503986  0.5040401\n",
      " 0.63421625 0.5676859  0.5979803  0.52732974 0.52524096 0.50693405\n",
      " 0.5612589  0.6049798  0.5444183  0.634756   0.60290337 0.599224\n",
      " 0.69824255 0.5010983  0.54697776 0.53945285 0.6610648  0.6165835\n",
      " 0.50207067 0.57501215]\n",
      "The rewards are: [0.6238332  0.663687   0.6341392  0.5772165  0.5748878  0.5747214\n",
      " 0.5040853  0.6152609  0.6295538  0.5305005  0.703007   0.6846191\n",
      " 0.66611516 0.6855992  0.53430814 0.63929933 0.7709946  0.67549217\n",
      " 0.54616225 0.6071142  0.63991463 0.76030135 0.5693775  0.5624571\n",
      " 0.6297126  0.541134   0.52837783 0.5459115  0.680073   0.6456246\n",
      " 0.5809246  0.5129712 ]\n",
      "The rewards are: [0.5952491  0.69681436 0.7323345  0.6259359  0.6220634  0.61798173\n",
      " 0.54156905 0.64240193 0.6728136  0.5680157  0.65619636 0.6252965\n",
      " 0.54302216 0.6782503  0.5785327  0.6721054  0.66279376 0.5654919\n",
      " 0.57432866 0.62389463 0.5172849  0.7782302  0.5226972  0.5547976\n",
      " 0.62263757 0.5935745  0.5855197  0.6511916  0.60034966 0.5516652\n",
      " 0.61919063 0.5319702 ]\n",
      "The rewards are: [0.51346564 0.53108066 0.64541733 0.5404182  0.55530787 0.6380937\n",
      " 0.8075861  0.6590048  0.6776796  0.5465812  0.71532243 0.6724917\n",
      " 0.6184782  0.68640435 0.65672445 0.6434093  0.5248966  0.5565065\n",
      " 0.52929366 0.6672249  0.59704196 0.6081175  0.55203575 0.59562933\n",
      " 0.727767   0.5926311  0.54599196 0.59207815 0.52867895 0.73718876\n",
      " 0.59108216 0.5516227 ]\n",
      "The rewards are: [0.53277326 0.6275126  0.5062522  0.6938302  0.65863305 0.50510395\n",
      " 0.506545   0.6131184  0.72559375 0.58780545 0.70359594 0.5976261\n",
      " 0.5287618  0.56403655 0.63502693 0.6487552  0.7268341  0.53336895\n",
      " 0.6984851  0.5905635  0.5606347  0.6050034  0.6776885  0.613587\n",
      " 0.5929753  0.5173282  0.65379494 0.5422917  0.574402   0.60873914\n",
      " 0.6667497  0.5891121 ]\n",
      "The rewards are: [0.70607454 0.54884195 0.500814   0.6223728  0.6526496  0.5418041\n",
      " 0.52523905 0.618844   0.703456   0.6435481  0.52813375 0.61350435\n",
      " 0.6569654  0.7381311  0.77893704 0.7111756  0.6354434  0.53863037\n",
      " 0.66803026 0.6445477  0.5868409  0.50955117 0.54737556 0.78471625\n",
      " 0.5748905  0.59418684 0.5694194  0.5136269  0.5379829  0.55709654\n",
      " 0.7588857  0.6769849 ]\n",
      "The rewards are: [0.53729326 0.72591794 0.7054319  0.63733417 0.58429855 0.6847651\n",
      " 0.68028545 0.6513866  0.5259845  0.69244736 0.6089389  0.6769049\n",
      " 0.62001145 0.5249638  0.67752874 0.6055945  0.5367928  0.59021544\n",
      " 0.656404   0.5603104  0.5063163  0.56432045 0.5248865  0.5026869\n",
      " 0.6705345  0.5692019  0.719456   0.60845584 0.52505594 0.7198563\n",
      " 0.6928708  0.6183268 ]\n",
      "The rewards are: [0.53197324 0.5694671  0.60417247 0.744686   0.63682765 0.50675035\n",
      " 0.57707953 0.61909306 0.5380915  0.72519624 0.7193459  0.56573135\n",
      " 0.60042    0.54553425 0.702882   0.6120599  0.6047624  0.7263503\n",
      " 0.55389106 0.6612745  0.6788943  0.7654158  0.75897497 0.6002605\n",
      " 0.5354523  0.5712602  0.5244974  0.642922   0.5564347  0.5837451\n",
      " 0.59129596 0.70643467]\n",
      "The rewards are: [0.5700468  0.5776093  0.68057853 0.5156983  0.7420479  0.7112977\n",
      " 0.628553   0.56645507 0.79153323 0.539802   0.58624303 0.59367085\n",
      " 0.566132   0.6470759  0.50878644 0.74435073 0.5605016  0.7038229\n",
      " 0.6442616  0.62158716 0.50741637 0.5578291  0.5231882  0.72482234\n",
      " 0.55983615 0.70852494 0.5997529  0.5792212  0.6358576  0.56659037\n",
      " 0.5531353  0.71824485]\n",
      "The rewards are: [0.5401305  0.70197636 0.68903613 0.79382616 0.6118462  0.55419433\n",
      " 0.62227654 0.51075035 0.59871083 0.7357774  0.5297744  0.7092146\n",
      " 0.52102035 0.53394765 0.59827584 0.5208201  0.69087607 0.57076514\n",
      " 0.70324415 0.60980415 0.5760243  0.77050054 0.6555908  0.6380041\n",
      " 0.69882125 0.61861444 0.7526408  0.6279233  0.6111212  0.6256929\n",
      " 0.6516278  0.63240105]\n",
      "The rewards are: [0.611885   0.53278714 0.5902965  0.735593   0.57899857 0.6519686\n",
      " 0.5944005  0.6035562  0.5036342  0.60546696 0.6831469  0.51301265\n",
      " 0.5085496  0.58823013 0.64689785 0.51932204 0.6055485  0.6821374\n",
      " 0.70077354 0.7496091  0.5368152  0.7739228  0.5469505  0.51440525\n",
      " 0.65987456 0.5576733  0.69224834 0.57687235 0.668527   0.50863755\n",
      " 0.64746594 0.5814715 ]\n",
      "The rewards are: [0.6636656  0.67210084 0.59687877 0.6117884  0.5465549  0.6442326\n",
      " 0.5444182  0.7123318  0.6268538  0.6829611  0.6728302  0.6420923\n",
      " 0.6708774  0.627093   0.61772674 0.5466307  0.7255057  0.7721932\n",
      " 0.5762921  0.59707934 0.57631516 0.55231196 0.5604606  0.63278013\n",
      " 0.6765934  0.64970976 0.60760087 0.6033109  0.66048205 0.61930907\n",
      " 0.6739888  0.7353177 ]\n",
      "The rewards are: [0.6551018  0.6468012  0.58194107 0.5719963  0.62315476 0.56889987\n",
      " 0.6111841  0.52397263 0.58226055 0.7512833  0.6704436  0.6355528\n",
      " 0.70988774 0.6486495  0.5860673  0.5029653  0.6501548  0.6747593\n",
      " 0.68028533 0.5889398  0.76020885 0.72924954 0.6782962  0.70881003\n",
      " 0.6364999  0.5284448  0.57270294 0.7802327  0.6525059  0.7884647\n",
      " 0.5158113  0.55864275]\n",
      "The rewards are: [0.5641844  0.7339803  0.8594607  0.73380506 0.62316984 0.59102243\n",
      " 0.5808172  0.5795374  0.6480413  0.70388603 0.5235767  0.63337666\n",
      " 0.56220835 0.50308996 0.76373285 0.62871176 0.63383996 0.65975636\n",
      " 0.5868786  0.6603421  0.58572227 0.61681455 0.5762185  0.6003296\n",
      " 0.7464176  0.5785818  0.61798525 0.7575041  0.5454441  0.5045741\n",
      " 0.5911771  0.52373147]\n",
      "The rewards are: [0.57625324 0.52206194 0.5234814  0.657737   0.5117581  0.52665156\n",
      " 0.56282806 0.584873   0.5054419  0.50523174 0.5846432  0.5281499\n",
      " 0.56653386 0.5141091  0.50417364 0.52939516 0.7216511  0.7667699\n",
      " 0.7425229  0.65725905 0.7137044  0.7592755  0.7864863  0.7310973\n",
      " 0.67125803 0.66052717 0.64059424 0.50683653 0.72988236 0.6852038\n",
      " 0.75449616 0.59129494]\n",
      "The rewards are: [0.685185   0.6656102  0.61908805 0.6408297  0.51748264 0.59717417\n",
      " 0.55941856 0.75727326 0.59529823 0.58880085 0.59363353 0.5968824\n",
      " 0.57714474 0.64451677 0.5203264  0.5941114  0.72530615 0.75217247\n",
      " 0.6641517  0.56515807 0.7495096  0.5013653  0.53394616 0.6549597\n",
      " 0.63552195 0.56629664 0.52960324 0.6848345  0.5400403  0.54872835\n",
      " 0.5553036  0.5553108 ]\n",
      "The rewards are: [0.58555126 0.7498062  0.73082674 0.6582844  0.77052    0.549038\n",
      " 0.5111865  0.65952444 0.71886015 0.6749022  0.7385898  0.6926922\n",
      " 0.5490338  0.68762136 0.6339815  0.5229428  0.7844274  0.6704908\n",
      " 0.5074709  0.63596106 0.64486927 0.54712    0.556026   0.6203378\n",
      " 0.78579104 0.600683   0.79319173 0.7957656  0.6205515  0.6939086\n",
      " 0.6750769  0.6147629 ]\n",
      "The rewards are: [0.5899894  0.6216176  0.63619643 0.6076308  0.61609894 0.7821918\n",
      " 0.6237294  0.7450022  0.64514107 0.5574773  0.7934953  0.77007556\n",
      " 0.6665013  0.69229686 0.59387654 0.63939077 0.6648539  0.7365462\n",
      " 0.6342001  0.6279558  0.6738374  0.56255776 0.57258457 0.6239301\n",
      " 0.72162294 0.64575917 0.680472   0.552462   0.7111387  0.60117805\n",
      " 0.5393962  0.80636424]\n",
      "The rewards are: [0.61712366 0.67477447 0.6510936  0.7648161  0.5699994  0.51708937\n",
      " 0.7745265  0.659319   0.5039237  0.66636574 0.5096719  0.50000393\n",
      " 0.60444903 0.7106479  0.5337184  0.6496661  0.59787065 0.8169651\n",
      " 0.6158221  0.51080227 0.63299733 0.761463   0.65487725 0.5522709\n",
      " 0.78268033 0.57792956 0.7365777  0.6713456  0.75714403 0.65154254\n",
      " 0.62262493 0.62989384]\n",
      "The rewards are: [0.739758   0.62051386 0.62232065 0.58643585 0.5803884  0.66334313\n",
      " 0.73934996 0.5072734  0.66932577 0.545675   0.683286   0.6154405\n",
      " 0.57657695 0.76998526 0.5967746  0.51630616 0.64809585 0.7005088\n",
      " 0.6368709  0.6411631  0.6728236  0.656197   0.657687   0.6040903\n",
      " 0.501503   0.52986646 0.66858476 0.71490717 0.57561874 0.7107905\n",
      " 0.55228454 0.6804805 ]\n",
      "The rewards are: [0.7356324  0.6369317  0.7073347  0.7030219  0.62423    0.675673\n",
      " 0.7634432  0.6974962  0.5115768  0.68361527 0.7788684  0.6309935\n",
      " 0.5625776  0.7555453  0.74125457 0.69939977 0.5183217  0.5905321\n",
      " 0.503658   0.5733492  0.65903825 0.69831145 0.50746703 0.6966165\n",
      " 0.54494727 0.7569555  0.52004063 0.6736062  0.596374   0.55374956\n",
      " 0.5853479  0.57551706]\n",
      "The rewards are: [0.6007617  0.66891843 0.57321006 0.50255436 0.6818115  0.563758\n",
      " 0.65216386 0.6971346  0.63914025 0.5691376  0.6184695  0.51580375\n",
      " 0.5266061  0.7671425  0.5754672  0.7466808  0.53781563 0.689229\n",
      " 0.5044069  0.75931174 0.58136964 0.68115026 0.61241704 0.7736641\n",
      " 0.62479365 0.54769135 0.5406986  0.56376916 0.6487326  0.59723955\n",
      " 0.50034297 0.68869567]\n",
      "The rewards are: [0.607809   0.566206   0.58525515 0.68063664 0.6415329  0.5721212\n",
      " 0.5788185  0.56795526 0.55879617 0.6558476  0.69191366 0.7199493\n",
      " 0.62183577 0.599108   0.5994419  0.62991405 0.5210649  0.68263555\n",
      " 0.5806973  0.66524905 0.50422513 0.70292073 0.6310936  0.51808554\n",
      " 0.56886715 0.6262361  0.57466716 0.59251857 0.57967794 0.5037551\n",
      " 0.5549052  0.7024862 ]\n",
      "The rewards are: [0.67047274 0.7954544  0.51769626 0.69807327 0.6068019  0.72638035\n",
      " 0.58572155 0.51317936 0.574074   0.5522037  0.61198294 0.5257505\n",
      " 0.6417374  0.8327372  0.5214431  0.5129081  0.5768919  0.5830181\n",
      " 0.64156437 0.7084932  0.648766   0.67390084 0.78287315 0.5550006\n",
      " 0.71472824 0.62281436 0.68837106 0.56858003 0.6406105  0.53192\n",
      " 0.51768446 0.7033617 ]\n",
      "The rewards are: [0.704513   0.5257449  0.5398641  0.6748119  0.68455005 0.6776256\n",
      " 0.6480911  0.6803254  0.72839    0.66889    0.5639962  0.67393565\n",
      " 0.65956384 0.59772646 0.5436093  0.5431916  0.57428205 0.8175468\n",
      " 0.5353773  0.5944657  0.66077167 0.7059695  0.5813436  0.75183797\n",
      " 0.51020104 0.58712316 0.6190923  0.60728    0.54740083 0.6086596\n",
      " 0.63789415 0.63742226]\n",
      "The rewards are: [0.7411235  0.5942659  0.63171995 0.7007058  0.63874245 0.6245726\n",
      " 0.55811495 0.6213215  0.7045481  0.6433537  0.81379116 0.74477005\n",
      " 0.7596645  0.7432573  0.5255566  0.73749536 0.60810065 0.5269593\n",
      " 0.605123   0.55215436 0.72318596 0.79890144 0.6977691  0.5496499\n",
      " 0.5720991  0.52155864 0.5928917  0.7261178  0.66660106 0.6369142\n",
      " 0.6977653  0.50517404]\n",
      "The rewards are: [0.7103992  0.5947364  0.5388764  0.61669594 0.57491356 0.7438853\n",
      " 0.68583053 0.63542587 0.5912985  0.52964765 0.6280886  0.6567344\n",
      " 0.6806386  0.5489806  0.6922799  0.5587702  0.5727862  0.5372983\n",
      " 0.5699156  0.6552002  0.54929477 0.6109167  0.6424525  0.6469744\n",
      " 0.591861   0.7405448  0.62135226 0.54251623 0.76119125 0.65607715\n",
      " 0.50736785 0.53848016]\n",
      "The rewards are: [0.5313222  0.63464636 0.5749742  0.82098764 0.5709052  0.65222275\n",
      " 0.5751246  0.62070745 0.74062437 0.6116524  0.6007139  0.58566874\n",
      " 0.7224375  0.62958074 0.5754348  0.54210144 0.5805591  0.68525356\n",
      " 0.5016209  0.5956971  0.73527795 0.73133457 0.562821   0.7185588\n",
      " 0.58525914 0.52096397 0.5376134  0.74408054 0.78356844 0.5510544\n",
      " 0.53051513 0.8108909 ]\n",
      "The rewards are: [0.65569407 0.56428003 0.5768519  0.745129   0.5628186  0.73375714\n",
      " 0.52221197 0.82291347 0.82754225 0.5108807  0.63048303 0.6529633\n",
      " 0.7663468  0.67542887 0.656652   0.53500605 0.64929265 0.59984434\n",
      " 0.64516973 0.6724854  0.50337315 0.558864   0.67313707 0.5103442\n",
      " 0.6196417  0.6912988  0.5141828  0.5543582  0.6405579  0.56117743\n",
      " 0.5717237  0.5026546 ]\n",
      "The rewards are: [0.7494927  0.5000299  0.6769314  0.7593719  0.55512947 0.67581683\n",
      " 0.66785425 0.51903576 0.5362185  0.59380734 0.6827969  0.6831919\n",
      " 0.5549867  0.51892066 0.7715652  0.78605586 0.5584185  0.76574403\n",
      " 0.66627663 0.6258639  0.808504   0.5651776  0.7381481  0.77774227\n",
      " 0.68070346 0.68558073 0.7442925  0.7954287  0.67809933 0.75395733\n",
      " 0.63907784 0.7336975 ]\n",
      "The rewards are: [0.72654593 0.63994247 0.5077011  0.66829246 0.5440827  0.5974542\n",
      " 0.6540584  0.54824764 0.6916624  0.6085017  0.6453092  0.607376\n",
      " 0.72599655 0.6082969  0.79390526 0.5195304  0.5988641  0.6382211\n",
      " 0.61813724 0.77993095 0.7008939  0.6650179  0.53571916 0.50433284\n",
      " 0.5530341  0.51985186 0.86581445 0.50519025 0.5593592  0.73994356\n",
      " 0.70838016 0.5090787 ]\n",
      "The rewards are: [0.60150474 0.53576833 0.63567066 0.6881595  0.55574787 0.56102437\n",
      " 0.53087914 0.63248366 0.7014807  0.67659074 0.65750146 0.7441505\n",
      " 0.7003145  0.7713445  0.5365125  0.7598324  0.71233976 0.5469028\n",
      " 0.6193125  0.50805897 0.6445639  0.7400754  0.65988815 0.51677406\n",
      " 0.69654024 0.52117777 0.6031871  0.58731276 0.6803722  0.71054965\n",
      " 0.72731966 0.6561023 ]\n",
      "The rewards are: [0.56047326 0.6480284  0.6343747  0.74051535 0.6019867  0.57904977\n",
      " 0.8294873  0.71665573 0.71693826 0.60741144 0.7653027  0.6299041\n",
      " 0.6427148  0.5383745  0.67395025 0.56429756 0.6309451  0.50681335\n",
      " 0.80934143 0.76353467 0.8754835  0.6027306  0.60786223 0.5983929\n",
      " 0.619324   0.5274506  0.563261   0.569486   0.72599846 0.58780754\n",
      " 0.6903337  0.66965216]\n",
      "The rewards are: [0.822882   0.6095695  0.6010023  0.6798087  0.8069803  0.6983376\n",
      " 0.6946691  0.74471825 0.7602764  0.5879939  0.5126992  0.6356396\n",
      " 0.6950887  0.7472186  0.62618303 0.63542014 0.6045453  0.50302935\n",
      " 0.6676632  0.6432522  0.51242733 0.7509695  0.6217864  0.78174716\n",
      " 0.63306236 0.7282989  0.80227894 0.63360816 0.6467041  0.54809326\n",
      " 0.71058565 0.54842603]\n",
      "The rewards are: [0.69553256 0.5953146  0.6040467  0.73138124 0.6127542  0.6996526\n",
      " 0.5255503  0.5793077  0.6368365  0.7268696  0.60395056 0.55925405\n",
      " 0.73008895 0.5368518  0.68574804 0.6720645  0.653197   0.53136533\n",
      " 0.7230693  0.6832131  0.6639154  0.6857593  0.5672122  0.6978478\n",
      " 0.8185057  0.69194543 0.58223367 0.6627145  0.6159073  0.68398315\n",
      " 0.58331865 0.7622861 ]\n",
      "The rewards are: [0.725847   0.5265556  0.7509217  0.65578157 0.6768211  0.6053502\n",
      " 0.75835335 0.8127693  0.7317466  0.51355827 0.7058708  0.7699982\n",
      " 0.71925414 0.55708146 0.5480784  0.59631383 0.51510096 0.7193761\n",
      " 0.77773625 0.8034786  0.5824301  0.525269   0.6754817  0.65393823\n",
      " 0.6480307  0.6278973  0.69244653 0.5751364  0.546179   0.5440175\n",
      " 0.50588274 0.5888934 ]\n",
      "The rewards are: [0.7810193  0.5160098  0.75663024 0.7192873  0.5144762  0.6528715\n",
      " 0.5364888  0.62499344 0.65804255 0.7591379  0.54594076 0.60811377\n",
      " 0.68378675 0.7715719  0.51811475 0.65681887 0.50625426 0.73347354\n",
      " 0.5412008  0.56718785 0.6352411  0.7606086  0.57233477 0.7290441\n",
      " 0.54878575 0.79392064 0.7447219  0.7186172  0.6460202  0.68845165\n",
      " 0.6870638  0.6836383 ]\n",
      "The rewards are: [0.7421238  0.6292287  0.6508727  0.66022575 0.7536213  0.55465937\n",
      " 0.61293197 0.5590896  0.8088757  0.5080014  0.7125423  0.556744\n",
      " 0.7027506  0.54315066 0.6042468  0.7216966  0.76840603 0.7013196\n",
      " 0.56754434 0.67071676 0.6209012  0.53209186 0.53213465 0.5435484\n",
      " 0.5942228  0.68359727 0.56536764 0.71814716 0.59518784 0.55919707\n",
      " 0.82838327 0.77867293]\n",
      "The rewards are: [0.5042073  0.56089175 0.66101253 0.7013625  0.6439852  0.765614\n",
      " 0.75614804 0.5130291  0.6606632  0.56760144 0.69969714 0.68200916\n",
      " 0.7246549  0.52802944 0.5054162  0.6289362  0.57991344 0.5779836\n",
      " 0.74303263 0.55195296 0.66740006 0.6922099  0.6792945  0.7646102\n",
      " 0.6277868  0.7487191  0.7688757  0.6670642  0.7817026  0.5823327\n",
      " 0.653091   0.7024962 ]\n",
      "The rewards are: [0.7807301  0.7691665  0.541964   0.6735378  0.6233214  0.6379904\n",
      " 0.59816843 0.8011961  0.64995044 0.54095155 0.61024034 0.59766644\n",
      " 0.5432111  0.72823936 0.5747976  0.7376891  0.79768777 0.70901066\n",
      " 0.6095224  0.84880465 0.5998928  0.63612974 0.50817025 0.69836\n",
      " 0.8495446  0.5847445  0.6241313  0.6366809  0.6127602  0.60845256\n",
      " 0.67877567 0.66693234]\n",
      "The rewards are: [0.68616885 0.6600108  0.6130151  0.68790805 0.5088264  0.6218241\n",
      " 0.6946662  0.6504215  0.55759645 0.7105264  0.7213506  0.7172456\n",
      " 0.62455815 0.814783   0.67591065 0.69738936 0.5919391  0.6549817\n",
      " 0.5598704  0.6990048  0.5962569  0.58727753 0.5671524  0.56148857\n",
      " 0.6558203  0.6168414  0.70997036 0.5464444  0.5995652  0.64315146\n",
      " 0.76324743 0.65196025]\n",
      "The rewards are: [0.5823934  0.69108725 0.78499156 0.6163417  0.64237046 0.68674624\n",
      " 0.7713638  0.6479866  0.6782876  0.5393378  0.6129551  0.6723051\n",
      " 0.7087836  0.65964335 0.7486621  0.5113506  0.51530576 0.5622677\n",
      " 0.6795413  0.7640994  0.6849439  0.5679833  0.5951468  0.7480217\n",
      " 0.7456488  0.7573673  0.6253162  0.5501117  0.6423515  0.62037915\n",
      " 0.5953088  0.51389295]\n",
      "The rewards are: [0.5803927  0.5085236  0.638831   0.64316124 0.67532784 0.8578921\n",
      " 0.6386683  0.7674997  0.50015414 0.5627421  0.673382   0.7487759\n",
      " 0.61887854 0.7391064  0.7627272  0.78258455 0.5438329  0.7534105\n",
      " 0.59386015 0.76114064 0.67226094 0.6109222  0.7388912  0.73658824\n",
      " 0.5568409  0.8061537  0.5398056  0.6834112  0.53369117 0.7819848\n",
      " 0.81226027 0.7187564 ]\n",
      "The rewards are: [0.6768156  0.7671014  0.72517097 0.5372875  0.69041747 0.51572144\n",
      " 0.72211975 0.74543947 0.60641956 0.78309065 0.655408   0.6216323\n",
      " 0.6822549  0.58396477 0.77072424 0.5494138  0.8089348  0.6124593\n",
      " 0.51373506 0.8055272  0.53587514 0.6087523  0.60155994 0.5601308\n",
      " 0.82494897 0.56467193 0.83503294 0.5688242  0.6366606  0.6196613\n",
      " 0.8488402  0.8081537 ]\n",
      "The rewards are: [0.6018996  0.57438856 0.60194707 0.6071674  0.63642824 0.6215559\n",
      " 0.7889707  0.64817524 0.80181444 0.60804117 0.79489434 0.6058292\n",
      " 0.7096535  0.58618915 0.69771457 0.7145859  0.64028364 0.62490845\n",
      " 0.70293164 0.6283117  0.7059561  0.62957424 0.6618227  0.60657626\n",
      " 0.5946401  0.80535054 0.7559078  0.54409564 0.6323688  0.6594093\n",
      " 0.6294924  0.8085324 ]\n",
      "The rewards are: [0.5917455  0.55651224 0.6367875  0.65759355 0.8670568  0.68909305\n",
      " 0.7118927  0.8507815  0.671547   0.66953623 0.7011119  0.6715129\n",
      " 0.63527536 0.6308192  0.6541086  0.7007292  0.7835542  0.7306822\n",
      " 0.6302658  0.5335558  0.66786337 0.6772689  0.5452555  0.6586428\n",
      " 0.8595812  0.6763112  0.6413563  0.7602001  0.50435174 0.5027668\n",
      " 0.5673112  0.6280372 ]\n",
      "The rewards are: [0.5942334  0.8202818  0.7912033  0.72630817 0.802858   0.78387827\n",
      " 0.61900926 0.69757354 0.6467509  0.5842047  0.7950791  0.7084681\n",
      " 0.5727661  0.64673775 0.54401535 0.5186897  0.7197947  0.70265573\n",
      " 0.7236076  0.62073886 0.64985144 0.8500073  0.77484864 0.7440195\n",
      " 0.51286393 0.69961655 0.526949   0.5665644  0.55484724 0.52507806\n",
      " 0.6303703  0.56976825]\n",
      "The rewards are: [0.5876713  0.5000347  0.64704305 0.58075285 0.6701836  0.5607625\n",
      " 0.5727565  0.5113565  0.60293806 0.56646514 0.55168754 0.5927351\n",
      " 0.72032434 0.6204766  0.68593836 0.5134618  0.5471201  0.8173502\n",
      " 0.81813204 0.86752117 0.8163171  0.8176385  0.7982613  0.7000761\n",
      " 0.8235419  0.69394374 0.6248759  0.85037583 0.633811   0.8605921\n",
      " 0.75568646 0.54538053]\n",
      "The rewards are: [0.6569737  0.6989407  0.8627558  0.5840979  0.6979781  0.7442308\n",
      " 0.5006771  0.5415869  0.8242022  0.547153   0.6296447  0.62675774\n",
      " 0.5457348  0.74412644 0.6278318  0.591661   0.7042044  0.70354074\n",
      " 0.75852066 0.65759265 0.7578167  0.6102997  0.8166018  0.7265474\n",
      " 0.61213374 0.6403102  0.6332028  0.6797766  0.7366415  0.5851686\n",
      " 0.6337838  0.54419047]\n",
      "The rewards are: [0.5042651  0.79814625 0.56151885 0.6703385  0.65931517 0.571975\n",
      " 0.6333189  0.6740679  0.7209689  0.53035486 0.72721267 0.76176167\n",
      " 0.728855   0.7708263  0.5317494  0.70013005 0.6636931  0.6277646\n",
      " 0.8039398  0.5250474  0.5683494  0.6318847  0.69390285 0.800863\n",
      " 0.60747004 0.6135693  0.7831972  0.7881358  0.62518036 0.7332621\n",
      " 0.68070024 0.6449647 ]\n",
      "The rewards are: [0.6451667  0.7104573  0.5231794  0.6643614  0.61152303 0.5642716\n",
      " 0.52724046 0.5312732  0.7842135  0.74723643 0.6022629  0.66046184\n",
      " 0.519543   0.7441232  0.6752319  0.63194704 0.8450512  0.7260391\n",
      " 0.7493793  0.73408365 0.6627853  0.7863561  0.73635036 0.7078428\n",
      " 0.86353856 0.71082294 0.61700124 0.6811159  0.72520894 0.6894315\n",
      " 0.58245564 0.6022086 ]\n",
      "The rewards are: [0.75017    0.63952804 0.68806136 0.8295867  0.58311903 0.52830434\n",
      " 0.6260335  0.5205889  0.80645704 0.7281507  0.59712195 0.84742117\n",
      " 0.57240134 0.59943914 0.6722433  0.6511492  0.53767556 0.61421436\n",
      " 0.8576397  0.5904668  0.5584314  0.7293811  0.6469952  0.6159844\n",
      " 0.605459   0.5727684  0.6889279  0.62669486 0.69454336 0.7803824\n",
      " 0.6399798  0.6356944 ]\n",
      "The rewards are: [0.5013315  0.68643415 0.58229226 0.7257256  0.67488825 0.8098035\n",
      " 0.6839516  0.68543965 0.6359715  0.7145978  0.8070868  0.8542045\n",
      " 0.6841378  0.5606302  0.6480634  0.7911048  0.8515196  0.52810323\n",
      " 0.5834806  0.7621659  0.50372195 0.80463415 0.51211023 0.7444141\n",
      " 0.74516237 0.7160676  0.7257111  0.56316537 0.8134367  0.505156\n",
      " 0.73766595 0.5703523 ]\n",
      "The rewards are: [0.70699626 0.73455495 0.70358986 0.7088372  0.6115758  0.79199386\n",
      " 0.7606865  0.8206367  0.7254011  0.61567134 0.64547706 0.6238472\n",
      " 0.7011209  0.5681786  0.64720076 0.573967   0.6619399  0.6974855\n",
      " 0.53392285 0.77481663 0.67930806 0.5553143  0.58472174 0.60867846\n",
      " 0.700608   0.6911834  0.68177885 0.5628706  0.6401562  0.719679\n",
      " 0.74590284 0.7819274 ]\n",
      "The rewards are: [0.8310352  0.8690082  0.6894812  0.66823864 0.7605969  0.6583416\n",
      " 0.89033943 0.5223174  0.51715165 0.8854864  0.6223781  0.79271525\n",
      " 0.7928286  0.540059   0.59556586 0.63566893 0.6105231  0.872081\n",
      " 0.66819745 0.6604732  0.7614119  0.8936306  0.52240866 0.54947555\n",
      " 0.668719   0.6584781  0.8786088  0.5475398  0.81891066 0.67170477\n",
      " 0.72308755 0.6224464 ]\n",
      "The rewards are: [0.5768378  0.6343078  0.7158325  0.881386   0.5827145  0.7464183\n",
      " 0.657273   0.74271345 0.7784808  0.73105115 0.79544497 0.524857\n",
      " 0.55505615 0.7837169  0.7775728  0.6350311  0.81168604 0.6457411\n",
      " 0.79468024 0.645714   0.78567713 0.68151414 0.60268074 0.7889332\n",
      " 0.73582613 0.73597205 0.53436327 0.72127837 0.89470786 0.77007705\n",
      " 0.7663556  0.84456855]\n",
      "The rewards are: [0.8356178  0.6646278  0.5587887  0.63518053 0.50328237 0.88647115\n",
      " 0.52268195 0.7054631  0.7738491  0.5030038  0.77951056 0.5377495\n",
      " 0.56578344 0.5012836  0.7750238  0.88216466 0.8560318  0.8923082\n",
      " 0.89335674 0.5528261  0.5124979  0.79196644 0.5023357  0.8052774\n",
      " 0.7116844  0.7344363  0.7343483  0.7156938  0.53658295 0.6867609\n",
      " 0.79050016 0.77463317]\n",
      "The rewards are: [0.82622874 0.81718886 0.5108178  0.7631381  0.69393826 0.77494645\n",
      " 0.5682917  0.8008707  0.57324255 0.65359867 0.58010346 0.682188\n",
      " 0.7359477  0.65329826 0.66691035 0.73293465 0.771509   0.78291106\n",
      " 0.76123726 0.77972794 0.79167664 0.79219335 0.6515416  0.6959218\n",
      " 0.6212452  0.673603   0.6974888  0.7827351  0.72098213 0.5194339\n",
      " 0.71915376 0.75504005]\n",
      "The rewards are: [0.8697732  0.82938    0.7799266  0.5607986  0.7795097  0.7607573\n",
      " 0.84708214 0.83564764 0.6628138  0.6252152  0.6511307  0.7117403\n",
      " 0.7492103  0.859355   0.71739995 0.70068496 0.6320572  0.63663363\n",
      " 0.7541809  0.51805973 0.6924776  0.8507748  0.50887716 0.6669974\n",
      " 0.7055943  0.8306265  0.62794596 0.62140536 0.73308253 0.79021764\n",
      " 0.83630145 0.8360974 ]\n",
      "The rewards are: [0.68899816 0.82789826 0.5739718  0.61574715 0.5837738  0.75052965\n",
      " 0.6700558  0.68039125 0.54494226 0.832764   0.7235807  0.724111\n",
      " 0.7667051  0.8960834  0.5408036  0.86643636 0.64542294 0.55924934\n",
      " 0.5640788  0.52395004 0.72674525 0.5007562  0.53802204 0.67009306\n",
      " 0.8476767  0.64431703 0.66260874 0.68776006 0.79663813 0.60202223\n",
      " 0.7346926  0.72280884]\n",
      "The rewards are: [0.6601038  0.79818916 0.70762867 0.7462371  0.6246509  0.65335804\n",
      " 0.6133714  0.60055286 0.680057   0.7050286  0.72393095 0.8630987\n",
      " 0.7731875  0.749831   0.6696569  0.64811546 0.6524593  0.5078052\n",
      " 0.72325987 0.67357147 0.7707667  0.71028495 0.6954079  0.7955532\n",
      " 0.60241574 0.6143845  0.78038645 0.7090226  0.56829274 0.7595077\n",
      " 0.575953   0.5953818 ]\n",
      "The rewards are: [0.71958536 0.6929643  0.71793157 0.758522   0.71373785 0.8042895\n",
      " 0.70642537 0.52054113 0.64679164 0.7748477  0.6778278  0.56738746\n",
      " 0.700311   0.7578094  0.9307181  0.7773659  0.5871995  0.5506319\n",
      " 0.8064849  0.7754594  0.7840921  0.51239526 0.5623229  0.8476737\n",
      " 0.8330899  0.83676004 0.50488937 0.80485684 0.5162346  0.6983561\n",
      " 0.75054336 0.628617  ]\n",
      "The rewards are: [0.61282384 0.84709966 0.56721246 0.7875867  0.650008   0.5979583\n",
      " 0.7158303  0.72998536 0.7304694  0.75829154 0.66314006 0.61156946\n",
      " 0.5637936  0.8016984  0.5178444  0.52999014 0.78736323 0.86175513\n",
      " 0.81257504 0.8071944  0.9121158  0.793829   0.89082956 0.71502966\n",
      " 0.6086614  0.5163389  0.7711453  0.84455323 0.74770004 0.5318194\n",
      " 0.65910125 0.5644601 ]\n",
      "The rewards are: [0.6920835  0.67917985 0.7623041  0.57330096 0.845828   0.79603475\n",
      " 0.5107574  0.74436617 0.8109105  0.76526946 0.6177001  0.59260756\n",
      " 0.69545573 0.7709154  0.7069377  0.5811411  0.6474084  0.6357148\n",
      " 0.61878026 0.68835276 0.50902635 0.52821434 0.9088635  0.79380673\n",
      " 0.77512157 0.8281184  0.7978608  0.51311225 0.6165324  0.67727876\n",
      " 0.8717982  0.76941186]\n",
      "The rewards are: [0.66228557 0.6576582  0.6765175  0.8373977  0.6117576  0.74119383\n",
      " 0.7448962  0.61456186 0.85879445 0.7852835  0.51311725 0.6025081\n",
      " 0.7617472  0.6668156  0.8849322  0.736736   0.6720594  0.87648284\n",
      " 0.80645037 0.72263163 0.66144913 0.6446957  0.50020164 0.7017003\n",
      " 0.640133   0.6509657  0.5000372  0.56125236 0.699206   0.78267694\n",
      " 0.67805797 0.6176286 ]\n",
      "The rewards are: [0.83934814 0.76469606 0.7475068  0.74607056 0.6152568  0.82995653\n",
      " 0.6791121  0.59437126 0.81433237 0.82559377 0.87371296 0.854345\n",
      " 0.60134846 0.7310331  0.8784142  0.6888361  0.5074815  0.64146066\n",
      " 0.73278326 0.8907856  0.6438487  0.6502328  0.62669665 0.6510563\n",
      " 0.8240831  0.7382023  0.7188026  0.74173576 0.6289714  0.59026796\n",
      " 0.79458034 0.74471325]\n",
      "The rewards are: [0.8094106  0.8210065  0.85754544 0.85877776 0.6026886  0.7199423\n",
      " 0.65708363 0.6538954  0.7330949  0.7041895  0.7686527  0.5717689\n",
      " 0.8742779  0.71709853 0.8312547  0.82102054 0.8194363  0.8240325\n",
      " 0.58565235 0.8125506  0.6575039  0.8077753  0.9274651  0.6348721\n",
      " 0.7005294  0.72349566 0.81141734 0.6782166  0.8727879  0.76157725\n",
      " 0.7839279  0.7758156 ]\n",
      "The rewards are: [0.7193933  0.5181731  0.7274656  0.6039589  0.76946485 0.6861013\n",
      " 0.5433246  0.5004888  0.73642963 0.85646546 0.75286657 0.6395631\n",
      " 0.85810345 0.6722782  0.57529974 0.7119105  0.5104883  0.78464353\n",
      " 0.69734734 0.68585116 0.84872    0.6579884  0.8427102  0.69012684\n",
      " 0.60448366 0.6092315  0.77911454 0.5811873  0.6015782  0.73735696\n",
      " 0.7848569  0.50555396]\n",
      "The rewards are: [0.8174306  0.89997554 0.7125053  0.5285045  0.69584745 0.77863705\n",
      " 0.55034447 0.8133868  0.5397961  0.6487097  0.72346705 0.89911395\n",
      " 0.6318716  0.8783559  0.52982396 0.7413594  0.7825785  0.8878724\n",
      " 0.8822735  0.5108944  0.7844999  0.71528596 0.6296591  0.79323316\n",
      " 0.84723437 0.52361274 0.8271107  0.6528073  0.7064595  0.6933639\n",
      " 0.9238311  0.84173834]\n",
      "The rewards are: [0.82220894 0.58211374 0.7211805  0.87509865 0.6429469  0.8083889\n",
      " 0.82322663 0.88643855 0.5914787  0.8575235  0.8663252  0.51235545\n",
      " 0.741098   0.5796653  0.77008003 0.78888184 0.79424065 0.8508975\n",
      " 0.54264665 0.57470816 0.7087685  0.6603453  0.85161257 0.7193406\n",
      " 0.8237593  0.7895572  0.52845305 0.5082313  0.86416787 0.6669597\n",
      " 0.82495594 0.7968634 ]\n",
      "The rewards are: [0.79665154 0.52037644 0.6034662  0.85528255 0.6976945  0.6795529\n",
      " 0.75784767 0.7275736  0.8261801  0.76287585 0.64208084 0.616876\n",
      " 0.7454203  0.65989    0.80535704 0.60995275 0.6405392  0.6222241\n",
      " 0.6517562  0.8295562  0.6385154  0.7504181  0.6092867  0.88188016\n",
      " 0.6132079  0.5662046  0.5744429  0.7093407  0.7996021  0.5378065\n",
      " 0.53803444 0.60079604]\n",
      "The rewards are: [0.6424975  0.5561631  0.62053984 0.81617296 0.7895669  0.8512487\n",
      " 0.5424596  0.7753491  0.69054574 0.7527543  0.83569753 0.8291967\n",
      " 0.8519961  0.81362486 0.7300809  0.78426087 0.90230155 0.5298698\n",
      " 0.75178677 0.6067347  0.8083246  0.59580255 0.76368976 0.8445184\n",
      " 0.7126996  0.75055045 0.68767464 0.75450855 0.6266278  0.6289894\n",
      " 0.903838   0.71317196]\n",
      "The rewards are: [0.67885065 0.82314694 0.8328941  0.73414    0.6166469  0.7809331\n",
      " 0.93383044 0.84759045 0.8621622  0.74552923 0.7146207  0.6862145\n",
      " 0.84816533 0.52966666 0.85804147 0.70492566 0.5131575  0.79760563\n",
      " 0.66473734 0.7425208  0.5956276  0.84423214 0.7031183  0.69774866\n",
      " 0.7460611  0.808419   0.75257033 0.88366187 0.6802126  0.6924678\n",
      " 0.778941   0.53973615]\n",
      "The rewards are: [0.56190205 0.8586515  0.7265313  0.83413374 0.90876657 0.87122875\n",
      " 0.68258226 0.7546888  0.7573914  0.7053207  0.7070407  0.7822132\n",
      " 0.7329209  0.6047985  0.66903734 0.82319015 0.75687927 0.76680017\n",
      " 0.55342066 0.5890246  0.6393071  0.86827517 0.58974254 0.7790809\n",
      " 0.6244228  0.6554486  0.8626112  0.8606649  0.8694248  0.85831803\n",
      " 0.8855976  0.62833333]\n",
      "The rewards are: [0.5341344  0.6589632  0.61826015 0.8755778  0.6018864  0.8920441\n",
      " 0.84280765 0.9109671  0.93928164 0.57313526 0.8753405  0.7318181\n",
      " 0.79068357 0.7203869  0.9577016  0.614715   0.6962895  0.66831976\n",
      " 0.5979676  0.7988242  0.7092989  0.7964544  0.9476349  0.72667825\n",
      " 0.60159427 0.5981613  0.67403483 0.66439956 0.6343994  0.8763995\n",
      " 0.8808065  0.8596429 ]\n",
      "The rewards are: [0.8107117  0.8181681  0.8822458  0.86669093 0.6137348  0.6880313\n",
      " 0.8274876  0.5337315  0.86984587 0.5573286  0.77810967 0.6517053\n",
      " 0.5514729  0.509027   0.6721851  0.6857797  0.86190665 0.78631806\n",
      " 0.66935897 0.61328834 0.74907076 0.80914533 0.7919487  0.9003937\n",
      " 0.7170703  0.69288    0.5883971  0.93705153 0.7233747  0.5371983\n",
      " 0.8217656  0.7310316 ]\n",
      "The rewards are: [0.7316975  0.79290843 0.7868792  0.80902624 0.7464983  0.6258224\n",
      " 0.87472457 0.64249885 0.7646423  0.84030527 0.76356226 0.72116727\n",
      " 0.83265346 0.5118292  0.6922063  0.7681702  0.7025709  0.51923585\n",
      " 0.7057429  0.8351223  0.69500464 0.56141645 0.7003465  0.83308303\n",
      " 0.77216834 0.59145147 0.88479453 0.77143854 0.64901686 0.8702493\n",
      " 0.57852244 0.6158392 ]\n",
      "The rewards are: [0.6309276  0.9425988  0.8542864  0.85688484 0.8724231  0.89820385\n",
      " 0.87299716 0.7440311  0.6547961  0.81205684 0.76953477 0.873959\n",
      " 0.6585908  0.80933255 0.63341683 0.5876152  0.79838604 0.77540004\n",
      " 0.83982366 0.865409   0.697256   0.74423206 0.77337974 0.72191733\n",
      " 0.6185514  0.71833473 0.5477344  0.74192965 0.66771525 0.5060243\n",
      " 0.7074371  0.78863895]\n",
      "The rewards are: [0.7956877  0.89009345 0.65858907 0.919599   0.546257   0.7236581\n",
      " 0.7700134  0.7716133  0.5600473  0.7461026  0.7440671  0.88299996\n",
      " 0.52161777 0.8703628  0.6232665  0.7582264  0.8224576  0.7661369\n",
      " 0.53339344 0.5859962  0.6729262  0.50312823 0.91673315 0.8239378\n",
      " 0.54325104 0.65128493 0.76798445 0.5683575  0.6942223  0.64266104\n",
      " 0.54006165 0.7078407 ]\n",
      "The rewards are: [0.81459296 0.9231009  0.56752914 0.656497   0.93607897 0.7686357\n",
      " 0.81406015 0.8857115  0.8597666  0.8026961  0.7207279  0.6590686\n",
      " 0.6975788  0.750084   0.5591624  0.64177334 0.8463167  0.83363146\n",
      " 0.5134844  0.8271456  0.6523331  0.7816206  0.8408087  0.68352515\n",
      " 0.76025635 0.66422755 0.74049556 0.912743   0.74336404 0.5367379\n",
      " 0.77902514 0.79802835]\n",
      "The rewards are: [0.7223394  0.7323466  0.6749127  0.93899566 0.8599455  0.71296495\n",
      " 0.8460162  0.7188968  0.51390964 0.7777482  0.5979145  0.5768038\n",
      " 0.8748414  0.708725   0.7881068  0.8531408  0.50706315 0.6154645\n",
      " 0.68925375 0.7953312  0.62868196 0.59089714 0.5625254  0.5338108\n",
      " 0.8405564  0.8663977  0.78570086 0.7298578  0.6378576  0.6052192\n",
      " 0.6992325  0.566384  ]\n",
      "The rewards are: [0.54161716 0.7255418  0.9380074  0.6065301  0.6668853  0.7577398\n",
      " 0.86643714 0.50958836 0.65787035 0.9036654  0.6708105  0.93136716\n",
      " 0.5548252  0.53745806 0.9310752  0.8367298  0.7613973  0.8579335\n",
      " 0.52469826 0.80060554 0.8303359  0.790134   0.69753915 0.88586646\n",
      " 0.5331791  0.84309644 0.5785602  0.92260736 0.5980351  0.6695273\n",
      " 0.7541309  0.8076372 ]\n",
      "The rewards are: [0.8174641  0.925302   0.8335259  0.7637329  0.5865838  0.62820065\n",
      " 0.7185717  0.69001585 0.9017823  0.6276856  0.59003186 0.93395674\n",
      " 0.7717551  0.8266914  0.66187304 0.5289838  0.51978767 0.6699899\n",
      " 0.8916159  0.7744926  0.5473834  0.7279033  0.8296398  0.8662037\n",
      " 0.6221788  0.852071   0.8514311  0.6817127  0.86157095 0.6285179\n",
      " 0.8212752  0.7929106 ]\n",
      "The rewards are: [0.82647294 0.92436796 0.57331747 0.70047855 0.7471012  0.52573645\n",
      " 0.65966684 0.8349     0.7446836  0.64405614 0.57047665 0.88179237\n",
      " 0.87876654 0.83076465 0.7302089  0.89528906 0.762461   0.60150325\n",
      " 0.60283864 0.6059042  0.53596693 0.84193546 0.82837915 0.628892\n",
      " 0.714045   0.75161207 0.60626847 0.584737   0.69717395 0.90670425\n",
      " 0.8683004  0.7862842 ]\n",
      "The rewards are: [0.671389   0.7253108  0.7506599  0.8330455  0.662578   0.8973224\n",
      " 0.72833014 0.7061162  0.5703787  0.7659973  0.7337107  0.89677775\n",
      " 0.7808579  0.5194337  0.79917115 0.5280074  0.84646183 0.55839145\n",
      " 0.9024219  0.5918997  0.8407464  0.6311128  0.64843905 0.54471296\n",
      " 0.5904774  0.6419866  0.7066292  0.84256935 0.5706411  0.85096216\n",
      " 0.8447191  0.82025295]\n",
      "The rewards are: [0.92691267 0.6169973  0.7651338  0.7728513  0.6771831  0.74637395\n",
      " 0.83557063 0.79926634 0.6765073  0.5567078  0.59106505 0.8750004\n",
      " 0.68807757 0.6183003  0.7512403  0.6698796  0.6010942  0.85589254\n",
      " 0.8082159  0.5037011  0.55065817 0.8872802  0.8822798  0.9121435\n",
      " 0.5369938  0.75730085 0.9072155  0.8131144  0.5401941  0.9035141\n",
      " 0.6085074  0.85398626]\n",
      "The rewards are: [0.73505217 0.68491    0.5426978  0.77122056 0.87572086 0.6613384\n",
      " 0.7044695  0.8655982  0.82469475 0.539296   0.6546331  0.50428754\n",
      " 0.7702305  0.78670406 0.6881348  0.85693336 0.8401033  0.65224177\n",
      " 0.55708367 0.8844954  0.7472046  0.8240576  0.7782329  0.6883761\n",
      " 0.5994616  0.8186411  0.84380627 0.51708937 0.95768315 0.8226104\n",
      " 0.5850777  0.7293454 ]\n",
      "The rewards are: [0.81863326 0.75646    0.7202068  0.75366515 0.84911644 0.81898046\n",
      " 0.62540466 0.71236503 0.6357358  0.6829272  0.62330204 0.9068879\n",
      " 0.86978894 0.59651524 0.93747383 0.6842474  0.79008377 0.63075703\n",
      " 0.61489767 0.8383831  0.71124196 0.6795466  0.87867635 0.7624416\n",
      " 0.86215866 0.57621884 0.76291764 0.86534554 0.7350294  0.8795538\n",
      " 0.7010665  0.74839777]\n",
      "The rewards are: [0.7314003  0.89116627 0.8384444  0.5775966  0.6823336  0.7869498\n",
      " 0.9261444  0.7017377  0.5792916  0.5617093  0.8367652  0.76691264\n",
      " 0.93050253 0.7580054  0.6397663  0.907136   0.90710384 0.62390506\n",
      " 0.87206554 0.8978819  0.6583009  0.6044348  0.7368397  0.6626259\n",
      " 0.75084496 0.61110646 0.9198204  0.8627122  0.62050724 0.9180279\n",
      " 0.5950453  0.8262307 ]\n",
      "The rewards are: [0.78193444 0.82527    0.561307   0.6594481  0.6671188  0.54508555\n",
      " 0.8179283  0.5982564  0.5469674  0.55199933 0.5441243  0.88221645\n",
      " 0.8541015  0.6980178  0.74976665 0.6012944  0.62411785 0.785101\n",
      " 0.7109974  0.7802361  0.65352714 0.5807968  0.7260127  0.51482964\n",
      " 0.85053277 0.56886256 0.7858304  0.8709197  0.5717131  0.6520358\n",
      " 0.8471947  0.61433285]\n",
      "The rewards are: [0.8568211  0.6843376  0.9519352  0.63176215 0.51252216 0.5098708\n",
      " 0.5839824  0.83273816 0.94143146 0.7859131  0.7990249  0.92591494\n",
      " 0.58771944 0.84489334 0.7840236  0.82858455 0.75688636 0.861698\n",
      " 0.7529857  0.87222534 0.8677251  0.7422608  0.73820037 0.8371406\n",
      " 0.5636299  0.9066758  0.61203295 0.69491136 0.61820745 0.8983743\n",
      " 0.92807704 0.69690454]\n",
      "The rewards are: [0.7703595  0.6700813  0.65538955 0.75278836 0.61755717 0.64753526\n",
      " 0.8366333  0.87795264 0.7752775  0.5813761  0.8051109  0.8031468\n",
      " 0.8206504  0.93960845 0.9049191  0.5785391  0.72342956 0.854154\n",
      " 0.80256104 0.7751593  0.90300155 0.6341175  0.68771553 0.86309016\n",
      " 0.88450146 0.7843222  0.7000358  0.93303645 0.7102251  0.7531363\n",
      " 0.7362552  0.88558257]\n",
      "The rewards are: [0.6744342  0.80668133 0.64430684 0.64905113 0.710082   0.68230236\n",
      " 0.7603154  0.7108638  0.8045279  0.7749941  0.94351107 0.65128505\n",
      " 0.876877   0.50695336 0.781968   0.7096327  0.5280201  0.87909937\n",
      " 0.5582507  0.79952747 0.68814886 0.8538437  0.8561792  0.91573423\n",
      " 0.7076303  0.5520145  0.6564811  0.93758786 0.7681222  0.62060976\n",
      " 0.78200644 0.8941225 ]\n",
      "The rewards are: [0.8158935  0.8732718  0.89892423 0.90354973 0.6729981  0.82592446\n",
      " 0.8845753  0.6819635  0.61007047 0.5352108  0.8702119  0.75910336\n",
      " 0.7791859  0.8513845  0.89717656 0.70415753 0.59691936 0.7007246\n",
      " 0.7545953  0.5855263  0.5221067  0.80633795 0.5293659  0.8616042\n",
      " 0.8237233  0.54867345 0.9281394  0.9105456  0.7835581  0.5719523\n",
      " 0.6967104  0.7306279 ]\n",
      "The rewards are: [0.5513437  0.5822392  0.87710917 0.7224837  0.87210757 0.665991\n",
      " 0.50677663 0.65382135 0.8513717  0.6569909  0.7218579  0.84711754\n",
      " 0.85022557 0.84371936 0.9029753  0.77834964 0.88890696 0.57930464\n",
      " 0.84084773 0.8199347  0.75385654 0.77283764 0.5601183  0.507349\n",
      " 0.5688554  0.64282    0.65204924 0.9409491  0.92775476 0.7716675\n",
      " 0.7871773  0.87603235]\n",
      "The rewards are: [0.5028766  0.88361865 0.7209783  0.8554057  0.90324724 0.67070276\n",
      " 0.8716089  0.80759966 0.91756314 0.9237567  0.7595327  0.6727926\n",
      " 0.6498829  0.70626354 0.5311911  0.7193991  0.6217237  0.85307753\n",
      " 0.83824736 0.80632496 0.76961464 0.8537186  0.95212924 0.50817055\n",
      " 0.63808095 0.83390623 0.86594373 0.7415693  0.9558039  0.8002731\n",
      " 0.6219313  0.9047885 ]\n",
      "The rewards are: [0.7573576  0.8461872  0.53978264 0.6550416  0.55576456 0.6449841\n",
      " 0.81854916 0.66834265 0.597341   0.7794755  0.65622497 0.5809246\n",
      " 0.52007824 0.79676145 0.93795425 0.8315156  0.8190665  0.5530734\n",
      " 0.6308225  0.70886266 0.67351985 0.5339775  0.84701407 0.96284455\n",
      " 0.5889318  0.7194081  0.8087006  0.6820982  0.94974023 0.59844726\n",
      " 0.7987086  0.676892  ]\n",
      "The rewards are: [0.724932   0.6064158  0.76125294 0.8337165  0.53863126 0.66731817\n",
      " 0.87275475 0.82908195 0.54776394 0.6755265  0.895862   0.8634508\n",
      " 0.8134477  0.73001975 0.8174213  0.91506314 0.85581553 0.77125376\n",
      " 0.52608716 0.72557    0.68508947 0.6759067  0.5270332  0.69780225\n",
      " 0.9370748  0.7073035  0.7732154  0.8626141  0.65601623 0.9158359\n",
      " 0.90226763 0.6096142 ]\n",
      "The rewards are: [0.58232415 0.85696155 0.840629   0.53701645 0.55223817 0.6833835\n",
      " 0.64722013 0.6217012  0.86887306 0.6413213  0.8483266  0.942017\n",
      " 0.8849721  0.83741033 0.7996091  0.77476597 0.8276546  0.8428068\n",
      " 0.7409239  0.6454386  0.5678519  0.52992785 0.83315295 0.87217754\n",
      " 0.84612066 0.89807945 0.7551331  0.79419917 0.78182787 0.825446\n",
      " 0.83923846 0.79927766]\n",
      "The rewards are: [0.8636322  0.7515953  0.6766927  0.5065208  0.5777483  0.5385497\n",
      " 0.7977875  0.7836847  0.73912495 0.7480191  0.8180297  0.62415063\n",
      " 0.5012549  0.6637409  0.92008924 0.53835994 0.81712687 0.5102975\n",
      " 0.59716445 0.68851334 0.61784095 0.55077916 0.8097896  0.8638606\n",
      " 0.9120963  0.86726385 0.7890627  0.7748966  0.706016   0.5264859\n",
      " 0.8512248  0.625177  ]\n",
      "The rewards are: [0.7046598  0.62619984 0.5076961  0.8045111  0.7924716  0.67923653\n",
      " 0.6081125  0.8556934  0.5687986  0.8301692  0.8057824  0.6747366\n",
      " 0.7401257  0.83923525 0.61987054 0.8584722  0.8880903  0.706101\n",
      " 0.9073824  0.6674497  0.5426263  0.8743696  0.89077896 0.8050378\n",
      " 0.8532601  0.79654044 0.5508776  0.59180343 0.8521124  0.90861094\n",
      " 0.7977221  0.6331867 ]\n",
      "The rewards are: [0.654852   0.94911087 0.9096401  0.7593087  0.8402488  0.9005189\n",
      " 0.878543   0.843288   0.59681743 0.8154429  0.8272934  0.7489266\n",
      " 0.950279   0.73420155 0.755181   0.68977857 0.6892447  0.682848\n",
      " 0.7201392  0.65360934 0.7355855  0.7060774  0.6197561  0.81174135\n",
      " 0.90246236 0.78482014 0.9188356  0.68698186 0.9283435  0.6897431\n",
      " 0.79207325 0.83475256]\n",
      "The rewards are: [0.600263   0.6304634  0.81890213 0.57715946 0.5747916  0.66897887\n",
      " 0.9030088  0.9049569  0.66292083 0.8936251  0.7008169  0.8487185\n",
      " 0.50615966 0.5507723  0.6480241  0.90291846 0.9346456  0.6580538\n",
      " 0.78819144 0.7463145  0.60182333 0.9056126  0.8909834  0.609195\n",
      " 0.53103846 0.7233642  0.58119714 0.7121834  0.8178831  0.7932976\n",
      " 0.76555943 0.87360984]\n",
      "The rewards are: [0.9394811  0.8251071  0.6434005  0.82985175 0.70367736 0.795828\n",
      " 0.78981256 0.92914665 0.8646723  0.874341   0.72828007 0.54567224\n",
      " 0.7392119  0.7180091  0.8575227  0.9054401  0.7881581  0.8137503\n",
      " 0.8354203  0.6693657  0.85891753 0.811421   0.716149   0.78150547\n",
      " 0.5680517  0.63873446 0.72870564 0.5701285  0.7967485  0.80805933\n",
      " 0.7403223  0.7487518 ]\n",
      "The rewards are: [0.91569763 0.5945313  0.7021229  0.8807745  0.86600673 0.6925647\n",
      " 0.80925834 0.8980854  0.8982612  0.62282294 0.5565787  0.84420544\n",
      " 0.63401604 0.94699025 0.9377693  0.7343679  0.87997276 0.57049525\n",
      " 0.79790586 0.61264914 0.8310628  0.72044545 0.75896895 0.8983212\n",
      " 0.8359479  0.7390252  0.91118395 0.5251464  0.9228096  0.8433463\n",
      " 0.72355753 0.845318  ]\n",
      "The rewards are: [0.64202595 0.8952996  0.69389    0.67134374 0.72945    0.88301843\n",
      " 0.5282486  0.6700235  0.89874834 0.95811397 0.84361446 0.86900663\n",
      " 0.76901686 0.5095975  0.9027711  0.6696137  0.70210004 0.8336574\n",
      " 0.5001884  0.7929725  0.8385793  0.9826822  0.658915   0.85274726\n",
      " 0.7658922  0.93171495 0.7978025  0.8789366  0.6121738  0.66792303\n",
      " 0.8457101  0.6889708 ]\n",
      "The rewards are: [0.7363868  0.8767795  0.7352281  0.7398654  0.8988468  0.9164943\n",
      " 0.72497195 0.7434455  0.61319447 0.95013976 0.8387011  0.9435604\n",
      " 0.87718034 0.5472665  0.7379181  0.84454226 0.8991779  0.7469028\n",
      " 0.609116   0.79558986 0.7673167  0.5534026  0.62131816 0.85905075\n",
      " 0.76649606 0.5100952  0.78343594 0.82224965 0.79507333 0.6744052\n",
      " 0.88896215 0.95094746]\n",
      "The rewards are: [0.7553519  0.7130284  0.50786465 0.8761683  0.8933641  0.8453932\n",
      " 0.8711538  0.6821514  0.59535325 0.9209382  0.5633425  0.60638505\n",
      " 0.85557735 0.7794562  0.62865    0.89354134 0.61248875 0.6639346\n",
      " 0.89573246 0.6142238  0.74181163 0.59484774 0.83497465 0.6427157\n",
      " 0.9676615  0.7680148  0.8956477  0.584972   0.7357352  0.63524884\n",
      " 0.8910824  0.72452337]\n",
      "The rewards are: [0.9025088  0.83403563 0.74953985 0.88576376 0.8706907  0.8468629\n",
      " 0.7793962  0.768997   0.71112823 0.9398179  0.82134134 0.8524296\n",
      " 0.7076786  0.8091281  0.8329608  0.72591794 0.84301054 0.8526875\n",
      " 0.8198748  0.77117515 0.71362156 0.6294107  0.6086887  0.92641926\n",
      " 0.85400206 0.7246311  0.87570834 0.60579807 0.7847733  0.76517254\n",
      " 0.66908586 0.65794647]\n",
      "The rewards are: [0.9364287  0.80820924 0.95543253 0.8130417  0.9539779  0.87278545\n",
      " 0.80179155 0.7672862  0.7974998  0.81819385 0.7220667  0.9101505\n",
      " 0.54761225 0.90698344 0.71925837 0.91443    0.9156895  0.56501496\n",
      " 0.8882878  0.57893527 0.83947766 0.74802965 0.7721366  0.831401\n",
      " 0.55430424 0.90222293 0.7334237  0.66640437 0.9140757  0.80833757\n",
      " 0.8398135  0.70983905]\n",
      "The rewards are: [0.81338996 0.71310425 0.57610786 0.6396547  0.75440663 0.89755815\n",
      " 0.6142209  0.646762   0.53625786 0.6873216  0.803615   0.9091408\n",
      " 0.92679316 0.76597637 0.915327   0.9268362  0.84229094 0.8906879\n",
      " 0.5515954  0.5003852  0.8241926  0.66298443 0.6856457  0.69067055\n",
      " 0.7558796  0.94525844 0.925048   0.8943301  0.9052936  0.79353714\n",
      " 0.86233246 0.82786536]\n",
      "The rewards are: [0.89875287 0.7829353  0.91058    0.9419653  0.90533817 0.7027772\n",
      " 0.8357119  0.9380064  0.71545625 0.9256536  0.88994336 0.611985\n",
      " 0.5415013  0.8277815  0.8872724  0.6387815  0.90664965 0.5038337\n",
      " 0.79424566 0.8331996  0.83179784 0.7531109  0.7762402  0.8806029\n",
      " 0.92029494 0.5689992  0.7073958  0.7045447  0.93126833 0.63931453\n",
      " 0.7808797  0.7933404 ]\n",
      "The rewards are: [0.64333814 0.81126934 0.7542991  0.6006665  0.93495107 0.7500623\n",
      " 0.87323034 0.5716281  0.82032007 0.54999316 0.6947772  0.88530505\n",
      " 0.5583556  0.59360385 0.94993424 0.63024306 0.6050533  0.6021526\n",
      " 0.8575339  0.886979   0.76514655 0.69181246 0.8008817  0.6497203\n",
      " 0.8066776  0.680883   0.922326   0.67988724 0.7313962  0.8309607\n",
      " 0.61396134 0.64705956]\n",
      "The rewards are: [0.92433995 0.6257105  0.6037893  0.58212173 0.6300676  0.93830687\n",
      " 0.9275351  0.64433444 0.7715256  0.8019772  0.9244941  0.8874074\n",
      " 0.88144016 0.7049946  0.7848799  0.7852294  0.934161   0.89939445\n",
      " 0.62633145 0.5253318  0.89388925 0.96210015 0.5267636  0.9275969\n",
      " 0.5964795  0.6918403  0.6447136  0.91728216 0.81710696 0.87516576\n",
      " 0.68110627 0.66686153]\n",
      "The rewards are: [0.78299385 0.90623796 0.67029905 0.7791619  0.95976204 0.7223821\n",
      " 0.8293876  0.90741414 0.55928826 0.92624253 0.89290226 0.69820297\n",
      " 0.91632247 0.8758101  0.8670553  0.5970403  0.8184704  0.7023259\n",
      " 0.8603836  0.8664795  0.93113023 0.802004   0.941908   0.96090496\n",
      " 0.6168487  0.8800782  0.87866414 0.8225474  0.6920369  0.9492162\n",
      " 0.86654305 0.7049184 ]\n",
      "The rewards are: [0.95352393 0.8089779  0.85052747 0.61116767 0.86621696 0.7246217\n",
      " 0.6612356  0.7888597  0.8267761  0.60699224 0.7088696  0.8344507\n",
      " 0.8020075  0.924707   0.94739014 0.8103222  0.67816514 0.64875716\n",
      " 0.8585498  0.75459474 0.6498652  0.93199074 0.77980196 0.6953666\n",
      " 0.7511837  0.7322319  0.90828913 0.8353293  0.91486335 0.620532\n",
      " 0.9205937  0.9477334 ]\n",
      "The rewards are: [0.77842206 0.80277324 0.8764258  0.5701258  0.77806425 0.5820742\n",
      " 0.5315552  0.6527506  0.761647   0.88436025 0.9290226  0.79527783\n",
      " 0.75029373 0.54008573 0.67554766 0.74561775 0.51721376 0.9441952\n",
      " 0.8649863  0.7744758  0.9684857  0.8940507  0.9593693  0.768059\n",
      " 0.72159606 0.95295465 0.79819024 0.57363534 0.86900145 0.8440286\n",
      " 0.75702053 0.797063  ]\n",
      "The rewards are: [0.9557205  0.5751584  0.6929502  0.81492937 0.61347383 0.89895284\n",
      " 0.7941026  0.61969036 0.70572305 0.86872154 0.8037343  0.6717809\n",
      " 0.664129   0.75081086 0.7925357  0.9409365  0.60324395 0.97333544\n",
      " 0.51040375 0.56499344 0.9601363  0.8473943  0.6047634  0.884114\n",
      " 0.8849726  0.6278577  0.84531665 0.81533676 0.55791694 0.9062096\n",
      " 0.9373378  0.95384437]\n",
      "The rewards are: [0.89089805 0.86264026 0.790873   0.8393077  0.84870404 0.6432001\n",
      " 0.6036105  0.78682876 0.6696266  0.82641345 0.7829133  0.8959996\n",
      " 0.7937624  0.7204637  0.99112105 0.8817777  0.79961216 0.87208503\n",
      " 0.8469836  0.7910813  0.72958845 0.9337662  0.9073786  0.8615087\n",
      " 0.8619324  0.9028488  0.60023326 0.7379231  0.75172746 0.9032836\n",
      " 0.7674198  0.59643614]\n",
      "The rewards are: [0.93992776 0.6010539  0.5707325  0.9352516  0.85829055 0.88198704\n",
      " 0.8289234  0.95820546 0.5870963  0.72478545 0.89556044 0.61670744\n",
      " 0.7526928  0.91618097 0.51199126 0.51969504 0.93689466 0.7834927\n",
      " 0.8345735  0.50158745 0.7576563  0.80187535 0.65045667 0.699453\n",
      " 0.8335706  0.8572631  0.79179156 0.788577   0.7991947  0.6345317\n",
      " 0.5045035  0.82845265]\n",
      "The rewards are: [0.9120317  0.9354998  0.7916013  0.61852884 0.68806523 0.5235744\n",
      " 0.81032914 0.8927936  0.8777831  0.8128537  0.52979594 0.89619297\n",
      " 0.7602764  0.8951673  0.8130744  0.55423945 0.87868005 0.6196374\n",
      " 0.94159144 0.7176694  0.9100644  0.7665571  0.96128774 0.71196085\n",
      " 0.53330743 0.92894423 0.7006322  0.51280123 0.77593    0.918614\n",
      " 0.74173373 0.8599727 ]\n",
      "The rewards are: [0.73971426 0.8941041  0.71714646 0.9582197  0.92536557 0.58533835\n",
      " 0.79611576 0.5347739  0.8583174  0.7536053  0.7702293  0.5112252\n",
      " 0.9171803  0.80196726 0.5903295  0.9680723  0.9282755  0.80058074\n",
      " 0.8206618  0.5894566  0.7933603  0.89292234 0.8569289  0.8256275\n",
      " 0.85902894 0.8039456  0.84350276 0.74307424 0.86302674 0.90432996\n",
      " 0.8234012  0.68097013]\n",
      "The rewards are: [0.72043043 0.8700455  0.7613982  0.6035304  0.8559316  0.85012084\n",
      " 0.64609975 0.7060719  0.75819415 0.6941044  0.5361761  0.8549698\n",
      " 0.83109224 0.5649774  0.7925658  0.68574727 0.67164266 0.7198312\n",
      " 0.7470249  0.86934716 0.56355095 0.8479426  0.87352544 0.6302415\n",
      " 0.77839494 0.9266729  0.79075515 0.9379951  0.6611971  0.7221681\n",
      " 0.88505137 0.8845169 ]\n",
      "The rewards are: [0.9487107  0.86063486 0.69279665 0.82514906 0.83846545 0.60647196\n",
      " 0.50835365 0.8420893  0.91483444 0.6142529  0.87361723 0.53142345\n",
      " 0.8845051  0.69858515 0.8072328  0.92934096 0.92344517 0.7127199\n",
      " 0.628095   0.70159125 0.7654497  0.89484316 0.79879904 0.6336892\n",
      " 0.94884855 0.61642677 0.90319437 0.6580473  0.6465177  0.7291276\n",
      " 0.8594166  0.5880772 ]\n",
      "The rewards are: [0.7154001  0.9736984  0.80503464 0.58145565 0.69422215 0.9413225\n",
      " 0.7018872  0.9403314  0.9913748  0.6837636  0.94830805 0.8117595\n",
      " 0.6403744  0.97993624 0.8034655  0.79753256 0.7903275  0.72993517\n",
      " 0.8043012  0.73110765 0.63113666 0.75829923 0.7778804  0.9516109\n",
      " 0.7521008  0.88632846 0.958724   0.952192   0.8753334  0.9678083\n",
      " 0.8324978  0.7803439 ]\n",
      "The rewards are: [0.67785025 0.615719   0.7448481  0.88302076 0.75199133 0.67919236\n",
      " 0.8106554  0.9263454  0.61226183 0.8363203  0.7803499  0.93767685\n",
      " 0.8423567  0.69895685 0.67001474 0.9159521  0.7521688  0.87543684\n",
      " 0.8699764  0.7481426  0.81859326 0.74524987 0.807678   0.65169454\n",
      " 0.91452634 0.86430675 0.9769304  0.86736333 0.82054305 0.89786565\n",
      " 0.9303948  0.9274301 ]\n",
      "The rewards are: [0.59184223 0.6931121  0.71863526 0.87886274 0.8966864  0.8181592\n",
      " 0.898368   0.8385342  0.9413128  0.8795973  0.9193476  0.9407897\n",
      " 0.64247465 0.76867646 0.85702276 0.8955964  0.8787467  0.5343585\n",
      " 0.89003754 0.94127595 0.7926102  0.87359977 0.7140862  0.76224875\n",
      " 0.909204   0.88327354 0.89554703 0.60365826 0.583945   0.53967994\n",
      " 0.51240885 0.8775593 ]\n",
      "The rewards are: [0.74186325 0.8326559  0.6124108  0.95628613 0.87654203 0.6805852\n",
      " 0.608599   0.81920457 0.79437876 0.8460288  0.51511717 0.8756825\n",
      " 0.81568974 0.8726241  0.7564688  0.6623187  0.6252214  0.94581443\n",
      " 0.83544916 0.6839365  0.82653755 0.74024075 0.91904247 0.88726896\n",
      " 0.82592505 0.7435299  0.89231044 0.8782616  0.5982876  0.88976145\n",
      " 0.8069244  0.9332804 ]\n",
      "The rewards are: [0.7596461  0.6037308  0.95364463 0.7672062  0.56659484 0.8955768\n",
      " 0.94957936 0.8671109  0.76748115 0.5077491  0.8086454  0.74871933\n",
      " 0.86575675 0.61611986 0.6545217  0.8899298  0.8758638  0.75720084\n",
      " 0.8476939  0.74394    0.91142035 0.85108346 0.89347744 0.5734394\n",
      " 0.8730304  0.54384965 0.74001676 0.8739804  0.67616737 0.8738905\n",
      " 0.79530936 0.8135805 ]\n",
      "The rewards are: [0.6445505  0.7928786  0.519129   0.5356422  0.8563574  0.9165125\n",
      " 0.6430974  0.6803798  0.5482333  0.8047048  0.9326318  0.8741626\n",
      " 0.7556215  0.64732736 0.9072889  0.76890767 0.91283035 0.51929915\n",
      " 0.6789632  0.81999934 0.90738183 0.8600791  0.637987   0.69946915\n",
      " 0.65817946 0.71303624 0.9423525  0.83431625 0.5771237  0.6451194\n",
      " 0.9089508  0.84263426]\n",
      "The rewards are: [0.92860055 0.5403163  0.8761564  0.89715457 0.9061255  0.89585674\n",
      " 0.78623384 0.83836263 0.6430687  0.8187245  0.5596071  0.932628\n",
      " 0.9549105  0.5094685  0.7126651  0.94773597 0.6752704  0.6528176\n",
      " 0.98038155 0.887063   0.7834215  0.77473944 0.85433173 0.72468686\n",
      " 0.8459424  0.95950305 0.91269726 0.8366886  0.7857305  0.8237255\n",
      " 0.8254566  0.91899645]\n",
      "The rewards are: [0.7964549  0.8913285  0.92555195 0.6333942  0.9465816  0.8821719\n",
      " 0.7931602  0.8743599  0.61198777 0.8708085  0.8663346  0.94833285\n",
      " 0.80726314 0.5346944  0.9361497  0.86705536 0.8589904  0.94727\n",
      " 0.9463865  0.87663794 0.6144684  0.8366157  0.94615996 0.9179491\n",
      " 0.8147678  0.5794777  0.77043706 0.8251496  0.85741985 0.87383133\n",
      " 0.7802651  0.90114737]\n",
      "The rewards are: [0.797623   0.76161325 0.80496484 0.83822197 0.7060432  0.9696474\n",
      " 0.6995463  0.51931715 0.7969451  0.86009747 0.6651189  0.50274384\n",
      " 0.55868727 0.6605435  0.82522416 0.9530852  0.8878129  0.7829094\n",
      " 0.95293957 0.55148697 0.74490845 0.636686   0.6672902  0.93767315\n",
      " 0.9146093  0.8005245  0.7959222  0.6548665  0.9340727  0.7592253\n",
      " 0.8777043  0.82222044]\n",
      "The rewards are: [0.80077106 0.64544195 0.62083036 0.6992727  0.6755732  0.5687141\n",
      " 0.9264953  0.5189924  0.69369084 0.91353786 0.59870154 0.6883096\n",
      " 0.81488556 0.90814286 0.6261181  0.91233337 0.77148896 0.8327858\n",
      " 0.8205819  0.5945045  0.9307022  0.97658914 0.59265363 0.8426522\n",
      " 0.8651038  0.8551031  0.9108517  0.94514    0.6891219  0.65857434\n",
      " 0.9565798  0.89822906]\n",
      "The rewards are: [0.7236683  0.88176686 0.8911936  0.92101014 0.9057439  0.93590456\n",
      " 0.7122774  0.83606094 0.88298786 0.9449499  0.5987916  0.81118035\n",
      " 0.90046424 0.765194   0.8389691  0.6840993  0.9708818  0.8327298\n",
      " 0.8373547  0.65871286 0.8933116  0.87150043 0.859377   0.831594\n",
      " 0.82202137 0.6912808  0.58811295 0.9277768  0.95182574 0.7304013\n",
      " 0.687741   0.79012585]\n",
      "The rewards are: [0.7262303  0.8931764  0.8710286  0.75977    0.7257927  0.9185417\n",
      " 0.7642504  0.96734023 0.6485596  0.86629164 0.52802896 0.5724715\n",
      " 0.7213774  0.695797   0.97670346 0.9641868  0.637071   0.917643\n",
      " 0.8563668  0.97365606 0.929227   0.7640554  0.9683858  0.664861\n",
      " 0.94333845 0.9012754  0.92906994 0.95444894 0.62036914 0.8873627\n",
      " 0.9634446  0.85101247]\n",
      "The rewards are: [0.8984963  0.8405135  0.92340213 0.8690565  0.57831615 0.5269132\n",
      " 0.82465065 0.9527148  0.9699879  0.8895057  0.60176176 0.9625497\n",
      " 0.94344485 0.79831    0.9494581  0.93578106 0.60473114 0.7249195\n",
      " 0.6876941  0.68503284 0.67309713 0.9049955  0.9374828  0.7650599\n",
      " 0.6435147  0.5355783  0.93870145 0.9570321  0.6242413  0.9429425\n",
      " 0.7771385  0.8213956 ]\n",
      "The rewards are: [0.9477544  0.67836857 0.6742122  0.7061716  0.9544965  0.9843114\n",
      " 0.9312677  0.8998947  0.8883131  0.61101365 0.85107183 0.7758786\n",
      " 0.7011477  0.8968735  0.8174344  0.94517994 0.9500365  0.7712514\n",
      " 0.9050845  0.8229406  0.90907377 0.80136144 0.85687876 0.74382025\n",
      " 0.7382921  0.9340912  0.7368537  0.85073805 0.8809727  0.96382385\n",
      " 0.81454253 0.8799421 ]\n",
      "The rewards are: [0.52604526 0.92034906 0.66226137 0.6485284  0.9212492  0.63227916\n",
      " 0.9384587  0.8112134  0.92448646 0.91849226 0.7215976  0.892102\n",
      " 0.7689074  0.76723117 0.9392347  0.90807444 0.5537745  0.6144157\n",
      " 0.8386492  0.8135684  0.75906193 0.7257753  0.5982412  0.6929512\n",
      " 0.68661624 0.65910494 0.67241514 0.63450456 0.89592123 0.88855773\n",
      " 0.9027472  0.83357173]\n",
      "The rewards are: [0.94328976 0.91588247 0.8083132  0.8985909  0.85495436 0.89777637\n",
      " 0.9067983  0.55620146 0.9703428  0.8376306  0.79410547 0.85719633\n",
      " 0.9493102  0.9013188  0.7224066  0.9005553  0.8752262  0.93751997\n",
      " 0.8062417  0.9042787  0.8809001  0.95882607 0.8977961  0.50845414\n",
      " 0.98061895 0.8474877  0.7445187  0.89513576 0.7023903  0.696665\n",
      " 0.8485413  0.9639248 ]\n",
      "The rewards are: [0.71968955 0.52456343 0.8236699  0.82496184 0.5221802  0.82612634\n",
      " 0.74137765 0.9222193  0.86573744 0.8013562  0.9607565  0.8379431\n",
      " 0.9015646  0.92978257 0.815984   0.7993563  0.51755124 0.73711616\n",
      " 0.78798425 0.86145353 0.95631206 0.716272   0.5097152  0.7702179\n",
      " 0.9852792  0.6876165  0.65365946 0.93162173 0.91458964 0.5984987\n",
      " 0.8179677  0.9842993 ]\n",
      "The rewards are: [0.98882407 0.61515564 0.82646936 0.962858   0.60186857 0.9718782\n",
      " 0.7401463  0.85971576 0.84066874 0.9070125  0.8379269  0.8637582\n",
      " 0.7555587  0.80474746 0.8162426  0.7096026  0.7691269  0.8683261\n",
      " 0.8066776  0.8826704  0.86480176 0.64608973 0.7487285  0.5493148\n",
      " 0.6329947  0.7362298  0.6913279  0.97456914 0.94082487 0.9511085\n",
      " 0.66662925 0.5285968 ]\n",
      "The rewards are: [0.92475796 0.94344455 0.679473   0.7268881  0.94211406 0.7716647\n",
      " 0.72410035 0.980895   0.8928114  0.79463476 0.89086115 0.77124476\n",
      " 0.8393175  0.9644607  0.6378701  0.899431   0.64215845 0.5853307\n",
      " 0.7187873  0.8254442  0.85431886 0.9515058  0.7339615  0.6426158\n",
      " 0.57631236 0.94776636 0.79492474 0.7981676  0.73296225 0.7987539\n",
      " 0.9595542  0.9474644 ]\n",
      "The rewards are: [0.7851773  0.9370485  0.7956918  0.9653342  0.5062303  0.92468303\n",
      " 0.7872316  0.9822202  0.8814513  0.902528   0.62772816 0.9887017\n",
      " 0.5210216  0.57452923 0.9765029  0.6117925  0.95217216 0.9557309\n",
      " 0.74807507 0.9627819  0.64924896 0.84802806 0.5395012  0.9407228\n",
      " 0.89216685 0.78474754 0.9939055  0.72213733 0.95479304 0.70108193\n",
      " 0.55098486 0.85004103]\n",
      "The rewards are: [0.937944   0.9026832  0.7410871  0.84931165 0.8089572  0.806803\n",
      " 0.83708024 0.85228133 0.92570424 0.9454989  0.5917703  0.9553391\n",
      " 0.9558123  0.82056385 0.88343245 0.71850854 0.9363063  0.68412703\n",
      " 0.86022043 0.53106004 0.94005954 0.6297002  0.9494155  0.81618774\n",
      " 0.95139676 0.7745169  0.64949405 0.5320879  0.67244047 0.8792558\n",
      " 0.8415092  0.9363408 ]\n",
      "The rewards are: [0.87514824 0.88717043 0.66087234 0.536948   0.83988714 0.76324505\n",
      " 0.82345825 0.9345852  0.98302126 0.5948139  0.7389798  0.9230957\n",
      " 0.88353574 0.6329167  0.7371216  0.76859754 0.91512746 0.7991173\n",
      " 0.98052925 0.8543736  0.64307517 0.57526076 0.57712865 0.88790464\n",
      " 0.71461195 0.6972723  0.9118551  0.6301493  0.9014368  0.6466377\n",
      " 0.80026835 0.56399703]\n",
      "The rewards are: [0.5865567  0.95623314 0.58672756 0.78649694 0.56676596 0.903232\n",
      " 0.56609637 0.80598396 0.93432647 0.89228445 0.90140235 0.8182381\n",
      " 0.82150984 0.5061977  0.80128646 0.91989046 0.8965737  0.91129965\n",
      " 0.8134652  0.7432706  0.96169394 0.8890674  0.79896617 0.697053\n",
      " 0.66239023 0.7409986  0.5164063  0.85268885 0.544419   0.9475176\n",
      " 0.80602986 0.66042626]\n",
      "The rewards are: [0.730729   0.9833852  0.86723894 0.76349473 0.8577416  0.95183665\n",
      " 0.78089476 0.8839114  0.83626246 0.74440724 0.82411283 0.9290084\n",
      " 0.9370215  0.6888942  0.98998636 0.5824787  0.8605982  0.66234714\n",
      " 0.9354824  0.7192652  0.67913264 0.7441915  0.56731576 0.88706565\n",
      " 0.9509964  0.7906275  0.5967191  0.8858832  0.6783124  0.8681239\n",
      " 0.58299226 0.9351255 ]\n",
      "The rewards are: [0.92568576 0.7589899  0.6751193  0.8912497  0.8826668  0.95101535\n",
      " 0.93215144 0.96986884 0.85904634 0.6388451  0.84656376 0.9195732\n",
      " 0.83688724 0.91712695 0.80552703 0.54074067 0.9031664  0.9741503\n",
      " 0.88013136 0.79337114 0.72922033 0.56973875 0.8618463  0.9565343\n",
      " 0.7987305  0.96856076 0.9128396  0.67935884 0.8028185  0.88236743\n",
      " 0.9432829  0.86788046]\n",
      "The rewards are: [0.901493   0.9266088  0.72137135 0.84209704 0.9211221  0.8105088\n",
      " 0.52276653 0.64529175 0.7746962  0.833457   0.7153864  0.8331508\n",
      " 0.8702285  0.9139094  0.94875723 0.8933337  0.5255069  0.8212491\n",
      " 0.9556892  0.7750642  0.80359757 0.5349539  0.75239    0.8535538\n",
      " 0.75244814 0.9205373  0.68452984 0.90748715 0.7433775  0.6903479\n",
      " 0.8964618  0.61924326]\n",
      "The rewards are: [0.8501491  0.75571233 0.6010633  0.5514409  0.91327816 0.9117415\n",
      " 0.91893387 0.722074   0.8372928  0.50960886 0.7014631  0.6037095\n",
      " 0.9034681  0.972948   0.9654258  0.8943607  0.8901114  0.9198003\n",
      " 0.97844815 0.7001689  0.80562484 0.9538015  0.9022503  0.8976926\n",
      " 0.73617685 0.81674    0.56373274 0.949225   0.89759713 0.8976237\n",
      " 0.91143054 0.62264156]\n",
      "The rewards are: [0.89158255 0.92904586 0.7779013  0.9610026  0.8196539  0.8387426\n",
      " 0.97339565 0.9750627  0.58997864 0.6377594  0.80017245 0.9642059\n",
      " 0.6496341  0.8236976  0.83032393 0.88679844 0.91484606 0.78871924\n",
      " 0.67231244 0.9231684  0.60453737 0.7651926  0.53931814 0.6578483\n",
      " 0.9623307  0.95305187 0.9198654  0.85320437 0.95173204 0.68619865\n",
      " 0.53623676 0.65562576]\n",
      "The rewards are: [0.5145193  0.83121264 0.51294464 0.7699145  0.53643763 0.87599576\n",
      " 0.89575267 0.5633755  0.574456   0.68213606 0.68447393 0.907674\n",
      " 0.71454996 0.9233021  0.95104015 0.9042898  0.9359928  0.90308356\n",
      " 0.7617756  0.8224188  0.9276282  0.58434075 0.5591037  0.51231337\n",
      " 0.5332519  0.95921284 0.9059532  0.9674222  0.6893275  0.61429316\n",
      " 0.7286303  0.93583494]\n",
      "The rewards are: [0.8632255  0.79247886 0.97379714 0.8486393  0.8449146  0.5096195\n",
      " 0.5937301  0.8445248  0.7958141  0.8048228  0.86987495 0.753872\n",
      " 0.7911882  0.7393614  0.64045686 0.71187633 0.9712493  0.7842934\n",
      " 0.96777225 0.9582416  0.816237   0.8262434  0.8919818  0.745489\n",
      " 0.57043254 0.9041858  0.95195526 0.88453734 0.9119212  0.8733838\n",
      " 0.5255458  0.95626426]\n",
      "The rewards are: [0.67419714 0.860399   0.7464627  0.5878615  0.9847305  0.6280792\n",
      " 0.95104533 0.84454376 0.58902156 0.95282334 0.7246646  0.641589\n",
      " 0.858832   0.5257409  0.9041259  0.7561674  0.9229819  0.6541553\n",
      " 0.8932071  0.65429926 0.9727076  0.87201655 0.86735964 0.9630357\n",
      " 0.8922631  0.98808914 0.79093915 0.9253398  0.95889795 0.7085362\n",
      " 0.6974856  0.75237477]\n",
      "The rewards are: [0.9720926  0.8186668  0.8886662  0.7358959  0.77887404 0.71226627\n",
      " 0.61064297 0.9254697  0.66792256 0.823931   0.8780577  0.9674599\n",
      " 0.81980157 0.91311085 0.8982105  0.9731924  0.70002395 0.69103444\n",
      " 0.9087569  0.9350072  0.8139339  0.93385226 0.9574159  0.61995184\n",
      " 0.83198684 0.91683733 0.84004265 0.98626626 0.74249196 0.74102694\n",
      " 0.76104265 0.9249013 ]\n",
      "The rewards are: [0.8986419  0.7947094  0.9022858  0.5871755  0.8784004  0.5720544\n",
      " 0.7373358  0.8872348  0.8308425  0.8990532  0.86251616 0.767194\n",
      " 0.953466   0.90804374 0.8958395  0.979779   0.9491596  0.8976983\n",
      " 0.79477173 0.8782551  0.8334165  0.6216617  0.9399346  0.60166824\n",
      " 0.567661   0.85070294 0.52131474 0.6247434  0.81462157 0.5152439\n",
      " 0.761769   0.8372806 ]\n",
      "The rewards are: [0.9002906  0.9099206  0.6191733  0.96758515 0.7783176  0.8782479\n",
      " 0.71546936 0.868212   0.8603469  0.7158534  0.71603435 0.95912284\n",
      " 0.9058328  0.5441766  0.5807696  0.5916991  0.96366173 0.610969\n",
      " 0.9131411  0.6605023  0.7838959  0.9614609  0.9639653  0.61452246\n",
      " 0.8039129  0.973956   0.92756915 0.7803729  0.5454184  0.9230465\n",
      " 0.878125   0.94348997]\n",
      "The rewards are: [0.9668209  0.79849946 0.8566979  0.6267942  0.7346134  0.9643936\n",
      " 0.9851366  0.6981389  0.874199   0.52757645 0.88849527 0.9816078\n",
      " 0.6697759  0.93850505 0.63372266 0.9046992  0.9321569  0.7858082\n",
      " 0.78839165 0.9541425  0.86872584 0.9333122  0.60724455 0.731678\n",
      " 0.5638865  0.7905932  0.96718174 0.8796271  0.9588836  0.7712444\n",
      " 0.85137963 0.58057714]\n",
      "The rewards are: [0.8389366  0.99222636 0.93785286 0.56432945 0.9600278  0.79593444\n",
      " 0.98249626 0.6069216  0.94080395 0.66216934 0.8700523  0.6016129\n",
      " 0.740613   0.8307836  0.55448616 0.9798086  0.95409477 0.55309975\n",
      " 0.6834868  0.80563813 0.6266433  0.88988286 0.9146526  0.8919896\n",
      " 0.8821031  0.9435357  0.59800094 0.91990954 0.59814745 0.899959\n",
      " 0.7908542  0.8902618 ]\n",
      "The rewards are: [0.6776321  0.9641277  0.86353433 0.9662863  0.5213985  0.8044364\n",
      " 0.9504496  0.52686954 0.7582234  0.7814375  0.9106181  0.55040675\n",
      " 0.90946335 0.95555824 0.8738594  0.7824598  0.9066576  0.8701647\n",
      " 0.5578166  0.9400026  0.68078434 0.9253967  0.8106562  0.90017736\n",
      " 0.89402026 0.50479394 0.66401196 0.90158516 0.81928664 0.82244474\n",
      " 0.98785466 0.9274782 ]\n",
      "The rewards are: [0.9188197  0.95319426 0.5524672  0.9071413  0.9291712  0.7972789\n",
      " 0.97262716 0.7865057  0.63886803 0.7570562  0.9760465  0.86447555\n",
      " 0.90972966 0.942385   0.57185763 0.9876917  0.6616114  0.7328466\n",
      " 0.93668365 0.9275259  0.90972453 0.720037   0.95209473 0.970922\n",
      " 0.9216209  0.8483572  0.84590155 0.81264347 0.5268426  0.98171586\n",
      " 0.79677385 0.94030833]\n",
      "The rewards are: [0.7611877  0.85532635 0.9638875  0.8796674  0.9034854  0.9452525\n",
      " 0.973625   0.6308528  0.8924992  0.56329507 0.80251044 0.77172726\n",
      " 0.93454754 0.86428684 0.75275433 0.8885897  0.69225717 0.7516473\n",
      " 0.8273024  0.53025216 0.69252396 0.86391157 0.9811256  0.7713143\n",
      " 0.8029578  0.90759575 0.9192923  0.8134079  0.91138184 0.52719235\n",
      " 0.8877532  0.90121406]\n",
      "The rewards are: [0.5174673  0.5533365  0.9558516  0.5147986  0.86859095 0.9249582\n",
      " 0.9162355  0.81012815 0.7468172  0.6340586  0.96593195 0.90015644\n",
      " 0.90625775 0.5669619  0.60719234 0.9233949  0.64480853 0.5281065\n",
      " 0.93536305 0.9726078  0.6761528  0.7343086  0.83136094 0.5435334\n",
      " 0.6086767  0.94176567 0.7831321  0.80395675 0.9501618  0.5066079\n",
      " 0.5517821  0.5402778 ]\n",
      "The rewards are: [0.97922313 0.98224306 0.82648957 0.9045398  0.923167   0.507202\n",
      " 0.8625921  0.93764794 0.5476541  0.9872076  0.6621727  0.6707867\n",
      " 0.9574633  0.7868625  0.9351961  0.89725393 0.5075285  0.54068005\n",
      " 0.9540923  0.9564766  0.7322774  0.77350986 0.954042   0.9662829\n",
      " 0.7948739  0.6868644  0.5877284  0.95771843 0.8490793  0.52244717\n",
      " 0.7607102  0.7298364 ]\n",
      "The rewards are: [0.9375487  0.9575272  0.9310515  0.6122886  0.95168906 0.9238315\n",
      " 0.9666022  0.8840046  0.73902446 0.85687846 0.83567876 0.5833814\n",
      " 0.50861907 0.7961623  0.9089013  0.96420074 0.9724646  0.9163003\n",
      " 0.8829054  0.85364205 0.8527055  0.6069514  0.8743828  0.8706986\n",
      " 0.76796424 0.9891349  0.5119372  0.8671215  0.92090416 0.86367995\n",
      " 0.860762   0.8017297 ]\n",
      "The rewards are: [0.97192746 0.887093   0.66063815 0.70958424 0.96734244 0.7806336\n",
      " 0.58252203 0.84003705 0.88848    0.91535753 0.97422725 0.9589192\n",
      " 0.70895576 0.984537   0.64196837 0.8801369  0.77681005 0.9757528\n",
      " 0.9306933  0.95900726 0.84117687 0.6694407  0.90404797 0.93358237\n",
      " 0.9819534  0.95174974 0.90655977 0.8109533  0.86674666 0.5359267\n",
      " 0.5627548  0.51828074]\n",
      "The rewards are: [0.94962    0.6216568  0.66266817 0.8547922  0.9641934  0.8657933\n",
      " 0.6492596  0.9857035  0.50553674 0.7947059  0.780003   0.8157826\n",
      " 0.953729   0.8846727  0.7934622  0.59413314 0.6632728  0.915539\n",
      " 0.9556522  0.76254725 0.6970233  0.9307876  0.97792894 0.8574123\n",
      " 0.9500198  0.8110209  0.6995182  0.77551335 0.8482142  0.84892607\n",
      " 0.96780527 0.96153563]\n",
      "The rewards are: [0.8523697  0.5327646  0.6587087  0.84093225 0.67643607 0.82262474\n",
      " 0.95094466 0.95236856 0.55520564 0.51748955 0.8512318  0.8451321\n",
      " 0.6568284  0.6605456  0.9023396  0.97599626 0.8996848  0.7958157\n",
      " 0.94243    0.9372363  0.9756471  0.8644485  0.8909375  0.97516507\n",
      " 0.67215633 0.85381484 0.8477722  0.8023144  0.85070264 0.8428224\n",
      " 0.8676619  0.71565443]\n",
      "The rewards are: [0.9511763  0.95444137 0.9758086  0.7812466  0.5074605  0.9361811\n",
      " 0.52659285 0.5574508  0.65333605 0.69593674 0.89530456 0.91404027\n",
      " 0.9667786  0.904527   0.6098993  0.98157793 0.97885257 0.8436777\n",
      " 0.53207254 0.9192142  0.9444864  0.51848555 0.81429607 0.9727578\n",
      " 0.9679823  0.8535587  0.841421   0.79803264 0.99174315 0.6005641\n",
      " 0.9829959  0.8609776 ]\n",
      "The rewards are: [0.822533   0.87039024 0.58412135 0.9222893  0.83403265 0.95626616\n",
      " 0.7066939  0.90545434 0.87578386 0.9073994  0.59300494 0.9426801\n",
      " 0.9178603  0.9554292  0.9686887  0.83911186 0.98242885 0.80999994\n",
      " 0.5885206  0.7398267  0.9858801  0.8420922  0.6646628  0.948577\n",
      " 0.7549052  0.88147444 0.90756893 0.5454333  0.9331875  0.73436016\n",
      " 0.90228504 0.8242023 ]\n",
      "The rewards are: [0.91613615 0.91801316 0.69622374 0.7388287  0.89392775 0.7280941\n",
      " 0.5749663  0.85732126 0.7463579  0.8336288  0.92118824 0.7624923\n",
      " 0.74143416 0.9766409  0.88878924 0.9885365  0.86768305 0.7375818\n",
      " 0.60876834 0.79039556 0.64300203 0.9689378  0.9597038  0.77715975\n",
      " 0.9002105  0.8177799  0.84971297 0.8188308  0.9493133  0.9515459\n",
      " 0.9748942  0.9156486 ]\n",
      "The rewards are: [0.89681464 0.5835219  0.91862994 0.9492715  0.94115704 0.963906\n",
      " 0.74315387 0.96083045 0.9308399  0.88058835 0.9325476  0.9696658\n",
      " 0.7123229  0.89899397 0.9776358  0.7534477  0.5986266  0.8332024\n",
      " 0.931417   0.9474943  0.7476139  0.76386625 0.86120933 0.58663094\n",
      " 0.89936215 0.7503466  0.64603174 0.5472542  0.6973066  0.76788145\n",
      " 0.85104084 0.6042016 ]\n",
      "The rewards are: [0.60863554 0.962085   0.88598025 0.5387473  0.82495075 0.9581526\n",
      " 0.7212783  0.83281887 0.96252316 0.5083171  0.88242704 0.96737266\n",
      " 0.8156276  0.7338138  0.83559185 0.9744489  0.88314915 0.876756\n",
      " 0.79950255 0.5775109  0.8314166  0.9856286  0.91782624 0.9492089\n",
      " 0.65158904 0.9587572  0.84699297 0.9628227  0.7551998  0.7001774\n",
      " 0.50305337 0.9056207 ]\n",
      "The rewards are: [0.6504511  0.6865939  0.93408203 0.8932985  0.9754377  0.85364586\n",
      " 0.9101911  0.94459    0.89053357 0.80336744 0.9118608  0.748483\n",
      " 0.9684106  0.9630876  0.63101184 0.90392834 0.8453515  0.9829931\n",
      " 0.6782394  0.9584976  0.88724124 0.6795873  0.99468803 0.8245781\n",
      " 0.8188365  0.64781886 0.66267574 0.8077147  0.90121615 0.8178845\n",
      " 0.91605884 0.7979547 ]\n",
      "The rewards are: [0.8817339  0.9813674  0.948979   0.9562581  0.5933935  0.9292786\n",
      " 0.875263   0.78105575 0.66371495 0.6183015  0.93984634 0.91684896\n",
      " 0.8551855  0.8300844  0.9509464  0.797133   0.9207989  0.85362417\n",
      " 0.97419214 0.78648615 0.9104274  0.9293843  0.8806442  0.9574313\n",
      " 0.8508894  0.9790284  0.90692556 0.9636134  0.96056515 0.6855829\n",
      " 0.9144992  0.936121  ]\n",
      "The rewards are: [0.8949206  0.97063804 0.9828029  0.9604471  0.9582844  0.81201637\n",
      " 0.96267384 0.8096063  0.99562895 0.91720307 0.823117   0.62355715\n",
      " 0.5567093  0.76009125 0.5907233  0.91130024 0.9600365  0.87584126\n",
      " 0.9397084  0.97035336 0.6960865  0.5327981  0.578304   0.6152306\n",
      " 0.8118541  0.7608969  0.7320566  0.9781634  0.9306434  0.77178776\n",
      " 0.55426043 0.84673   ]\n",
      "The rewards are: [0.6963163  0.9577982  0.90769494 0.882802   0.9361446  0.5626673\n",
      " 0.9255817  0.8089807  0.83040917 0.74393106 0.78662217 0.92261016\n",
      " 0.98371315 0.951139   0.97883224 0.7654364  0.8601293  0.8415099\n",
      " 0.9870827  0.538214   0.9745959  0.9653359  0.5287189  0.9734467\n",
      " 0.95957416 0.6569369  0.79057395 0.7839114  0.9307959  0.981632\n",
      " 0.9514881  0.8840837 ]\n",
      "The rewards are: [0.874291   0.7805361  0.88713306 0.7321531  0.9250329  0.9502151\n",
      " 0.8063921  0.96816206 0.84651524 0.7423909  0.9765985  0.6255095\n",
      " 0.6573711  0.7597508  0.9298605  0.9136531  0.99402064 0.9629232\n",
      " 0.9624194  0.7786146  0.96161807 0.54202586 0.751983   0.87646985\n",
      " 0.81570107 0.9071211  0.8923123  0.9150791  0.95952743 0.83052814\n",
      " 0.8324798  0.85798144]\n",
      "The rewards are: [0.7163514  0.6621314  0.9475452  0.9245364  0.9347016  0.7063151\n",
      " 0.9874493  0.55764556 0.92572665 0.8933108  0.9380001  0.82847863\n",
      " 0.86499095 0.97650856 0.9282885  0.9346018  0.7316624  0.977794\n",
      " 0.9929564  0.710436   0.58377546 0.5829148  0.9278821  0.97819006\n",
      " 0.7928656  0.9317803  0.8684978  0.90658    0.87744176 0.9756073\n",
      " 0.6861201  0.82450056]\n",
      "The rewards are: [0.7765854  0.58440536 0.9268292  0.9468875  0.9719059  0.5220057\n",
      " 0.54600567 0.89580613 0.9005006  0.89550716 0.9278657  0.9585291\n",
      " 0.8888516  0.9068396  0.97777116 0.6454408  0.931752   0.7318191\n",
      " 0.9637849  0.9729003  0.5363282  0.756525   0.83055705 0.5525841\n",
      " 0.7143498  0.8582417  0.98308575 0.97644466 0.85985696 0.97841394\n",
      " 0.9214099  0.96065724]\n",
      "The rewards are: [0.72602874 0.7197905  0.7911512  0.6227352  0.7863083  0.86134756\n",
      " 0.5467337  0.98006254 0.97176456 0.9605076  0.9189038  0.9423676\n",
      " 0.582926   0.8919535  0.88837564 0.6511319  0.9599039  0.87716466\n",
      " 0.9702501  0.8252216  0.96374977 0.8823713  0.5831548  0.8498826\n",
      " 0.82503307 0.64079756 0.9018966  0.87003493 0.8474839  0.9758741\n",
      " 0.695464   0.8283443 ]\n",
      "The rewards are: [0.9412118  0.54809994 0.81666577 0.8956859  0.71785206 0.90359235\n",
      " 0.89639777 0.8745345  0.74248964 0.98231137 0.9816326  0.5560699\n",
      " 0.89325833 0.9712743  0.9948986  0.99107474 0.58622164 0.6503709\n",
      " 0.9242288  0.96920335 0.5363832  0.6052163  0.54455525 0.9383586\n",
      " 0.6277614  0.7375355  0.7964163  0.92874944 0.7317529  0.97193795\n",
      " 0.8500693  0.9732304 ]\n",
      "The rewards are: [0.9721396  0.9023496  0.96220964 0.8537241  0.966047   0.9585573\n",
      " 0.9893271  0.7151683  0.8302188  0.9001087  0.8981892  0.9164674\n",
      " 0.62640256 0.7961803  0.950655   0.8759003  0.6618231  0.92894495\n",
      " 0.9577572  0.67569274 0.53431755 0.8618249  0.57564914 0.9752549\n",
      " 0.7626851  0.9121028  0.5657797  0.92351806 0.97159946 0.9449755\n",
      " 0.85792613 0.9107766 ]\n",
      "The rewards are: [0.92051893 0.8989552  0.74020296 0.7015418  0.97520304 0.661442\n",
      " 0.72787374 0.62328655 0.8446265  0.9962315  0.65664685 0.5229695\n",
      " 0.9514615  0.7024695  0.9276498  0.5215474  0.9249687  0.96505815\n",
      " 0.9842679  0.53548574 0.9826512  0.9707271  0.8719489  0.8571253\n",
      " 0.85366255 0.7327598  0.9290035  0.75199443 0.95699406 0.8957587\n",
      " 0.85857016 0.89490587]\n",
      "The rewards are: [0.76286787 0.875267   0.85467625 0.8653033  0.99385417 0.79009074\n",
      " 0.8927313  0.8084715  0.85940045 0.88992167 0.96459055 0.9222355\n",
      " 0.76134384 0.92806625 0.99715024 0.7690418  0.55090845 0.9174525\n",
      " 0.6992639  0.9660728  0.98622304 0.9754159  0.84779394 0.79338706\n",
      " 0.86549485 0.55977386 0.9324767  0.7553788  0.6171384  0.9044953\n",
      " 0.6454982  0.6911659 ]\n",
      "The rewards are: [0.90873796 0.7443812  0.93982875 0.67760193 0.9568695  0.9621935\n",
      " 0.61788034 0.80287176 0.6923607  0.6426869  0.7744912  0.86757904\n",
      " 0.9802776  0.99281114 0.8568938  0.9636117  0.53275627 0.53713495\n",
      " 0.9561996  0.9777649  0.946621   0.55062526 0.60282624 0.9818356\n",
      " 0.68777955 0.76129913 0.8378362  0.8669618  0.71168745 0.88303035\n",
      " 0.8654866  0.7917924 ]\n",
      "The rewards are: [0.68576336 0.76564425 0.9621293  0.9419053  0.61471224 0.82357687\n",
      " 0.7379275  0.85819614 0.945684   0.8944218  0.73768795 0.73144233\n",
      " 0.9233495  0.91565734 0.92207414 0.8218016  0.84524834 0.94874984\n",
      " 0.67239606 0.8830586  0.8660031  0.9673996  0.56212974 0.95003265\n",
      " 0.9000729  0.8289028  0.7163708  0.660769   0.51414394 0.71241516\n",
      " 0.9806168  0.9269223 ]\n",
      "The rewards are: [0.9407554  0.93807185 0.9782124  0.84048915 0.5052389  0.91833234\n",
      " 0.59431714 0.93495846 0.9104236  0.95088935 0.7198048  0.6978854\n",
      " 0.9064331  0.732094   0.975522   0.7962798  0.92041934 0.72962284\n",
      " 0.9414529  0.86209935 0.83181137 0.9656704  0.7075858  0.9745163\n",
      " 0.9744252  0.9900221  0.7561793  0.94615036 0.8414714  0.8109472\n",
      " 0.9300056  0.9365714 ]\n",
      "The rewards are: [0.8922529  0.9256483  0.94929034 0.7806042  0.735431   0.754969\n",
      " 0.9710151  0.99459356 0.9590556  0.636698   0.62362087 0.695098\n",
      " 0.8241165  0.94455284 0.97835094 0.98303926 0.7845844  0.7921243\n",
      " 0.8907261  0.9469997  0.8409311  0.7988988  0.8307728  0.96625817\n",
      " 0.9898173  0.9471966  0.88706404 0.58471006 0.9472821  0.9243469\n",
      " 0.98305833 0.8879768 ]\n",
      "The rewards are: [0.85412765 0.94443387 0.908952   0.75107574 0.7735886  0.6498525\n",
      " 0.9687677  0.9343618  0.950478   0.6623639  0.9798095  0.74562824\n",
      " 0.8067488  0.96806765 0.96806794 0.9742955  0.75502896 0.96129113\n",
      " 0.818656   0.7603435  0.9750601  0.9694251  0.6424944  0.9589092\n",
      " 0.92036074 0.9403783  0.9462317  0.6520286  0.92417765 0.7162689\n",
      " 0.6251988  0.9394626 ]\n",
      "The rewards are: [0.99297947 0.81678015 0.9264228  0.67610925 0.9098667  0.65019673\n",
      " 0.7930942  0.9330619  0.598696   0.99249375 0.83205754 0.667147\n",
      " 0.92354476 0.9351978  0.84473544 0.9707601  0.92296374 0.8831006\n",
      " 0.91849434 0.864261   0.6729119  0.8414855  0.6200642  0.91362435\n",
      " 0.80516446 0.68960416 0.96856165 0.53828347 0.8628551  0.5408339\n",
      " 0.6959164  0.6373649 ]\n",
      "The rewards are: [0.85116893 0.9347611  0.7185419  0.93966603 0.9585575  0.872842\n",
      " 0.79341143 0.92891103 0.85166454 0.93803746 0.8646122  0.8959625\n",
      " 0.9512849  0.9069909  0.67723393 0.9894995  0.6480868  0.89603263\n",
      " 0.6450647  0.6015039  0.96756595 0.94297093 0.8694299  0.82989717\n",
      " 0.9506694  0.914535   0.57691705 0.97867966 0.8945071  0.959406\n",
      " 0.64541876 0.76418614]\n",
      "The rewards are: [0.5511139  0.96257764 0.6305889  0.9607436  0.9819735  0.77692425\n",
      " 0.98224926 0.91925406 0.8744634  0.836758   0.8746254  0.9299974\n",
      " 0.95000017 0.9737855  0.7264622  0.9691775  0.8530644  0.7253143\n",
      " 0.8888566  0.79342175 0.97259575 0.5317124  0.82260513 0.93738735\n",
      " 0.9058043  0.92530185 0.9303597  0.99050105 0.60608906 0.83496886\n",
      " 0.99050516 0.9471002 ]\n",
      "The rewards are: [0.5953169  0.76331735 0.8770412  0.94073594 0.89232606 0.89160115\n",
      " 0.7642164  0.75832796 0.94174343 0.95006573 0.8959026  0.8923564\n",
      " 0.5113601  0.6251736  0.9596163  0.9750021  0.624313   0.96874106\n",
      " 0.73888856 0.96657616 0.99142444 0.9750217  0.6292995  0.9647226\n",
      " 0.9576315  0.7460684  0.9006487  0.96229815 0.9579934  0.9457105\n",
      " 0.8660848  0.99304456]\n",
      "The rewards are: [0.9828792  0.94999707 0.9233511  0.7742101  0.892006   0.95196205\n",
      " 0.94718164 0.97667104 0.95686173 0.57194084 0.8578597  0.90979874\n",
      " 0.97389483 0.9876109  0.79044837 0.8923286  0.8219911  0.9850935\n",
      " 0.7426867  0.7429277  0.8334021  0.8714338  0.9164026  0.9165122\n",
      " 0.7594629  0.9369483  0.8842725  0.7683519  0.97847956 0.9502664\n",
      " 0.953368   0.5760211 ]\n",
      "The rewards are: [0.99609226 0.9034904  0.85886776 0.7939692  0.76699126 0.9477064\n",
      " 0.8487417  0.79619545 0.9843704  0.63843644 0.9323834  0.72986394\n",
      " 0.8477734  0.90360403 0.9089254  0.8406276  0.9895152  0.9497782\n",
      " 0.8542212  0.84361666 0.98951566 0.51299065 0.90536034 0.90296364\n",
      " 0.96929944 0.87933075 0.9760331  0.9032947  0.5254395  0.9497031\n",
      " 0.7130555  0.98802453]\n",
      "The rewards are: [0.87090594 0.80227584 0.9866491  0.65243846 0.9035761  0.966422\n",
      " 0.9680926  0.65560246 0.83691555 0.71300596 0.6723005  0.98700863\n",
      " 0.98216033 0.8854591  0.90621114 0.921797   0.63457423 0.96899205\n",
      " 0.9845851  0.9974796  0.9927664  0.841526   0.98129797 0.9814786\n",
      " 0.9708943  0.9615534  0.8932014  0.9788831  0.97396016 0.9006625\n",
      " 0.9849963  0.9431626 ]\n",
      "The rewards are: [0.9773557  0.84000075 0.85019636 0.8078127  0.8966411  0.96815914\n",
      " 0.9220587  0.95834416 0.7319049  0.7664055  0.777568   0.8928083\n",
      " 0.80709314 0.83462    0.7795969  0.8626521  0.86300385 0.963458\n",
      " 0.519042   0.99033535 0.9643161  0.81012994 0.9709327  0.75381446\n",
      " 0.9035242  0.8402207  0.9351417  0.6632856  0.80531645 0.9922788\n",
      " 0.9749356  0.73037916]\n",
      "The rewards are: [0.8348072  0.89946425 0.80945635 0.79730004 0.9558811  0.85796493\n",
      " 0.9333792  0.99237555 0.9881147  0.8508215  0.9703599  0.8854229\n",
      " 0.9878824  0.95650345 0.99002576 0.9591546  0.7612076  0.63193506\n",
      " 0.5991992  0.82667965 0.97890204 0.98436606 0.95563424 0.9886634\n",
      " 0.8421261  0.8056995  0.97579634 0.888126   0.77871186 0.8107981\n",
      " 0.98202974 0.9747522 ]\n",
      "The rewards are: [0.6276053  0.96358293 0.9102162  0.9653747  0.96651524 0.6961745\n",
      " 0.8785493  0.9872264  0.98545384 0.6192358  0.8910263  0.82960147\n",
      " 0.9756967  0.8129433  0.966018   0.94430673 0.8616142  0.90254354\n",
      " 0.97505367 0.86882806 0.9651859  0.6677313  0.9772161  0.97708446\n",
      " 0.5279428  0.8216737  0.8516052  0.90713346 0.80922526 0.880535\n",
      " 0.90985346 0.7836238 ]\n",
      "The rewards are: [0.92680556 0.97858983 0.6604678  0.97171855 0.94672185 0.98278445\n",
      " 0.74567777 0.9676455  0.9826826  0.6360756  0.97666705 0.878815\n",
      " 0.8345137  0.6579444  0.9817648  0.9704963  0.98061746 0.9861649\n",
      " 0.5911686  0.9602109  0.8920555  0.9454334  0.7032876  0.9808375\n",
      " 0.5063634  0.9581803  0.77899945 0.71877193 0.67008424 0.9243399\n",
      " 0.89463514 0.7313412 ]\n",
      "The rewards are: [0.86270136 0.9765736  0.5856846  0.9650889  0.86890364 0.9378936\n",
      " 0.97764194 0.96500665 0.88733083 0.9891472  0.96966904 0.9725724\n",
      " 0.987255   0.7262816  0.7069667  0.5467766  0.97361565 0.9784411\n",
      " 0.98906296 0.98313683 0.6229639  0.5742546  0.5650055  0.958919\n",
      " 0.8598785  0.7307273  0.9609255  0.72433966 0.9043303  0.98856187\n",
      " 0.58570045 0.7814517 ]\n",
      "The rewards are: [0.9602172  0.8559531  0.7058612  0.9423196  0.87497205 0.9824264\n",
      " 0.925407   0.93078    0.9556794  0.9696591  0.7272107  0.96663094\n",
      " 0.9399524  0.9502702  0.86030155 0.590655   0.8064192  0.5727571\n",
      " 0.5855941  0.95577776 0.5774903  0.98364335 0.9572106  0.7442975\n",
      " 0.9316805  0.94377244 0.8022623  0.76307994 0.98059547 0.85490096\n",
      " 0.81807363 0.6440187 ]\n",
      "The rewards are: [0.93908924 0.96779335 0.51755154 0.96980405 0.9079868  0.9148761\n",
      " 0.98488337 0.9566601  0.89942235 0.95885795 0.8491002  0.8711419\n",
      " 0.7390077  0.7562411  0.831792   0.5884586  0.8662832  0.87047696\n",
      " 0.8730252  0.7666107  0.7678007  0.82547796 0.8681806  0.9593389\n",
      " 0.92656344 0.98595375 0.7847856  0.984309   0.91267264 0.9374149\n",
      " 0.5071815  0.794906  ]\n",
      "The rewards are: [0.9645789  0.96035504 0.65710616 0.95530003 0.6142084  0.9594938\n",
      " 0.72873443 0.5651175  0.9732116  0.95578885 0.9331742  0.69497764\n",
      " 0.98661023 0.9613736  0.70658916 0.6364101  0.9144387  0.8018577\n",
      " 0.960461   0.9141561  0.8339082  0.92607665 0.9295079  0.76391745\n",
      " 0.6229218  0.6530394  0.9449357  0.80390126 0.9064853  0.97967404\n",
      " 0.9743927  0.8684648 ]\n",
      "The rewards are: [0.56325495 0.9796832  0.9852991  0.8793479  0.87263715 0.66618764\n",
      " 0.72042    0.9848475  0.5839039  0.8538831  0.9470265  0.9729091\n",
      " 0.9851726  0.76872283 0.8347359  0.6878027  0.67952377 0.96029896\n",
      " 0.7451946  0.92716986 0.5018059  0.9746183  0.92649645 0.873915\n",
      " 0.95520896 0.5305536  0.79537976 0.720649   0.9554187  0.9429764\n",
      " 0.91414046 0.9955317 ]\n",
      "The rewards are: [0.6889364  0.95649624 0.5195683  0.9647918  0.92195046 0.83005655\n",
      " 0.8496676  0.7286152  0.9711628  0.6645433  0.9620899  0.5453189\n",
      " 0.6061493  0.9905166  0.9795487  0.71605724 0.6955661  0.53595084\n",
      " 0.9741499  0.9034352  0.546051   0.75865954 0.83766276 0.976487\n",
      " 0.92450905 0.9243311  0.9311346  0.9037927  0.93839014 0.9950328\n",
      " 0.9370777  0.8720857 ]\n",
      "The rewards are: [0.9812651  0.9236244  0.54546386 0.96781486 0.8680736  0.923394\n",
      " 0.5387324  0.85982436 0.9747283  0.69256544 0.94164705 0.94282013\n",
      " 0.9116718  0.96556205 0.9488413  0.7182059  0.9685657  0.8145685\n",
      " 0.9951121  0.96644884 0.8141473  0.5771557  0.5171928  0.75072587\n",
      " 0.93654746 0.51220983 0.9736701  0.9798489  0.88687336 0.91549104\n",
      " 0.94586885 0.944367  ]\n",
      "The rewards are: [0.9894075  0.9790117  0.9713958  0.7245773  0.9545621  0.61338466\n",
      " 0.97251046 0.84953445 0.9452701  0.7222472  0.56184614 0.9348554\n",
      " 0.5231328  0.99255264 0.9565296  0.82995266 0.85523015 0.56640804\n",
      " 0.98973596 0.70441735 0.9906915  0.51213866 0.9703203  0.90519506\n",
      " 0.94807076 0.8357119  0.96715397 0.9630329  0.9876621  0.82853615\n",
      " 0.79424614 0.961888  ]\n",
      "The rewards are: [0.82420397 0.8582615  0.98067135 0.94462454 0.8691987  0.95390576\n",
      " 0.80276287 0.94802254 0.7492457  0.98194665 0.7250711  0.957203\n",
      " 0.947579   0.79281294 0.86997044 0.93755436 0.74646544 0.9366112\n",
      " 0.92178273 0.58744895 0.86047316 0.85972846 0.9503939  0.87179965\n",
      " 0.9756176  0.66257113 0.68324584 0.9545984  0.5628803  0.99239445\n",
      " 0.93777895 0.90611434]\n",
      "The rewards are: [0.9811721  0.93240106 0.57903504 0.8322276  0.93545085 0.9878847\n",
      " 0.5259261  0.95721257 0.6844174  0.6093473  0.7588217  0.93962073\n",
      " 0.51589614 0.9993876  0.98919255 0.5986011  0.97774154 0.55247384\n",
      " 0.9543026  0.8166517  0.95463413 0.98144907 0.653296   0.97967106\n",
      " 0.99570763 0.89069825 0.81755656 0.66439486 0.8999981  0.81944084\n",
      " 0.8445808  0.97596776]\n",
      "The rewards are: [0.74574023 0.6174753  0.8359672  0.9667762  0.71421856 0.93226683\n",
      " 0.99265456 0.8259051  0.81222236 0.990917   0.97036695 0.8182623\n",
      " 0.81409585 0.7062558  0.7065107  0.9002565  0.97545016 0.5939508\n",
      " 0.96401316 0.9404156  0.968404   0.74491006 0.96883196 0.64521646\n",
      " 0.9437026  0.9309369  0.9348798  0.9255919  0.8953274  0.89008653\n",
      " 0.94185513 0.94931394]\n",
      "The rewards are: [0.72280174 0.58531976 0.8739887  0.7894767  0.9331175  0.86111885\n",
      " 0.7077534  0.92706376 0.9971865  0.76754534 0.9714162  0.8794908\n",
      " 0.66053385 0.98787165 0.7511663  0.9288091  0.7546773  0.83920646\n",
      " 0.75640696 0.978205   0.8314144  0.75313896 0.82467425 0.90057456\n",
      " 0.9714826  0.9906571  0.98938096 0.98114175 0.8358068  0.8724907\n",
      " 0.9052188  0.9848631 ]\n",
      "The rewards are: [0.8818919  0.9833544  0.95808226 0.9429038  0.5226498  0.97016937\n",
      " 0.7419541  0.5389071  0.72132015 0.84250563 0.9390106  0.89917964\n",
      " 0.90200764 0.87702453 0.91097146 0.65551466 0.518282   0.57108676\n",
      " 0.6263508  0.97235245 0.7304613  0.9211518  0.95898    0.93796986\n",
      " 0.5113009  0.9735936  0.9378106  0.99487334 0.9869257  0.9305745\n",
      " 0.96383315 0.97662395]\n",
      "The rewards are: [0.5364211  0.91510725 0.95040715 0.9566095  0.9162946  0.9657051\n",
      " 0.93477964 0.5311322  0.5900534  0.7435177  0.809255   0.96223557\n",
      " 0.6437623  0.7292627  0.5647545  0.627532   0.7525978  0.8452577\n",
      " 0.97558755 0.98057395 0.8873487  0.7313929  0.9824631  0.96305865\n",
      " 0.9711157  0.6023292  0.8549083  0.7208343  0.863212   0.8725432\n",
      " 0.99710363 0.7126282 ]\n",
      "The rewards are: [0.83088696 0.97426265 0.87647116 0.9613175  0.8164796  0.8475406\n",
      " 0.83886456 0.7826839  0.6803297  0.9293586  0.85616684 0.57901365\n",
      " 0.8432767  0.94865596 0.86361504 0.5860787  0.7661087  0.9740029\n",
      " 0.96534014 0.9814162  0.5152412  0.69695646 0.9653468  0.8349898\n",
      " 0.9340017  0.8476815  0.89975244 0.6411262  0.96405447 0.8522308\n",
      " 0.8597691  0.99310267]\n",
      "The rewards are: [0.995977   0.70370454 0.93921995 0.6221299  0.9938305  0.779911\n",
      " 0.71044266 0.9710716  0.8030826  0.91784894 0.8697349  0.68062496\n",
      " 0.9596712  0.9843629  0.8616741  0.781066   0.7281389  0.51726013\n",
      " 0.6504231  0.9697167  0.5517612  0.84535336 0.6614608  0.97832096\n",
      " 0.6573945  0.72598255 0.7746843  0.80568993 0.65743196 0.988218\n",
      " 0.976168   0.73284227]\n",
      "The rewards are: [0.6608898  0.81109035 0.70946705 0.8739647  0.93436694 0.90918875\n",
      " 0.58613795 0.9540538  0.86259866 0.98443824 0.9834289  0.77855444\n",
      " 0.79226816 0.8742962  0.87338656 0.69640374 0.8992554  0.9720908\n",
      " 0.92905307 0.63516337 0.99445456 0.7944517  0.5339915  0.5962068\n",
      " 0.7545611  0.7950511  0.55705917 0.7080277  0.92643154 0.8078237\n",
      " 0.5499897  0.5536009 ]\n",
      "The rewards are: [0.94990736 0.63731045 0.99657047 0.94583654 0.7039662  0.65407336\n",
      " 0.9263971  0.99027866 0.9624207  0.90327805 0.593004   0.7813513\n",
      " 0.6871866  0.96471846 0.86711    0.87504387 0.9438166  0.8593656\n",
      " 0.8761924  0.7381655  0.9902113  0.63338375 0.9906502  0.88397145\n",
      " 0.9277047  0.51092625 0.5144969  0.9525586  0.6422059  0.95828223\n",
      " 0.54536015 0.9049615 ]\n",
      "The rewards are: [0.9064441  0.95466423 0.789622   0.90988755 0.9437382  0.9880668\n",
      " 0.9384511  0.6738933  0.8439014  0.98608124 0.9860643  0.55799437\n",
      " 0.81333303 0.72878313 0.85190445 0.98085827 0.56599766 0.7848037\n",
      " 0.9611964  0.95710707 0.5449121  0.92630494 0.9730013  0.5653353\n",
      " 0.931684   0.7551026  0.6941942  0.85304505 0.9808796  0.5187844\n",
      " 0.76108897 0.8691679 ]\n",
      "The rewards are: [0.98349726 0.9392164  0.7734793  0.9813138  0.9732458  0.5972262\n",
      " 0.7128605  0.96184886 0.9354175  0.9792559  0.9742076  0.820246\n",
      " 0.8834991  0.9569671  0.88408464 0.87883043 0.8824985  0.7712893\n",
      " 0.84689087 0.9574388  0.9440642  0.94678736 0.97517395 0.6788253\n",
      " 0.97740936 0.88545185 0.84209293 0.7155158  0.71046257 0.989451\n",
      " 0.7788677  0.8916002 ]\n",
      "The rewards are: [0.9928133  0.7513871  0.6737132  0.99121946 0.9701496  0.9912115\n",
      " 0.5525476  0.8814445  0.99197584 0.9782989  0.92106533 0.8001926\n",
      " 0.58038205 0.77313036 0.93391764 0.9917767  0.9898544  0.97494125\n",
      " 0.9073311  0.8641003  0.9716409  0.97929025 0.9081738  0.9637158\n",
      " 0.9871502  0.885124   0.95467144 0.8447009  0.9705334  0.91745806\n",
      " 0.65020186 0.9439688 ]\n",
      "The rewards are: [0.8991469  0.97548294 0.88810545 0.62331635 0.9505086  0.9602507\n",
      " 0.6209338  0.7967724  0.97855264 0.9339063  0.5304938  0.943571\n",
      " 0.9522692  0.8487916  0.84367406 0.7018627  0.5513105  0.9532326\n",
      " 0.63072544 0.98390585 0.8282002  0.63642514 0.82411176 0.7110417\n",
      " 0.99248075 0.8025832  0.8300329  0.9917746  0.96297675 0.89145344\n",
      " 0.7677914  0.96508116]\n",
      "The rewards are: [0.9823684  0.9829748  0.74754167 0.7982927  0.97711027 0.9867468\n",
      " 0.9136951  0.9887959  0.9313933  0.981618   0.7099674  0.66385525\n",
      " 0.9035612  0.9215705  0.85858446 0.80476314 0.8606873  0.9050835\n",
      " 0.97240114 0.5766002  0.9695133  0.9819048  0.9969944  0.6748879\n",
      " 0.7834685  0.7465916  0.67866325 0.97536474 0.82361424 0.9613432\n",
      " 0.92996347 0.67866325]\n",
      "The rewards are: [0.98087204 0.9542024  0.9876472  0.96517146 0.63087875 0.98882514\n",
      " 0.98714024 0.8129617  0.97237307 0.9179126  0.9443452  0.989363\n",
      " 0.8988042  0.99435174 0.996546   0.96839654 0.9729169  0.6292088\n",
      " 0.9895901  0.6607632  0.9877644  0.9975667  0.8844115  0.9565853\n",
      " 0.5223051  0.9356478  0.96202856 0.9259176  0.93735987 0.62627524\n",
      " 0.82593495 0.89113134]\n",
      "The rewards are: [0.8657044  0.961227   0.7902685  0.9334105  0.8144931  0.9269165\n",
      " 0.9844461  0.61566156 0.8153193  0.5399415  0.89386857 0.99680257\n",
      " 0.53033906 0.97416794 0.9076361  0.78796375 0.5104923  0.9499736\n",
      " 0.8950709  0.5561994  0.9543914  0.56256735 0.8829995  0.916638\n",
      " 0.9003339  0.7197782  0.86958194 0.9037916  0.90921336 0.66631603\n",
      " 0.6519598  0.9850529 ]\n",
      "The rewards are: [0.99312055 0.8323468  0.576566   0.9369351  0.9813509  0.9388429\n",
      " 0.6265613  0.97616655 0.98650914 0.98167074 0.9896577  0.9851621\n",
      " 0.85251874 0.7669503  0.7681529  0.6837231  0.8328156  0.9010058\n",
      " 0.85958815 0.93079424 0.93276423 0.9254793  0.9371066  0.74076885\n",
      " 0.9387027  0.8219843  0.9401547  0.99268264 0.97776467 0.9095266\n",
      " 0.5916208  0.89487916]\n",
      "The rewards are: [0.70338464 0.96574736 0.97661966 0.8670835  0.7984409  0.76636904\n",
      " 0.971202   0.94190747 0.9429599  0.8415742  0.7136206  0.5932211\n",
      " 0.9928618  0.76734805 0.9162691  0.98527586 0.9673597  0.98685753\n",
      " 0.9814135  0.98720413 0.96508485 0.8403153  0.96520096 0.9429918\n",
      " 0.94529676 0.9572589  0.99464107 0.72317594 0.9653342  0.9763184\n",
      " 0.9696492  0.50810665]\n",
      "The rewards are: [0.9920946  0.82390565 0.87608045 0.9328898  0.9694812  0.8656753\n",
      " 0.86182696 0.8050579  0.99165314 0.9678592  0.6588299  0.9816564\n",
      " 0.82356244 0.5279212  0.6253369  0.7348596  0.95068514 0.680275\n",
      " 0.6183212  0.7516627  0.999102   0.9957766  0.6967351  0.5007173\n",
      " 0.98754    0.78144103 0.59190375 0.891314   0.9457067  0.9838771\n",
      " 0.66794163 0.904647  ]\n",
      "The rewards are: [0.5019592  0.91003096 0.84661514 0.9722707  0.50756574 0.72973543\n",
      " 0.53572494 0.5222654  0.88498527 0.7496609  0.8873717  0.53504956\n",
      " 0.67815316 0.99064565 0.8073476  0.93944323 0.96522397 0.99188566\n",
      " 0.5581296  0.9890665  0.9801877  0.56131136 0.86029524 0.98183525\n",
      " 0.76076907 0.6359612  0.9744588  0.7706022  0.5325925  0.9590077\n",
      " 0.80392563 0.91076356]\n",
      "The rewards are: [0.8386865  0.8554786  0.87687296 0.89849627 0.9399842  0.95260143\n",
      " 0.8333125  0.9137518  0.9843501  0.8872182  0.9789899  0.9668196\n",
      " 0.9906991  0.9624825  0.9667663  0.7840274  0.96757185 0.88772124\n",
      " 0.99032485 0.98797    0.7617235  0.890421   0.71362823 0.71230406\n",
      " 0.907421   0.796497   0.59010714 0.99612504 0.9528032  0.57234555\n",
      " 0.943627   0.8632375 ]\n",
      "The rewards are: [0.9877977  0.8357922  0.7447941  0.95838404 0.50490063 0.9808394\n",
      " 0.8863758  0.90979695 0.8451482  0.8110048  0.89213794 0.91848963\n",
      " 0.91541344 0.9697898  0.9950122  0.72110426 0.9742843  0.90883213\n",
      " 0.9772454  0.9566519  0.8715188  0.9822597  0.9096022  0.56344455\n",
      " 0.95482564 0.98167324 0.957254   0.8503498  0.56769097 0.8183928\n",
      " 0.8227067  0.97680014]\n",
      "The rewards are: [0.99327713 0.9656552  0.93529797 0.90612745 0.95957416 0.6373504\n",
      " 0.9841307  0.973356   0.8972111  0.84442    0.6358243  0.9944922\n",
      " 0.965457   0.7555166  0.50921726 0.9959105  0.9688648  0.98748374\n",
      " 0.8183075  0.9088158  0.9097054  0.6418701  0.601689   0.53819877\n",
      " 0.9569208  0.91800517 0.5586645  0.8796797  0.9952122  0.86602014\n",
      " 0.75522655 0.9045754 ]\n",
      "The rewards are: [0.55170506 0.8506591  0.741417   0.75311124 0.97119427 0.56730783\n",
      " 0.9824471  0.8917184  0.8430665  0.65208185 0.87997353 0.94408333\n",
      " 0.7125733  0.703577   0.7444417  0.94298035 0.97579306 0.8683371\n",
      " 0.94456583 0.9439394  0.90715003 0.97478306 0.9923388  0.9190899\n",
      " 0.9117164  0.94766164 0.9800657  0.9225776  0.8071286  0.8625625\n",
      " 0.8557796  0.88313824]\n",
      "The rewards are: [0.916184   0.71487385 0.9971355  0.82504725 0.83080745 0.5509685\n",
      " 0.61103743 0.982496   0.696646   0.885491   0.97337985 0.9946515\n",
      " 0.83430344 0.7650111  0.81968486 0.75154525 0.7578808  0.945833\n",
      " 0.8101888  0.96497715 0.9652864  0.9606347  0.8550426  0.72048426\n",
      " 0.7195901  0.91957283 0.8382259  0.63658804 0.94737333 0.9508548\n",
      " 0.92767084 0.8948134 ]\n",
      "The rewards are: [0.90263456 0.9787031  0.90942246 0.868757   0.926345   0.8808726\n",
      " 0.97202706 0.98997635 0.6352899  0.7928909  0.9340319  0.9451668\n",
      " 0.93503535 0.6621639  0.935748   0.8896137  0.89450747 0.5295905\n",
      " 0.931541   0.95825255 0.88728845 0.59328884 0.9709881  0.9673235\n",
      " 0.66144204 0.9002486  0.9729804  0.8200059  0.96937    0.97450024\n",
      " 0.76860875 0.97895056]\n",
      "The rewards are: [0.75946534 0.9528636  0.9977284  0.9427001  0.63620186 0.76098895\n",
      " 0.89765936 0.9699349  0.8103134  0.9504909  0.8930467  0.9329771\n",
      " 0.9447155  0.59767205 0.91031367 0.70112395 0.8389916  0.9290282\n",
      " 0.9909142  0.9074099  0.5313957  0.75837123 0.99057394 0.76911587\n",
      " 0.9820617  0.9727664  0.76062876 0.969958   0.88716966 0.9678659\n",
      " 0.9932138  0.6504227 ]\n",
      "The rewards are: [0.9832697  0.5177813  0.5758298  0.9996371  0.76648194 0.9981558\n",
      " 0.88507444 0.97885305 0.92642    0.73881084 0.68648887 0.9808648\n",
      " 0.9907231  0.90369767 0.83008    0.99819726 0.9977083  0.9284544\n",
      " 0.96180993 0.8917816  0.9921612  0.72980994 0.9335431  0.99280447\n",
      " 0.7854399  0.99424666 0.79620355 0.7779426  0.9690964  0.92680484\n",
      " 0.97571903 0.7315677 ]\n",
      "The rewards are: [0.9788296  0.53058594 0.9659938  0.85752016 0.98586106 0.9897883\n",
      " 0.93404305 0.9174697  0.99297214 0.98327523 0.9680333  0.87888026\n",
      " 0.9892124  0.80533254 0.96686316 0.95960975 0.5918764  0.716538\n",
      " 0.9529149  0.99506146 0.95243526 0.9499875  0.96193963 0.9968323\n",
      " 0.90941167 0.8845392  0.8903985  0.98087466 0.71896774 0.85285074\n",
      " 0.73952484 0.9577226 ]\n",
      "The rewards are: [0.91922045 0.9945781  0.8487486  0.5201292  0.9446451  0.922636\n",
      " 0.8727303  0.9888199  0.8387525  0.9338905  0.9794661  0.8592306\n",
      " 0.94661504 0.9729776  0.9561935  0.8791742  0.710619   0.9335719\n",
      " 0.97845036 0.711868   0.9257742  0.9723622  0.9786228  0.9412597\n",
      " 0.79523057 0.9816691  0.9912054  0.7133266  0.61108714 0.602462\n",
      " 0.90682065 0.9940644 ]\n",
      "The rewards are: [0.97627854 0.98428136 0.59762514 0.98038554 0.9353781  0.86696124\n",
      " 0.9786612  0.97296137 0.93122596 0.6768669  0.82142186 0.96686137\n",
      " 0.78245366 0.88261884 0.93897927 0.9323941  0.57345754 0.91938394\n",
      " 0.98773926 0.7079401  0.9178624  0.9412702  0.8919025  0.9759434\n",
      " 0.6128426  0.9813964  0.98434216 0.991134   0.93431145 0.8632915\n",
      " 0.86223584 0.96885824]\n",
      "The rewards are: [0.77916616 0.87213635 0.9704705  0.7948141  0.9014118  0.55960727\n",
      " 0.9735605  0.9858154  0.9901811  0.95596945 0.9770337  0.7250242\n",
      " 0.96342146 0.9795569  0.9164808  0.954472   0.9623368  0.9880372\n",
      " 0.96199393 0.98233646 0.91445166 0.9943256  0.6054321  0.95359874\n",
      " 0.82988894 0.75291723 0.8928734  0.5295671  0.91200817 0.932634\n",
      " 0.9852565  0.93987375]\n",
      "The rewards are: [0.93680024 0.98820543 0.9205476  0.9895667  0.9714713  0.82058287\n",
      " 0.9387482  0.98084384 0.93017846 0.9577183  0.89135987 0.9765896\n",
      " 0.7464106  0.98801386 0.9864342  0.98337793 0.9788209  0.87140155\n",
      " 0.75189024 0.6494923  0.87344784 0.91232455 0.9125739  0.99447024\n",
      " 0.99247485 0.9363683  0.74463683 0.916424   0.8312831  0.99246573\n",
      " 0.9800892  0.59501195]\n",
      "The rewards are: [0.98696995 0.99094385 0.9823788  0.889461   0.90968055 0.7318615\n",
      " 0.89433736 0.6243863  0.63585013 0.9434592  0.66826874 0.582611\n",
      " 0.93118715 0.63453114 0.72170264 0.8677151  0.8751534  0.752809\n",
      " 0.75018114 0.9566513  0.9841106  0.69141036 0.9047916  0.99833894\n",
      " 0.98163337 0.80562276 0.70035    0.72065413 0.902005   0.84953064\n",
      " 0.7140432  0.99109626]\n",
      "The rewards are: [0.951468   0.98971015 0.65912825 0.6028959  0.5230384  0.8882074\n",
      " 0.85150343 0.8950923  0.9687318  0.96042454 0.9370993  0.6028453\n",
      " 0.7766106  0.9330843  0.8857402  0.8733213  0.76724136 0.998548\n",
      " 0.8940107  0.977482   0.9022588  0.9187832  0.99076426 0.60360706\n",
      " 0.8978421  0.77102995 0.9761155  0.7585683  0.9633917  0.95382464\n",
      " 0.77732754 0.9691897 ]\n",
      "The rewards are: [0.7715687  0.7662016  0.811753   0.91369903 0.7905039  0.9725537\n",
      " 0.94825864 0.89536476 0.9919878  0.9861509  0.7638272  0.8577565\n",
      " 0.80882305 0.71691805 0.5990036  0.99217623 0.9953367  0.9744037\n",
      " 0.68986464 0.9976502  0.8957277  0.9905155  0.97468555 0.8171031\n",
      " 0.7528377  0.83573264 0.7981424  0.59185004 0.9484172  0.8019424\n",
      " 0.5517572  0.78948534]\n",
      "The rewards are: [0.98030776 0.64795196 0.90045565 0.73756015 0.82405305 0.6797459\n",
      " 0.9326316  0.798004   0.740795   0.9709491  0.9717406  0.8490173\n",
      " 0.93344814 0.75868946 0.7882846  0.99584216 0.97872525 0.8341945\n",
      " 0.8344512  0.98123723 0.9923862  0.98342484 0.6515303  0.95809704\n",
      " 0.86070675 0.9944206  0.90208906 0.8701178  0.91819125 0.925087\n",
      " 0.8931778  0.9612127 ]\n",
      "The rewards are: [0.99927455 0.5213936  0.918337   0.8900255  0.9906901  0.7388536\n",
      " 0.77124965 0.9838373  0.95536935 0.82361704 0.9105585  0.96364856\n",
      " 0.98882407 0.9538228  0.9667354  0.63744473 0.9839298  0.9919756\n",
      " 0.8740149  0.983175   0.9120975  0.96400326 0.528959   0.58067995\n",
      " 0.995526   0.9853757  0.9881412  0.9583502  0.9530499  0.911132\n",
      " 0.54341596 0.8371354 ]\n",
      "The rewards are: [0.93547237 0.9896382  0.97584075 0.9879743  0.55101144 0.986182\n",
      " 0.985329   0.93481636 0.57925576 0.9080352  0.77874726 0.951266\n",
      " 0.99114954 0.69506717 0.69698185 0.65647614 0.78286517 0.9079006\n",
      " 0.96231925 0.62905294 0.7994957  0.63302374 0.93248916 0.8742539\n",
      " 0.9833891  0.9889514  0.92860645 0.71970797 0.8244684  0.7846099\n",
      " 0.9541432  0.94422543]\n",
      "The rewards are: [0.8149851  0.98583335 0.9394845  0.96085805 0.9901934  0.88823134\n",
      " 0.94611865 0.7525108  0.99643683 0.79606044 0.87811655 0.98858285\n",
      " 0.6403609  0.85527784 0.9644551  0.98588353 0.81177336 0.83906823\n",
      " 0.5270034  0.98961383 0.93586653 0.7678669  0.98766243 0.6221848\n",
      " 0.85574615 0.9564461  0.96654797 0.9679524  0.9335133  0.9969438\n",
      " 0.57441366 0.53104097]\n",
      "The rewards are: [0.5968661  0.6956966  0.91352165 0.841999   0.5141283  0.5145543\n",
      " 0.90795845 0.99508154 0.6347722  0.852491   0.6432543  0.94441485\n",
      " 0.9449445  0.9571475  0.8743985  0.89830476 0.87001806 0.8533828\n",
      " 0.9873148  0.94430226 0.9772563  0.8948783  0.99167913 0.9504975\n",
      " 0.92024225 0.9750118  0.9341702  0.9391121  0.9854172  0.902885\n",
      " 0.6438403  0.8519204 ]\n",
      "The rewards are: [0.98836875 0.99535817 0.6509204  0.83057594 0.98628706 0.5639504\n",
      " 0.84023315 0.8186353  0.8639954  0.8057534  0.95501065 0.8076258\n",
      " 0.81217813 0.9199706  0.9722302  0.992845   0.9823412  0.7344949\n",
      " 0.97826654 0.6773045  0.8727827  0.8091347  0.92374474 0.78646356\n",
      " 0.9888411  0.9721467  0.72273684 0.76514405 0.65897495 0.77220327\n",
      " 0.8528709  0.9698157 ]\n",
      "The rewards are: [0.85940874 0.81992656 0.85954946 0.8836526  0.505307   0.75356215\n",
      " 0.76802605 0.6349158  0.8419664  0.8398407  0.9732073  0.51652324\n",
      " 0.60277545 0.98648596 0.7234723  0.92120844 0.91597867 0.56427515\n",
      " 0.97998375 0.8472165  0.6728719  0.944247   0.71587956 0.7622985\n",
      " 0.9871034  0.79462093 0.98799706 0.8676092  0.8644131  0.99445987\n",
      " 0.9679251  0.61056036]\n",
      "The rewards are: [0.8094263  0.80376846 0.83015704 0.9823913  0.8731506  0.9679233\n",
      " 0.9552611  0.90319115 0.9923963  0.9928127  0.881078   0.9552689\n",
      " 0.9210868  0.93415415 0.8156904  0.9402474  0.85648423 0.7682887\n",
      " 0.88553655 0.9795441  0.98701954 0.9174639  0.51375645 0.65954334\n",
      " 0.65917444 0.9594867  0.8715528  0.88168234 0.63474315 0.97753\n",
      " 0.9269886  0.6375667 ]\n",
      "The rewards are: [0.9873934  0.94058865 0.9821801  0.9668522  0.9543587  0.50984406\n",
      " 0.9280202  0.83273435 0.99520063 0.95249164 0.5261565  0.6122573\n",
      " 0.95996904 0.99177504 0.98656833 0.8422009  0.7914578  0.82479084\n",
      " 0.94359714 0.99225134 0.9967901  0.7828683  0.97176164 0.88993806\n",
      " 0.97903675 0.9875079  0.52462804 0.769924   0.8617391  0.90205973\n",
      " 0.9950145  0.7836653 ]\n",
      "The rewards are: [0.9330549  0.97902256 0.88076997 0.9236297  0.9903572  0.7419375\n",
      " 0.7823981  0.89138407 0.93072647 0.8756721  0.8763306  0.756268\n",
      " 0.95623076 0.97647923 0.78358126 0.9938216  0.9862068  0.9475532\n",
      " 0.96744496 0.74066204 0.9133252  0.80190164 0.9931825  0.5318914\n",
      " 0.92684644 0.79535186 0.81029695 0.914624   0.79217166 0.99418926\n",
      " 0.96121424 0.99787056]\n",
      "The rewards are: [0.91896766 0.9983829  0.541086   0.8843839  0.5302689  0.52604216\n",
      " 0.9680647  0.88179934 0.9980367  0.8007062  0.9354301  0.9893317\n",
      " 0.99663085 0.63432616 0.9091698  0.9939731  0.9604881  0.9898822\n",
      " 0.94114375 0.9992138  0.8379337  0.57960945 0.8722316  0.81696385\n",
      " 0.901165   0.9322059  0.99047196 0.96068764 0.9622497  0.9866399\n",
      " 0.9392741  0.93090576]\n",
      "The rewards are: [0.9817894  0.9551257  0.95942426 0.7815802  0.98125535 0.7476466\n",
      " 0.9530044  0.8698427  0.96057916 0.8048875  0.8751169  0.9233459\n",
      " 0.9719562  0.9354026  0.5701194  0.9882586  0.9312727  0.9415664\n",
      " 0.9764107  0.89222383 0.9138604  0.8104426  0.9305774  0.70204383\n",
      " 0.9303751  0.9262268  0.98884773 0.976994   0.9900057  0.9888998\n",
      " 0.9886081  0.97802275]\n",
      "The rewards are: [0.99316156 0.96106213 0.9831381  0.9920065  0.67447984 0.7673285\n",
      " 0.890826   0.62705153 0.89094955 0.9283032  0.95688087 0.9355819\n",
      " 0.98343754 0.91145056 0.92697805 0.93172675 0.9440727  0.99242556\n",
      " 0.85678667 0.98534214 0.76114196 0.9895244  0.9614185  0.9958573\n",
      " 0.5464458  0.5961174  0.5068223  0.97601795 0.8616361  0.70002276\n",
      " 0.8454561  0.9979249 ]\n",
      "The rewards are: [0.9949698  0.88905    0.98180044 0.65903455 0.6352841  0.5155702\n",
      " 0.98186696 0.98809636 0.9910391  0.97864956 0.91563475 0.85564303\n",
      " 0.9961134  0.66846526 0.9986578  0.9041737  0.99352247 0.94675297\n",
      " 0.709614   0.99826413 0.58510333 0.6091237  0.97125643 0.9339495\n",
      " 0.69962925 0.9655051  0.9946272  0.57705945 0.66139907 0.9888986\n",
      " 0.84750444 0.9324415 ]\n",
      "The rewards are: [0.5727661  0.66687316 0.8026031  0.73156184 0.96404934 0.67223066\n",
      " 0.70495814 0.860957   0.7781864  0.9261281  0.9103392  0.95418286\n",
      " 0.7882617  0.8528704  0.988934   0.86192346 0.9450956  0.83324456\n",
      " 0.7576453  0.99245363 0.79441094 0.7479383  0.9565747  0.794887\n",
      " 0.935989   0.9876232  0.9048793  0.77966106 0.98757046 0.97419626\n",
      " 0.92973024 0.82456845]\n",
      "The rewards are: [0.9580608  0.83267146 0.95507497 0.9507776  0.7641249  0.9898713\n",
      " 0.8384349  0.85546833 0.84919655 0.9752533  0.96949434 0.8945831\n",
      " 0.54413575 0.93674684 0.98810893 0.95649475 0.7629302  0.7901038\n",
      " 0.9949319  0.97816545 0.6068759  0.93561053 0.73955536 0.86644924\n",
      " 0.97575915 0.85106945 0.97448695 0.98901397 0.94115883 0.6172152\n",
      " 0.9856791  0.95799756]\n",
      "The rewards are: [0.86181843 0.9893498  0.9801706  0.9774833  0.5092694  0.5551462\n",
      " 0.99594903 0.98838055 0.99750745 0.80147296 0.9788892  0.8646075\n",
      " 0.5464035  0.97424513 0.9925626  0.98165363 0.95150924 0.9651449\n",
      " 0.99079025 0.9292536  0.9805815  0.9742163  0.74921083 0.94820905\n",
      " 0.93893605 0.9979341  0.9898196  0.5588265  0.5170285  0.99551\n",
      " 0.9181715  0.9828492 ]\n",
      "The rewards are: [0.85005033 0.9726926  0.824088   0.9993864  0.74777013 0.9253981\n",
      " 0.8019714  0.9784425  0.5465607  0.6241231  0.907288   0.9853521\n",
      " 0.832639   0.98871124 0.72284776 0.92634594 0.9600288  0.9902733\n",
      " 0.9460489  0.84176016 0.78202873 0.9940764  0.6564973  0.51859576\n",
      " 0.97802174 0.56406564 0.94404197 0.98211354 0.93572783 0.97296655\n",
      " 0.88932973 0.85564053]\n",
      "The rewards are: [0.95744693 0.68707013 0.8703565  0.9218662  0.5737534  0.95263886\n",
      " 0.5131648  0.96616566 0.8279965  0.9727842  0.8895673  0.9974504\n",
      " 0.75395435 0.9890547  0.9841367  0.6928335  0.64800954 0.97880566\n",
      " 0.5468241  0.9684497  0.9579432  0.9724019  0.9583279  0.87624586\n",
      " 0.67460245 0.72135365 0.6839694  0.9972197  0.9957296  0.8093645\n",
      " 0.9578062  0.93332994]\n",
      "The rewards are: [0.7943197  0.9770305  0.9807355  0.5590988  0.8685523  0.99066645\n",
      " 0.52644914 0.52997637 0.6985977  0.6882549  0.967507   0.94944406\n",
      " 0.6745432  0.9853359  0.8529661  0.9713292  0.70239747 0.7390996\n",
      " 0.9882984  0.5340617  0.9890492  0.5226957  0.926239   0.9760917\n",
      " 0.51232594 0.85404915 0.9951481  0.8919989  0.900534   0.9321211\n",
      " 0.9936342  0.97734696]\n",
      "The rewards are: [0.9191035  0.9810066  0.99454015 0.87910277 0.9439003  0.6173656\n",
      " 0.9637728  0.67119944 0.89457446 0.98794854 0.98696196 0.95037687\n",
      " 0.9973194  0.9016838  0.7897284  0.92228186 0.6581362  0.5582859\n",
      " 0.93515825 0.9806887  0.9835443  0.6973787  0.9920998  0.95748615\n",
      " 0.95570683 0.8926055  0.9761548  0.9292625  0.5295179  0.5014402\n",
      " 0.76173043 0.5180557 ]\n",
      "The rewards are: [0.98586893 0.9888465  0.852785   0.97478616 0.9172135  0.9796077\n",
      " 0.94404197 0.55326045 0.97506535 0.55929863 0.939298   0.78536624\n",
      " 0.75861275 0.9595726  0.90858054 0.9625341  0.96944964 0.95324796\n",
      " 0.9930266  0.5125233  0.981686   0.9790627  0.9968401  0.93567127\n",
      " 0.8101729  0.9968952  0.9122191  0.9188692  0.900236   0.9868019\n",
      " 0.97702414 0.9705556 ]\n",
      "The rewards are: [0.9839627  0.9942689  0.91883236 0.9861605  0.952232   0.57250243\n",
      " 0.7867138  0.95383656 0.9164593  0.9033724  0.9135627  0.9395407\n",
      " 0.8473463  0.852539   0.957629   0.98799044 0.97750187 0.91363984\n",
      " 0.9863826  0.81032574 0.7319547  0.96644676 0.9928964  0.9602165\n",
      " 0.99251723 0.9933314  0.58382124 0.906878   0.93877774 0.94454426\n",
      " 0.96661425 0.8582581 ]\n",
      "The rewards are: [0.9933289  0.88399726 0.71533495 0.9731684  0.8823978  0.7554909\n",
      " 0.72866565 0.9924665  0.9863673  0.95501745 0.86923903 0.9777884\n",
      " 0.94751745 0.93789357 0.9484869  0.98654    0.97829616 0.9830903\n",
      " 0.8688169  0.99300766 0.98225486 0.98129994 0.5917042  0.8209507\n",
      " 0.9884139  0.98584336 0.9803452  0.6602264  0.69472355 0.96418655\n",
      " 0.99394566 0.9912253 ]\n",
      "The rewards are: [0.78890777 0.62222266 0.8953077  0.9650938  0.9591578  0.9896569\n",
      " 0.9855802  0.9756479  0.98701596 0.8022828  0.90684664 0.992806\n",
      " 0.9784016  0.8569145  0.990928   0.69654125 0.7944602  0.94148606\n",
      " 0.6046616  0.8690529  0.98078525 0.8018437  0.96998984 0.8428336\n",
      " 0.97196823 0.5960428  0.85788476 0.9809014  0.99575895 0.9901336\n",
      " 0.94722396 0.8405589 ]\n",
      "The rewards are: [0.9888763  0.99149406 0.9949432  0.7849429  0.75133693 0.98825586\n",
      " 0.9536497  0.91733587 0.96175325 0.6914024  0.89852995 0.8829666\n",
      " 0.5272264  0.99616086 0.8388841  0.8266131  0.99155104 0.9649869\n",
      " 0.78296834 0.64776206 0.60693085 0.9920359  0.9011607  0.87882197\n",
      " 0.9495195  0.96825266 0.9850825  0.95781773 0.9035193  0.9762695\n",
      " 0.98353726 0.9050331 ]\n",
      "The rewards are: [0.6112844  0.94724345 0.9463726  0.9533912  0.97319657 0.59764665\n",
      " 0.859185   0.70975566 0.96424484 0.747023   0.9838802  0.97287726\n",
      " 0.6173234  0.86581266 0.99518317 0.9927233  0.9755221  0.7462155\n",
      " 0.5014355  0.74363214 0.9872773  0.7946508  0.99278533 0.7501101\n",
      " 0.89477557 0.95208967 0.761053   0.94261616 0.98455185 0.9666685\n",
      " 0.88817626 0.50282764]\n",
      "The rewards are: [0.974038   0.96027005 0.9594188  0.8575726  0.8941339  0.9451568\n",
      " 0.8001903  0.99029434 0.99455994 0.89371496 0.710455   0.5454065\n",
      " 0.9722073  0.9484184  0.99763393 0.67924327 0.98080945 0.98481166\n",
      " 0.99305266 0.7657057  0.99242896 0.9610572  0.68768233 0.9861616\n",
      " 0.8967629  0.98780966 0.8876028  0.8393549  0.98916936 0.99303246\n",
      " 0.6372151  0.9615051 ]\n",
      "The rewards are: [0.9772394  0.9357127  0.8881369  0.88141894 0.5810164  0.5598909\n",
      " 0.8925873  0.9609098  0.913995   0.8019711  0.71363425 0.9977725\n",
      " 0.934336   0.95056295 0.99108785 0.51823515 0.9399939  0.5905745\n",
      " 0.95831823 0.99406093 0.9488324  0.91798985 0.9587374  0.5154297\n",
      " 0.9974256  0.8434123  0.5965991  0.93467206 0.5998988  0.8943959\n",
      " 0.9729292  0.8786928 ]\n",
      "The rewards are: [0.942596   0.97239333 0.5210779  0.93271255 0.875646   0.99175334\n",
      " 0.7066732  0.73046774 0.99145633 0.87505585 0.9801983  0.96531224\n",
      " 0.870499   0.9931238  0.9619224  0.96715397 0.9479706  0.9348504\n",
      " 0.97806895 0.9051894  0.9893723  0.92816    0.8925828  0.5373021\n",
      " 0.8259815  0.9936898  0.87899345 0.99167776 0.8396931  0.7900749\n",
      " 0.9972631  0.98973924]\n",
      "The rewards are: [0.5505051  0.9922849  0.94916326 0.72597325 0.9254356  0.9884985\n",
      " 0.9225135  0.9854197  0.97697145 0.7548486  0.73060375 0.9318817\n",
      " 0.9703832  0.9810828  0.9050044  0.7573766  0.9491358  0.9927941\n",
      " 0.99091446 0.8984078  0.9794296  0.9620283  0.8005303  0.7292954\n",
      " 0.9767851  0.9140725  0.7354519  0.9438436  0.9337831  0.8851504\n",
      " 0.7693866  0.73440427]\n",
      "The rewards are: [0.87463695 0.9240398  0.95372885 0.9800812  0.93700755 0.9839941\n",
      " 0.99636793 0.9645657  0.98302275 0.7783224  0.94012576 0.86085945\n",
      " 0.97760016 0.84518504 0.9960109  0.98933035 0.95438665 0.9741398\n",
      " 0.979361   0.9575126  0.8249517  0.9835089  0.9565802  0.9320041\n",
      " 0.82508355 0.9556532  0.99681276 0.73050475 0.9685222  0.96285427\n",
      " 0.9676443  0.8330809 ]\n",
      "The rewards are: [0.99483395 0.977705   0.7083129  0.99575186 0.5187521  0.96654683\n",
      " 0.9953998  0.8375934  0.9711438  0.99628407 0.93545246 0.8831347\n",
      " 0.96383536 0.9886431  0.9955746  0.9705136  0.70302624 0.6248174\n",
      " 0.9625487  0.97685826 0.9960245  0.9874098  0.9743972  0.84394455\n",
      " 0.8918315  0.6342642  0.9394508  0.9806651  0.9849338  0.92391837\n",
      " 0.58364564 0.92510927]\n",
      "The rewards are: [0.9485053  0.8794281  0.9812201  0.9968346  0.99889624 0.97244734\n",
      " 0.9794383  0.98465735 0.9336794  0.9432213  0.9379529  0.94953555\n",
      " 0.5450436  0.9855474  0.89703333 0.6398109  0.5492422  0.9863267\n",
      " 0.71865195 0.6934786  0.88282365 0.90839285 0.6584354  0.92992646\n",
      " 0.7381431  0.62879515 0.94697064 0.76052994 0.99301285 0.9912486\n",
      " 0.94663286 0.8958193 ]\n",
      "The rewards are: [0.95895517 0.8542075  0.99143654 0.94023293 0.5128192  0.9274022\n",
      " 0.99591464 0.8893288  0.977616   0.6055119  0.92509645 0.92713016\n",
      " 0.9620076  0.73677605 0.99234676 0.91200703 0.84867954 0.95097506\n",
      " 0.9535047  0.8441218  0.92765194 0.9980198  0.87481344 0.91264343\n",
      " 0.95401424 0.9693168  0.9768835  0.96838814 0.8628781  0.9563012\n",
      " 0.9737486  0.52941793]\n",
      "The rewards are: [0.85645664 0.9191721  0.99581414 0.955423   0.99228024 0.93146014\n",
      " 0.9977381  0.9841793  0.9850419  0.89279044 0.998184   0.99021953\n",
      " 0.9920454  0.63476056 0.5441925  0.9683699  0.98995167 0.917006\n",
      " 0.94677496 0.9154573  0.9656455  0.803256   0.9994808  0.9363179\n",
      " 0.96941257 0.9595407  0.955311   0.9356274  0.9790284  0.53438807\n",
      " 0.9872858  0.98320955]\n",
      "The rewards are: [0.9730453  0.89391124 0.8746287  0.97918326 0.92685145 0.52897847\n",
      " 0.8821027  0.59670365 0.94889355 0.7678849  0.977094   0.97585183\n",
      " 0.9924238  0.98615867 0.9384721  0.6263071  0.91866785 0.9942052\n",
      " 0.97595674 0.9608324  0.9838801  0.73162335 0.7382653  0.8763303\n",
      " 0.9127193  0.8677758  0.65248936 0.7007006  0.71003634 0.9348742\n",
      " 0.98801464 0.98268616]\n",
      "The rewards are: [0.9158919  0.77226955 0.5976961  0.9170279  0.59742135 0.7433579\n",
      " 0.92873174 0.904336   0.69518876 0.94963074 0.60128313 0.75383884\n",
      " 0.9530157  0.9820947  0.9894706  0.67162454 0.9336643  0.9650283\n",
      " 0.85127324 0.9747575  0.85842544 0.97691935 0.79257697 0.7833823\n",
      " 0.99710363 0.89337754 0.73450494 0.8968815  0.9697873  0.59947616\n",
      " 0.90722454 0.9899234 ]\n",
      "The rewards are: [0.6917974  0.8652583  0.9506211  0.97405696 0.95001274 0.99060035\n",
      " 0.9473777  0.8180145  0.9797505  0.9406935  0.9007874  0.981659\n",
      " 0.9071187  0.8356519  0.89281327 0.98621076 0.99630296 0.9136061\n",
      " 0.93552315 0.997954   0.99273986 0.9187863  0.9788573  0.9881412\n",
      " 0.9663444  0.6830163  0.9234321  0.8931671  0.97403044 0.9566371\n",
      " 0.6377431  0.91553044]\n",
      "The rewards are: [0.8348841  0.95761275 0.63801944 0.99514765 0.94250846 0.9779975\n",
      " 0.5869145  0.80169    0.8364816  0.920251   0.9818346  0.7233759\n",
      " 0.9283941  0.95817465 0.9802067  0.93956065 0.6196723  0.99150664\n",
      " 0.9232821  0.89356315 0.9802581  0.5562731  0.62406754 0.9716664\n",
      " 0.97081596 0.9868176  0.8958948  0.9113898  0.90161717 0.9981457\n",
      " 0.8979265  0.5379747 ]\n",
      "The rewards are: [0.9782056  0.9984627  0.5647905  0.994286   0.9836426  0.9719436\n",
      " 0.64500445 0.86875534 0.99386615 0.9935922  0.74450874 0.87664515\n",
      " 0.7201447  0.93759876 0.98787004 0.9887509  0.98791236 0.9212125\n",
      " 0.905901   0.96876043 0.55388373 0.9830813  0.7675553  0.6904576\n",
      " 0.7747334  0.993418   0.8087744  0.920936   0.9730996  0.9725227\n",
      " 0.75637776 0.945761  ]\n",
      "The rewards are: [0.99105763 0.90261096 0.7571206  0.659853   0.8950586  0.69534284\n",
      " 0.9961403  0.95643324 0.76989895 0.97522724 0.9688757  0.93609214\n",
      " 0.5720531  0.9620889  0.850835   0.92407626 0.8463563  0.8428921\n",
      " 0.96846473 0.7882186  0.70527416 0.87501657 0.9894748  0.9933756\n",
      " 0.9189267  0.95769984 0.993057   0.9637742  0.92125326 0.98244274\n",
      " 0.98048544 0.8054032 ]\n",
      "The rewards are: [0.6147717  0.9935098  0.9985089  0.83042586 0.9971366  0.78682894\n",
      " 0.77389026 0.7603725  0.5334421  0.99522346 0.977122   0.54568994\n",
      " 0.9994618  0.98055226 0.95832413 0.79398555 0.5718274  0.9965089\n",
      " 0.98804736 0.9871934  0.9797723  0.9527055  0.9875085  0.93582124\n",
      " 0.8307932  0.83556455 0.930454   0.9920412  0.55222905 0.93935055\n",
      " 0.91135925 0.9511647 ]\n",
      "The rewards are: [0.9819534  0.92893857 0.87411064 0.91146994 0.8814463  0.98771065\n",
      " 0.9641822  0.86791134 0.9682721  0.9159013  0.9345572  0.9729644\n",
      " 0.97233236 0.74683243 0.9278565  0.9784799  0.9526779  0.98602283\n",
      " 0.9148866  0.9472791  0.98852587 0.99395764 0.5677668  0.89351916\n",
      " 0.8589334  0.9054337  0.5618013  0.9562952  0.99361455 0.63715535\n",
      " 0.5194325  0.9547012 ]\n",
      "The rewards are: [0.9549695  0.8484459  0.9937511  0.9295781  0.8169069  0.9724088\n",
      " 0.91320056 0.97402984 0.70123947 0.9136886  0.9780742  0.9961732\n",
      " 0.6508989  0.80562645 0.99152386 0.82289857 0.94997466 0.9939382\n",
      " 0.90893316 0.96499234 0.960325   0.96346295 0.9123931  0.96091175\n",
      " 0.9849605  0.72320133 0.9512878  0.974227   0.6630208  0.78550893\n",
      " 0.64804596 0.99033886]\n",
      "The rewards are: [0.84088993 0.9584676  0.971763   0.8004055  0.93288195 0.97766453\n",
      " 0.92170626 0.84819174 0.8078578  0.8978404  0.78585047 0.9884884\n",
      " 0.96609926 0.68421584 0.84578097 0.94491416 0.8381993  0.59702355\n",
      " 0.9605028  0.99687886 0.6012298  0.9149057  0.97024506 0.8717831\n",
      " 0.59214115 0.98999363 0.78106654 0.8773037  0.9273596  0.9917672\n",
      " 0.5252708  0.9934929 ]\n",
      "The rewards are: [0.97976047 0.91467494 0.9424846  0.9852763  0.936889   0.5717676\n",
      " 0.7251074  0.9972103  0.9743234  0.9706331  0.9715371  0.6738787\n",
      " 0.87100446 0.9873782  0.94172084 0.618306   0.966233   0.90150815\n",
      " 0.99586403 0.9326978  0.9895738  0.76571804 0.96962476 0.9216212\n",
      " 0.9957551  0.97325677 0.6675202  0.93347836 0.9145365  0.92618924\n",
      " 0.8183626  0.9702771 ]\n",
      "The rewards are: [0.92392707 0.9874024  0.9113354  0.99482214 0.6592278  0.9331841\n",
      " 0.93830025 0.8565487  0.98419446 0.82645506 0.637634   0.9885485\n",
      " 0.8681774  0.9019385  0.9808881  0.67270637 0.6609152  0.7793407\n",
      " 0.9488855  0.9599283  0.9990709  0.97374696 0.98500395 0.96927106\n",
      " 0.9708075  0.974919   0.9982292  0.8156539  0.9770675  0.9930501\n",
      " 0.9950806  0.9539308 ]\n",
      "The rewards are: [0.9819726  0.7164188  0.7772221  0.5806645  0.62428975 0.6930556\n",
      " 0.78154147 0.92163223 0.9861411  0.6984472  0.9506183  0.9966763\n",
      " 0.72575533 0.99209315 0.7206575  0.5136006  0.8819201  0.7474511\n",
      " 0.92497313 0.8991306  0.96641254 0.99927515 0.7477711  0.945942\n",
      " 0.98382217 0.78106934 0.8597522  0.84410715 0.9352015  0.8068102\n",
      " 0.9962347  0.7536254 ]\n",
      "The rewards are: [0.96500933 0.6037582  0.99190444 0.9951639  0.8449323  0.8599692\n",
      " 0.98116577 0.59119886 0.9410288  0.7236333  0.9987274  0.9431272\n",
      " 0.8593659  0.99591774 0.7832184  0.99820197 0.9955497  0.5989672\n",
      " 0.9691795  0.9737715  0.81967974 0.9261618  0.5632617  0.50109607\n",
      " 0.8201742  0.8807275  0.9185376  0.9328106  0.9949067  0.9922956\n",
      " 0.9978908  0.9851243 ]\n",
      "The rewards are: [0.78339237 0.88388723 0.96919036 0.8334591  0.94633985 0.8458198\n",
      " 0.9662646  0.94180095 0.9951283  0.9800348  0.8379712  0.991139\n",
      " 0.76615024 0.62024516 0.96850675 0.9025487  0.89739215 0.99741507\n",
      " 0.6100063  0.7391662  0.9668309  0.9441652  0.9892454  0.9839632\n",
      " 0.9597532  0.71272516 0.9955918  0.9825935  0.98615277 0.52314955\n",
      " 0.68549246 0.9720771 ]\n",
      "The rewards are: [0.75057703 0.99817324 0.7487394  0.8390672  0.74467    0.8688429\n",
      " 0.9977864  0.957553   0.9906386  0.8055168  0.8622423  0.7230954\n",
      " 0.64544183 0.9827185  0.9866085  0.98052144 0.74392337 0.7562717\n",
      " 0.99067515 0.92086035 0.8231308  0.99206865 0.73082364 0.9087035\n",
      " 0.5201037  0.9896247  0.93765086 0.94599736 0.9954462  0.8942332\n",
      " 0.88956654 0.99941874]\n",
      "The rewards are: [0.9148004  0.72340304 0.7981374  0.91473556 0.9817376  0.9701562\n",
      " 0.8918484  0.8857196  0.768961   0.9802453  0.991202   0.99245924\n",
      " 0.9895538  0.623157   0.72319835 0.9659268  0.9967614  0.8588568\n",
      " 0.9278587  0.96229917 0.9898707  0.9488106  0.7131992  0.9592575\n",
      " 0.99488896 0.9341663  0.65360886 0.9790709  0.9250665  0.66084504\n",
      " 0.9713685  0.93746525]\n",
      "The rewards are: [0.83147055 0.9214998  0.98547596 0.9880314  0.9719567  0.5343257\n",
      " 0.894428   0.80480224 0.98651206 0.5974666  0.9885024  0.5903051\n",
      " 0.8783736  0.85263556 0.6601683  0.99656063 0.9613894  0.71455675\n",
      " 0.7881959  0.98034316 0.9944127  0.9102042  0.69557095 0.825966\n",
      " 0.64344513 0.7766381  0.51678175 0.92309326 0.9212037  0.9566986\n",
      " 0.6378046  0.96764666]\n",
      "The rewards are: [0.98357195 0.852171   0.91091937 0.9988257  0.8884657  0.98678607\n",
      " 0.91346437 0.9673717  0.89281464 0.80756354 0.870656   0.94622153\n",
      " 0.66695696 0.5223784  0.75389194 0.5033984  0.9336443  0.9931558\n",
      " 0.98869634 0.7041939  0.70887566 0.94883794 0.9947339  0.963963\n",
      " 0.8853883  0.91797197 0.8337551  0.89847827 0.9764748  0.8390987\n",
      " 0.88667184 0.95185137]\n",
      "The rewards are: [0.9898145  0.9458351  0.9950643  0.99188095 0.9924705  0.9948338\n",
      " 0.966085   0.9946801  0.81106174 0.9974632  0.862332   0.91043234\n",
      " 0.9683271  0.81545264 0.85642314 0.9876633  0.67770535 0.9850116\n",
      " 0.96960855 0.9537936  0.86713433 0.9955076  0.9959266  0.90943485\n",
      " 0.71260357 0.81756186 0.52915055 0.9915985  0.8960216  0.9712369\n",
      " 0.9348174  0.9108765 ]\n",
      "The rewards are: [0.8782746  0.9714049  0.96741587 0.9917271  0.81553984 0.976249\n",
      " 0.8498422  0.59113234 0.9189402  0.9905172  0.600634   0.9954861\n",
      " 0.94639003 0.87093437 0.59745204 0.7396848  0.9908915  0.9928294\n",
      " 0.9337919  0.93255913 0.83783305 0.99193364 0.9522616  0.9977131\n",
      " 0.9912463  0.8817552  0.6007502  0.96961606 0.98923546 0.92361933\n",
      " 0.99429697 0.9784309 ]\n",
      "The rewards are: [0.9058658  0.992141   0.9778275  0.83166194 0.62758756 0.92415017\n",
      " 0.90553206 0.51510763 0.93601245 0.86580354 0.98802793 0.98497623\n",
      " 0.99215347 0.9417446  0.9643499  0.99162924 0.87758803 0.8581286\n",
      " 0.74877465 0.99355847 0.71377397 0.9982293  0.9864093  0.9117149\n",
      " 0.7515048  0.94593316 0.9872639  0.9824399  0.93496406 0.81749564\n",
      " 0.7550403  0.8867229 ]\n",
      "The rewards are: [0.8756911  0.82590896 0.9706488  0.73199165 0.6202156  0.8108367\n",
      " 0.8264637  0.8684636  0.9758381  0.97991425 0.9884094  0.577471\n",
      " 0.610521   0.99797374 0.98759884 0.96786433 0.98380846 0.9555466\n",
      " 0.99687684 0.99601537 0.99740416 0.95804864 0.715815   0.8490005\n",
      " 0.99690056 0.9311412  0.99839264 0.99873143 0.8049227  0.73259753\n",
      " 0.9320461  0.57092685]\n",
      "The rewards are: [0.9371797  0.93747574 0.9768475  0.6995654  0.95368516 0.907443\n",
      " 0.9783239  0.97982955 0.96561897 0.9938658  0.8812064  0.69303113\n",
      " 0.9006442  0.51635283 0.8490663  0.98681086 0.97139233 0.98667705\n",
      " 0.8477074  0.9667259  0.99512464 0.9244626  0.63769513 0.95789254\n",
      " 0.9713391  0.98408324 0.99157363 0.77654666 0.6612493  0.8517725\n",
      " 0.7906841  0.96689266]\n",
      "The rewards are: [0.78517693 0.9444553  0.8981157  0.99633104 0.9482771  0.8607768\n",
      " 0.9297409  0.94597787 0.95467335 0.9611914  0.77024084 0.95464915\n",
      " 0.73451257 0.93978    0.7026085  0.989852   0.98593974 0.9971967\n",
      " 0.96638894 0.9962476  0.99889994 0.999258   0.8817971  0.9158201\n",
      " 0.9858247  0.9954139  0.6749559  0.8750884  0.88841754 0.9939056\n",
      " 0.97114176 0.99362046]\n",
      "The rewards are: [0.8738246  0.66727877 0.7720623  0.99001557 0.98754454 0.9917903\n",
      " 0.97465116 0.79015636 0.8375027  0.9871431  0.9330916  0.9921417\n",
      " 0.99333644 0.8902505  0.91959095 0.9893811  0.9349468  0.67961925\n",
      " 0.99941695 0.9965244  0.9395044  0.96598566 0.9860269  0.78112286\n",
      " 0.9909951  0.89896697 0.75407755 0.98773426 0.97869074 0.83006936\n",
      " 0.9235402  0.99115855]\n",
      "The rewards are: [0.98916656 0.97087765 0.9839333  0.8501186  0.68739605 0.98604846\n",
      " 0.88080066 0.98831624 0.9988115  0.9976908  0.8656783  0.98673636\n",
      " 0.9506817  0.5526136  0.92615306 0.52953714 0.9902699  0.58947\n",
      " 0.5429266  0.77777404 0.75972736 0.9875201  0.965948   0.9505968\n",
      " 0.8855305  0.9831843  0.91587776 0.9566698  0.8377284  0.94380355\n",
      " 0.96281415 0.9849283 ]\n",
      "The rewards are: [0.926296   0.81338614 0.895427   0.9615969  0.9737526  0.9973539\n",
      " 0.97705954 0.968212   0.9444429  0.5355122  0.94845176 0.96157616\n",
      " 0.9910678  0.98908114 0.91975176 0.97966    0.93093324 0.99292153\n",
      " 0.7271985  0.92797774 0.9170942  0.7924053  0.9762664  0.886272\n",
      " 0.9912435  0.95074195 0.65006655 0.91653734 0.84880936 0.9168508\n",
      " 0.8964075  0.99665254]\n",
      "The rewards are: [0.9652775  0.7333676  0.9218204  0.99421555 0.9973687  0.9512128\n",
      " 0.99072343 0.5646797  0.7012323  0.9946814  0.56336033 0.71105844\n",
      " 0.99570125 0.98257565 0.72193444 0.59995544 0.9419958  0.98162085\n",
      " 0.97496754 0.7788021  0.99408144 0.53442335 0.9940082  0.980456\n",
      " 0.9687038  0.74971116 0.7022527  0.5599537  0.94334596 0.9749815\n",
      " 0.84418166 0.9109168 ]\n",
      "The rewards are: [0.9865891  0.87687075 0.88740325 0.9054568  0.7235051  0.97379375\n",
      " 0.9952981  0.9916448  0.8349544  0.99846905 0.9874529  0.9980229\n",
      " 0.9883823  0.9970995  0.5177144  0.749093   0.8051687  0.6102712\n",
      " 0.998992   0.8024922  0.62315255 0.9982638  0.5291222  0.93177426\n",
      " 0.7087312  0.99888366 0.92929125 0.983742   0.97753656 0.90542024\n",
      " 0.9940586  0.96391875]\n",
      "The rewards are: [0.99640214 0.90615046 0.99380684 0.9716987  0.9915308  0.86416537\n",
      " 0.8772404  0.72219515 0.89407426 0.81751066 0.95600814 0.89727414\n",
      " 0.8747433  0.9957611  0.5770631  0.99668103 0.8690621  0.9886339\n",
      " 0.9693559  0.93483853 0.9923362  0.81460154 0.931226   0.98471904\n",
      " 0.9793256  0.904195   0.98051625 0.89855224 0.63495207 0.99393165\n",
      " 0.8568702  0.96029335]\n",
      "The rewards are: [0.52598727 0.99059546 0.9468113  0.8300359  0.82541424 0.90171045\n",
      " 0.983842   0.89058226 0.88144517 0.5831524  0.601299   0.7359397\n",
      " 0.7078482  0.91615075 0.9251393  0.60997945 0.99113864 0.83673024\n",
      " 0.97324747 0.90115803 0.97740424 0.97988826 0.9878522  0.97453755\n",
      " 0.5194372  0.9516052  0.7210131  0.96905476 0.9927167  0.9542671\n",
      " 0.99077386 0.97614664]\n",
      "The rewards are: [0.9569594  0.5231478  0.9278876  0.99916804 0.96396196 0.963349\n",
      " 0.7723351  0.52539235 0.9906183  0.94125134 0.98528314 0.98544276\n",
      " 0.9745593  0.8439866  0.66339874 0.95934755 0.69458634 0.99780303\n",
      " 0.8398826  0.7345865  0.52126503 0.91653526 0.9294774  0.9949779\n",
      " 0.99217075 0.9478228  0.5384549  0.9919274  0.51328605 0.8664938\n",
      " 0.55118984 0.8040769 ]\n",
      "The rewards are: [0.98394495 0.83429635 0.84940386 0.65300953 0.9972964  0.9964514\n",
      " 0.99148107 0.5493132  0.7590101  0.9782865  0.81803364 0.8776298\n",
      " 0.97082764 0.8024296  0.9782647  0.9349196  0.9636615  0.78028756\n",
      " 0.9929595  0.9495491  0.97474074 0.97898716 0.99813193 0.7096355\n",
      " 0.9591522  0.8601254  0.92602533 0.99480927 0.9276376  0.99806315\n",
      " 0.87924683 0.88358414]\n",
      "The rewards are: [0.5129036  0.9970772  0.98830473 0.99903214 0.98549116 0.989106\n",
      " 0.983691   0.70670784 0.80557555 0.9959649  0.94044864 0.82044816\n",
      " 0.9873251  0.9933348  0.94547844 0.9839198  0.504598   0.9963536\n",
      " 0.99802303 0.9612431  0.606419   0.65499514 0.9959996  0.75935227\n",
      " 0.9320929  0.56832516 0.810271   0.70544636 0.9367517  0.9276773\n",
      " 0.995666   0.699235  ]\n",
      "The rewards are: [0.9681998  0.96750724 0.99183875 0.57878053 0.8944931  0.96976537\n",
      " 0.99857116 0.9818971  0.98864657 0.7090319  0.980115   0.99722457\n",
      " 0.73598194 0.93353707 0.5128635  0.63232833 0.9968323  0.8754198\n",
      " 0.55070865 0.9972167  0.94152653 0.97969246 0.9781424  0.98851764\n",
      " 0.97348875 0.91402787 0.9987692  0.8335036  0.9628554  0.86285603\n",
      " 0.531019   0.9383815 ]\n",
      "The rewards are: [0.99870574 0.9934642  0.9934576  0.9885604  0.95213336 0.9627837\n",
      " 0.8454792  0.5114331  0.77127045 0.99612075 0.8902744  0.97630435\n",
      " 0.9179718  0.9871703  0.83217025 0.99865025 0.9582149  0.9888332\n",
      " 0.99489355 0.901478   0.85424566 0.969695   0.9985253  0.783417\n",
      " 0.6422868  0.9828016  0.938498   0.993624   0.93338466 0.9093121\n",
      " 0.9991429  0.83187556]\n",
      "The rewards are: [0.88614976 0.76372963 0.9075603  0.84957    0.6531552  0.99589634\n",
      " 0.7416494  0.99275666 0.999696   0.9810838  0.83697885 0.89734113\n",
      " 0.9744119  0.99394786 0.6697829  0.9745354  0.56177646 0.9901528\n",
      " 0.93877953 0.5867625  0.90494394 0.9962698  0.8386241  0.97985154\n",
      " 0.9119619  0.60556626 0.9090699  0.922464   0.9421004  0.9938148\n",
      " 0.8926855  0.8580793 ]\n",
      "The rewards are: [0.9733516  0.98493445 0.9933227  0.8735278  0.92823786 0.92798895\n",
      " 0.94339997 0.997693   0.9935409  0.75484216 0.8921567  0.9495239\n",
      " 0.9848697  0.91502243 0.56862634 0.9941784  0.99841046 0.9127801\n",
      " 0.92809963 0.97493255 0.98076206 0.9811318  0.9280897  0.9287328\n",
      " 0.9335286  0.9945056  0.99530977 0.9583903  0.94860685 0.95329285\n",
      " 0.9734412  0.97600526]\n",
      "The rewards are: [0.95535684 0.94911623 0.9476362  0.9468678  0.8423406  0.97572255\n",
      " 0.9965802  0.99496764 0.6116033  0.9715236  0.9962276  0.93697363\n",
      " 0.95259947 0.99484324 0.9855282  0.9652853  0.9336017  0.789937\n",
      " 0.9837526  0.9880162  0.91525424 0.69182163 0.9968405  0.8643701\n",
      " 0.9933329  0.7458288  0.9669454  0.9747464  0.9924293  0.9680554\n",
      " 0.9612973  0.99467367]\n",
      "The rewards are: [0.99808455 0.5678049  0.98418254 0.8523716  0.8773115  0.9870465\n",
      " 0.8547327  0.993694   0.86679417 0.80717725 0.9223432  0.9833899\n",
      " 0.9385662  0.92975473 0.8566381  0.9811577  0.990789   0.5990643\n",
      " 0.8515759  0.9688345  0.75392216 0.9769678  0.9893289  0.99689424\n",
      " 0.9557583  0.7447656  0.97863513 0.93164366 0.8482921  0.9188648\n",
      " 0.9580027  0.99664754]\n",
      "The rewards are: [0.9604697  0.916247   0.987217   0.99736506 0.9657556  0.9623965\n",
      " 0.8891634  0.94232583 0.9647494  0.9625823  0.9906565  0.743585\n",
      " 0.9031673  0.9049073  0.9298773  0.76927763 0.564901   0.99319625\n",
      " 0.94824517 0.9162277  0.96192145 0.9337166  0.79881734 0.95408803\n",
      " 0.98099315 0.9984485  0.98970103 0.9371386  0.8558706  0.9180782\n",
      " 0.9156476  0.99081063]\n",
      "The rewards are: [0.6734367  0.9699925  0.71805775 0.8095323  0.57435054 0.934307\n",
      " 0.75729555 0.9872572  0.8811271  0.80112326 0.9962436  0.75283957\n",
      " 0.8248547  0.7576781  0.97606474 0.6684669  0.9539127  0.9690137\n",
      " 0.88563406 0.8267924  0.98408604 0.6185549  0.9043617  0.9902075\n",
      " 0.88792634 0.927326   0.93582815 0.98750466 0.93993956 0.6860127\n",
      " 0.87223184 0.9845094 ]\n",
      "The rewards are: [0.72936666 0.76588595 0.8936375  0.9979785  0.9944265  0.80090207\n",
      " 0.9367869  0.9852143  0.99894005 0.9293556  0.6642456  0.9988127\n",
      " 0.5625277  0.9432194  0.97278994 0.66501975 0.99684817 0.99724495\n",
      " 0.7927398  0.790468   0.9213616  0.78769475 0.91206574 0.8836606\n",
      " 0.9561026  0.80299264 0.7316751  0.77068484 0.86672467 0.97256655\n",
      " 0.9921976  0.9674343 ]\n",
      "The rewards are: [0.9675125  0.98360795 0.64501494 0.9906058  0.6797115  0.9933188\n",
      " 0.98529124 0.9954202  0.9892631  0.94267666 0.92121524 0.9937075\n",
      " 0.98256636 0.8563762  0.87833196 0.9901294  0.9847751  0.7010914\n",
      " 0.98730844 0.84103215 0.99264634 0.9982456  0.9976763  0.98601365\n",
      " 0.99563354 0.9773796  0.9850311  0.9980432  0.9969151  0.98134136\n",
      " 0.99160624 0.8921182 ]\n",
      "The rewards are: [0.9816596  0.9952976  0.9884212  0.5628201  0.88245326 0.9982823\n",
      " 0.5483932  0.7309539  0.9448128  0.98991895 0.96128494 0.9995845\n",
      " 0.8693787  0.9771922  0.9357459  0.66053605 0.9429501  0.9847407\n",
      " 0.6833948  0.8582014  0.99829096 0.83949345 0.99693656 0.96766907\n",
      " 0.9913203  0.92371696 0.9719856  0.6628413  0.9732335  0.9261738\n",
      " 0.95026976 0.9816683 ]\n",
      "The rewards are: [0.90849197 0.9995597  0.9979888  0.7058075  0.95272076 0.99427587\n",
      " 0.99082667 0.91717947 0.93109345 0.9411673  0.9187062  0.90826476\n",
      " 0.70227927 0.98673916 0.97613984 0.9611945  0.9855999  0.995419\n",
      " 0.7698994  0.9837382  0.83169156 0.99582726 0.7908723  0.89777803\n",
      " 0.9783434  0.99494237 0.9965239  0.99288005 0.9344735  0.99709094\n",
      " 0.9663647  0.998629  ]\n",
      "The rewards are: [0.893962   0.5823519  0.9734799  0.99698573 0.9911697  0.9933918\n",
      " 0.99517137 0.82859355 0.9354005  0.9321218  0.99197453 0.9878043\n",
      " 0.9470296  0.9625098  0.98135614 0.98432213 0.9240606  0.9809857\n",
      " 0.9322271  0.8920256  0.9750265  0.9027511  0.59651995 0.7012577\n",
      " 0.90955365 0.8048897  0.6503723  0.6069799  0.75601    0.9526092\n",
      " 0.9860409  0.94224346]\n",
      "The rewards are: [0.94988936 0.9931191  0.92501587 0.7377381  0.9754465  0.9355733\n",
      " 0.90415937 0.8772884  0.7298451  0.92179495 0.8301474  0.9944747\n",
      " 0.9838366  0.75538385 0.9249214  0.98368394 0.8980206  0.95899725\n",
      " 0.7390391  0.82780176 0.8947225  0.99423957 0.984344   0.9218746\n",
      " 0.9950832  0.74177146 0.9959728  0.9416744  0.99377304 0.995828\n",
      " 0.79995185 0.56142884]\n",
      "The rewards are: [0.9570946  0.8398327  0.77285177 0.9658752  0.85666996 0.8961483\n",
      " 0.7695046  0.8052456  0.97491914 0.9944735  0.99235356 0.55826104\n",
      " 0.82870436 0.9681272  0.7947218  0.7993819  0.99691963 0.93893653\n",
      " 0.81475836 0.97923607 0.99415624 0.98614675 0.80847424 0.6701726\n",
      " 0.7963637  0.65545404 0.77503926 0.72058725 0.9271686  0.85775423\n",
      " 0.9965268  0.9538842 ]\n",
      "The rewards are: [0.5635831  0.9886079  0.60443074 0.7056424  0.9901288  0.9984668\n",
      " 0.87838393 0.9095815  0.9970419  0.9940317  0.88084424 0.5789356\n",
      " 0.9550356  0.976318   0.9980128  0.52734226 0.78875476 0.91593176\n",
      " 0.9676184  0.9863853  0.97940683 0.9571807  0.80535537 0.97209543\n",
      " 0.9564173  0.7427997  0.98829156 0.9731375  0.9996402  0.99213177\n",
      " 0.86399424 0.734944  ]\n",
      "The rewards are: [0.827676   0.9781447  0.5349495  0.5902039  0.99391913 0.94815564\n",
      " 0.9837738  0.8684358  0.9919601  0.9888553  0.93171734 0.98191756\n",
      " 0.9769807  0.6232852  0.98203063 0.7412883  0.8518851  0.97977656\n",
      " 0.7337606  0.98430634 0.61105967 0.9990741  0.98699397 0.8487934\n",
      " 0.9988446  0.9927181  0.9950759  0.995804   0.8612831  0.7513183\n",
      " 0.8312516  0.93503284]\n",
      "The rewards are: [0.8603924  0.9836745  0.9441596  0.6122991  0.9169948  0.88225996\n",
      " 0.9459947  0.6616608  0.9854896  0.8887882  0.766711   0.7034833\n",
      " 0.9789131  0.97582334 0.90793544 0.94931376 0.968696   0.85202533\n",
      " 0.99889225 0.9839125  0.9443392  0.9621771  0.9937151  0.92054176\n",
      " 0.944754   0.99288875 0.8446556  0.7606012  0.9323708  0.9848385\n",
      " 0.9755077  0.9372542 ]\n",
      "The rewards are: [0.99801767 0.9977622  0.96183836 0.577465   0.99539655 0.9920254\n",
      " 0.5381717  0.9726017  0.92396307 0.99288553 0.8210972  0.99806577\n",
      " 0.92917866 0.93275374 0.80378467 0.99142706 0.94988495 0.9778391\n",
      " 0.92333555 0.9923449  0.98030233 0.8436274  0.9928665  0.9928275\n",
      " 0.8600723  0.9687891  0.982894   0.9477988  0.9334115  0.81674254\n",
      " 0.936044   0.5687359 ]\n",
      "The rewards are: [0.9978058  0.90640354 0.99211943 0.9724524  0.5396762  0.98610735\n",
      " 0.86972886 0.5308718  0.9948933  0.94601625 0.9318346  0.93314564\n",
      " 0.787121   0.9985514  0.9484449  0.6088809  0.7066385  0.89563185\n",
      " 0.9925822  0.72773546 0.9558081  0.9967874  0.98244023 0.9159589\n",
      " 0.87707293 0.9916911  0.8677766  0.98825014 0.9863651  0.97223896\n",
      " 0.9123329  0.96957135]\n",
      "The rewards are: [0.9972011  0.7596028  0.95193607 0.95621604 0.773097   0.98376554\n",
      " 0.97698045 0.98826516 0.91916466 0.7520974  0.8863048  0.9886246\n",
      " 0.75901735 0.9425361  0.95302546 0.99902153 0.95636886 0.9980692\n",
      " 0.95186895 0.80191094 0.8315324  0.67846155 0.51143885 0.95425767\n",
      " 0.84962255 0.9430535  0.99706453 0.7905632  0.9752172  0.99544525\n",
      " 0.9903661  0.9286421 ]\n",
      "The rewards are: [0.6309924  0.9676808  0.8642268  0.6980621  0.75683004 0.98852193\n",
      " 0.8572835  0.9580532  0.96579206 0.98183    0.9814905  0.9754601\n",
      " 0.9871329  0.6042096  0.9604971  0.9147806  0.98196447 0.82486635\n",
      " 0.8913373  0.94908863 0.7051388  0.71367496 0.99101895 0.9713156\n",
      " 0.9379789  0.6760938  0.5211381  0.9795793  0.83067656 0.62216175\n",
      " 0.9962308  0.96024686]\n",
      "The rewards are: [0.8225684  0.61563903 0.98214644 0.9480592  0.531514   0.7785153\n",
      " 0.9985814  0.8802226  0.7925781  0.96872663 0.9252114  0.98225915\n",
      " 0.7524635  0.9858462  0.9990396  0.88504755 0.999175   0.99225664\n",
      " 0.9648807  0.98422825 0.9975769  0.97429997 0.70103294 0.55301243\n",
      " 0.88450354 0.9631825  0.80727845 0.8938462  0.9985434  0.7264733\n",
      " 0.9474728  0.97583175]\n",
      "The rewards are: [0.989664   0.9527938  0.96584255 0.7018223  0.97799563 0.9746833\n",
      " 0.9946063  0.9277609  0.97812825 0.978674   0.8951147  0.9578989\n",
      " 0.9684632  0.96563876 0.9760616  0.9649724  0.60114676 0.76150393\n",
      " 0.93045324 0.89811367 0.86303777 0.96988857 0.87193686 0.9403123\n",
      " 0.7286809  0.84874254 0.9585896  0.88527507 0.9755992  0.99423224\n",
      " 0.967924   0.974555  ]\n",
      "The rewards are: [0.9841979  0.83388907 0.9831965  0.94873506 0.5017209  0.8196119\n",
      " 0.9630026  0.97851974 0.9971656  0.9874998  0.6567662  0.99627626\n",
      " 0.7144761  0.6597166  0.73256284 0.54595727 0.94249237 0.98288065\n",
      " 0.692245   0.9844619  0.9601588  0.99593496 0.973717   0.5195932\n",
      " 0.92647266 0.99363744 0.5635515  0.9156922  0.9065152  0.93771815\n",
      " 0.9916108  0.8964536 ]\n",
      "The rewards are: [0.9714119  0.9953826  0.96978676 0.9825231  0.8996354  0.99714345\n",
      " 0.60316557 0.99374044 0.96237767 0.9684787  0.78754133 0.90683126\n",
      " 0.9011706  0.91165173 0.9892231  0.9678803  0.9817853  0.97579\n",
      " 0.9947254  0.83896047 0.8592237  0.99548954 0.9239458  0.9191019\n",
      " 0.9336762  0.8935815  0.9921251  0.8612874  0.8715809  0.9931217\n",
      " 0.97435284 0.99842775]\n",
      "The rewards are: [0.9995222  0.9046778  0.9862422  0.9884444  0.87609476 0.89271945\n",
      " 0.7580706  0.93473405 0.95648557 0.86187243 0.9589739  0.97147536\n",
      " 0.5351437  0.982107   0.9802698  0.67465353 0.5541177  0.7272635\n",
      " 0.9918642  0.85823184 0.96930647 0.99970895 0.6268538  0.9021549\n",
      " 0.98542374 0.95632505 0.8075536  0.99520785 0.9983215  0.9920786\n",
      " 0.8205179  0.84092444]\n",
      "The rewards are: [0.77492756 0.8168542  0.93421644 0.9743627  0.9942768  0.98929286\n",
      " 0.98193353 0.9896852  0.8736699  0.8518693  0.9773875  0.96769965\n",
      " 0.6453554  0.7999369  0.99886864 0.83522856 0.93105    0.97914416\n",
      " 0.6120199  0.9458187  0.83062804 0.99847335 0.98402417 0.99968505\n",
      " 0.92840683 0.9680011  0.95176864 0.9640767  0.99011874 0.9503534\n",
      " 0.68919015 0.9124721 ]\n",
      "The rewards are: [0.9951644  0.8881472  0.9733515  0.991318   0.9618242  0.9680843\n",
      " 0.93037605 0.9622478  0.99672735 0.99239975 0.5059869  0.8035051\n",
      " 0.9613157  0.74498826 0.8501048  0.985058   0.98032814 0.9933042\n",
      " 0.9598688  0.5873743  0.9958145  0.995199   0.9876809  0.97141457\n",
      " 0.95761174 0.90800387 0.88038355 0.950131   0.50831383 0.9973418\n",
      " 0.99471396 0.99450123]\n",
      "The rewards are: [0.9672133  0.67663795 0.9656442  0.9833557  0.9829995  0.98824525\n",
      " 0.9755073  0.9586781  0.999003   0.73780113 0.99221015 0.9843316\n",
      " 0.9936147  0.77733874 0.9471317  0.9467984  0.5413425  0.614123\n",
      " 0.9963278  0.9862439  0.8564043  0.96526104 0.9806943  0.7797446\n",
      " 0.94623595 0.99493355 0.97720784 0.9952016  0.9663757  0.9360637\n",
      " 0.9922172  0.8811986 ]\n",
      "The rewards are: [0.9943303  0.5881677  0.9950959  0.9894198  0.99791557 0.8967096\n",
      " 0.9953275  0.9879952  0.8047747  0.989773   0.7297622  0.9980288\n",
      " 0.9744254  0.98783934 0.97650105 0.5025832  0.9862812  0.9725647\n",
      " 0.9946737  0.9217758  0.9826483  0.65917003 0.66526455 0.9297106\n",
      " 0.99888283 0.9963141  0.9952945  0.7962263  0.65158814 0.9658322\n",
      " 0.76496375 0.9845887 ]\n",
      "The rewards are: [0.9925983  0.99777883 0.8375711  0.83018917 0.9878856  0.9962534\n",
      " 0.96975136 0.9396001  0.96194226 0.7443238  0.9919499  0.7648361\n",
      " 0.9561971  0.940567   0.9637002  0.994695   0.97587854 0.96370846\n",
      " 0.88949436 0.92561847 0.90108454 0.94623893 0.99021965 0.9697826\n",
      " 0.9967002  0.56930566 0.8527713  0.9985304  0.9873284  0.90107733\n",
      " 0.9325442  0.9933113 ]\n",
      "The rewards are: [0.968476   0.95192987 0.98347867 0.9384635  0.9973278  0.9875212\n",
      " 0.7074276  0.98953    0.9735492  0.92118996 0.9326026  0.98134667\n",
      " 0.99772674 0.9249308  0.98256886 0.95818996 0.58651096 0.9944659\n",
      " 0.79878354 0.96297055 0.9762324  0.9142934  0.9976694  0.8868632\n",
      " 0.73707515 0.9956917  0.977394   0.8569855  0.98385346 0.99778193\n",
      " 0.9983729  0.96143246]\n",
      "The rewards are: [0.55267406 0.8465984  0.9654601  0.91129017 0.97998434 0.9945639\n",
      " 0.98673534 0.9955493  0.8631096  0.96726114 0.9978071  0.9598268\n",
      " 0.9824859  0.9992539  0.9925955  0.9852219  0.9493249  0.99549484\n",
      " 0.94190574 0.91717017 0.9749316  0.5635176  0.7782718  0.9160674\n",
      " 0.996976   0.98983455 0.99663806 0.9956583  0.9246495  0.8046801\n",
      " 0.9788204  0.8014035 ]\n",
      "The rewards are: [0.9668141  0.8947342  0.5842412  0.81745803 0.9349     0.9983675\n",
      " 0.6125213  0.70364004 0.9672756  0.9616237  0.947174   0.830188\n",
      " 0.8161992  0.995883   0.9842778  0.9992818  0.862506   0.9991948\n",
      " 0.5647865  0.92954373 0.5692683  0.98549855 0.98848677 0.9390777\n",
      " 0.9769538  0.9910348  0.99537283 0.9653171  0.99351573 0.9982987\n",
      " 0.86524075 0.8693052 ]\n",
      "The rewards are: [0.8952711  0.793556   0.8420357  0.9495452  0.6717855  0.5431616\n",
      " 0.84778726 0.90537566 0.9022501  0.99763596 0.7985112  0.9209546\n",
      " 0.9876287  0.79276615 0.966067   0.9982034  0.8593006  0.9988588\n",
      " 0.598493   0.55069375 0.96131504 0.96552306 0.9925976  0.98907334\n",
      " 0.9920541  0.8371828  0.63884056 0.9795908  0.54132664 0.9431342\n",
      " 0.9344752  0.98024267]\n",
      "The rewards are: [0.99837446 0.63224846 0.9926381  0.5821838  0.9640447  0.99324715\n",
      " 0.8357209  0.998626   0.8887944  0.9635522  0.97406435 0.821318\n",
      " 0.9816458  0.9972294  0.91096413 0.9315738  0.9989736  0.9858086\n",
      " 0.99781173 0.7852007  0.9962852  0.98027873 0.5471067  0.9188376\n",
      " 0.996696   0.8972063  0.9883349  0.99415576 0.997999   0.73142916\n",
      " 0.9909683  0.9969638 ]\n",
      "The rewards are: [0.9782721  0.53332573 0.976273   0.9974101  0.98819494 0.9623601\n",
      " 0.9793814  0.9839849  0.9194795  0.92780596 0.99717027 0.6476245\n",
      " 0.9941484  0.9904213  0.96455896 0.90457267 0.988166   0.977136\n",
      " 0.6086748  0.7356751  0.94112027 0.9902372  0.65417176 0.9943974\n",
      " 0.95593166 0.7781423  0.75933605 0.94356936 0.6495922  0.9955101\n",
      " 0.9907573  0.8601855 ]\n",
      "The rewards are: [0.9540964  0.9741495  0.9753797  0.95842355 0.9522054  0.99909854\n",
      " 0.5921609  0.93466115 0.9969951  0.89061093 0.5570825  0.9407543\n",
      " 0.80962735 0.99536514 0.8022684  0.9988148  0.9758648  0.99068016\n",
      " 0.9935098  0.8537019  0.85549545 0.9693431  0.9961451  0.5398393\n",
      " 0.6560859  0.9960542  0.9827352  0.90652066 0.5861214  0.91293806\n",
      " 0.99624604 0.9947149 ]\n",
      "The rewards are: [0.9391153  0.9987005  0.65947396 0.9974138  0.9881549  0.93753695\n",
      " 0.85241896 0.9789538  0.99904436 0.9815338  0.85429716 0.90848136\n",
      " 0.8829058  0.9888938  0.68921036 0.6828014  0.98599154 0.9901361\n",
      " 0.99513113 0.9511823  0.7985647  0.7997529  0.98040295 0.7116024\n",
      " 0.9203547  0.8490038  0.943492   0.98741794 0.9771308  0.6415199\n",
      " 0.6302396  0.92032826]\n",
      "The rewards are: [0.96762943 0.99145997 0.813319   0.7267565  0.9779523  0.8685412\n",
      " 0.989431   0.69474304 0.9882812  0.9801516  0.9801021  0.96644807\n",
      " 0.53660065 0.9947247  0.994592   0.9994874  0.9973007  0.8912171\n",
      " 0.98949695 0.99723935 0.8894474  0.6736403  0.98816943 0.9900356\n",
      " 0.9163003  0.99404114 0.5970841  0.57640654 0.9964551  0.6733715\n",
      " 0.96049017 0.9908879 ]\n",
      "The rewards are: [0.87651956 0.9093131  0.7769336  0.9294004  0.97077125 0.9882139\n",
      " 0.95195234 0.99608684 0.7466334  0.9721876  0.84042275 0.71036714\n",
      " 0.992618   0.9810175  0.98961127 0.8047768  0.9512817  0.99912065\n",
      " 0.98863065 0.7332093  0.7114654  0.7494115  0.8634799  0.67232376\n",
      " 0.9624013  0.9918609  0.994052   0.9853893  0.69831604 0.9926621\n",
      " 0.8978743  0.9936091 ]\n",
      "The rewards are: [0.9361078  0.7262973  0.9883641  0.7778139  0.9907569  0.6574644\n",
      " 0.9963386  0.99555945 0.655804   0.6048417  0.941474   0.9726059\n",
      " 0.945585   0.9830078  0.9990563  0.99763906 0.9899419  0.95377105\n",
      " 0.8763121  0.76931226 0.99351513 0.67693937 0.9276186  0.9090571\n",
      " 0.90457577 0.9047634  0.98943895 0.784804   0.98935866 0.9678802\n",
      " 0.95935106 0.9973362 ]\n",
      "The rewards are: [0.9563441  0.9984723  0.9781008  0.6973886  0.99683136 0.9909731\n",
      " 0.9998485  0.9818475  0.83670914 0.99712664 0.99399525 0.9863945\n",
      " 0.99868387 0.76913226 0.9933108  0.9798132  0.9844752  0.94146365\n",
      " 0.9916837  0.80394584 0.9432202  0.86586773 0.9067131  0.96554494\n",
      " 0.6389193  0.9413386  0.74851584 0.96282876 0.9656473  0.70257074\n",
      " 0.9652112  0.9770941 ]\n",
      "The rewards are: [0.9469726  0.99667907 0.933335   0.99684817 0.9898127  0.5848881\n",
      " 0.98697203 0.9883741  0.9975979  0.98460996 0.9997516  0.61351264\n",
      " 0.8730081  0.9476237  0.96166825 0.9995764  0.9749997  0.88584316\n",
      " 0.7391021  0.99349195 0.86458826 0.8440102  0.9532182  0.9112757\n",
      " 0.99771535 0.996278   0.99065757 0.9413631  0.7802764  0.9469442\n",
      " 0.9967968  0.6184762 ]\n",
      "The rewards are: [0.9729135  0.9972007  0.97476506 0.90804905 0.9997222  0.9524432\n",
      " 0.9932326  0.9154127  0.9864804  0.95592403 0.71098864 0.9237099\n",
      " 0.8451123  0.9853255  0.9897524  0.9208825  0.89403236 0.96855384\n",
      " 0.9949633  0.9223688  0.9986412  0.9517615  0.9749693  0.86724645\n",
      " 0.9731415  0.9997564  0.97253346 0.98411167 0.99535084 0.64036596\n",
      " 0.53150684 0.9975937 ]\n",
      "The rewards are: [0.9056527  0.81329376 0.9631177  0.99359506 0.9877599  0.94577307\n",
      " 0.95462275 0.87278235 0.7752731  0.75774133 0.8916004  0.99384093\n",
      " 0.998329   0.5809323  0.9901342  0.998719   0.97502655 0.70024025\n",
      " 0.85457385 0.69617456 0.99465203 0.9711906  0.99928975 0.9946002\n",
      " 0.960673   0.71266884 0.88055205 0.9932367  0.9724371  0.8037029\n",
      " 0.7816051  0.9838876 ]\n",
      "The rewards are: [0.96566385 0.998445   0.57620895 0.93657696 0.99863404 0.9392192\n",
      " 0.9945338  0.9953709  0.52766335 0.99442047 0.99774796 0.85928744\n",
      " 0.9959265  0.97078395 0.81083745 0.9896354  0.92041004 0.81339157\n",
      " 0.7866593  0.6023184  0.98477143 0.9867287  0.96333253 0.7123273\n",
      " 0.9036036  0.9812686  0.56979764 0.9557634  0.8307046  0.8651386\n",
      " 0.95328057 0.6477789 ]\n",
      "The rewards are: [0.9127056  0.96853316 0.633521   0.9343785  0.94725865 0.9820024\n",
      " 0.99725693 0.9582138  0.95678145 0.9970567  0.9913379  0.99527514\n",
      " 0.96643585 0.54252446 0.8722076  0.98575056 0.98177356 0.99437344\n",
      " 0.8004181  0.99469936 0.8088417  0.98783374 0.9715157  0.85645944\n",
      " 0.99487466 0.99970514 0.51776165 0.96958995 0.85864836 0.97899467\n",
      " 0.9979899  0.5225113 ]\n",
      "The rewards are: [0.98925215 0.99674267 0.73061556 0.9857261  0.99692315 0.8939381\n",
      " 0.98963565 0.8722133  0.92967826 0.99194956 0.99967015 0.99626726\n",
      " 0.84463763 0.9847675  0.5546238  0.62812716 0.9374475  0.99557966\n",
      " 0.936938   0.97863114 0.9807524  0.89473397 0.96671027 0.5796537\n",
      " 0.9597035  0.8563816  0.99619746 0.9990134  0.9317934  0.99850935\n",
      " 0.9809873  0.98748267]\n",
      "The rewards are: [0.8733599  0.8909866  0.803735   0.98279047 0.9848927  0.8839251\n",
      " 0.9655564  0.9961816  0.7427446  0.791773   0.9965958  0.54349995\n",
      " 0.9511811  0.99768865 0.88363147 0.9939428  0.99788624 0.76179856\n",
      " 0.99467295 0.98474556 0.97781247 0.8807566  0.88200885 0.9615612\n",
      " 0.97054875 0.998519   0.9907032  0.9528321  0.9992125  0.71896493\n",
      " 0.9597888  0.99370414]\n",
      "The rewards are: [0.8482351  0.7825811  0.97439235 0.64394116 0.563032   0.98769486\n",
      " 0.99538994 0.9604147  0.922019   0.522002   0.5842548  0.9379752\n",
      " 0.99429893 0.9987326  0.9369948  0.9510416  0.91285354 0.56111157\n",
      " 0.9977756  0.97854316 0.95476234 0.90559757 0.9859951  0.96515876\n",
      " 0.9867813  0.9990288  0.9994148  0.9763529  0.78383833 0.99718297\n",
      " 0.79427224 0.9994641 ]\n",
      "The rewards are: [0.99711716 0.9862135  0.9671066  0.95537704 0.97301507 0.59987587\n",
      " 0.6853668  0.9947127  0.65602565 0.97759557 0.8903281  0.9897232\n",
      " 0.99682826 0.9985661  0.9949207  0.9945259  0.93560547 0.9462398\n",
      " 0.99636394 0.9503451  0.9361217  0.96321285 0.9228985  0.9941176\n",
      " 0.9419763  0.9956518  0.95247066 0.99738175 0.9911204  0.9932073\n",
      " 0.97468626 0.9056935 ]\n",
      "The rewards are: [0.9854188  0.84876144 0.5696001  0.97908396 0.58256716 0.95440316\n",
      " 0.81780523 0.9251125  0.9976889  0.9347909  0.9512216  0.97356784\n",
      " 0.82057315 0.9926065  0.9574374  0.7224722  0.9921822  0.7854261\n",
      " 0.9845596  0.97743773 0.995833   0.87237716 0.9501128  0.77541304\n",
      " 0.9942688  0.8856096  0.9867469  0.9900559  0.97958916 0.9155503\n",
      " 0.9424584  0.9727911 ]\n",
      "The rewards are: [0.9633782  0.7318677  0.9970554  0.9003745  0.98931015 0.7807271\n",
      " 0.9948336  0.9924385  0.9922806  0.95607513 0.89113086 0.99653447\n",
      " 0.9961151  0.9527022  0.99643505 0.9957854  0.80422324 0.9909372\n",
      " 0.9765189  0.99535346 0.99923503 0.99812025 0.53986293 0.9415833\n",
      " 0.89840424 0.9495183  0.9914231  0.9938824  0.96626085 0.98429996\n",
      " 0.95769    0.6412969 ]\n",
      "The rewards are: [0.9746382  0.9900242  0.56682414 0.9982822  0.9039363  0.987351\n",
      " 0.9070353  0.99339867 0.91793895 0.9421603  0.99165934 0.8786253\n",
      " 0.90951085 0.7903608  0.9958619  0.9982686  0.9824901  0.9578579\n",
      " 0.9951089  0.8551124  0.97459507 0.66521907 0.9139056  0.9175203\n",
      " 0.97398144 0.8663517  0.9647788  0.8873676  0.9954958  0.99734807\n",
      " 0.575825   0.950499  ]\n",
      "The rewards are: [0.90536207 0.99103886 0.9969421  0.8513404  0.9866968  0.85955256\n",
      " 0.8777592  0.9727693  0.8184827  0.65216357 0.9585886  0.9791703\n",
      " 0.98822767 0.9971666  0.5596747  0.9849219  0.919278   0.9231226\n",
      " 0.9879177  0.9690277  0.67849594 0.522955   0.96107495 0.90051347\n",
      " 0.7151181  0.9767635  0.9717491  0.9953453  0.8895406  0.6988615\n",
      " 0.50785416 0.91282094]\n",
      "The rewards are: [0.73040676 0.7549619  0.7412665  0.94706154 0.970708   0.99590343\n",
      " 0.9963511  0.7765529  0.6486706  0.7822013  0.992416   0.9681952\n",
      " 0.9104185  0.98956305 0.99045837 0.9543555  0.9843312  0.9574327\n",
      " 0.9910362  0.7699132  0.9968816  0.8561314  0.88003004 0.9963735\n",
      " 0.91262203 0.92843133 0.6123497  0.9947661  0.54776615 0.9450101\n",
      " 0.96457547 0.9438648 ]\n",
      "The rewards are: [0.9805612  0.7009504  0.90442103 0.958846   0.98596907 0.98706204\n",
      " 0.9910493  0.9430117  0.9787204  0.9967303  0.94300514 0.64975023\n",
      " 0.8589134  0.99839264 0.7736837  0.99714833 0.6354309  0.6086863\n",
      " 0.9901065  0.8127838  0.9963205  0.933575   0.8999428  0.91316503\n",
      " 0.9961366  0.6382297  0.9724443  0.97218215 0.947772   0.9917247\n",
      " 0.93434286 0.99879175]\n",
      "The rewards are: [0.92105216 0.9555392  0.9843848  0.94357646 0.98928636 0.9933422\n",
      " 0.6730992  0.9451059  0.9912395  0.77425826 0.56326526 0.9952043\n",
      " 0.76083386 0.98445904 0.9502321  0.86237437 0.993152   0.99564594\n",
      " 0.90467274 0.9978769  0.69926804 0.77956486 0.99862003 0.92828315\n",
      " 0.9927186  0.96140546 0.7939068  0.5765199  0.99136776 0.94817066\n",
      " 0.97258747 0.9567204 ]\n",
      "The rewards are: [0.96957076 0.8199873  0.93736094 0.9125168  0.88657016 0.79204565\n",
      " 0.592397   0.9948521  0.98406833 0.6433773  0.99893194 0.82339334\n",
      " 0.97330034 0.9765313  0.9826066  0.89054036 0.9813641  0.9636365\n",
      " 0.5278931  0.9881831  0.7557104  0.7280925  0.995069   0.9946742\n",
      " 0.99780947 0.895579   0.6774697  0.9993555  0.9837878  0.9471876\n",
      " 0.9061538  0.9956488 ]\n",
      "The rewards are: [0.50401115 0.9970892  0.7691264  0.9896576  0.5643489  0.9041433\n",
      " 0.9949209  0.9917999  0.98535824 0.80475163 0.9463625  0.70681375\n",
      " 0.99543756 0.95362    0.92101526 0.9629497  0.6463671  0.9645899\n",
      " 0.9432413  0.995769   0.99964154 0.9711157  0.76536745 0.9908375\n",
      " 0.9889774  0.9802459  0.78827375 0.9906433  0.86192507 0.8994322\n",
      " 0.9969086  0.8767099 ]\n",
      "The rewards are: [0.8156121  0.83539224 0.9948395  0.8766224  0.9704779  0.9941606\n",
      " 0.9891262  0.9054558  0.96170783 0.9125154  0.6190025  0.98865473\n",
      " 0.98327327 0.9867172  0.9510493  0.998594   0.97056997 0.9791018\n",
      " 0.95430094 0.9974343  0.9317554  0.98059845 0.9750456  0.96719927\n",
      " 0.794594   0.79925835 0.88931113 0.96543604 0.9963043  0.5580356\n",
      " 0.5422742  0.9767593 ]\n",
      "The rewards are: [0.98943114 0.6327443  0.99204355 0.92302215 0.672881   0.99967146\n",
      " 0.9879987  0.98242444 0.61192614 0.9846677  0.9755667  0.9842121\n",
      " 0.8486597  0.7282307  0.9267173  0.8268675  0.9405937  0.9569111\n",
      " 0.60917974 0.9268708  0.8512897  0.6446203  0.99528164 0.9988502\n",
      " 0.986087   0.99678457 0.99814296 0.9884419  0.96493393 0.6435034\n",
      " 0.92852074 0.9970066 ]\n",
      "The rewards are: [0.976652   0.8686573  0.99626154 0.9988164  0.99761593 0.9987514\n",
      " 0.8132228  0.96135426 0.98617494 0.9788321  0.9350015  0.84648263\n",
      " 0.9419883  0.98475283 0.6670945  0.9971053  0.98356265 0.6140059\n",
      " 0.835945   0.578751   0.6423073  0.91032416 0.99701023 0.9381109\n",
      " 0.9356524  0.9698224  0.9136085  0.99928904 0.5252633  0.70074546\n",
      " 0.99460536 0.9429391 ]\n",
      "The rewards are: [0.81953293 0.9938864  0.5929027  0.88505733 0.99462765 0.7766856\n",
      " 0.9466831  0.988663   0.99823546 0.9505713  0.9989237  0.9783918\n",
      " 0.98329264 0.71296644 0.9967417  0.59103316 0.9963062  0.7911978\n",
      " 0.7555485  0.6635108  0.506533   0.992812   0.9956228  0.97726667\n",
      " 0.6271308  0.98315847 0.98228216 0.55168986 0.96306473 0.9416308\n",
      " 0.9649497  0.99459654]\n",
      "The rewards are: [0.99631786 0.9373149  0.9756445  0.9749453  0.977656   0.97849256\n",
      " 0.71842194 0.9336554  0.9581129  0.73339355 0.8888457  0.6372826\n",
      " 0.5151773  0.817446   0.99767977 0.8992451  0.91829115 0.8054007\n",
      " 0.9620208  0.9830614  0.8931579  0.9858828  0.6478011  0.9638277\n",
      " 0.99095964 0.94151247 0.9534639  0.9559027  0.9416322  0.9361336\n",
      " 0.8829455  0.99015254]\n",
      "The rewards are: [0.9635398  0.98684883 0.9636779  0.66977984 0.98675793 0.8991899\n",
      " 0.74094135 0.86017156 0.9253544  0.91553795 0.9621007  0.83904105\n",
      " 0.9780763  0.94534266 0.99322987 0.9367143  0.9915521  0.88110685\n",
      " 0.9954692  0.9416773  0.9541769  0.9843456  0.5989586  0.9970445\n",
      " 0.9749458  0.9993806  0.97301537 0.995084   0.96176535 0.69950974\n",
      " 0.9805217  0.9842664 ]\n",
      "The rewards are: [0.97061086 0.77086335 0.9954411  0.8547144  0.9890204  0.98374987\n",
      " 0.9357052  0.9549755  0.9658531  0.9998024  0.8126063  0.9824652\n",
      " 0.9779213  0.95709366 0.64514804 0.9944723  0.8693118  0.7903371\n",
      " 0.990267   0.98016316 0.8862576  0.9930568  0.9323137  0.99802065\n",
      " 0.9312861  0.9963349  0.6343067  0.97653586 0.9446703  0.8507924\n",
      " 0.989235   0.59527755]\n",
      "The rewards are: [0.99588984 0.71967214 0.9965592  0.99619496 0.90498686 0.90160006\n",
      " 0.86191475 0.9943904  0.96679115 0.97806156 0.67035866 0.9946091\n",
      " 0.9798886  0.8668009  0.9729139  0.5480332  0.9609914  0.84664434\n",
      " 0.975718   0.9163494  0.9928559  0.9619577  0.8424475  0.6942607\n",
      " 0.9347448  0.754664   0.9186885  0.99707246 0.99608153 0.94733566\n",
      " 0.8412103  0.99832827]\n",
      "The rewards are: [0.7693242  0.9899103  0.99636877 0.94998425 0.9611125  0.9978521\n",
      " 0.90325785 0.9982529  0.96025556 0.74003845 0.59547186 0.99155945\n",
      " 0.7979016  0.94679075 0.9905592  0.9868205  0.9741775  0.9910569\n",
      " 0.8445883  0.9831329  0.8388582  0.9759085  0.9799937  0.9847956\n",
      " 0.621865   0.99949634 0.8788953  0.92775697 0.99888057 0.95063967\n",
      " 0.99506384 0.9513617 ]\n",
      "The rewards are: [0.7601854  0.9951748  0.8892728  0.9672764  0.89780617 0.9620697\n",
      " 0.60119814 0.99371815 0.8513556  0.54503447 0.9959478  0.8562594\n",
      " 0.88216794 0.7809133  0.901562   0.9881088  0.90135676 0.78704804\n",
      " 0.9948384  0.9986443  0.9921813  0.98809683 0.9421194  0.9909469\n",
      " 0.8169528  0.8796774  0.54084074 0.726899   0.6395863  0.90909886\n",
      " 0.9746163  0.9982546 ]\n",
      "The rewards are: [0.9976546  0.992058   0.7853211  0.9918664  0.980702   0.58451396\n",
      " 0.7081769  0.97106546 0.98433    0.9993674  0.99663526 0.8322428\n",
      " 0.99698514 0.97927856 0.9377352  0.9539673  0.9945095  0.97597426\n",
      " 0.9959234  0.9583079  0.95024836 0.74430174 0.99169695 0.65594566\n",
      " 0.78120446 0.9141362  0.9412654  0.96547014 0.95963794 0.9931972\n",
      " 0.99956673 0.9965581 ]\n",
      "The rewards are: [0.8897008  0.9943709  0.9776169  0.76030445 0.99144566 0.992062\n",
      " 0.89910746 0.9865254  0.89410895 0.9322598  0.9749356  0.95508695\n",
      " 0.9860947  0.99282867 0.92403656 0.8691657  0.89058006 0.9475759\n",
      " 0.9993389  0.99907863 0.9308311  0.99608326 0.73089224 0.9874184\n",
      " 0.97749114 0.9730865  0.86980796 0.6416562  0.73976636 0.966694\n",
      " 0.99631125 0.8329485 ]\n",
      "The rewards are: [0.99846846 0.9399287  0.97634196 0.9899067  0.6174146  0.99190265\n",
      " 0.9484052  0.9824333  0.9975547  0.8144462  0.8540241  0.9786084\n",
      " 0.53264403 0.76763684 0.97796154 0.8905787  0.6484629  0.6243549\n",
      " 0.5556081  0.98527217 0.94647855 0.92132604 0.97780687 0.99379635\n",
      " 0.71297383 0.99689364 0.95633596 0.8574809  0.97921443 0.9879033\n",
      " 0.95179725 0.9545807 ]\n",
      "The rewards are: [0.97462636 0.96005595 0.9699135  0.99648094 0.97310334 0.52844113\n",
      " 0.9643416  0.5552162  0.9541224  0.8995775  0.9508592  0.96706903\n",
      " 0.99685633 0.9961971  0.9769772  0.7983956  0.9922759  0.9926099\n",
      " 0.9972229  0.95465916 0.90728503 0.8026807  0.83971363 0.99769044\n",
      " 0.99880373 0.96560293 0.99741936 0.7277356  0.89923394 0.632574\n",
      " 0.99040306 0.98897237]\n",
      "The rewards are: [0.9964149  0.9556013  0.7363954  0.99132115 0.96595687 0.97276074\n",
      " 0.9160169  0.9916372  0.9805648  0.9661391  0.99795145 0.786174\n",
      " 0.8893132  0.99818844 0.9825775  0.9995408  0.862933   0.99474084\n",
      " 0.9964457  0.9866687  0.9989868  0.9652178  0.99614006 0.97585267\n",
      " 0.9940257  0.9134005  0.96848136 0.95817333 0.9970663  0.98580015\n",
      " 0.72560304 0.9633977 ]\n",
      "The rewards are: [0.997299   0.8049976  0.9661896  0.61985296 0.9905393  0.9080913\n",
      " 0.76887846 0.69652665 0.9996171  0.7858275  0.99510574 0.8917602\n",
      " 0.99891746 0.9408273  0.76460624 0.89466435 0.84823686 0.61914414\n",
      " 0.90392095 0.99295914 0.8993019  0.9282729  0.994105   0.9841756\n",
      " 0.8769958  0.99873644 0.8694813  0.66757274 0.9981148  0.9603372\n",
      " 0.9639612  0.9757875 ]\n",
      "The rewards are: [0.99656147 0.9976119  0.7695931  0.7039273  0.9966473  0.98125285\n",
      " 0.88531035 0.9086726  0.95711166 0.9953361  0.8864671  0.91015726\n",
      " 0.9641861  0.97160834 0.8653889  0.5877354  0.86688125 0.9483209\n",
      " 0.99537754 0.81841636 0.9616208  0.959472   0.9636615  0.8405888\n",
      " 0.6230456  0.9470327  0.8665871  0.9742785  0.960202   0.9968182\n",
      " 0.99797684 0.9949634 ]\n",
      "The rewards are: [0.87880796 0.9184541  0.93777716 0.9917418  0.9633384  0.9988439\n",
      " 0.6866249  0.9663744  0.8858346  0.9217206  0.9905483  0.99975616\n",
      " 0.99879694 0.97874534 0.9607151  0.8130838  0.9744881  0.9905352\n",
      " 0.98901016 0.9940836  0.92368764 0.9819234  0.97994906 0.98185045\n",
      " 0.7717735  0.75924516 0.9985696  0.9217255  0.97528994 0.9785065\n",
      " 0.99746764 0.7961254 ]\n",
      "The rewards are: [0.9536848  0.98706156 0.9752818  0.70754784 0.9879963  0.97865796\n",
      " 0.55641186 0.820907   0.9799903  0.9888349  0.9947507  0.957991\n",
      " 0.9426253  0.9921532  0.99797946 0.99452305 0.84906685 0.9780086\n",
      " 0.8920754  0.9286628  0.97892886 0.99742585 0.9670283  0.86644447\n",
      " 0.99420446 0.9866758  0.9913775  0.50184697 0.99454224 0.9564319\n",
      " 0.9556917  0.86329854]\n",
      "The rewards are: [0.99924374 0.9060787  0.8302274  0.9621962  0.91893625 0.99746597\n",
      " 0.9976059  0.86222506 0.90926826 0.9961183  0.95179886 0.94012713\n",
      " 0.75293654 0.9745137  0.99748343 0.915495   0.9662498  0.99306315\n",
      " 0.9910494  0.77259856 0.89640146 0.6374313  0.7464038  0.9852073\n",
      " 0.9565363  0.9216462  0.9772296  0.9936392  0.99907565 0.95827556\n",
      " 0.8208994  0.9646707 ]\n",
      "The rewards are: [0.8673765  0.9728238  0.99751675 0.5817148  0.86542225 0.94908434\n",
      " 0.98469895 0.95296156 0.9087522  0.99767035 0.6920419  0.57810026\n",
      " 0.9926494  0.9892988  0.8378747  0.9969292  0.99744654 0.9686872\n",
      " 0.98744106 0.9962005  0.99444985 0.864901   0.999164   0.9077559\n",
      " 0.9938176  0.6618394  0.8656832  0.9729758  0.72295594 0.8459521\n",
      " 0.9517097  0.7888486 ]\n",
      "The rewards are: [0.9594064  0.9783917  0.9768023  0.61568034 0.9961365  0.9988967\n",
      " 0.983588   0.99733365 0.6757179  0.7887049  0.9972783  0.9840771\n",
      " 0.90882546 0.7571913  0.9407531  0.531009   0.76755303 0.9976412\n",
      " 0.78544635 0.9858102  0.7506358  0.8106226  0.6164487  0.9805417\n",
      " 0.9477672  0.99161    0.77411765 0.9983322  0.9984616  0.98623383\n",
      " 0.97392863 0.95392114]\n",
      "The rewards are: [0.7041029  0.9976821  0.9016598  0.99175656 0.9987631  0.94797015\n",
      " 0.9558564  0.71114135 0.9875551  0.7793579  0.98778987 0.76632845\n",
      " 0.9616247  0.9799834  0.93442607 0.9891493  0.70130044 0.5442653\n",
      " 0.9929079  0.6369317  0.71255636 0.9802336  0.9717336  0.8778205\n",
      " 0.9954093  0.98493075 0.9944825  0.9945391  0.99783725 0.9884367\n",
      " 0.86767006 0.99881136]\n",
      "The rewards are: [0.9936466  0.8931392  0.67991966 0.77871907 0.97553194 0.9901175\n",
      " 0.73635805 0.7455506  0.9968196  0.8412847  0.8928658  0.9736007\n",
      " 0.88509655 0.95239884 0.909356   0.98293936 0.9905352  0.61889344\n",
      " 0.95993096 0.9550278  0.5539918  0.99936265 0.9973611  0.95560884\n",
      " 0.927836   0.9857333  0.87667173 0.9950387  0.9950825  0.987872\n",
      " 0.95206344 0.977234  ]\n",
      "The rewards are: [0.9991968  0.99966    0.8027062  0.99597436 0.8151312  0.98346806\n",
      " 0.99617946 0.64654225 0.51765716 0.99738806 0.52499574 0.8339584\n",
      " 0.9645197  0.72837085 0.90028685 0.99335456 0.93913496 0.6699692\n",
      " 0.9873236  0.98118985 0.99827564 0.82246125 0.9966917  0.998268\n",
      " 0.5173921  0.98197764 0.9821139  0.99493486 0.9871955  0.8091282\n",
      " 0.98721814 0.9968189 ]\n",
      "The rewards are: [0.9934356  0.99564123 0.9153701  0.9775317  0.9699888  0.96775115\n",
      " 0.88459146 0.8763324  0.97742313 0.99346066 0.974835   0.932217\n",
      " 0.6672405  0.7996336  0.6415     0.93504786 0.74788207 0.99898404\n",
      " 0.8510649  0.9914193  0.9988815  0.650096   0.9873351  0.99563146\n",
      " 0.8918459  0.8009604  0.6398028  0.7141386  0.98347974 0.99812466\n",
      " 0.9956844  0.9953211 ]\n",
      "The rewards are: [0.7884592  0.9989568  0.8531598  0.6834835  0.9500568  0.95508796\n",
      " 0.9910137  0.99774843 0.80402833 0.99911445 0.950259   0.9965976\n",
      " 0.86272496 0.9825979  0.91949016 0.99845123 0.99309665 0.9968989\n",
      " 0.9828675  0.989916   0.917212   0.9319667  0.97469246 0.8893145\n",
      " 0.98002094 0.9633771  0.88256395 0.6552531  0.96398443 0.7847217\n",
      " 0.97002375 0.9971681 ]\n",
      "The rewards are: [0.7633817  0.9970866  0.99168056 0.6901966  0.9700192  0.99833125\n",
      " 0.9129257  0.8922207  0.97034556 0.99190617 0.9985398  0.997491\n",
      " 0.9979646  0.98932356 0.989903   0.9811173  0.8778086  0.93752676\n",
      " 0.97133696 0.9674357  0.6414179  0.8300828  0.7218485  0.66528946\n",
      " 0.99188    0.9977362  0.9945205  0.97079986 0.9953891  0.6231711\n",
      " 0.9902828  0.8973044 ]\n",
      "The rewards are: [0.9930521  0.98507047 0.9709282  0.70859003 0.9647257  0.97148955\n",
      " 0.9975145  0.98728454 0.77628845 0.99881905 0.98867756 0.97963536\n",
      " 0.9933716  0.9911718  0.945756   0.99793494 0.9501336  0.98842853\n",
      " 0.945806   0.8863518  0.9957508  0.94985086 0.99459803 0.9976641\n",
      " 0.9843858  0.9964329  0.93194205 0.9016775  0.9324543  0.9945294\n",
      " 0.9942655  0.8310697 ]\n",
      "The rewards are: [0.93730646 0.9255476  0.9772789  0.92949027 0.9368793  0.97558177\n",
      " 0.99110025 0.9984968  0.9985825  0.9978211  0.7238236  0.9927129\n",
      " 0.9830998  0.9067756  0.7142149  0.878487   0.9993031  0.8781538\n",
      " 0.9330528  0.99253076 0.9875345  0.900368   0.86012906 0.99011725\n",
      " 0.98159987 0.99805105 0.9979869  0.97873896 0.9248994  0.8742355\n",
      " 0.9940613  0.99751604]\n",
      "The rewards are: [0.99475443 0.9882705  0.8986985  0.6818091  0.8218469  0.9764856\n",
      " 0.8985549  0.97516143 0.9881741  0.84884185 0.8412991  0.97945327\n",
      " 0.92369074 0.9784304  0.98105663 0.99348456 0.8782664  0.92412186\n",
      " 0.99850696 0.9157598  0.9194183  0.9980842  0.78572863 0.7828832\n",
      " 0.99712807 0.99809545 0.9497972  0.9755476  0.8684471  0.99361175\n",
      " 0.96217275 0.9960859 ]\n",
      "The rewards are: [0.9970776  0.86097085 0.9782601  0.71364534 0.9921349  0.63396436\n",
      " 0.98878396 0.99577963 0.9975228  0.99193794 0.5160291  0.9164434\n",
      " 0.9920481  0.9828355  0.526958   0.97317874 0.90600866 0.99767095\n",
      " 0.81004274 0.9978243  0.6516955  0.99809927 0.9897413  0.9970776\n",
      " 0.72856826 0.99551827 0.97845274 0.992156   0.8174035  0.999508\n",
      " 0.8518977  0.994111  ]\n",
      "The rewards are: [0.98468494 0.998287   0.98286426 0.95212686 0.95983845 0.9881393\n",
      " 0.9504859  0.99551827 0.9377198  0.89671    0.8874595  0.99836165\n",
      " 0.8819943  0.97088504 0.6806869  0.9901507  0.82037866 0.9966536\n",
      " 0.9699565  0.9992835  0.9456046  0.9671349  0.9995561  0.9954802\n",
      " 0.7492151  0.99329704 0.85297775 0.5634207  0.9700636  0.6816925\n",
      " 0.99540496 0.99781656]\n",
      "The rewards are: [0.90999454 0.99548596 0.99457175 0.99777347 0.8408527  0.9997434\n",
      " 0.82383287 0.9824195  0.9048854  0.9966331  0.99163955 0.5631574\n",
      " 0.98792624 0.9733425  0.99491405 0.91342324 0.9885903  0.9652395\n",
      " 0.9882174  0.95219374 0.72706616 0.974757   0.99338126 0.8419176\n",
      " 0.84251547 0.99548763 0.9973278  0.605209   0.8660108  0.88597697\n",
      " 0.80435723 0.891415  ]\n",
      "The rewards are: [0.9995664  0.9338142  0.63715047 0.54346067 0.98407656 0.9909272\n",
      " 0.9193391  0.9978415  0.92692465 0.96621054 0.9090441  0.93005615\n",
      " 0.98199236 0.7896841  0.9918113  0.9700655  0.9434641  0.95606905\n",
      " 0.97062653 0.9235403  0.7446636  0.98546994 0.8203618  0.99545884\n",
      " 0.9976584  0.97275364 0.8108197  0.9973157  0.9039351  0.96005857\n",
      " 0.9980422  0.99886   ]\n",
      "The rewards are: [0.99351805 0.61197376 0.867918   0.9284622  0.853733   0.9807334\n",
      " 0.9873679  0.99166167 0.99632275 0.99081063 0.5570895  0.87557286\n",
      " 0.95473033 0.811553   0.8911589  0.61364734 0.8605524  0.9751443\n",
      " 0.9835495  0.86997366 0.9748989  0.8329871  0.9808146  0.65271664\n",
      " 0.9610657  0.9569039  0.84929824 0.9975637  0.9959467  0.85558265\n",
      " 0.99187976 0.9604641 ]\n",
      "The rewards are: [0.9433062  0.9981741  0.99280155 0.85177445 0.72296304 0.99712306\n",
      " 0.97417384 0.71208096 0.9575682  0.8666027  0.980583   0.672082\n",
      " 0.976002   0.97936386 0.998218   0.9668419  0.99086046 0.6417573\n",
      " 0.9985958  0.83308125 0.99950075 0.861623   0.88264096 0.7166999\n",
      " 0.76960593 0.7499917  0.99755645 0.8439688  0.5242881  0.9975721\n",
      " 0.9020575  0.9986187 ]\n",
      "The rewards are: [0.95396346 0.9967187  0.9845064  0.9927691  0.9398264  0.954233\n",
      " 0.96532303 0.9931844  0.9927817  0.98035425 0.97646767 0.99890125\n",
      " 0.9148823  0.9964461  0.91786534 0.5506078  0.9876245  0.90734386\n",
      " 0.9993     0.9790206  0.9938976  0.9830048  0.9936407  0.9975648\n",
      " 0.9561959  0.93797064 0.9972898  0.6008902  0.9998073  0.98042655\n",
      " 0.98413956 0.9110921 ]\n",
      "The rewards are: [0.84874624 0.97146827 0.99506456 0.5990057  0.95695496 0.99331206\n",
      " 0.7765527  0.6257362  0.96568453 0.9386969  0.99955124 0.9975418\n",
      " 0.9296179  0.9961119  0.8769056  0.8822348  0.9941057  0.9013943\n",
      " 0.9986351  0.97437423 0.99775535 0.9830903  0.9734403  0.9781472\n",
      " 0.9422381  0.99027866 0.9400751  0.9980071  0.99626833 0.9849186\n",
      " 0.99114424 0.9993587 ]\n",
      "The rewards are: [0.9996043  0.9753194  0.98168117 0.94989145 0.995424   0.99814\n",
      " 0.99311686 0.9573609  0.9843104  0.9944026  0.9612679  0.9017997\n",
      " 0.8778538  0.8840403  0.85738635 0.9998987  0.99763083 0.9892881\n",
      " 0.8453575  0.9594549  0.6642773  0.9816938  0.9993838  0.8948584\n",
      " 0.98383594 0.9654911  0.99444145 0.84487087 0.9148805  0.8826872\n",
      " 0.74021584 0.98336595]\n",
      "The rewards are: [0.5152043  0.7638379  0.9994361  0.9972161  0.9680207  0.954553\n",
      " 0.9882868  0.7420801  0.8625315  0.99906296 0.946488   0.9864255\n",
      " 0.7782769  0.8903089  0.97397757 0.99799156 0.87108266 0.7657517\n",
      " 0.94109243 0.76028967 0.976607   0.9295723  0.99777585 0.9914213\n",
      " 0.985254   0.993792   0.97170186 0.76742876 0.889657   0.9904751\n",
      " 0.6345417  0.575467  ]\n",
      "The rewards are: [0.6136914  0.9738317  0.5367241  0.85041547 0.9380771  0.65066403\n",
      " 0.99628806 0.99163276 0.9929039  0.67230296 0.998049   0.9937728\n",
      " 0.88792324 0.9961635  0.972472   0.81030023 0.9907624  0.9955987\n",
      " 0.6388136  0.97957015 0.7169036  0.55541927 0.93798184 0.96710634\n",
      " 0.99469537 0.8854601  0.998346   0.51602876 0.9175388  0.959764\n",
      " 0.9019683  0.932295  ]\n",
      "The rewards are: [0.9837943  0.56839985 0.571768   0.97632265 0.98626816 0.9648416\n",
      " 0.9844056  0.9857491  0.99679416 0.7586025  0.9981421  0.97705007\n",
      " 0.9711954  0.99529415 0.6673105  0.9953393  0.98782027 0.9978582\n",
      " 0.98638517 0.9605822  0.86506355 0.91273284 0.91325235 0.9978702\n",
      " 0.974585   0.9842882  0.9977775  0.96562475 0.9996743  0.9857432\n",
      " 0.9908612  0.77474505]\n",
      "The rewards are: [0.70837647 0.9944502  0.5331714  0.9763131  0.94022083 0.99932957\n",
      " 0.9923408  0.520683   0.7627802  0.9069967  0.7521673  0.9179579\n",
      " 0.5945334  0.99286723 0.96028435 0.8796795  0.70931506 0.98394644\n",
      " 0.9787703  0.73058337 0.98894715 0.9908125  0.95071733 0.9138869\n",
      " 0.7122135  0.9723714  0.9976299  0.9910732  0.9756629  0.887775\n",
      " 0.99399346 0.9834661 ]\n",
      "The rewards are: [0.9680551  0.9733503  0.99923766 0.9925211  0.767753   0.99824786\n",
      " 0.99329776 0.9660452  0.99069023 0.9822827  0.963331   0.9241356\n",
      " 0.9675223  0.99668545 0.63362485 0.99133486 0.96637094 0.5921713\n",
      " 0.9775963  0.9611975  0.9822597  0.99540377 0.9982609  0.8187767\n",
      " 0.5793657  0.99795985 0.9828813  0.91295415 0.9445464  0.9013946\n",
      " 0.99488246 0.556311  ]\n",
      "The rewards are: [0.9879851  0.7400319  0.67067325 0.955422   0.9944595  0.99657947\n",
      " 0.9214135  0.9954601  0.9990803  0.93389195 0.9594875  0.9644033\n",
      " 0.998869   0.648021   0.54088885 0.9956417  0.9342461  0.84652585\n",
      " 0.9068734  0.93138766 0.99752945 0.9982692  0.99744946 0.8120534\n",
      " 0.9932776  0.98018056 0.9745661  0.997018   0.7665113  0.99864227\n",
      " 0.993919   0.5669867 ]\n",
      "The rewards are: [0.55212337 0.9724008  0.97370934 0.811978   0.99313325 0.9996032\n",
      " 0.7243818  0.95871514 0.9952508  0.5515146  0.9860874  0.9993082\n",
      " 0.9420884  0.98375595 0.9887545  0.8002007  0.9935948  0.97543836\n",
      " 0.97305804 0.985973   0.7446931  0.958815   0.5536552  0.98167336\n",
      " 0.908064   0.9990069  0.967366   0.9994791  0.9463625  0.96883047\n",
      " 0.96121556 0.9030203 ]\n",
      "The rewards are: [0.9501799  0.97163546 0.9934256  0.94516563 0.958388   0.99872017\n",
      " 0.96597767 0.97393304 0.9278879  0.78349775 0.966427   0.99759585\n",
      " 0.99962056 0.9541444  0.9986551  0.9511069  0.999627   0.9302269\n",
      " 0.50242454 0.58635145 0.9960402  0.9923282  0.9265203  0.7277166\n",
      " 0.55779356 0.9672317  0.83132577 0.99256974 0.9792548  0.60951334\n",
      " 0.99858284 0.58666354]\n",
      "The rewards are: [0.7088939  0.9996277  0.94307554 0.99393445 0.96694094 0.9267271\n",
      " 0.9984464  0.98367864 0.99831223 0.83209324 0.82885545 0.9791783\n",
      " 0.9737691  0.9800131  0.9678216  0.62532103 0.8321221  0.9968792\n",
      " 0.9897988  0.9807045  0.56205773 0.9914703  0.549915   0.9635215\n",
      " 0.9167621  0.99795    0.8101635  0.69570124 0.69876987 0.9097477\n",
      " 0.997865   0.9852475 ]\n",
      "The rewards are: [0.9863194  0.90362245 0.9890056  0.7301038  0.5262154  0.98111975\n",
      " 0.99562246 0.9201648  0.50001866 0.99794716 0.9954627  0.88717484\n",
      " 0.9747422  0.9969586  0.6394702  0.9919037  0.9029795  0.99964833\n",
      " 0.97539324 0.9481374  0.5081975  0.9990835  0.9421146  0.9185495\n",
      " 0.9394201  0.9978967  0.97586536 0.8230716  0.9883642  0.81407744\n",
      " 0.79872954 0.8456566 ]\n",
      "The rewards are: [0.9986972  0.97244364 0.9908922  0.74374324 0.9659593  0.9975834\n",
      " 0.93276507 0.9968761  0.96089715 0.82654643 0.9994661  0.9860708\n",
      " 0.99575895 0.9873869  0.99962735 0.9956774  0.8565763  0.98983824\n",
      " 0.5283068  0.97318125 0.9809775  0.972784   0.9996125  0.6441808\n",
      " 0.98854905 0.9981993  0.9989667  0.9965688  0.68713695 0.99492836\n",
      " 0.9642977  0.9953923 ]\n",
      "The rewards are: [0.8104591  0.99940443 0.7251061  0.9949209  0.9823959  0.99816304\n",
      " 0.51133597 0.9196572  0.99495417 0.9819717  0.9456779  0.91745406\n",
      " 0.9267027  0.9609957  0.9985253  0.9963127  0.9028622  0.96835506\n",
      " 0.9772026  0.8893118  0.9962082  0.9751163  0.9962214  0.7776561\n",
      " 0.85876334 0.8275528  0.9979645  0.71386606 0.9847073  0.99097764\n",
      " 0.5636592  0.8532565 ]\n",
      "The rewards are: [0.995684   0.9981493  0.99859935 0.99617493 0.9993337  0.9946325\n",
      " 0.9965258  0.9028685  0.9691871  0.9958902  0.9979662  0.9975802\n",
      " 0.9896778  0.9816374  0.88250786 0.92457193 0.7392575  0.71459526\n",
      " 0.95648134 0.93702316 0.97267646 0.8370226  0.9695434  0.5825635\n",
      " 0.97577727 0.99953437 0.9888707  0.5666075  0.9978829  0.9406237\n",
      " 0.9898044  0.88525844]\n",
      "The rewards are: [0.9659855  0.60282266 0.9165043  0.6078891  0.99550074 0.9866109\n",
      " 0.9915131  0.91085494 0.9986897  0.99189234 0.90888363 0.735594\n",
      " 0.62601835 0.6052532  0.8986873  0.9932139  0.8649842  0.9692341\n",
      " 0.99881375 0.61835724 0.9993129  0.88606447 0.98763067 0.9712314\n",
      " 0.5904568  0.9453786  0.9970836  0.89424604 0.79718643 0.9979013\n",
      " 0.9912423  0.53034365]\n",
      "The rewards are: [0.9998579  0.8916895  0.89747995 0.98822635 0.9718184  0.9917847\n",
      " 0.9969415  0.9997359  0.7629082  0.8046897  0.8368303  0.92399085\n",
      " 0.6748778  0.98265254 0.9983082  0.9988312  0.9997615  0.9888433\n",
      " 0.99527407 0.9336878  0.97607416 0.9936606  0.8514143  0.99918634\n",
      " 0.85148215 0.92128444 0.94553024 0.92922866 0.82307684 0.9987035\n",
      " 0.83102095 0.9934634 ]\n",
      "The rewards are: [0.742312   0.99009484 0.9985903  0.8794992  0.9971077  0.9993729\n",
      " 0.9922375  0.94305754 0.987854   0.97283    0.9981002  0.9971994\n",
      " 0.6060862  0.99853146 0.937473   0.70636034 0.6083666  0.9844114\n",
      " 0.9973109  0.51552814 0.90572673 0.9367704  0.88372767 0.99085367\n",
      " 0.89880496 0.954259   0.99838495 0.9368936  0.99541473 0.97975093\n",
      " 0.94114184 0.77599865]\n",
      "The rewards are: [0.9862201  0.9133009  0.5060234  0.96156484 0.85027266 0.51798314\n",
      " 0.9878144  0.973436   0.9807161  0.9808188  0.94914126 0.98861873\n",
      " 0.9318354  0.984098   0.9454895  0.99713695 0.9484423  0.95778185\n",
      " 0.9965209  0.8246857  0.99658126 0.9982205  0.88583726 0.992875\n",
      " 0.5626332  0.99372804 0.9822547  0.6681341  0.9833007  0.9969138\n",
      " 0.721464   0.9844088 ]\n",
      "The rewards are: [0.97057265 0.99178666 0.99826294 0.997619   0.9820024  0.9995401\n",
      " 0.9127102  0.9892825  0.7807512  0.8480267  0.9329258  0.9976502\n",
      " 0.895732   0.65427905 0.9923516  0.997514   0.9425532  0.9771787\n",
      " 0.9967597  0.9997254  0.65075165 0.8353766  0.8229276  0.99158645\n",
      " 0.95129234 0.9304337  0.99753845 0.9976799  0.89105034 0.96575433\n",
      " 0.9830236  0.7742518 ]\n",
      "The rewards are: [0.9991066  0.845808   0.9546233  0.9548501  0.8080065  0.9793871\n",
      " 0.9965533  0.58784926 0.9895203  0.6362667  0.89819896 0.99921274\n",
      " 0.99836487 0.9711307  0.976937   0.9988201  0.9779478  0.99890614\n",
      " 0.8824181  0.9994295  0.99805    0.92030233 0.529912   0.8286692\n",
      " 0.9547582  0.95555204 0.994044   0.87257934 0.9784952  0.9907512\n",
      " 0.91855955 0.96920425]\n",
      "The rewards are: [0.9908778  0.998147   0.98837876 0.8943172  0.98018503 0.92992944\n",
      " 0.9981072  0.9065672  0.9381607  0.997387   0.8339888  0.9898735\n",
      " 0.99924785 0.9948566  0.9885317  0.9966528  0.99689    0.7963428\n",
      " 0.8959456  0.9667618  0.9492116  0.99982613 0.63032144 0.9968328\n",
      " 0.9963277  0.70693886 0.9938723  0.8679311  0.98631984 0.5193384\n",
      " 0.95641667 0.9993382 ]\n",
      "The rewards are: [0.9970945  0.7786076  0.879302   0.9995067  0.9952592  0.9605581\n",
      " 0.96584785 0.9994246  0.90235484 0.84882396 0.9615988  0.9281941\n",
      " 0.8599472  0.9137147  0.99362767 0.99557614 0.9932132  0.9984871\n",
      " 0.9574045  0.8618357  0.9861464  0.9128083  0.9966538  0.9885358\n",
      " 0.9965603  0.8280511  0.5110694  0.9909576  0.5325517  0.9411561\n",
      " 0.9062162  0.7743944 ]\n",
      "The rewards are: [0.99748284 0.9548616  0.99844736 0.8992171  0.8692903  0.97853124\n",
      " 0.9824781  0.9981135  0.74720025 0.881634   0.9576102  0.99836093\n",
      " 0.9828316  0.87810874 0.9135209  0.99342114 0.97618586 0.993961\n",
      " 0.83348614 0.995948   0.7141022  0.9986935  0.7788015  0.8522505\n",
      " 0.98453265 0.98817575 0.99820447 0.9270313  0.87736917 0.631414\n",
      " 0.8784318  0.88819504]\n",
      "The rewards are: [0.9993998  0.9949057  0.662535   0.9467722  0.9698279  0.9438849\n",
      " 0.7008067  0.98224086 0.92626154 0.5297644  0.8566365  0.98841107\n",
      " 0.6968189  0.9854387  0.7305917  0.6160822  0.9756929  0.9998419\n",
      " 0.997248   0.9896006  0.9851715  0.99863005 0.9740674  0.9953418\n",
      " 0.95560014 0.79886174 0.99597967 0.9778652  0.85984874 0.8799852\n",
      " 0.8870583  0.76738656]\n",
      "The rewards are: [0.8070599  0.9976152  0.8156804  0.52073485 0.93345666 0.9945738\n",
      " 0.9710207  0.7843971  0.9938168  0.9748198  0.8550818  0.96693426\n",
      " 0.99310654 0.9890203  0.9012351  0.63653016 0.55250454 0.9655744\n",
      " 0.9971565  0.9892854  0.9941432  0.53702146 0.65108913 0.9928127\n",
      " 0.9811677  0.99564856 0.9844306  0.73135066 0.972049   0.8566148\n",
      " 0.8125918  0.99370426]\n",
      "The rewards are: [0.8504855  0.99665606 0.6054431  0.98292196 0.5729651  0.9689549\n",
      " 0.99929345 0.9716911  0.9917493  0.672108   0.9790653  0.98964745\n",
      " 0.8106113  0.6204395  0.99644405 0.9955635  0.9711258  0.83969605\n",
      " 0.7639179  0.99591917 0.8683868  0.91416115 0.98307574 0.99963164\n",
      " 0.7875577  0.99606043 0.94139385 0.682383   0.9803867  0.88265145\n",
      " 0.9778282  0.98689526]\n",
      "The rewards are: [0.99593985 0.81517047 0.67613345 0.99391586 0.99831045 0.99960154\n",
      " 0.99617827 0.989901   0.9145001  0.8443926  0.783485   0.99944466\n",
      " 0.50541866 0.92173874 0.92359793 0.9763238  0.99286675 0.7692538\n",
      " 0.6250419  0.98857725 0.95186013 0.62037957 0.6697716  0.789269\n",
      " 0.57622623 0.9610343  0.98504955 0.988704   0.8611741  0.997879\n",
      " 0.9996598  0.9983943 ]\n",
      "The rewards are: [0.95274866 0.985297   0.992969   0.98961467 0.8188327  0.5379186\n",
      " 0.93924874 0.85024095 0.8859185  0.9439007  0.9843301  0.9915671\n",
      " 0.95059377 0.98957586 0.9955586  0.9968863  0.9824891  0.73559964\n",
      " 0.96362776 0.7103129  0.99627054 0.9833166  0.9922011  0.9305071\n",
      " 0.99352705 0.9859853  0.9908957  0.98066574 0.99650973 0.9308213\n",
      " 0.93889004 0.9878477 ]\n",
      "The rewards are: [0.9879483  0.7599096  0.9984584  0.99535096 0.9794784  0.9814408\n",
      " 0.9968305  0.99947125 0.9443373  0.99835783 0.95491385 0.9981318\n",
      " 0.8997808  0.99834096 0.8121099  0.9053788  0.71445614 0.9097774\n",
      " 0.7577973  0.8792707  0.98617935 0.9806593  0.97679317 0.9716898\n",
      " 0.9033245  0.9657034  0.98509455 0.9994748  0.99789065 0.9516126\n",
      " 0.9205316  0.53429496]\n",
      "The rewards are: [0.998958   0.95836824 0.98575425 0.8315142  0.84030646 0.80112755\n",
      " 0.98533845 0.988437   0.99449867 0.9497781  0.99574476 0.87642014\n",
      " 0.99544406 0.99725217 0.89541596 0.99849534 0.9575841  0.99780315\n",
      " 0.98500985 0.9650281  0.71251893 0.9912243  0.9997609  0.99546\n",
      " 0.9907408  0.9953891  0.997841   0.6903045  0.7357226  0.8175175\n",
      " 0.9971192  0.9055915 ]\n",
      "The rewards are: [0.9789258  0.9981566  0.9989248  0.9932492  0.8667135  0.99595153\n",
      " 0.99027026 0.8559395  0.9274905  0.99623954 0.99645066 0.8453166\n",
      " 0.997113   0.8881302  0.9907829  0.9976895  0.95399415 0.7183293\n",
      " 0.8487494  0.9887599  0.9914551  0.9946173  0.9829652  0.97965413\n",
      " 0.99766564 0.9901008  0.67405343 0.99686795 0.9951638  0.99770087\n",
      " 0.96067554 0.850257  ]\n",
      "The rewards are: [0.9669271  0.85986227 0.9378766  0.9963716  0.6838962  0.9644549\n",
      " 0.8588567  0.89985704 0.9851693  0.972509   0.9965546  0.7874057\n",
      " 0.8541309  0.9655767  0.9975147  0.9982638  0.9983323  0.9947147\n",
      " 0.94947124 0.9921571  0.99624455 0.9762582  0.9382464  0.5383626\n",
      " 0.9950058  0.9831324  0.5482857  0.6080612  0.99634176 0.9874565\n",
      " 0.96271306 0.99747086]\n",
      "The rewards are: [0.99463046 0.7322573  0.8270241  0.9116122  0.996846   0.9832972\n",
      " 0.5644779  0.9376147  0.9802332  0.6184214  0.99793845 0.93197024\n",
      " 0.69631046 0.99988043 0.994799   0.9780557  0.9230406  0.9864705\n",
      " 0.9361467  0.8329395  0.6084281  0.9938938  0.58932257 0.9934676\n",
      " 0.9965564  0.9937973  0.9880406  0.98973745 0.9990734  0.785329\n",
      " 0.71827114 0.66725457]\n",
      "The rewards are: [0.9046238  0.83438194 0.97940683 0.6092452  0.975938   0.99859434\n",
      " 0.9920839  0.84191823 0.98661345 0.6516625  0.9823011  0.97923684\n",
      " 0.99592066 0.99958926 0.9941909  0.99793065 0.98449755 0.88715786\n",
      " 0.99912363 0.93617195 0.5643052  0.99594253 0.95956635 0.9771737\n",
      " 0.929914   0.99973434 0.76345634 0.9651226  0.9202038  0.6879982\n",
      " 0.9631883  0.9666698 ]\n",
      "The rewards are: [0.9820002  0.99675673 0.9950636  0.6581751  0.99499124 0.9734082\n",
      " 0.99839777 0.9783497  0.9935276  0.99249697 0.98677117 0.994545\n",
      " 0.9143722  0.9839243  0.9418176  0.9983175  0.80994207 0.86290187\n",
      " 0.8796463  0.90023804 0.53760076 0.97082335 0.9128682  0.6157155\n",
      " 0.9571094  0.83526534 0.77695197 0.86165434 0.9995289  0.99940026\n",
      " 0.9225567  0.98837924]\n",
      "The rewards are: [0.94842    0.94764197 0.9997937  0.844614   0.8692261  0.9729724\n",
      " 0.85718626 0.6000191  0.9837351  0.99674314 0.9909355  0.9981779\n",
      " 0.8881309  0.95134646 0.9637334  0.956457   0.95175385 0.95990723\n",
      " 0.9994319  0.999086   0.9353707  0.93828744 0.88957155 0.7985161\n",
      " 0.999143   0.9902     0.985495   0.7650157  0.99790406 0.9975452\n",
      " 0.94269645 0.9703593 ]\n",
      "The rewards are: [0.90335697 0.9997862  0.6254925  0.9895471  0.9772036  0.9967692\n",
      " 0.96706444 0.8999391  0.99310076 0.7913625  0.9982324  0.9956649\n",
      " 0.6396284  0.99256766 0.8871238  0.8700537  0.8342567  0.8202771\n",
      " 0.95927703 0.86743414 0.9944711  0.632148   0.59509677 0.9855226\n",
      " 0.98971975 0.99562526 0.9972356  0.9151985  0.99892753 0.90385485\n",
      " 0.9697833  0.94740874]\n",
      "The rewards are: [0.9974361  0.53852206 0.9233435  0.94606733 0.99504733 0.9942168\n",
      " 0.83124804 0.7828314  0.9978902  0.9427452  0.89581597 0.9984524\n",
      " 0.8466637  0.79920286 0.85345334 0.9925909  0.946815   0.95353884\n",
      " 0.9553926  0.9234665  0.986159   0.8816798  0.9159586  0.6763203\n",
      " 0.99858814 0.86442035 0.98253006 0.9655956  0.99029666 0.9750617\n",
      " 0.85396487 0.9071409 ]\n",
      "The rewards are: [0.6539753  0.98117834 0.83180857 0.96635044 0.99697495 0.9708844\n",
      " 0.65137666 0.8888678  0.658352   0.98862505 0.98716146 0.98802626\n",
      " 0.9654406  0.99029654 0.571616   0.96817344 0.7355725  0.99580514\n",
      " 0.99670744 0.983817   0.98012793 0.8644555  0.96008587 0.9982262\n",
      " 0.53836    0.7028096  0.95182717 0.82116634 0.99761105 0.84813625\n",
      " 0.6828955  0.98244506]\n",
      "The rewards are: [0.99800116 0.9300941  0.9456852  0.9476147  0.9427944  0.9472911\n",
      " 0.7378492  0.9667495  0.9698607  0.9627383  0.9913775  0.9554948\n",
      " 0.94711244 0.93754584 0.99651223 0.96428007 0.9944397  0.9929333\n",
      " 0.8755883  0.99914587 0.99819946 0.8392457  0.97553205 0.9702191\n",
      " 0.99924904 0.9457835  0.99724835 0.9017301  0.8774858  0.994048\n",
      " 0.9986791  0.8236782 ]\n",
      "The rewards are: [0.99423003 0.98780906 0.9929066  0.99566627 0.9979227  0.9748506\n",
      " 0.6288817  0.9934057  0.75185555 0.96084684 0.9966037  0.87447685\n",
      " 0.9965634  0.7793016  0.98944074 0.99644023 0.99715316 0.8852461\n",
      " 0.9840156  0.9971673  0.93392617 0.9983328  0.99616396 0.9847244\n",
      " 0.98616403 0.63516665 0.66463995 0.9334605  0.9939557  0.6165213\n",
      " 0.9918251  0.9876343 ]\n",
      "The rewards are: [0.998609   0.9716371  0.9978294  0.9651319  0.7290687  0.9435078\n",
      " 0.8816275  0.916165   0.58005655 0.88928294 0.9267656  0.9996402\n",
      " 0.6360078  0.99461067 0.8438713  0.8518615  0.61894804 0.9835233\n",
      " 0.907172   0.9979906  0.9608258  0.9991967  0.9925476  0.86272424\n",
      " 0.99944776 0.99766076 0.97559273 0.96237874 0.78694063 0.9892825\n",
      " 0.98416835 0.9478556 ]\n",
      "The rewards are: [0.5936633  0.65881556 0.99830794 0.98200136 0.9528334  0.7374931\n",
      " 0.93925387 0.9956807  0.99228525 0.9915044  0.84753925 0.95056945\n",
      " 0.99613994 0.9930656  0.9036285  0.9766917  0.9544383  0.9923465\n",
      " 0.99147207 0.959227   0.7169296  0.77921194 0.9877538  0.9935174\n",
      " 0.9912286  0.9893685  0.9799256  0.5972328  0.9812603  0.9217823\n",
      " 0.9891986  0.86092734]\n",
      "The rewards are: [0.77031577 0.7093843  0.8143222  0.7622144  0.96912307 0.58559597\n",
      " 0.9913024  0.9839062  0.5555519  0.929572   0.53523713 0.9881009\n",
      " 0.9897798  0.9954377  0.99421364 0.99757975 0.6045082  0.9939208\n",
      " 0.9867497  0.98546576 0.9388186  0.99841726 0.99990535 0.6750278\n",
      " 0.7110725  0.9781356  0.999033   0.91712916 0.9942973  0.9865078\n",
      " 0.92802674 0.9676308 ]\n",
      "The rewards are: [0.97086585 0.9920508  0.88276607 0.99241793 0.8085748  0.9984114\n",
      " 0.8818583  0.9984434  0.984005   0.9981066  0.9422036  0.7908043\n",
      " 0.9853485  0.9874916  0.994825   0.99454725 0.56680083 0.9523094\n",
      " 0.99239576 0.9162162  0.80418223 0.7017408  0.57592714 0.9998512\n",
      " 0.87134063 0.9525141  0.98594487 0.9955265  0.9859359  0.9258798\n",
      " 0.9997148  0.57651824]\n",
      "The rewards are: [0.99537575 0.98706645 0.9830692  0.9904716  0.97211605 0.8609391\n",
      " 0.80603087 0.89809626 0.9216731  0.98908955 0.87629884 0.8346936\n",
      " 0.9970258  0.75260013 0.9821514  0.79839414 0.9537589  0.51642966\n",
      " 0.99907863 0.78610957 0.960256   0.99907744 0.9993267  0.98838633\n",
      " 0.9969171  0.997647   0.99905306 0.9937151  0.99921143 0.98615706\n",
      " 0.9825963  0.60143226]\n",
      "The rewards are: [0.8307664  0.9824898  0.9821047  0.9526751  0.9492377  0.9987356\n",
      " 0.98651034 0.84308726 0.9929438  0.9921828  0.6910439  0.97575676\n",
      " 0.9572286  0.9968202  0.9802169  0.96466565 0.9984041  0.9902678\n",
      " 0.7446908  0.9997137  0.88220364 0.97275275 0.8292944  0.99896955\n",
      " 0.98456615 0.99858093 0.97022736 0.99909997 0.9967981  0.9581109\n",
      " 0.8810444  0.9391009 ]\n",
      "The rewards are: [0.9922661  0.9025631  0.6955234  0.8782836  0.9947161  0.7890669\n",
      " 0.9930026  0.9862466  0.9969446  0.9991498  0.97795826 0.9995988\n",
      " 0.99748117 0.99233586 0.93236625 0.97515434 0.9584233  0.9909101\n",
      " 0.93581814 0.9844632  0.98209846 0.69097435 0.9277931  0.9646865\n",
      " 0.94543004 0.8963157  0.9964663  0.78618383 0.9975078  0.8907248\n",
      " 0.99642485 0.97816956]\n",
      "The rewards are: [0.9574303  0.97366637 0.9418829  0.99525213 0.99788505 0.964427\n",
      " 0.990756   0.80565274 0.99122953 0.98567015 0.98644894 0.56167233\n",
      " 0.9016691  0.96177274 0.70370656 0.99880195 0.9754294  0.9428345\n",
      " 0.9953479  0.89921147 0.98321044 0.82698506 0.688169   0.9914692\n",
      " 0.97976905 0.97964364 0.90026826 0.98096883 0.99686015 0.78900826\n",
      " 0.9834404  0.99333596]\n",
      "The rewards are: [0.94977766 0.99455583 0.9195589  0.99653745 0.9702801  0.95796716\n",
      " 0.9244119  0.9938262  0.9712068  0.98078525 0.9822057  0.99913955\n",
      " 0.7008585  0.9961308  0.995443   0.9933814  0.7865785  0.74521846\n",
      " 0.97792506 0.9978254  0.84755445 0.99836093 0.62694687 0.9555844\n",
      " 0.92931235 0.9853483  0.986315   0.961043   0.99385417 0.55944496\n",
      " 0.93601716 0.9546193 ]\n",
      "The rewards are: [0.9626059  0.70758474 0.97222316 0.9864841  0.8682768  0.5736799\n",
      " 0.9980716  0.9984573  0.99808264 0.9321722  0.9846036  0.9606104\n",
      " 0.98468286 0.9949346  0.5318003  0.9916944  0.9634999  0.98460543\n",
      " 0.9966073  0.9346732  0.99880433 0.91653967 0.9969747  0.80680794\n",
      " 0.5233295  0.9809771  0.5711746  0.5051437  0.98010147 0.66850066\n",
      " 0.6542162  0.7306212 ]\n",
      "The rewards are: [0.82352173 0.99890864 0.96479756 0.99960834 0.9805088  0.9941146\n",
      " 0.99369156 0.9991647  0.8614844  0.938593   0.515405   0.67783105\n",
      " 0.9800568  0.9359696  0.9988306  0.78654474 0.99793625 0.9740535\n",
      " 0.9852722  0.9505074  0.90968347 0.64793634 0.681086   0.90421474\n",
      " 0.89581454 0.96673334 0.774351   0.99908614 0.9996081  0.7040156\n",
      " 0.9958442  0.9442408 ]\n",
      "The rewards are: [0.9958365  0.9907957  0.9694771  0.943683   0.9906419  0.94863814\n",
      " 0.64819217 0.9989048  0.7970761  0.7831253  0.73019814 0.98166955\n",
      " 0.9223075  0.9979352  0.6707425  0.8689514  0.98577166 0.9953029\n",
      " 0.9995301  0.8460306  0.87932396 0.951307   0.6579581  0.9056367\n",
      " 0.9733141  0.98647285 0.6854903  0.99402833 0.67994523 0.67236894\n",
      " 0.8676461  0.99663025]\n",
      "The rewards are: [0.985592   0.83698595 0.9504197  0.9714801  0.9897522  0.99661034\n",
      " 0.94669    0.9976421  0.99903667 0.97834855 0.88235027 0.889505\n",
      " 0.71441966 0.9935905  0.9617848  0.5960544  0.98785675 0.99726355\n",
      " 0.9808668  0.9984126  0.98517877 0.94509166 0.80960745 0.94385386\n",
      " 0.96649975 0.96915185 0.8735116  0.9923224  0.9568223  0.9235025\n",
      " 0.99128854 0.96291596]\n",
      "The rewards are: [0.7968233  0.9919229  0.97811586 0.9956273  0.91609234 0.9474666\n",
      " 0.5196822  0.9893272  0.99934036 0.8916143  0.9999188  0.9251993\n",
      " 0.6028467  0.7297608  0.99944955 0.9938188  0.99903095 0.996872\n",
      " 0.73646104 0.72081447 0.7963276  0.9970926  0.8972997  0.9821039\n",
      " 0.99354786 0.9299111  0.9993923  0.9997799  0.9085108  0.996012\n",
      " 0.995434   0.9632302 ]\n",
      "The rewards are: [0.9983382  0.95608354 0.5947144  0.5426447  0.9679671  0.9349188\n",
      " 0.9755241  0.95160097 0.9189109  0.99669015 0.9902687  0.87656504\n",
      " 0.99919754 0.9878527  0.97061735 0.9869609  0.89402    0.97900087\n",
      " 0.7094694  0.76728606 0.99525684 0.99465126 0.96042824 0.8356033\n",
      " 0.96395075 0.9983846  0.9984479  0.748989   0.91689837 0.99217105\n",
      " 0.97271055 0.916748  ]\n",
      "The rewards are: [0.96864456 0.9706453  0.99681216 0.6068786  0.9491783  0.9761429\n",
      " 0.8163726  0.6503051  0.9591533  0.9969674  0.9146708  0.55276877\n",
      " 0.95544744 0.9985178  0.6464499  0.9995066  0.8534838  0.9835539\n",
      " 0.999845   0.74408823 0.5005025  0.9507304  0.87796164 0.9994006\n",
      " 0.99583983 0.9824181  0.95352894 0.7849069  0.7101387  0.9976488\n",
      " 0.9971752  0.8244632 ]\n",
      "The rewards are: [0.97066754 0.9081917  0.9838418  0.9527584  0.94720143 0.62754184\n",
      " 0.98522794 0.95303226 0.96997035 0.9741566  0.9936128  0.7625044\n",
      " 0.99877256 0.6977302  0.9443811  0.9416853  0.9886085  0.998304\n",
      " 0.9527683  0.7013903  0.6702188  0.9928128  0.9996308  0.9598365\n",
      " 0.80443424 0.9683345  0.96216273 0.96953994 0.9961731  0.9517316\n",
      " 0.9969963  0.9771255 ]\n",
      "The rewards are: [0.92689115 0.6440242  0.9945673  0.9394813  0.57853776 0.99432486\n",
      " 0.9488314  0.6335259  0.99899286 0.9974964  0.91691643 0.90466243\n",
      " 0.9476409  0.90577805 0.9968573  0.9993223  0.9962471  0.81894606\n",
      " 0.88127893 0.6922931  0.58202916 0.8381967  0.7760498  0.9717228\n",
      " 0.88979954 0.97856766 0.99654335 0.6542711  0.9668095  0.9318938\n",
      " 0.9758277  0.97183615]\n",
      "The rewards are: [0.88821733 0.8869955  0.9969689  0.998409   0.57490027 0.9719381\n",
      " 0.99875724 0.9953068  0.9990466  0.99400085 0.99538714 0.9869263\n",
      " 0.6541544  0.9420077  0.9681112  0.99988544 0.6259771  0.98366135\n",
      " 0.99943155 0.92072314 0.99629515 0.99622786 0.9971443  0.9084131\n",
      " 0.97807294 0.9998946  0.62488586 0.98234946 0.84169096 0.69092464\n",
      " 0.8768434  0.99275005]\n",
      "The rewards are: [0.9464718  0.9812825  0.9975414  0.99283534 0.9673611  0.97844154\n",
      " 0.9989548  0.7908105  0.9991742  0.8899037  0.97331446 0.9567842\n",
      " 0.9252109  0.8419403  0.75504214 0.99863523 0.9992999  0.94666237\n",
      " 0.9998417  0.9913618  0.8978468  0.7334045  0.99380386 0.9426597\n",
      " 0.5867853  0.9994055  0.8070562  0.9982799  0.9974414  0.6726206\n",
      " 0.9959294  0.9984042 ]\n",
      "The rewards are: [0.9920602  0.99631906 0.9959978  0.99943334 0.9823069  0.966344\n",
      " 0.98498017 0.9720286  0.895209   0.99940515 0.88959503 0.9535771\n",
      " 0.98550075 0.87968856 0.9018395  0.99984014 0.9949838  0.9969639\n",
      " 0.90920913 0.99775887 0.9742365  0.9978363  0.98050094 0.92727244\n",
      " 0.90739065 0.99788123 0.9702871  0.87738127 0.996576   0.96598345\n",
      " 0.96798396 0.94910324]\n",
      "The rewards are: [0.6394083  0.96463346 0.990657   0.9972812  0.93721986 0.8813331\n",
      " 0.99790704 0.98696566 0.9963535  0.59558755 0.96904606 0.99982315\n",
      " 0.95033413 0.9909599  0.99169743 0.99562716 0.9885893  0.98684406\n",
      " 0.66707283 0.9936971  0.9974656  0.9882145  0.78005886 0.8306481\n",
      " 0.9855284  0.74535894 0.9951244  0.98687464 0.5723566  0.93461084\n",
      " 0.69971216 0.9962463 ]\n",
      "The rewards are: [0.9529239  0.74759394 0.5455579  0.9832923  0.5481503  0.9066153\n",
      " 0.9932823  0.97103184 0.99645114 0.92909807 0.7876122  0.8749055\n",
      " 0.9961351  0.9906042  0.98292047 0.97007984 0.9971312  0.8103717\n",
      " 0.7987539  0.97761244 0.9881706  0.87134224 0.9879915  0.65959656\n",
      " 0.99900836 0.8583196  0.7152218  0.9888024  0.96746695 0.99630404\n",
      " 0.9722392  0.9772602 ]\n",
      "The rewards are: [0.99897444 0.8698935  0.9977932  0.98602724 0.9751398  0.99141073\n",
      " 0.75234866 0.7401734  0.9978409  0.7986715  0.918591   0.99705493\n",
      " 0.5055116  0.8746689  0.5737156  0.98075104 0.9984717  0.9292372\n",
      " 0.995379   0.7698848  0.99975294 0.99718225 0.9824783  0.85648084\n",
      " 0.9742702  0.9978649  0.9824509  0.9480125  0.85769343 0.9839983\n",
      " 0.99843544 0.9863106 ]\n",
      "The rewards are: [0.9972145  0.94772875 0.99829143 0.9998902  0.64631    0.98677105\n",
      " 0.8125647  0.9146783  0.93636674 0.69300365 0.5102226  0.99039346\n",
      " 0.64775085 0.94818676 0.9977574  0.60197663 0.9975368  0.9901821\n",
      " 0.9992725  0.8423276  0.9941034  0.8054202  0.9890472  0.88997346\n",
      " 0.7219349  0.966314   0.99949265 0.9916048  0.98244876 0.9789629\n",
      " 0.9438397  0.9792429 ]\n",
      "The rewards are: [0.9982064  0.951087   0.69980377 0.99909663 0.52821684 0.9871137\n",
      " 0.9971048  0.93634415 0.85942423 0.92234236 0.9722946  0.9009875\n",
      " 0.99577194 0.8634044  0.99685305 0.9959926  0.9722344  0.60532653\n",
      " 0.73359865 0.6790763  0.82859945 0.89915085 0.9990559  0.9944981\n",
      " 0.8346654  0.80301994 0.7619453  0.9505254  0.9876245  0.7218288\n",
      " 0.9998597  0.99818414]\n",
      "The rewards are: [0.96367615 0.96363825 0.9963425  0.9933936  0.99850595 0.94404775\n",
      " 0.9967114  0.9954769  0.9956018  0.9502206  0.66274315 0.9966775\n",
      " 0.9841292  0.98176193 0.99289554 0.95340085 0.9633659  0.99221945\n",
      " 0.6891619  0.9983229  0.9011911  0.9425003  0.8012735  0.99441624\n",
      " 0.86675256 0.98712397 0.99452835 0.9759971  0.6580253  0.92084605\n",
      " 0.9822289  0.89275604]\n",
      "The rewards are: [0.76742226 0.99159735 0.56966    0.77311975 0.97974914 0.8680572\n",
      " 0.9171662  0.99882156 0.99149984 0.975549   0.7837943  0.9675038\n",
      " 0.95355344 0.9360072  0.98329306 0.9383575  0.98923033 0.9721477\n",
      " 0.91776943 0.9662887  0.996516   0.9962534  0.9763134  0.71531475\n",
      " 0.91424865 0.99894506 0.99867827 0.99680185 0.6996762  0.6104488\n",
      " 0.9919253  0.9791549 ]\n",
      "The rewards are: [0.9993318  0.9165762  0.93719643 0.9979972  0.9898129  0.90368724\n",
      " 0.70727444 0.9993767  0.94045645 0.9814105  0.74157923 0.99512947\n",
      " 0.9888692  0.6353502  0.87866807 0.74373776 0.99862194 0.9191454\n",
      " 0.99707365 0.5482698  0.9920523  0.92018276 0.85613924 0.979282\n",
      " 0.9502074  0.85212535 0.6339248  0.9994005  0.97529685 0.99130213\n",
      " 0.9824985  0.84052336]\n",
      "The rewards are: [0.95702004 0.99859744 0.8495494  0.9882069  0.95857227 0.93662757\n",
      " 0.97947264 0.99762964 0.99509406 0.9799519  0.82019264 0.9980223\n",
      " 0.9939873  0.7080003  0.9743906  0.85565877 0.66939414 0.79983836\n",
      " 0.9732361  0.99984515 0.99807954 0.9984787  0.98362607 0.7976153\n",
      " 0.999721   0.7707353  0.99893934 0.9971756  0.95757425 0.8269277\n",
      " 0.99440336 0.62648857]\n",
      "The rewards are: [0.9890886  0.9542848  0.9948167  0.93900114 0.97938466 0.5943692\n",
      " 0.9896897  0.99561054 0.99384487 0.9717263  0.8926492  0.9968816\n",
      " 0.96184444 0.87692726 0.99771404 0.9740025  0.99613947 0.9935499\n",
      " 0.8289735  0.60132986 0.96635824 0.9980416  0.90775436 0.904951\n",
      " 0.9965592  0.7976741  0.96966594 0.9575196  0.86207247 0.97936285\n",
      " 0.99327326 0.81955606]\n",
      "The rewards are: [0.8721127  0.64832884 0.99271214 0.9984249  0.99440706 0.8983571\n",
      " 0.9947713  0.96279734 0.9981054  0.91719586 0.9930483  0.9867365\n",
      " 0.9989354  0.5306844  0.9997657  0.886702   0.9558638  0.9864654\n",
      " 0.77758425 0.98769146 0.99842215 0.697755   0.9998099  0.5810479\n",
      " 0.92343223 0.976939   0.99179745 0.7235559  0.9404988  0.99928975\n",
      " 0.9195317  0.9963385 ]\n",
      "The rewards are: [0.96849155 0.6733405  0.9974739  0.50768274 0.93641794 0.9997002\n",
      " 0.5856604  0.99772805 0.71353585 0.9994524  0.9994246  0.8223016\n",
      " 0.9602894  0.96690494 0.97978127 0.8945592  0.9958187  0.8623554\n",
      " 0.78308284 0.8833054  0.9144982  0.67742723 0.97359407 0.9476424\n",
      " 0.9986683  0.8631606  0.8906795  0.96470934 0.7893113  0.8925018\n",
      " 0.964518   0.8893566 ]\n",
      "The rewards are: [0.9969126  0.98426104 0.92128605 0.79494673 0.794242   0.90071845\n",
      " 0.939909   0.9773911  0.892269   0.8951028  0.9791389  0.65680987\n",
      " 0.98786443 0.8366318  0.9976413  0.98667634 0.9261658  0.9937784\n",
      " 0.9978544  0.7667727  0.98952824 0.9836875  0.96145993 0.99426454\n",
      " 0.995764   0.9955954  0.9998374  0.9538236  0.96173406 0.9997912\n",
      " 0.81921417 0.8889743 ]\n",
      "The rewards are: [0.79319084 0.99612445 0.99855226 0.97774905 0.8390903  0.9993573\n",
      " 0.65219086 0.9969374  0.87688166 0.91730845 0.9637601  0.6238738\n",
      " 0.96954155 0.5274689  0.91397464 0.9858192  0.9715826  0.9950381\n",
      " 0.9983284  0.58897346 0.9114964  0.9823438  0.8883715  0.9900649\n",
      " 0.9983234  0.9737453  0.87453485 0.99383366 0.6555293  0.9974016\n",
      " 0.98586327 0.9778267 ]\n",
      "The rewards are: [0.999652   0.9043346  0.9996222  0.9514     0.6489715  0.9986039\n",
      " 0.9943533  0.9566638  0.647893   0.9987205  0.6669634  0.83998746\n",
      " 0.7212855  0.99277836 0.9788776  0.6752467  0.9969187  0.9675066\n",
      " 0.8624423  0.99286383 0.9867186  0.96176386 0.99915266 0.99844426\n",
      " 0.8502823  0.99837923 0.99209505 0.74075294 0.8103991  0.9704696\n",
      " 0.9711584  0.99786264]\n",
      "The rewards are: [0.9336447  0.6795643  0.8392719  0.99008405 0.9766267  0.9437329\n",
      " 0.6734488  0.9998914  0.99281704 0.63922405 0.84599125 0.9864152\n",
      " 0.82229686 0.9986395  0.94706637 0.595828   0.9997223  0.98826957\n",
      " 0.9757565  0.96477616 0.9849318  0.9169216  0.99534386 0.9969278\n",
      " 0.7842613  0.97417647 0.9158662  0.92525154 0.99750715 0.9216375\n",
      " 0.9917462  0.9991252 ]\n",
      "The rewards are: [0.9992919  0.74599314 0.9963337  0.96691203 0.99850285 0.99023634\n",
      " 0.87972146 0.99970144 0.8950395  0.9930473  0.9997063  0.9965115\n",
      " 0.99483633 0.9682861  0.9613614  0.9664523  0.9983156  0.9871689\n",
      " 0.9985191  0.8855068  0.9341715  0.8231581  0.52163136 0.95065725\n",
      " 0.557154   0.96131283 0.9185233  0.9989899  0.9903439  0.99626404\n",
      " 0.99061185 0.9839733 ]\n",
      "The rewards are: [0.92983866 0.960052   0.5539504  0.50373584 0.9775557  0.7597776\n",
      " 0.9420984  0.87588406 0.93643415 0.99968505 0.995606   0.9567248\n",
      " 0.8748023  0.94914854 0.9803956  0.9982551  0.9995776  0.98365235\n",
      " 0.99474597 0.9908414  0.587043   0.996566   0.94684476 0.9029677\n",
      " 0.99729115 0.8791419  0.99459404 0.8837968  0.97132844 0.98452157\n",
      " 0.9991787  0.60366625]\n",
      "The rewards are: [0.98056406 0.9943012  0.9893959  0.80754393 0.97894055 0.776967\n",
      " 0.9592406  0.5867768  0.9342738  0.9829155  0.9935284  0.74499565\n",
      " 0.85586715 0.99892586 0.6709615  0.9955374  0.55898505 0.95664275\n",
      " 0.9878209  0.5728751  0.9697381  0.99837744 0.6214252  0.97481626\n",
      " 0.9222446  0.9977424  0.6207085  0.70476055 0.9999707  0.9965545\n",
      " 0.9905385  0.99628484]\n",
      "The rewards are: [0.99387145 0.9568647  0.9818502  0.9969591  0.7188975  0.9237555\n",
      " 0.94943696 0.99872667 0.9917025  0.86703616 0.9883271  0.99177295\n",
      " 0.99024385 0.9979305  0.9830667  0.9970898  0.998309   0.99966514\n",
      " 0.92056113 0.7017257  0.99814975 0.7918028  0.98317164 0.9294498\n",
      " 0.9042568  0.9898851  0.60242933 0.66548824 0.9925696  0.9826032\n",
      " 0.9888732  0.99973756]\n",
      "The rewards are: [0.8710531  0.99373144 0.9804827  0.9873749  0.9747722  0.9964734\n",
      " 0.99461305 0.76787025 0.99735355 0.9986564  0.6929352  0.9892141\n",
      " 0.9932987  0.99629104 0.87981266 0.9906426  0.9795195  0.9673588\n",
      " 0.79009384 0.5150755  0.5193045  0.9975777  0.9976623  0.96672016\n",
      " 0.9309904  0.99649376 0.9912868  0.9963456  0.9750872  0.94945407\n",
      " 0.9971699  0.99609166]\n",
      "The rewards are: [0.99966466 0.9807974  0.9983841  0.8357902  0.9979226  0.94223815\n",
      " 0.5432055  0.97224253 0.89305645 0.99892277 0.98998    0.9972421\n",
      " 0.9021328  0.9981457  0.97636205 0.7147934  0.93921286 0.75591063\n",
      " 0.93035436 0.99201304 0.9424553  0.9786113  0.9975762  0.9713528\n",
      " 0.99331635 0.9577205  0.7316338  0.9993761  0.99443674 0.97181815\n",
      " 0.9999651  0.8199128 ]\n",
      "The rewards are: [0.9754287  0.99334043 0.9961253  0.7603395  0.9938632  0.9746732\n",
      " 0.8771427  0.9806553  0.62544197 0.54077524 0.9476697  0.9984244\n",
      " 0.94758874 0.97042185 0.9902794  0.8571719  0.9837869  0.75801295\n",
      " 0.9995003  0.5230129  0.9893735  0.99934    0.9824203  0.99290353\n",
      " 0.957864   0.95862037 0.9951774  0.7676045  0.9997347  0.97923046\n",
      " 0.8531808  0.9820063 ]\n",
      "The rewards are: [0.9965055  0.9988661  0.57241267 0.99877936 0.9913685  0.9564\n",
      " 0.9284572  0.99326575 0.99727976 0.9797106  0.54012954 0.5001929\n",
      " 0.9293865  0.984428   0.98232174 0.9880449  0.9558942  0.9971915\n",
      " 0.959649   0.63131535 0.9786596  0.99060494 0.99495727 0.9957522\n",
      " 0.9565472  0.86992675 0.9904405  0.7967328  0.95202196 0.9685921\n",
      " 0.99309    0.9937889 ]\n",
      "The rewards are: [0.9950536  0.8613194  0.9469154  0.980703   0.9989768  0.74101484\n",
      " 0.99735165 0.9918961  0.9757638  0.93573856 0.9278795  0.98307943\n",
      " 0.98863643 0.80463684 0.9849568  0.9988182  0.6795109  0.9910193\n",
      " 0.9924517  0.79565483 0.9710717  0.954567   0.99927586 0.98323244\n",
      " 0.9984378  0.9352021  0.99004465 0.9809301  0.97468185 0.8625928\n",
      " 0.99043673 0.9973463 ]\n",
      "The rewards are: [0.9939805  0.99300754 0.60822606 0.7669662  0.9757555  0.9858602\n",
      " 0.6047765  0.96670794 0.991285   0.9915788  0.9976132  0.9446886\n",
      " 0.9959842  0.99881834 0.98695976 0.935403   0.99770325 0.9735921\n",
      " 0.99038154 0.9808796  0.9947699  0.9819519  0.9583259  0.98951787\n",
      " 0.9940439  0.99346787 0.720638   0.97859544 0.5884345  0.7891642\n",
      " 0.99942964 0.9981133 ]\n",
      "The rewards are: [0.99896085 0.9668196  0.7174185  0.97911125 0.93616235 0.9994635\n",
      " 0.9267742  0.9870983  0.97732395 0.99430025 0.9570002  0.80483\n",
      " 0.9857449  0.819104   0.7462892  0.93653023 0.8294358  0.94399834\n",
      " 0.7239401  0.82082933 0.9492613  0.99908483 0.99379224 0.9965815\n",
      " 0.9814144  0.9989505  0.8175146  0.9782638  0.99975723 0.85594136\n",
      " 0.9812595  0.9383902 ]\n",
      "The rewards are: [0.99853766 0.9964179  0.989035   0.9925063  0.9899642  0.99137527\n",
      " 0.9319447  0.9697038  0.90323895 0.94249535 0.99761057 0.5740979\n",
      " 0.9549513  0.9519809  0.99094826 0.9957838  0.99915314 0.9994925\n",
      " 0.941698   0.97130615 0.6624839  0.9467426  0.97589827 0.6473782\n",
      " 0.9535332  0.9998166  0.98287475 0.99973243 0.70252466 0.99583805\n",
      " 0.72285664 0.9427315 ]\n",
      "The rewards are: [0.96568656 0.99853253 0.8974621  0.84367037 0.8037081  0.6998422\n",
      " 0.9255897  0.9989924  0.9664914  0.8690835  0.99503857 0.95155823\n",
      " 0.7619982  0.54647297 0.95081174 0.6093709  0.9919258  0.9863897\n",
      " 0.99915016 0.96616924 0.9785912  0.703546   0.9984763  0.99220663\n",
      " 0.99936587 0.9467736  0.56811607 0.9944569  0.53191096 0.99149317\n",
      " 0.99995613 0.78133416]\n",
      "The rewards are: [0.85476804 0.9617303  0.7641668  0.9992341  0.9159999  0.9869697\n",
      " 0.9987233  0.8408822  0.94354695 0.98074293 0.97244376 0.98672396\n",
      " 0.6087314  0.9973507  0.9992306  0.86176807 0.89374286 0.9563934\n",
      " 0.9951094  0.99918014 0.9975752  0.98269135 0.97771555 0.9969221\n",
      " 0.99652207 0.9744494  0.99923015 0.86786383 0.92366475 0.94867915\n",
      " 0.93985665 0.7712563 ]\n",
      "The rewards are: [0.99992037 0.99647313 0.99079555 0.9945576  0.8496497  0.9882013\n",
      " 0.98223877 0.99856645 0.7655005  0.9720909  0.94449085 0.9479029\n",
      " 0.99530846 0.9997987  0.9168427  0.9982272  0.90671325 0.9965358\n",
      " 0.98105156 0.98798335 0.9551467  0.8551714  0.99193126 0.9990357\n",
      " 0.5011135  0.9905979  0.9898656  0.99528044 0.77854496 0.6026555\n",
      " 0.9927085  0.7656503 ]\n",
      "The rewards are: [0.9642425  0.9798356  0.74692625 0.98406684 0.9588134  0.9054675\n",
      " 0.66959804 0.9595485  0.99179524 0.9449683  0.92552644 0.7276617\n",
      " 0.98986953 0.9997843  0.9524141  0.9690063  0.9996859  0.872382\n",
      " 0.6823889  0.6134246  0.7800692  0.97491574 0.9972516  0.9972065\n",
      " 0.9206161  0.9981035  0.7391086  0.929998   0.971857   0.9984546\n",
      " 0.97339135 0.99994314]\n",
      "The rewards are: [0.8458382  0.9996722  0.98342746 0.9637396  0.97351223 0.9556093\n",
      " 0.98790085 0.9922861  0.9097881  0.998197   0.9968311  0.98002326\n",
      " 0.9995901  0.8677765  0.5876952  0.6736688  0.93169713 0.9804637\n",
      " 0.6961993  0.99562526 0.8392079  0.85708946 0.81840736 0.9779773\n",
      " 0.9158086  0.9801303  0.99265105 0.9748185  0.81772465 0.99773264\n",
      " 0.9747224  0.99205875]\n",
      "The rewards are: [0.9941783  0.87180185 0.92557883 0.9984207  0.99678195 0.90619785\n",
      " 0.9993799  0.97796476 0.9993687  0.89658874 0.92388755 0.99645644\n",
      " 0.9981761  0.9845916  0.9519256  0.90607697 0.6418435  0.95509404\n",
      " 0.91315717 0.9987098  0.98692364 0.95631915 0.99808156 0.99278283\n",
      " 0.99986327 0.9996068  0.9479705  0.9892737  0.9139952  0.8687579\n",
      " 0.99634844 0.78266424]\n",
      "The rewards are: [0.9132729  0.5837492  0.9974739  0.99993706 0.9717395  0.7936613\n",
      " 0.8810549  0.98322463 0.8005592  0.9901135  0.9904145  0.88990456\n",
      " 0.99770254 0.9600937  0.9504001  0.99556243 0.99754816 0.9997938\n",
      " 0.95068204 0.9992937  0.95810556 0.99614525 0.96745735 0.6448742\n",
      " 0.87014586 0.9659344  0.99029666 0.9843047  0.97542894 0.99956125\n",
      " 0.6850561  0.99949706]\n",
      "The rewards are: [0.99638534 0.9888538  0.7549935  0.9148407  0.9437444  0.97303873\n",
      " 0.79579794 0.9956126  0.9581315  0.9883322  0.96484286 0.97653836\n",
      " 0.9985454  0.9977289  0.5905704  0.509334   0.59021235 0.92920476\n",
      " 0.8711143  0.99395424 0.98945624 0.973116   0.96984047 0.84988475\n",
      " 0.9136242  0.94347936 0.9970011  0.89294523 0.98928016 0.985544\n",
      " 0.93483967 0.96746427]\n",
      "The rewards are: [0.9751908  0.9865372  0.93813014 0.8309188  0.9848749  0.9949575\n",
      " 0.96091616 0.8750597  0.9980605  0.80684537 0.9433861  0.8977276\n",
      " 0.9984692  0.6857829  0.99212146 0.98289317 0.99887794 0.95823437\n",
      " 0.9584985  0.99714977 0.9506878  0.99369323 0.9977064  0.89676386\n",
      " 0.9977431  0.97226906 0.9998265  0.89847845 0.97096026 0.99816847\n",
      " 0.987643   0.91462445]\n",
      "The rewards are: [0.99059206 0.99906415 0.99863964 0.78888    0.9759679  0.9992238\n",
      " 0.99948967 0.6890572  0.9458905  0.9950971  0.9994103  0.9703113\n",
      " 0.97285664 0.99621767 0.9995177  0.997026   0.8869995  0.5719994\n",
      " 0.9935096  0.9921349  0.7194333  0.9938234  0.9995622  0.9908478\n",
      " 0.9832561  0.99717915 0.9861833  0.99115986 0.9952246  0.9965725\n",
      " 0.6183452  0.9692639 ]\n",
      "The rewards are: [0.9614924  0.8394483  0.9484727  0.90358204 0.86216974 0.90309125\n",
      " 0.9022765  0.50885355 0.9930188  0.8804427  0.9852653  0.78085613\n",
      " 0.97527367 0.931177   0.9951615  0.94628996 0.9124689  0.98508865\n",
      " 0.94602585 0.9925483  0.98767555 0.9961947  0.9929716  0.8056082\n",
      " 0.9984522  0.99033266 0.9975176  0.98429257 0.6485698  0.9581469\n",
      " 0.8510428  0.9956239 ]\n",
      "The rewards are: [0.98839474 0.9992176  0.9988588  0.99879164 0.78542274 0.99809045\n",
      " 0.91204286 0.5211025  0.9990514  0.8098505  0.97463644 0.615381\n",
      " 0.99307865 0.98933417 0.78575295 0.84840417 0.99920577 0.547443\n",
      " 0.9711167  0.887999   0.9975102  0.99299026 0.9879881  0.99976045\n",
      " 0.8537662  0.9560683  0.99603844 0.9993574  0.9992663  0.9166223\n",
      " 0.9187385  0.99423146]\n",
      "The rewards are: [0.6874605  0.9288531  0.9984181  0.7729164  0.9833682  0.9955603\n",
      " 0.9978258  0.9857487  0.9917653  0.9619403  0.73427534 0.999509\n",
      " 0.90973634 0.8687271  0.99408925 0.99251795 0.9986712  0.9911588\n",
      " 0.9656944  0.8149545  0.99825734 0.98380554 0.7099357  0.9931252\n",
      " 0.9958858  0.9988537  0.9990313  0.72885185 0.985629   0.98847127\n",
      " 0.80440193 0.99715424]\n",
      "The rewards are: [0.998042   0.9939506  0.994474   0.9971507  0.9997414  0.9658104\n",
      " 0.9795491  0.9932847  0.9930928  0.9187687  0.9939175  0.93413883\n",
      " 0.8310063  0.73718226 0.90714896 0.92381656 0.7196805  0.6921585\n",
      " 0.99276394 0.7928258  0.8496047  0.8728561  0.9969914  0.99907374\n",
      " 0.993893   0.68857116 0.5104998  0.7128291  0.95403135 0.931861\n",
      " 0.9415075  0.9776384 ]\n",
      "The rewards are: [0.968088   0.9980616  0.9982096  0.9652308  0.9997168  0.67572147\n",
      " 0.8767278  0.9833241  0.53037643 0.980735   0.9917489  0.9805228\n",
      " 0.71163636 0.9919487  0.99894387 0.99824154 0.81710726 0.92358446\n",
      " 0.9937874  0.99954396 0.9942064  0.74978507 0.9917749  0.98043936\n",
      " 0.92360264 0.98580337 0.55832577 0.7127042  0.8315358  0.90000963\n",
      " 0.9996382  0.91278744]\n",
      "The rewards are: [0.8645303  0.9964405  0.9630002  0.97320956 0.9927383  0.74217576\n",
      " 0.6912897  0.9870962  0.9896208  0.98271805 0.9537345  0.9091547\n",
      " 0.97925866 0.9972331  0.89613205 0.9764885  0.99965036 0.99964774\n",
      " 0.8734384  0.89022225 0.92522573 0.971509   0.98507524 0.9064385\n",
      " 0.6419985  0.96680564 0.94582254 0.9712071  0.9994062  0.99649674\n",
      " 0.60285234 0.96427876]\n",
      "The rewards are: [0.9798702  0.9949109  0.99819547 0.98126125 0.5035703  0.9910856\n",
      " 0.9943351  0.99192506 0.99569535 0.99539256 0.97650266 0.99145776\n",
      " 0.9996902  0.998538   0.744418   0.8926508  0.8441381  0.6680151\n",
      " 0.9981329  0.9974234  0.999116   0.9536004  0.998319   0.98401153\n",
      " 0.98948216 0.9999473  0.7736152  0.9536404  0.8746447  0.96963847\n",
      " 0.9708539  0.9025477 ]\n",
      "The rewards are: [0.7271968  0.9960782  0.9780703  0.64037937 0.991105   0.9880976\n",
      " 0.96816695 0.9975293  0.9556448  0.6768583  0.71994567 0.9998306\n",
      " 0.9960069  0.860723   0.9657526  0.99073666 0.82258624 0.9945365\n",
      " 0.791187   0.6161538  0.9994153  0.9962702  0.9533933  0.9997657\n",
      " 0.8022159  0.9781317  0.9947708  0.5125662  0.856621   0.9999331\n",
      " 0.6933378  0.9893098 ]\n",
      "The rewards are: [0.998206   0.9935796  0.99561834 0.5196524  0.9973833  0.9822484\n",
      " 0.9418739  0.9426274  0.9963631  0.99107987 0.6834094  0.99484444\n",
      " 0.99759173 0.9398256  0.9309531  0.9936599  0.9593434  0.967796\n",
      " 0.83098626 0.99032414 0.9990194  0.99945265 0.9482981  0.9923699\n",
      " 0.9491173  0.9771089  0.51943815 0.99496645 0.94904405 0.99011564\n",
      " 0.740095   0.9733373 ]\n",
      "The rewards are: [0.9262427  0.77034664 0.63811594 0.99384344 0.80027115 0.9597782\n",
      " 0.998262   0.8811955  0.9163373  0.93570316 0.997065   0.9694053\n",
      " 0.97236675 0.5735314  0.9735414  0.9343534  0.6218489  0.960687\n",
      " 0.9932494  0.9946016  0.79592294 0.99678975 0.98298544 0.9994375\n",
      " 0.9677546  0.6917737  0.9451467  0.90677184 0.9858527  0.9981462\n",
      " 0.9891338  0.90278745]\n",
      "The rewards are: [0.9644747  0.8059639  0.8204162  0.97534424 0.98819155 0.8984611\n",
      " 0.6248051  0.9994935  0.99401253 0.9977919  0.999877   0.98918533\n",
      " 0.80217016 0.99970955 0.9794938  0.8285515  0.5445713  0.9961499\n",
      " 0.9938765  0.9994822  0.9827308  0.9951067  0.9944396  0.58169514\n",
      " 0.965416   0.6494087  0.99916434 0.9984742  0.99167776 0.9930433\n",
      " 0.98627466 0.5368348 ]\n",
      "The rewards are: [0.9665191  0.9891361  0.99764985 0.7641517  0.9974112  0.97196174\n",
      " 0.9782276  0.6802397  0.98981    0.99846494 0.7657244  0.99943787\n",
      " 0.7100466  0.9875224  0.9866304  0.97801524 0.69274217 0.9682159\n",
      " 0.97582895 0.9887971  0.91403186 0.9866071  0.9997235  0.9866508\n",
      " 0.98749393 0.9343863  0.99866045 0.97081125 0.99995327 0.97550666\n",
      " 0.99800426 0.94271237]\n",
      "The rewards are: [0.922596   0.9994351  0.9811178  0.9982333  0.9619392  0.9848461\n",
      " 0.9991654  0.996705   0.99264985 0.99613935 0.98437077 0.8181677\n",
      " 0.99254483 0.7207281  0.5608259  0.9972249  0.78218055 0.9963709\n",
      " 0.9978163  0.9419688  0.99810284 0.9314499  0.93667215 0.926256\n",
      " 0.9670706  0.99929535 0.9987729  0.9739724  0.6972529  0.9979984\n",
      " 0.9726917  0.99691135]\n",
      "The rewards are: [0.80429506 0.6028205  0.9239419  0.8728036  0.94046843 0.9625756\n",
      " 0.90779024 0.99671644 0.92397416 0.8401557  0.99906176 0.99898237\n",
      " 0.8361005  0.99144495 0.881973   0.9655198  0.92484564 0.998064\n",
      " 0.99889576 0.85214055 0.98514163 0.99691355 0.8988265  0.9868954\n",
      " 0.99656206 0.98409384 0.9959298  0.879526   0.92314404 0.95961225\n",
      " 0.9940978  0.89466393]\n",
      "The rewards are: [0.9871946  0.78853834 0.99390864 0.9916535  0.97779834 0.85611194\n",
      " 0.99929404 0.977451   0.98458993 0.99847263 0.9974324  0.9881173\n",
      " 0.910962   0.99647444 0.73530614 0.6227196  0.9994493  0.9945081\n",
      " 0.9107311  0.94430107 0.66302645 0.9001173  0.96601903 0.99242157\n",
      " 0.9645351  0.8761803  0.9960847  0.950039   0.622587   0.99958986\n",
      " 0.99370533 0.7597887 ]\n",
      "The rewards are: [0.99104136 0.9998822  0.96328706 0.9992106  0.801098   0.9711285\n",
      " 0.98547226 0.87720245 0.53305674 0.64552385 0.6051217  0.7932913\n",
      " 0.99391407 0.9248161  0.99969304 0.92568547 0.96540713 0.99216664\n",
      " 0.99738544 0.785332   0.7087467  0.98661125 0.99817586 0.9948789\n",
      " 0.9982256  0.99867153 0.78873265 0.9931779  0.798758   0.9971015\n",
      " 0.89593    0.9993518 ]\n",
      "The rewards are: [0.70014596 0.99401605 0.9583893  0.9753794  0.99583936 0.99754286\n",
      " 0.8885839  0.87309337 0.98350126 0.83548135 0.9989266  0.932566\n",
      " 0.993608   0.9987858  0.9959812  0.7943031  0.9608528  0.9904749\n",
      " 0.7934509  0.99883896 0.99929357 0.9621942  0.98950934 0.99420315\n",
      " 0.9989857  0.99955577 0.9891832  0.85667163 0.9498491  0.9909769\n",
      " 0.96626896 0.9972499 ]\n",
      "The rewards are: [0.97743636 0.9076202  0.97347    0.8479498  0.9308729  0.9960212\n",
      " 0.7730538  0.97404003 0.88804066 0.99922395 0.999233   0.97368854\n",
      " 0.89939153 0.9941246  0.9991787  0.99107504 0.64093643 0.8980281\n",
      " 0.9272345  0.98554647 0.9960536  0.99696535 0.8186475  0.9490707\n",
      " 0.98279107 0.99117845 0.9614327  0.9939318  0.99951637 0.7988998\n",
      " 0.9626758  0.9487477 ]\n",
      "The rewards are: [0.99820006 0.99531436 0.9985953  0.99084127 0.99929035 0.9929134\n",
      " 0.9905793  0.99966025 0.9708731  0.9990269  0.6069226  0.8515002\n",
      " 0.99685293 0.8534787  0.79790163 0.99389404 0.8983956  0.6211405\n",
      " 0.98137003 0.9998423  0.9298308  0.9826433  0.7584442  0.6835696\n",
      " 0.99560106 0.9977616  0.99918264 0.99052864 0.784669   0.9848133\n",
      " 0.7503278  0.97325313]\n",
      "The rewards are: [0.9991448  0.98488855 0.9996138  0.8472218  0.9096535  0.98409444\n",
      " 0.9997118  0.56863713 0.9863811  0.9340658  0.50371045 0.99644095\n",
      " 0.9814348  0.99958545 0.9997602  0.9948361  0.94315845 0.97218084\n",
      " 0.9992262  0.9451067  0.998623   0.91311663 0.9860744  0.7718529\n",
      " 0.9995072  0.9922909  0.9964876  0.98814666 0.89939755 0.9996257\n",
      " 0.99055684 0.96405935]\n",
      "The rewards are: [0.99743336 0.703825   0.9470945  0.85428214 0.96503395 0.99977976\n",
      " 0.99067044 0.9828492  0.9943579  0.99922967 0.9602936  0.95320165\n",
      " 0.9537733  0.64172417 0.99823534 0.9789283  0.97549903 0.9676989\n",
      " 0.7508266  0.9570358  0.9007696  0.97643834 0.99787104 0.97590476\n",
      " 0.9942213  0.9788383  0.97848034 0.56901574 0.68182933 0.5315801\n",
      " 0.9517746  0.6248553 ]\n",
      "The rewards are: [0.93915117 0.9996859  0.9764811  0.9417185  0.9931866  0.9203994\n",
      " 0.90534383 0.9653525  0.72010005 0.8278751  0.85410243 0.8126245\n",
      " 0.9736988  0.72996056 0.9994161  0.99490744 0.9884327  0.6305227\n",
      " 0.9996767  0.9984452  0.8860816  0.80377674 0.998701   0.8843623\n",
      " 0.99798477 0.5319769  0.9364905  0.9064524  0.9885626  0.99712545\n",
      " 0.7682007  0.9949502 ]\n",
      "The rewards are: [0.74259865 0.8937685  0.9975993  0.74868554 0.68703103 0.9598675\n",
      " 0.99288905 0.9954461  0.9779171  0.953841   0.96069336 0.98768824\n",
      " 0.90382504 0.99842227 0.96296185 0.9259771  0.98211724 0.9567091\n",
      " 0.9564267  0.9491113  0.9752229  0.9987429  0.980515   0.9867584\n",
      " 0.9977314  0.99535674 0.822859   0.9939243  0.9817037  0.9784057\n",
      " 0.9416449  0.6522816 ]\n",
      "The rewards are: [0.99129105 0.9929342  0.9486077  0.9562994  0.9958412  0.8026534\n",
      " 0.96913266 0.9811763  0.7644323  0.99665487 0.994207   0.94626606\n",
      " 0.94737494 0.9591691  0.97012186 0.94627994 0.9888532  0.88467455\n",
      " 0.92124814 0.7670372  0.93094534 0.9252437  0.9696895  0.991319\n",
      " 0.9967428  0.9527805  0.9731535  0.97649616 0.9972778  0.99139565\n",
      " 0.9981718  0.66098255]\n",
      "The rewards are: [0.83085334 0.56771034 0.9790759  0.83664167 0.9978824  0.99854904\n",
      " 0.99145025 0.98481536 0.7344855  0.91774464 0.98495007 0.99672145\n",
      " 0.99814105 0.7886608  0.9962853  0.9949049  0.71928835 0.997355\n",
      " 0.9993869  0.99825615 0.91977    0.9975326  0.98637646 0.9997571\n",
      " 0.9836691  0.5598306  0.925833   0.7621592  0.9734404  0.8200955\n",
      " 0.9869199  0.9930895 ]\n",
      "The rewards are: [0.9990534  0.9999341  0.9818617  0.98152494 0.99381554 0.82916945\n",
      " 0.99086964 0.9891011  0.99938476 0.99996614 0.9941618  0.61143136\n",
      " 0.99889225 0.9913742  0.7597593  0.9972365  0.9877323  0.9262938\n",
      " 0.9883245  0.970883   0.86075217 0.9758706  0.9863479  0.9795578\n",
      " 0.9974732  0.95992005 0.9927067  0.8083677  0.9432218  0.873944\n",
      " 0.9907612  0.99440575]\n",
      "The rewards are: [0.9995245  0.9991437  0.99935263 0.99732995 0.85942775 0.6924957\n",
      " 0.9876935  0.55345434 0.9805977  0.9309871  0.61706376 0.7342252\n",
      " 0.9971782  0.994858   0.9994331  0.9964399  0.9996227  0.994921\n",
      " 0.95992965 0.51632214 0.6753224  0.9820556  0.99478394 0.9575362\n",
      " 0.50904673 0.5080057  0.9936265  0.999879   0.9759694  0.99186134\n",
      " 0.99035066 0.7482916 ]\n",
      "The rewards are: [0.83337843 0.9905538  0.9966487  0.9756143  0.9974673  0.9155194\n",
      " 0.98891556 0.7456128  0.99955326 0.9004872  0.998429   0.62961614\n",
      " 0.97764957 0.84225464 0.8608135  0.9990509  0.9984597  0.6666814\n",
      " 0.99308574 0.99715877 0.99277765 0.99848574 0.9608572  0.99860734\n",
      " 0.995053   0.94840115 0.9951224  0.9722721  0.99868625 0.91006994\n",
      " 0.57226795 0.8226897 ]\n",
      "The rewards are: [0.99150884 0.99722373 0.99576604 0.9816721  0.9986407  0.9629195\n",
      " 0.9240206  0.5094659  0.99585813 0.95328546 0.9977323  0.7761317\n",
      " 0.9241298  0.9888178  0.99800974 0.88894016 0.74750334 0.8701446\n",
      " 0.9641066  0.94087225 0.9700487  0.66698587 0.9951939  0.995471\n",
      " 0.8840951  0.99398524 0.99961555 0.9774656  0.9858372  0.972684\n",
      " 0.99729055 0.99764806]\n",
      "The rewards are: [0.9907482  0.89461833 0.9990563  0.9367434  0.6193373  0.99773824\n",
      " 0.9860373  0.99761814 0.83261645 0.99952495 0.8960992  0.9767851\n",
      " 0.99884725 0.9981171  0.5492428  0.9673141  0.57120925 0.9480564\n",
      " 0.7708636  0.9760926  0.6645916  0.5715153  0.95344603 0.86581063\n",
      " 0.93325484 0.9973973  0.93861914 0.99470985 0.96389174 0.98965937\n",
      " 0.98432297 0.93634456]\n",
      "The rewards are: [0.99637234 0.9661167  0.9665913  0.996651   0.7766454  0.99958557\n",
      " 0.98538417 0.99852353 0.97848046 0.98112935 0.97030795 0.999851\n",
      " 0.9658373  0.9851559  0.9948596  0.83765    0.9938617  0.9931733\n",
      " 0.9661438  0.9607106  0.98091346 0.9048527  0.9668519  0.9997955\n",
      " 0.99995065 0.9914221  0.93351024 0.9921665  0.95838183 0.8048598\n",
      " 0.9991037  0.99313605]\n",
      "The rewards are: [0.9953951  0.99973625 0.9939061  0.996234   0.9990314  0.9831456\n",
      " 0.9463848  0.9720489  0.96811134 0.9782472  0.99993813 0.99615794\n",
      " 0.9916751  0.99063385 0.996123   0.9769791  0.9989256  0.97315246\n",
      " 0.68451995 0.9784021  0.85661334 0.800037   0.77891994 0.9990864\n",
      " 0.988618   0.99070626 0.90828353 0.56523526 0.957529   0.92016\n",
      " 0.93785655 0.9644486 ]\n",
      "The rewards are: [0.9998122  0.9960193  0.9992455  0.70954555 0.9993703  0.9986386\n",
      " 0.9970197  0.96384954 0.9382453  0.99997044 0.9967528  0.9997298\n",
      " 0.9967309  0.9779318  0.9959304  0.99892825 0.98552436 0.75010115\n",
      " 0.9982318  0.9999795  0.9987914  0.9749005  0.6930198  0.9734552\n",
      " 0.9814933  0.9312489  0.6547883  0.74892414 0.9696567  0.52217466\n",
      " 0.8647436  0.9985643 ]\n",
      "The rewards are: [0.99540776 0.92292243 0.8349152  0.7962568  0.71319264 0.73549944\n",
      " 0.9996997  0.8951008  0.98299384 0.9999026  0.6790364  0.9994469\n",
      " 0.5227377  0.9830912  0.60670453 0.9875745  0.9990362  0.96054024\n",
      " 0.9747523  0.6360866  0.8007896  0.99894303 0.8713394  0.9635226\n",
      " 0.9793214  0.99845624 0.7109535  0.7696001  0.984464   0.9873202\n",
      " 0.9960681  0.99596524]\n",
      "The rewards are: [0.772665   0.99972194 0.99646866 0.9588152  0.60765713 0.7719669\n",
      " 0.9761782  0.9755216  0.91942656 0.9673518  0.9922646  0.99970657\n",
      " 0.82129335 0.9364903  0.99819094 0.91736263 0.99909055 0.9938362\n",
      " 0.9942889  0.9748009  0.5935902  0.9920055  0.99223536 0.99120283\n",
      " 0.9799091  0.75260216 0.99767977 0.9930519  0.99975234 0.9441016\n",
      " 0.99712914 0.9910308 ]\n",
      "The rewards are: [0.994812   0.663871   0.9871043  0.90084934 0.9985941  0.98519367\n",
      " 0.9996915  0.998697   0.62033105 0.64938766 0.6244969  0.9908308\n",
      " 0.98054826 0.98080647 0.9709933  0.9309688  0.99854904 0.9757967\n",
      " 0.959861   0.83633274 0.938883   0.88670933 0.9972996  0.99693227\n",
      " 0.9966845  0.9963303  0.97220427 0.97079664 0.993505   0.998418\n",
      " 0.94230074 0.9985354 ]\n",
      "The rewards are: [0.99738723 0.998123   0.9857035  0.99959916 0.967967   0.9772778\n",
      " 0.9894007  0.9965496  0.97529674 0.7991617  0.96376616 0.97204655\n",
      " 0.99633753 0.99604887 0.9882068  0.99445736 0.99847895 0.9353877\n",
      " 0.9921451  0.95388013 0.99771416 0.84658587 0.99957746 0.9738999\n",
      " 0.87296295 0.9974089  0.9935574  0.999017   0.99795973 0.80905706\n",
      " 0.99476916 0.9692022 ]\n",
      "The rewards are: [0.99895453 0.99859565 0.9990119  0.97863835 0.5309213  0.9808395\n",
      " 0.98479146 0.70444036 0.56181854 0.9820592  0.99676174 0.6148521\n",
      " 0.99786395 0.9977151  0.90505207 0.98878914 0.8914543  0.98670316\n",
      " 0.694401   0.9774656  0.9992489  0.93782634 0.95426536 0.9992384\n",
      " 0.99208856 0.98891044 0.95013875 0.9949451  0.95128274 0.98368144\n",
      " 0.98002887 0.99943465]\n",
      "The rewards are: [0.7724687  0.9992318  0.87870103 0.8952878  0.999092   0.9480173\n",
      " 0.99441504 0.9995285  0.9842577  0.9980318  0.957413   0.97441405\n",
      " 0.9907829  0.99169016 0.97693115 0.9991923  0.9890324  0.99718934\n",
      " 0.9976947  0.7347053  0.9990326  0.8563063  0.9944449  0.9577052\n",
      " 0.9984989  0.9974716  0.9989537  0.97281265 0.99883443 0.8723331\n",
      " 0.97161466 0.97249055]\n",
      "The rewards are: [0.55344325 0.99704355 0.98914146 0.9662307  0.85722214 0.63833654\n",
      " 0.9792292  0.938941   0.98304325 0.89719737 0.95106786 0.9465985\n",
      " 0.9963833  0.9942364  0.99862087 0.93244946 0.9990645  0.9877402\n",
      " 0.8944823  0.9659769  0.9886208  0.98520386 0.6211328  0.99950933\n",
      " 0.9892012  0.9844557  0.97784185 0.8643471  0.9952807  0.9740735\n",
      " 0.96817195 0.9216357 ]\n",
      "The rewards are: [0.94536155 0.9992569  0.7061272  0.9859061  0.9957552  0.97863674\n",
      " 0.8991678  0.502088   0.96019137 0.97157234 0.9983354  0.99768734\n",
      " 0.9992205  0.9326374  0.99736196 0.97744703 0.9971666  0.99936754\n",
      " 0.99875927 0.9301174  0.9988293  0.89236325 0.9996916  0.9974195\n",
      " 0.9467475  0.9990268  0.99679667 0.99902403 0.99969316 0.93294173\n",
      " 0.96967834 0.98623604]\n",
      "The rewards are: [0.9994282  0.9814238  0.98278296 0.86018187 0.98656267 0.7370004\n",
      " 0.99927694 0.9888892  0.9913517  0.98498905 0.9931197  0.9988299\n",
      " 0.9960873  0.95350444 0.9978669  0.953914   0.9724505  0.92408806\n",
      " 0.9847899  0.9971625  0.99822587 0.977221   0.6318277  0.9729752\n",
      " 0.9834487  0.9960781  0.9870682  0.9996854  0.9924831  0.9919871\n",
      " 0.9969278  0.8400635 ]\n",
      "The rewards are: [0.5232834  0.71846366 0.9761036  0.77793926 0.72831446 0.587802\n",
      " 0.99687934 0.96441466 0.99689484 0.9894298  0.9994324  0.96402633\n",
      " 0.90146166 0.9944877  0.9930529  0.97131795 0.8891949  0.99965096\n",
      " 0.99996793 0.95395803 0.998863   0.9993957  0.99785954 0.9604665\n",
      " 0.9587364  0.981312   0.98644966 0.96826583 0.9597476  0.9812655\n",
      " 0.951941   0.988513  ]\n",
      "The rewards are: [0.8485983  0.9999467  0.8760695  0.57364386 0.9971214  0.5493922\n",
      " 0.9982463  0.9901765  0.9975049  0.599835   0.9100832  0.86259997\n",
      " 0.62691414 0.57520455 0.573885   0.9239487  0.9810967  0.99533576\n",
      " 0.77423894 0.9991873  0.9996679  0.9829107  0.91090125 0.9922576\n",
      " 0.99391174 0.99944013 0.96048915 0.9680397  0.9926468  0.9777908\n",
      " 0.9282668  0.9230868 ]\n",
      "The rewards are: [0.9703462  0.5997632  0.99109614 0.86013126 0.99843115 0.6936627\n",
      " 0.9317754  0.9168442  0.99467367 0.9980909  0.9103261  0.9996669\n",
      " 0.95824873 0.9953206  0.9853758  0.99949217 0.5331317  0.9107389\n",
      " 0.7930947  0.9996728  0.9852549  0.9997081  0.97749865 0.92315674\n",
      " 0.99985504 0.99956447 0.97323215 0.7429033  0.91713476 0.9980071\n",
      " 0.9709076  0.9908798 ]\n",
      "The rewards are: [0.7074777  0.985328   0.9948479  0.9957989  0.97346956 0.9894085\n",
      " 0.9995646  0.9995932  0.97909784 0.8371532  0.7704564  0.9986557\n",
      " 0.9999654  0.9988802  0.67149425 0.9959722  0.9991296  0.9784923\n",
      " 0.8776918  0.9511502  0.9903385  0.59003574 0.9158512  0.88883746\n",
      " 0.6171793  0.9981704  0.9991542  0.8628027  0.99707186 0.919041\n",
      " 0.9910411  0.979076  ]\n",
      "The rewards are: [0.9451744  0.97304755 0.88643366 0.99891186 0.8161273  0.99102294\n",
      " 0.9997501  0.63809985 0.9595611  0.9865442  0.6087735  0.9990048\n",
      " 0.99897027 0.9868537  0.88307977 0.996644   0.9404584  0.99716395\n",
      " 0.8188295  0.52951056 0.9900648  0.9931016  0.9348674  0.97963595\n",
      " 0.99863005 0.9849274  0.7051326  0.99943334 0.99915135 0.94914734\n",
      " 0.998547   0.99035245]\n",
      "The rewards are: [0.9997234  0.8896876  0.86787796 0.8420417  0.95681024 0.88544774\n",
      " 0.99192023 0.7475718  0.99806565 0.95709777 0.9693495  0.8810072\n",
      " 0.95118994 0.8243622  0.99639493 0.9932209  0.99556583 0.99820936\n",
      " 0.8760488  0.9699295  0.979478   0.9781741  0.9986083  0.93192303\n",
      " 0.9896299  0.6150107  0.99009365 0.89058167 0.99955565 0.56091774\n",
      " 0.99784744 0.9874205 ]\n",
      "The rewards are: [0.9954644  0.92098546 0.99851567 0.9944911  0.99843556 0.98849237\n",
      " 0.99421316 0.9566865  0.99012494 0.91306424 0.76453495 0.968118\n",
      " 0.7985249  0.99904484 0.646062   0.9937757  0.99337995 0.9495611\n",
      " 0.9474339  0.9890521  0.9864867  0.84620774 0.9883937  0.9990951\n",
      " 0.9921043  0.97276163 0.915429   0.9975344  0.94316083 0.9968907\n",
      " 0.994964   0.92927283]\n",
      "The rewards are: [0.840873   0.9986688  0.95138586 0.99880576 0.98798686 0.97098666\n",
      " 0.9718445  0.9924314  0.9787492  0.9936986  0.9921767  0.9902057\n",
      " 0.95994455 0.9982066  0.8545688  0.9792946  0.92668086 0.9552589\n",
      " 0.9977241  0.9124538  0.805922   0.9962992  0.9820072  0.9977513\n",
      " 0.9928859  0.99971646 0.90434194 0.9439621  0.94875294 0.999421\n",
      " 0.6677748  0.667806  ]\n",
      "The rewards are: [0.99411654 0.9486482  0.9929079  0.76929754 0.9931161  0.99696463\n",
      " 0.9342348  0.997297   0.9926722  0.9994165  0.95963347 0.99260205\n",
      " 0.99597424 0.9967706  0.99298626 0.87763816 0.9988741  0.9987551\n",
      " 0.9139284  0.9983595  0.9954051  0.9388122  0.92340267 0.9790158\n",
      " 0.99042916 0.9546237  0.99555236 0.98793143 0.99325997 0.9941711\n",
      " 0.93758494 0.9678046 ]\n",
      "The rewards are: [0.9974039  0.6078868  0.9928382  0.9337331  0.9965603  0.990328\n",
      " 0.9499631  0.9963341  0.9925276  0.9051036  0.9789944  0.99096674\n",
      " 0.99788195 0.9630273  0.52343047 0.9785606  0.98425376 0.9929014\n",
      " 0.9432987  0.9908557  0.9426806  0.9996296  0.9469546  0.99675155\n",
      " 0.8936086  0.99854916 0.98137075 0.99847835 0.91582197 0.9967753\n",
      " 0.98751277 0.66154736]\n",
      "The rewards are: [0.81633997 0.7744166  0.9781597  0.7771867  0.6305265  0.58518875\n",
      " 0.9997392  0.9620227  0.998887   0.9958377  0.8812991  0.8083647\n",
      " 0.9037006  0.83160365 0.9701679  0.942405   0.99978644 0.9988446\n",
      " 0.94234574 0.9997696  0.95841855 0.828777   0.9981172  0.9228872\n",
      " 0.9792947  0.974035   0.99850297 0.99715626 0.8516004  0.99581194\n",
      " 0.9282326  0.9995208 ]\n",
      "The rewards are: [0.9442161  0.9733088  0.9574302  0.99747    0.9870524  0.99928075\n",
      " 0.99824333 0.99975556 0.8443122  0.94657946 0.9297865  0.99458224\n",
      " 0.99637574 0.9477286  0.77551806 0.9990753  0.9836289  0.96604764\n",
      " 0.9975062  0.9983772  0.9995751  0.99181455 0.99856406 0.9559972\n",
      " 0.9982673  0.9982633  0.99152464 0.9099273  0.95912    0.9784185\n",
      " 0.98002577 0.987318  ]\n",
      "The rewards are: [0.9939493  0.9999155  0.99997044 0.9689906  0.99461716 0.95872086\n",
      " 0.5860552  0.9960162  0.99126023 0.9983095  0.9992113  0.99626046\n",
      " 0.9902512  0.9999424  0.9910835  0.91077465 0.86145914 0.99262094\n",
      " 0.90347904 0.9246961  0.9950724  0.99929833 0.9960396  0.7367216\n",
      " 0.9960413  0.9512019  0.9448616  0.997652   0.97438544 0.99792576\n",
      " 0.9970552  0.99972147]\n",
      "The rewards are: [0.99957055 0.9911404  0.9966204  0.8033615  0.87579256 0.9960057\n",
      " 0.97970337 0.9970278  0.97851926 0.81921417 0.99761957 0.9915324\n",
      " 0.9939466  0.7142099  0.87384146 0.9884957  0.9957033  0.9905501\n",
      " 0.99108374 0.9330311  0.9921537  0.7415415  0.8902595  0.7646967\n",
      " 0.7897484  0.9454115  0.99859935 0.9721754  0.9989794  0.63997656\n",
      " 0.9667664  0.5983216 ]\n",
      "The rewards are: [0.990231   0.96489346 0.9978942  0.9924816  0.9987349  0.9885033\n",
      " 0.91100067 0.72564065 0.9988174  0.9799974  0.9928411  0.9998925\n",
      " 0.50951517 0.99995816 0.99989176 0.9995696  0.9608572  0.90053\n",
      " 0.9826733  0.9959273  0.9974341  0.99814355 0.99690634 0.8961003\n",
      " 0.9794136  0.8066531  0.99325377 0.9999162  0.5324008  0.9864672\n",
      " 0.99652463 0.92729765]\n",
      "The rewards are: [0.9918784  0.99934524 0.96865696 0.9765053  0.5759087  0.99061006\n",
      " 0.9894684  0.99550605 0.9983354  0.986101   0.99908483 0.99727196\n",
      " 0.9474635  0.9272354  0.9839967  0.98665524 0.7024985  0.9928526\n",
      " 0.97937906 0.999579   0.9623299  0.9982352  0.9965569  0.9943599\n",
      " 0.9993006  0.9736353  0.9900984  0.99378514 0.769605   0.98707426\n",
      " 0.9851553  0.9578125 ]\n",
      "The rewards are: [0.9921629  0.935774   0.9875709  0.8643541  0.99713516 0.94471985\n",
      " 0.9932458  0.99931586 0.9845398  0.9991763  0.9866963  0.9868723\n",
      " 0.9337448  0.98658866 0.9969559  0.9972441  0.98727036 0.9597661\n",
      " 0.89375156 0.9949622  0.5595927  0.8902006  0.9810447  0.95081854\n",
      " 0.88986737 0.99961215 0.9992465  0.9040794  0.9852129  0.96177065\n",
      " 0.8900533  0.9923497 ]\n",
      "The rewards are: [0.97173125 0.9504014  0.99942917 0.9908422  0.8955419  0.98859054\n",
      " 0.9788563  0.50972563 0.9982955  0.9654786  0.9995894  0.9962753\n",
      " 0.9980184  0.9343019  0.9907789  0.56525326 0.9763733  0.9965245\n",
      " 0.9979115  0.97982466 0.9978242  0.6850343  0.97411764 0.927459\n",
      " 0.9974598  0.8656582  0.5405022  0.994334   0.9834952  0.9556848\n",
      " 0.9763583  0.8695017 ]\n",
      "The rewards are: [0.54224336 0.9987231  0.70099676 0.9533227  0.95556325 0.9192171\n",
      " 0.99914646 0.9303291  0.6806523  0.8568523  0.9963587  0.99916685\n",
      " 0.9887362  0.98846126 0.9999503  0.99834156 0.6422409  0.57917374\n",
      " 0.89325786 0.97319466 0.9987841  0.870026   0.99461824 0.9660415\n",
      " 0.9127374  0.9944389  0.93745124 0.996579   0.9953844  0.99688405\n",
      " 0.99795353 0.9932653 ]\n",
      "The rewards are: [0.93639684 0.95688695 0.6889859  0.5820226  0.57655466 0.99987745\n",
      " 0.9609329  0.99993086 0.9664996  0.97765005 0.97986037 0.8717221\n",
      " 0.99850744 0.98015654 0.87372833 0.99870455 0.6281714  0.87636024\n",
      " 0.9418184  0.8357676  0.99388796 0.99830616 0.994451   0.57231927\n",
      " 0.9894561  0.7285586  0.78407866 0.9520673  0.994636   0.8784304\n",
      " 0.92734706 0.87948793]\n",
      "The rewards are: [0.9956055  0.99460226 0.998887   0.8232921  0.9937098  0.9932248\n",
      " 0.8240112  0.99593383 0.7842012  0.9958895  0.8175628  0.87845176\n",
      " 0.91444826 0.8533     0.7403509  0.9990508  0.92667377 0.83315724\n",
      " 0.9774584  0.98731136 0.8629026  0.99830014 0.9993038  0.99756444\n",
      " 0.9799585  0.99807906 0.9696175  0.98310626 0.9992692  0.998879\n",
      " 0.99572504 0.9548756 ]\n",
      "The rewards are: [0.90627944 0.99832505 0.94316155 0.9973953  0.99874216 0.98363113\n",
      " 0.99694186 0.9636958  0.75423616 0.9711121  0.9924505  0.96810013\n",
      " 0.9261534  0.8388204  0.9554156  0.83071464 0.95955783 0.9965244\n",
      " 0.9932039  0.9995029  0.98823357 0.99183124 0.9975158  0.99931276\n",
      " 0.9903758  0.7777993  0.97157186 0.67130995 0.9981275  0.9927458\n",
      " 0.65909773 0.98039323]\n",
      "The rewards are: [0.9953157  0.9994522  0.9729063  0.9750231  0.94899756 0.9408057\n",
      " 0.8805982  0.99790585 0.9314597  0.93558306 0.6516586  0.98747665\n",
      " 0.98952746 0.98784524 0.91476905 0.9508947  0.99853206 0.99216557\n",
      " 0.9823369  0.8366464  0.5153214  0.96948886 0.9963325  0.98897105\n",
      " 0.9964509  0.9927751  0.8722819  0.6217846  0.9993863  0.9871007\n",
      " 0.87819296 0.9995449 ]\n",
      "The rewards are: [0.8257709  0.9813517  0.999253   0.9670931  0.99519783 0.9698598\n",
      " 0.8469196  0.9719111  0.9982077  0.9275867  0.9814648  0.9341046\n",
      " 0.9722304  0.99912566 0.9989938  0.87340856 0.96229994 0.9997485\n",
      " 0.9991233  0.9961528  0.90790695 0.99957174 0.98041886 0.9054513\n",
      " 0.9921033  0.90796393 0.9981883  0.9711652  0.87201    0.97065353\n",
      " 0.98184574 0.99904996]\n",
      "The rewards are: [0.8484581  0.80955625 0.9986694  0.9994149  0.9875229  0.939368\n",
      " 0.8817688  0.9731669  0.8843991  0.9990645  0.5211902  0.99898773\n",
      " 0.9985475  0.6342392  0.9999181  0.5792269  0.98640084 0.89973295\n",
      " 0.8608449  0.9973724  0.9822212  0.9702288  0.9977652  0.7115217\n",
      " 0.9704616  0.6209983  0.8193388  0.9930962  0.9428523  0.99190557\n",
      " 0.72605073 0.8801952 ]\n",
      "The rewards are: [0.68155414 0.9462686  0.7864074  0.91804916 0.9977126  0.9978042\n",
      " 0.5974261  0.98500615 0.9776652  0.99052244 0.9964316  0.8611744\n",
      " 0.8323454  0.98801816 0.99826187 0.915858   0.9982844  0.9389104\n",
      " 0.62690294 0.94089675 0.98888236 0.9314805  0.999856   0.9990761\n",
      " 0.8162317  0.9929931  0.9894243  0.8146622  0.9515322  0.89252144\n",
      " 0.69058913 0.98630047]\n",
      "The rewards are: [0.9729796  0.98520863 0.9901211  0.9831578  0.5116424  0.9976278\n",
      " 0.9997271  0.96430004 0.99793077 0.9994087  0.89237785 0.80544496\n",
      " 0.8469424  0.52959615 0.9993418  0.99839956 0.9979785  0.9999101\n",
      " 0.96923333 0.9983742  0.80349594 0.97019    0.99959666 0.99984074\n",
      " 0.9858693  0.6664703  0.9992067  0.97197604 0.97563803 0.52112025\n",
      " 0.9955271  0.65049165]\n",
      "The rewards are: [0.9699838  0.9878919  0.9376106  0.9866172  0.9979937  0.9989492\n",
      " 0.9720034  0.99259627 0.9976192  0.9650151  0.56919706 0.9921645\n",
      " 0.9856763  0.9944701  0.994531   0.99123865 0.9952512  0.9986299\n",
      " 0.99976045 0.9754063  0.82138824 0.55140615 0.98948133 0.99508756\n",
      " 0.7586217  0.991265   0.9832364  0.5735426  0.9965829  0.99918157\n",
      " 0.7377345  0.97837377]\n",
      "The rewards are: [0.9991068  0.9632116  0.95883363 0.99756324 0.9045958  0.9329458\n",
      " 0.99610126 0.60252875 0.9914609  0.68956363 0.9983175  0.9960375\n",
      " 0.8526591  0.94716096 0.78248394 0.9773347  0.99847466 0.99834836\n",
      " 0.61578476 0.9954627  0.99018025 0.9848815  0.9969789  0.92765325\n",
      " 0.78387326 0.8585393  0.99860966 0.9992048  0.99349594 0.9824142\n",
      " 0.9962237  0.9901574 ]\n",
      "The rewards are: [0.92394435 0.9742588  0.7691669  0.9934558  0.99955314 0.921812\n",
      " 0.8591188  0.8522156  0.6271895  0.97296745 0.5972912  0.911941\n",
      " 0.99917763 0.937928   0.9102992  0.7504246  0.972961   0.9260636\n",
      " 0.99831957 0.9819119  0.89296985 0.9964489  0.9374215  0.9597889\n",
      " 0.99871135 0.7254825  0.912275   0.8432584  0.96394444 0.8332622\n",
      " 0.9990951  0.85197973]\n",
      "The rewards are: [0.98105615 0.86729765 0.9962924  0.7751536  0.99066216 0.8618144\n",
      " 0.9988299  0.99898916 0.9951781  0.9968389  0.9693766  0.97575426\n",
      " 0.8349733  0.90932673 0.9997968  0.75256765 0.9936243  0.9982717\n",
      " 0.8611739  0.9942292  0.9995278  0.9405589  0.9942914  0.7981241\n",
      " 0.9415045  0.69108695 0.9986656  0.99353117 0.77118975 0.9779593\n",
      " 0.94042426 0.95782596]\n",
      "The rewards are: [0.81644124 0.9957611  0.61785364 0.5653594  0.9786926  0.9913789\n",
      " 0.7930666  0.9998147  0.98385    0.5825062  0.9912772  0.9891298\n",
      " 0.6450732  0.82955897 0.88497156 0.99797565 0.98790085 0.96019113\n",
      " 0.9846675  0.9991085  0.8819501  0.8759088  0.9704673  0.8255169\n",
      " 0.98162466 0.95380586 0.99415284 0.99296415 0.96958166 0.5960663\n",
      " 0.9914225  0.9901328 ]\n",
      "The rewards are: [0.8668734  0.9553189  0.9461687  0.9724034  0.99986327 0.99971884\n",
      " 0.79048896 0.9260823  0.7495857  0.9570492  0.70691895 0.9970789\n",
      " 0.9738921  0.99715626 0.99495775 0.9830595  0.9864217  0.9069587\n",
      " 0.55472326 0.97277147 0.9656669  0.5531499  0.99991333 0.9796014\n",
      " 0.9164624  0.9998105  0.994086   0.9979861  0.9911485  0.9987943\n",
      " 0.98631775 0.99936265]\n",
      "The rewards are: [0.9266388  0.54142773 0.81294215 0.9940643  0.9953721  0.94643646\n",
      " 0.98892653 0.96963453 0.9990108  0.9990331  0.9951681  0.93569744\n",
      " 0.9666501  0.9995499  0.99945635 0.95287246 0.889443   0.9479178\n",
      " 0.993944   0.99967504 0.99560744 0.99568117 0.669162   0.894167\n",
      " 0.911008   0.91398937 0.9908347  0.67496836 0.99287343 0.82971674\n",
      " 0.7159568  0.73555315]\n",
      "The rewards are: [0.98721075 0.9441359  0.59900564 0.8739178  0.99632275 0.717982\n",
      " 0.9996275  0.94824845 0.8566793  0.95666957 0.93960106 0.953615\n",
      " 0.6205277  0.9402575  0.85231704 0.9890919  0.9993831  0.92967963\n",
      " 0.95254254 0.9862177  0.98987037 0.9741678  0.9594184  0.55902004\n",
      " 0.96994567 0.9977107  0.99989414 0.97551674 0.7464274  0.99978036\n",
      " 0.96637213 0.5969873 ]\n",
      "The rewards are: [0.99574786 0.9990048  0.9128768  0.9926721  0.8633761  0.76235163\n",
      " 0.78502953 0.61821526 0.99372333 0.9124689  0.99146605 0.97503483\n",
      " 0.9997086  0.9458908  0.9984567  0.9725062  0.7851351  0.97433984\n",
      " 0.9853904  0.94121057 0.9518455  0.89953727 0.9119021  0.98496705\n",
      " 0.9978124  0.99059886 0.9887207  0.9966703  0.6341487  0.90251267\n",
      " 0.7465926  0.95555073]\n",
      "The rewards are: [0.9890248  0.984411   0.99855787 0.90286326 0.8918417  0.85999465\n",
      " 0.9312367  0.996855   0.99606943 0.9993285  0.99805355 0.9611358\n",
      " 0.9917373  0.56381667 0.99847966 0.8969915  0.9486215  0.914213\n",
      " 0.9781421  0.95247877 0.9884863  0.5830716  0.9878864  0.93870544\n",
      " 0.913297   0.99809843 0.9307045  0.9107544  0.9862514  0.9822448\n",
      " 0.8099032  0.99842286]\n",
      "The rewards are: [0.99966264 0.9980939  0.94968903 0.9907414  0.99869365 0.74581486\n",
      " 0.9862953  0.51197904 0.9996511  0.9627788  0.9687308  0.9999355\n",
      " 0.9954334  0.5124253  0.7418966  0.9531688  0.9960459  0.8088378\n",
      " 0.9119091  0.94361955 0.5267482  0.9859489  0.9993098  0.9652547\n",
      " 0.95803314 0.99263    0.99958307 0.5011987  0.6193195  0.9863289\n",
      " 0.9878429  0.999358  ]\n",
      "The rewards are: [0.9947982  0.99937457 0.98245376 0.99432904 0.90508586 0.9802956\n",
      " 0.9965216  0.95581585 0.9870961  0.9996389  0.9949945  0.9943235\n",
      " 0.9837299  0.99800557 0.976106   0.9302779  0.9969778  0.9011999\n",
      " 0.9721078  0.99694496 0.90861833 0.9814912  0.793626   0.8478488\n",
      " 0.981643   0.5783076  0.99878675 0.6768912  0.9847928  0.91392595\n",
      " 0.99892765 0.91392773]\n",
      "The rewards are: [0.94537616 0.9997559  0.9956529  0.99571323 0.87223893 0.99771786\n",
      " 0.99952614 0.99188036 0.9951231  0.87414426 0.9855723  0.99955183\n",
      " 0.9185805  0.9959462  0.9957287  0.97572577 0.92512184 0.97001237\n",
      " 0.6290102  0.9088827  0.5244732  0.9537425  0.587438   0.9675976\n",
      " 0.9980458  0.9030625  0.9324082  0.9984869  0.99223137 0.9629302\n",
      " 0.9987686  0.9990081 ]\n",
      "The rewards are: [0.783433   0.9110974  0.9980531  0.9971764  0.9692226  0.92512417\n",
      " 0.98747116 0.99455404 0.99908566 0.93791044 0.9278185  0.975474\n",
      " 0.7659783  0.9935969  0.54790825 0.9776164  0.9882889  0.9981139\n",
      " 0.99967    0.9701853  0.999423   0.9874499  0.9975222  0.9932969\n",
      " 0.95015997 0.9996295  0.795428   0.69211626 0.9984896  0.9943745\n",
      " 0.9911141  0.79334676]\n",
      "The rewards are: [0.99308515 0.9859905  0.9987437  0.8686468  0.9862396  0.9371443\n",
      " 0.9996973  0.9939568  0.9492913  0.9943189  0.9965867  0.6018376\n",
      " 0.93716615 0.8096103  0.97919583 0.98243237 0.99923956 0.9967014\n",
      " 0.9988457  0.99835396 0.9992902  0.9331684  0.9919201  0.8139375\n",
      " 0.6835779  0.98211145 0.63698244 0.9837362  0.9834742  0.9989053\n",
      " 0.94509274 0.9462746 ]\n",
      "The rewards are: [0.86072105 0.8320763  0.9969913  0.9297177  0.99993527 0.8767996\n",
      " 0.9969343  0.9650454  0.9632782  0.84048986 0.92965376 0.99593914\n",
      " 0.99983966 0.99773777 0.9951638  0.972518   0.9987729  0.99969614\n",
      " 0.95696306 0.7657516  0.7170095  0.9977865  0.99937797 0.99986184\n",
      " 0.9998398  0.9904833  0.9936792  0.99725145 0.998716   0.9036935\n",
      " 0.61688006 0.99881494]\n",
      "The rewards are: [0.973957   0.9780919  0.9829928  0.99655664 0.9965984  0.94046706\n",
      " 0.96177983 0.87172276 0.924653   0.9960957  0.9795933  0.9835406\n",
      " 0.9345193  0.9978794  0.6658082  0.7607484  0.99747545 0.7192938\n",
      " 0.91890144 0.9966204  0.9850987  0.9918425  0.8626935  0.9859205\n",
      " 0.99211675 0.6148487  0.7517999  0.5592361  0.9999428  0.9771577\n",
      " 0.9963192  0.99371666]\n",
      "The rewards are: [0.91022086 0.99738485 0.9420709  0.9772694  0.85228777 0.99961627\n",
      " 0.9999763  0.90723896 0.99900645 0.8911308  0.9392962  0.975437\n",
      " 0.9850091  0.9987508  0.9860765  0.9343749  0.99971396 0.64652956\n",
      " 0.9451587  0.99940383 0.6343323  0.9973168  0.9947737  0.9922639\n",
      " 0.99285734 0.8754283  0.81846225 0.986945   0.9756715  0.8125885\n",
      " 0.6045649  0.9947188 ]\n",
      "The rewards are: [0.9646904  0.91173315 0.9965655  0.99980944 0.9958125  0.9994591\n",
      " 0.924424   0.99034226 0.9972511  0.9878441  0.99751914 0.99959034\n",
      " 0.86851656 0.59888643 0.9972905  0.90187526 0.8146491  0.99977297\n",
      " 0.9000022  0.9990909  0.99827707 0.9994443  0.9992841  0.83335674\n",
      " 0.53461474 0.985832   0.52651703 0.99791914 0.9265383  0.99812704\n",
      " 0.9984515  0.9927008 ]\n",
      "The rewards are: [0.90367645 0.86566055 0.9994881  0.95318884 0.97797215 0.9963806\n",
      " 0.9985121  0.96631306 0.5110502  0.7974608  0.99904937 0.9722425\n",
      " 0.9633942  0.9981938  0.99967587 0.996863   0.99123365 0.99722016\n",
      " 0.98380727 0.973517   0.98599213 0.9992403  0.8145903  0.9936753\n",
      " 0.95283115 0.9073958  0.8393463  0.9995116  0.99952817 0.803667\n",
      " 0.9719202  0.99244785]\n",
      "The rewards are: [0.76251954 0.54625213 0.9518326  0.97332025 0.99520844 0.99527407\n",
      " 0.9780222  0.9908014  0.82131904 0.99428284 0.9886904  0.59449077\n",
      " 0.8696827  0.95861065 0.9980558  0.96444994 0.9159561  0.77424634\n",
      " 0.6053321  0.8433565  0.9969292  0.9270774  0.666312   0.9997032\n",
      " 0.9694613  0.9961593  0.9980357  0.9314288  0.8613099  0.94812995\n",
      " 0.9956632  0.9993259 ]\n",
      "The rewards are: [0.7697472  0.96190125 0.9643462  0.99436176 0.9800649  0.8023803\n",
      " 0.95088255 0.8740957  0.9741561  0.9509816  0.9983908  0.81965953\n",
      " 0.9920237  0.70609397 0.98443013 0.9811383  0.99930155 0.60377955\n",
      " 0.9986796  0.51964086 0.9740865  0.86115116 0.8034539  0.62103784\n",
      " 0.6738787  0.97883564 0.64821315 0.97668356 0.97087896 0.9945708\n",
      " 0.9269095  0.9997174 ]\n",
      "The rewards are: [0.99910516 0.84688973 0.9732506  0.96584475 0.94103247 0.9995493\n",
      " 0.99554646 0.9550342  0.985919   0.8866881  0.9359522  0.7608955\n",
      " 0.99983895 0.96026194 0.9149147  0.8510187  0.9909608  0.9996045\n",
      " 0.92678285 0.9997614  0.961046   0.92468387 0.9988714  0.9955979\n",
      " 0.9814254  0.999438   0.97813934 0.8144938  0.8424619  0.9102971\n",
      " 0.9956195  0.94511104]\n",
      "The rewards are: [0.98268855 0.7611559  0.70307225 0.7520045  0.9929589  0.99804616\n",
      " 0.99984133 0.9945569  0.7523286  0.8769409  0.9082938  0.9413825\n",
      " 0.95023745 0.9906393  0.99968374 0.99581367 0.99439514 0.9604377\n",
      " 0.99927896 0.7165945  0.9964881  0.92960185 0.62613094 0.922026\n",
      " 0.91429037 0.99644035 0.53330743 0.8545145  0.96796954 0.8737934\n",
      " 0.9699323  0.9997086 ]\n",
      "The rewards are: [0.9994655  0.67115456 0.9977155  0.9825585  0.99536055 0.99357283\n",
      " 0.9991203  0.9988236  0.99398804 0.9552655  0.9974239  0.99961\n",
      " 0.9662179  0.98326796 0.55162424 0.9996692  0.99665487 0.7538417\n",
      " 0.9886955  0.7891879  0.9864093  0.998078   0.9951609  0.8710084\n",
      " 0.99958485 0.9792403  0.99958986 0.57861656 0.99538887 0.82702804\n",
      " 0.88377756 0.9429509 ]\n",
      "The rewards are: [0.9965758  0.54066247 0.9036028  0.9676115  0.9360091  0.84785855\n",
      " 0.9544745  0.9964993  0.87051904 0.9980293  0.9956031  0.99882716\n",
      " 0.99784863 0.9901507  0.98945194 0.99968433 0.9989629  0.9735362\n",
      " 0.87938166 0.98779154 0.9462284  0.84088767 0.9587686  0.9162778\n",
      " 0.9049725  0.98659295 0.8982922  0.99986064 0.9981881  0.94382465\n",
      " 0.99647754 0.98156345]\n",
      "The rewards are: [0.99849916 0.78123444 0.9523689  0.9183983  0.9979814  0.9601738\n",
      " 0.99104065 0.9679652  0.9854455  0.98838717 0.97614247 0.73849064\n",
      " 0.9790602  0.9720944  0.8475767  0.99553984 0.9986425  0.81136084\n",
      " 0.99643815 0.9990195  0.99923694 0.9997975  0.998938   0.99630296\n",
      " 0.9856645  0.9995566  0.57057816 0.99745053 0.5325494  0.9999651\n",
      " 0.99085134 0.9540051 ]\n",
      "The rewards are: [0.96318483 0.9988834  0.91129947 0.9706379  0.9706988  0.9742688\n",
      " 0.99931073 0.8756586  0.94117624 0.9326461  0.8540316  0.9949018\n",
      " 0.6938956  0.8686781  0.91182405 0.7844143  0.944404   0.9981743\n",
      " 0.99567837 0.87680864 0.8853672  0.92598546 0.9586942  0.9237253\n",
      " 0.98935777 0.99868256 0.99838746 0.9876236  0.9106645  0.9989379\n",
      " 0.9825388  0.9980702 ]\n",
      "The rewards are: [0.9602706  0.9886     0.9859822  0.9717486  0.9938261  0.99753284\n",
      " 0.990424   0.99718225 0.9434052  0.9659989  0.9992151  0.99324095\n",
      " 0.95865655 0.74097115 0.99281573 0.9987264  0.99243516 0.7697112\n",
      " 0.9981706  0.995613   0.99898666 0.9992229  0.9995453  0.99099004\n",
      " 0.9702002  0.59119153 0.87730014 0.9856893  0.99933136 0.99926263\n",
      " 0.9885821  0.99919194]\n",
      "The rewards are: [0.9965898  0.98223156 0.9867144  0.99543816 0.99950254 0.99950695\n",
      " 0.9940513  0.9932614  0.522597   0.9831077  0.9678294  0.77481556\n",
      " 0.9450937  0.807224   0.9308702  0.68404186 0.9164914  0.9875244\n",
      " 0.9750734  0.91240114 0.9589544  0.96301633 0.99893254 0.9860303\n",
      " 0.96387213 0.5776472  0.6372641  0.66918784 0.70533437 0.9664845\n",
      " 0.9994135  0.9859125 ]\n",
      "The rewards are: [0.99957544 0.9927275  0.7873648  0.86321247 0.988658   0.84789836\n",
      " 0.9864363  0.9993468  0.93368334 0.98985344 0.87392503 0.99955827\n",
      " 0.9805484  0.97727513 0.88955975 0.8660911  0.99374086 0.9152832\n",
      " 0.9996561  0.5259648  0.8601133  0.98748267 0.9917794  0.95874614\n",
      " 0.94099045 0.9948095  0.9788794  0.99694103 0.98937    0.9999218\n",
      " 0.96570456 0.99017334]\n",
      "The rewards are: [0.69496477 0.9996848  0.7304591  0.9378535  0.9076045  0.9922925\n",
      " 0.9867883  0.9815529  0.59569997 0.99959093 0.9991535  0.9995995\n",
      " 0.60192806 0.9949764  0.99218047 0.9924896  0.9933106  0.9991573\n",
      " 0.99919313 0.9436965  0.999665   0.942139   0.9992849  0.82629865\n",
      " 0.99952984 0.9915143  0.9085615  0.76574874 0.99709773 0.93832576\n",
      " 0.86964285 0.9962645 ]\n",
      "The rewards are: [0.99990416 0.9471996  0.5673141  0.9997447  0.9356542  0.9979371\n",
      " 0.99328893 0.99388313 0.9890722  0.9994838  0.994201   0.748118\n",
      " 0.5301551  0.9997279  0.92062056 0.9950801  0.6915974  0.9987219\n",
      " 0.50237715 0.9948614  0.99104136 0.9971323  0.99444216 0.9946338\n",
      " 0.99945825 0.9995407  0.9454244  0.9470284  0.99786913 0.96880645\n",
      " 0.8799665  0.65747255]\n",
      "The rewards are: [0.55719024 0.9809418  0.84864914 0.9985989  0.9997842  0.91185915\n",
      " 0.873089   0.9975139  0.7623251  0.99613094 0.88008225 0.8123428\n",
      " 0.99969244 0.867196   0.971922   0.99294186 0.99958104 0.97854084\n",
      " 0.9886326  0.99989927 0.90645987 0.98386246 0.9145477  0.90309674\n",
      " 0.9981002  0.9999031  0.9849745  0.9652756  0.8450188  0.9641717\n",
      " 0.9850197  0.7396199 ]\n",
      "The rewards are: [0.9872556  0.99990606 0.9986266  0.94769806 0.9917578  0.9671003\n",
      " 0.9715987  0.9544574  0.9772676  0.848755   0.97840446 0.9910761\n",
      " 0.96836275 0.9888025  0.9989478  0.5494152  0.99947375 0.6119873\n",
      " 0.9514399  0.99975365 0.9983706  0.97693914 0.64959604 0.86826235\n",
      " 0.7705109  0.9934034  0.9844433  0.8945014  0.9987093  0.99735934\n",
      " 0.9804161  0.9078245 ]\n",
      "The rewards are: [0.75822365 0.54309994 0.99285007 0.9884461  0.96683025 0.50322074\n",
      " 0.99358433 0.99966955 0.99832934 0.9925309  0.9982291  0.55600464\n",
      " 0.9999498  0.98136854 0.8247901  0.9699747  0.93292844 0.9997471\n",
      " 0.9981186  0.99954224 0.93749744 0.99965537 0.99992585 0.9863886\n",
      " 0.9957046  0.99812466 0.9804027  0.99911505 0.9800831  0.6846349\n",
      " 0.990417   0.919837  ]\n",
      "The rewards are: [0.8483852  0.77238864 0.9416075  0.98903906 0.9368448  0.551059\n",
      " 0.9644548  0.8101379  0.9968522  0.99852425 0.99967504 0.99877495\n",
      " 0.9435937  0.99389017 0.9244179  0.9759222  0.8989319  0.88079166\n",
      " 0.9985714  0.8852527  0.99864155 0.6134202  0.9989619  0.9569361\n",
      " 0.99989414 0.9987     0.5639953  0.9927941  0.99851316 0.999566\n",
      " 0.99901664 0.99903214]\n",
      "The rewards are: [0.99472886 0.9248654  0.84040445 0.9456195  0.99927    0.98504096\n",
      " 0.79176944 0.9712441  0.9981755  0.9932828  0.8455244  0.8986129\n",
      " 0.99816006 0.99542135 0.98668796 0.95727944 0.93150216 0.9145713\n",
      " 0.96060634 0.9934428  0.9413617  0.99553007 0.54073006 0.9923476\n",
      " 0.53323054 0.97566956 0.96105134 0.9990578  0.97818667 0.9746407\n",
      " 0.9982633  0.89335805]\n",
      "The rewards are: [0.9581655  0.99500114 0.9972734  0.9729217  0.99722457 0.9831339\n",
      " 0.99781126 0.9284018  0.8900266  0.89113355 0.9308289  0.9990773\n",
      " 0.9719411  0.8772263  0.7809392  0.99940515 0.9929838  0.9250684\n",
      " 0.50334597 0.9995623  0.91278774 0.9987257  0.9978362  0.99024135\n",
      " 0.98439205 0.9940844  0.93814224 0.99903584 0.99992466 0.84123915\n",
      " 0.9965455  0.77455336]\n",
      "The rewards are: [0.89586943 0.9001498  0.98079026 0.9834163  0.9996184  0.9735125\n",
      " 0.9974148  0.9993788  0.9643895  0.95686483 0.8766152  0.7288126\n",
      " 0.97877526 0.9983975  0.95476717 0.98743224 0.9993285  0.99872345\n",
      " 0.9940789  0.86704135 0.6298273  0.65638787 0.99116546 0.9980446\n",
      " 0.97289497 0.9933396  0.9845408  0.9990165  0.80868465 0.9951703\n",
      " 0.9897468  0.9177718 ]\n",
      "The rewards are: [0.9724726  0.6934621  0.9700356  0.988523   0.9994394  0.9241121\n",
      " 0.9821301  0.9595126  0.8611842  0.89076835 0.9750686  0.9968284\n",
      " 0.99763215 0.9429741  0.97246075 0.9781426  0.97883934 0.77126396\n",
      " 0.88282144 0.9709725  0.99721825 0.9963774  0.929251   0.91823554\n",
      " 0.99613047 0.9947168  0.571432   0.9596407  0.85484475 0.9868063\n",
      " 0.9998338  0.9921808 ]\n",
      "The rewards are: [0.99970055 0.9004685  0.9693876  0.9570779  0.8462241  0.9785181\n",
      " 0.99996233 0.89664125 0.6317016  0.97191316 0.9949509  0.99224263\n",
      " 0.9995509  0.93494123 0.8731454  0.6918558  0.8392436  0.9995028\n",
      " 0.8847604  0.98424214 0.98273844 0.9848068  0.91808635 0.9788052\n",
      " 0.8319327  0.9551369  0.99433833 0.59423476 0.84627074 0.6577115\n",
      " 0.96985865 0.9839548 ]\n",
      "The rewards are: [0.9951964  0.92856264 0.98252064 0.98922276 0.8294592  0.58868665\n",
      " 0.99905366 0.9982868  0.99286133 0.9557856  0.60754365 0.5199152\n",
      " 0.94455284 0.9938844  0.9400184  0.6045699  0.99984515 0.54509485\n",
      " 0.99954826 0.9999391  0.98400235 0.94008195 0.99983144 0.99859804\n",
      " 0.9967528  0.96570945 0.9964971  0.9898699  0.977335   0.766567\n",
      " 0.99821246 0.99923027]\n",
      "The rewards are: [0.9991334  0.9973763  0.99939823 0.9918669  0.8951623  0.9982134\n",
      " 0.9763535  0.9275947  0.72938854 0.9619116  0.9992169  0.9961211\n",
      " 0.99775046 0.8732718  0.9993698  0.9955707  0.9086304  0.97990376\n",
      " 0.9992648  0.9952394  0.9999429  0.9121082  0.9957462  0.801936\n",
      " 0.9959369  0.99937683 0.9168083  0.987987   0.81027675 0.72844553\n",
      " 0.9960412  0.9329992 ]\n",
      "The rewards are: [0.9776715  0.99401605 0.891562   0.88220143 0.99167246 0.99873\n",
      " 0.99730515 0.98401755 0.998662   0.9027694  0.9842696  0.98417425\n",
      " 0.99827707 0.99954045 0.6464492  0.9787459  0.51769376 0.55739826\n",
      " 0.94730955 0.99950135 0.7954778  0.9048395  0.99643195 0.9880916\n",
      " 0.99241865 0.85259795 0.72257346 0.99923563 0.999813   0.7637834\n",
      " 0.97703826 0.9765019 ]\n",
      "The rewards are: [0.9995765  0.9999758  0.9996356  0.9987469  0.9977755  0.9867084\n",
      " 0.88928145 0.99684453 0.99646336 0.798428   0.9789448  0.99971205\n",
      " 0.9994842  0.97558504 0.8965886  0.9893245  0.9959985  0.92970824\n",
      " 0.99821055 0.9213307  0.99852943 0.9945042  0.99961084 0.9488984\n",
      " 0.9937973  0.90928096 0.97891974 0.9830898  0.945385   0.81143886\n",
      " 0.8934455  0.858835  ]\n",
      "The rewards are: [0.98299813 0.97656345 0.9512305  0.9984268  0.89903647 0.9618654\n",
      " 0.9987784  0.94320226 0.93638563 0.9837284  0.9925303  0.93347126\n",
      " 0.80851513 0.8626705  0.97478855 0.871087   0.97509176 0.8099514\n",
      " 0.91993    0.98497933 0.9985978  0.9956612  0.85358775 0.9748946\n",
      " 0.9697714  0.99982905 0.9982291  0.99888486 0.98626536 0.9977558\n",
      " 0.7876237  0.9636097 ]\n",
      "The rewards are: [0.8666143  0.7007652  0.9257972  0.82391447 0.9451453  0.9874006\n",
      " 0.6579946  0.99865794 0.9929749  0.99927217 0.9936346  0.6980965\n",
      " 0.9697119  0.55059433 0.9707108  0.99657553 0.9943175  0.98119867\n",
      " 0.99700123 0.9992513  0.99934334 0.9932248  0.99969184 0.9907012\n",
      " 0.99644226 0.9805761  0.99660635 0.9998367  0.83593583 0.98816\n",
      " 0.8677502  0.7763901 ]\n",
      "The rewards are: [0.9952814  0.8164687  0.9890465  0.9991928  0.797499   0.9922083\n",
      " 0.9998393  0.979627   0.7372301  0.9855058  0.7260435  0.61373854\n",
      " 0.974848   0.77848154 0.9936684  0.9968923  0.9999156  0.81103045\n",
      " 0.8109261  0.68962705 0.9985442  0.9702351  0.76204556 0.9993291\n",
      " 0.95131755 0.9392329  0.98861736 0.7857459  0.502222   0.99876595\n",
      " 0.9997569  0.9385407 ]\n",
      "The rewards are: [0.50566036 0.76572096 0.95494944 0.98850006 0.9974819  0.99538594\n",
      " 0.6785739  0.99958855 0.99723285 0.750597   0.99586284 0.9853977\n",
      " 0.60642236 0.9983234  0.9970387  0.99560636 0.6957429  0.9976357\n",
      " 0.9283827  0.74814993 0.7324618  0.9819234  0.97287726 0.9973986\n",
      " 0.85745287 0.8660909  0.9988695  0.8452813  0.9996325  0.9993211\n",
      " 0.9937144  0.7234941 ]\n",
      "The rewards are: [0.9279497  0.89911973 0.8924164  0.996179   0.99637103 0.59100217\n",
      " 0.89269876 0.92538065 0.99974626 0.7014323  0.95385563 0.9847031\n",
      " 0.97459644 0.9996965  0.96010244 0.9904902  0.66621697 0.99838316\n",
      " 0.99351305 0.9228159  0.9999821  0.9636607  0.88756746 0.53818834\n",
      " 0.9927771  0.9862347  0.8252189  0.994447   0.96022564 0.99981576\n",
      " 0.98911554 0.93942416]\n",
      "The rewards are: [0.97310627 0.9896516  0.65393186 0.93354815 0.7110998  0.94300497\n",
      " 0.9969181  0.99772555 0.9912812  0.98687893 0.64500594 0.99871457\n",
      " 0.97314405 0.99892247 0.9263608  0.9995421  0.7939115  0.99934274\n",
      " 0.95896435 0.9789437  0.9806387  0.9991093  0.99268216 0.5511579\n",
      " 0.9226975  0.8040075  0.99732333 0.8743412  0.9940918  0.9999567\n",
      " 0.7160857  0.958229  ]\n",
      "The rewards are: [0.996971   0.8885172  0.7879909  0.84342575 0.9971865  0.98780304\n",
      " 0.7674032  0.9975835  0.9953023  0.9094326  0.9610635  0.8648621\n",
      " 0.99950635 0.9983656  0.9986064  0.99917835 0.99534637 0.9963714\n",
      " 0.923993   0.9616993  0.9969675  0.9957104  0.8981938  0.99721754\n",
      " 0.9934668  0.7972258  0.99385864 0.9969022  0.7598412  0.99793553\n",
      " 0.9942239  0.99370533]\n",
      "The rewards are: [0.9617989  0.99407566 0.6213663  0.9994899  0.9952441  0.9687572\n",
      " 0.99363375 0.9603073  0.9957306  0.6890061  0.5730961  0.9832429\n",
      " 0.89342153 0.9950971  0.9777109  0.92872196 0.81124425 0.54713327\n",
      " 0.9676788  0.99684155 0.9734283  0.7217678  0.96847546 0.96986747\n",
      " 0.9982333  0.99868864 0.9987863  0.99937207 0.99998724 0.97980314\n",
      " 0.85800636 0.99061567]\n",
      "The rewards are: [0.93238884 0.9920622  0.99245864 0.9730737  0.9996352  0.9495466\n",
      " 0.86942625 0.93163115 0.9860852  0.7567676  0.9986546  0.994831\n",
      " 0.999668   0.8721845  0.9933236  0.814769   0.9991392  0.99724054\n",
      " 0.99986064 0.8330996  0.62620366 0.72735596 0.9704578  0.99997675\n",
      " 0.9919887  0.9148003  0.94261795 0.9994241  0.97504073 0.98927885\n",
      " 0.98890495 0.9125594 ]\n",
      "The rewards are: [0.97663975 0.99940383 0.9996735  0.99899703 0.99872005 0.9965011\n",
      " 0.917787   0.99980897 0.9994024  0.99329877 0.99833304 0.8793149\n",
      " 0.97368354 0.9518088  0.99097085 0.99295616 0.99954456 0.9858737\n",
      " 0.7501507  0.9999721  0.99553704 0.99969935 0.99955434 0.9998241\n",
      " 0.9958085  0.9903955  0.982949   0.99982256 0.9482378  0.8012391\n",
      " 0.99034065 0.9700734 ]\n",
      "The rewards are: [0.99428177 0.99883527 0.5454912  0.9398596  0.84416026 0.94478214\n",
      " 0.7440161  0.99993193 0.8673062  0.506625   0.9993598  0.9661481\n",
      " 0.98416626 0.99896467 0.9980422  0.99977845 0.8818296  0.9985696\n",
      " 0.9744192  0.9675059  0.9981501  0.9888054  0.99944717 0.9989838\n",
      " 0.990114   0.99269813 0.991055   0.9981791  0.92610395 0.9849583\n",
      " 0.9995633  0.6200576 ]\n",
      "The rewards are: [0.9904929  0.99427265 0.9983621  0.9816434  0.97316474 0.7271281\n",
      " 0.9920461  0.7822129  0.9746596  0.9954424  0.9141482  0.82021564\n",
      " 0.99724567 0.9944746  0.9820202  0.9979152  0.9961112  0.99730825\n",
      " 0.9815609  0.9751369  0.9995395  0.9559508  0.9960395  0.9184371\n",
      " 0.98706585 0.9353511  0.90343577 0.99545044 0.96891207 0.6797317\n",
      " 0.6121021  0.95475715]\n",
      "The rewards are: [0.9933902  0.988383   0.99989784 0.9996952  0.9912178  0.9849629\n",
      " 0.99852717 0.98982364 0.95449144 0.9392847  0.9897211  0.994825\n",
      " 0.98568106 0.9999571  0.534641   0.98609936 0.9967955  0.9933484\n",
      " 0.9996928  0.99472    0.9938782  0.97563577 0.9902389  0.99843043\n",
      " 0.99817765 0.9983216  0.9674096  0.99979657 0.994437   0.9404249\n",
      " 0.8298136  0.7328574 ]\n",
      "The rewards are: [0.9278846  0.7439978  0.9835354  0.7466113  0.8391404  0.99830544\n",
      " 0.9935855  0.94261354 0.62178826 0.99963045 0.9838982  0.9964539\n",
      " 0.9999701  0.99992454 0.99721694 0.9946136  0.9990446  0.9972473\n",
      " 0.8697192  0.97802824 0.99910337 0.9108735  0.99719644 0.9648121\n",
      " 0.9829578  0.99696475 0.9988702  0.9980902  0.64282924 0.93788475\n",
      " 0.9988445  0.66936314]\n",
      "The rewards are: [0.940982   0.810221   0.99957055 0.9755946  0.68424165 0.99748284\n",
      " 0.95034814 0.99959356 0.998589   0.7673319  0.9975553  0.8166128\n",
      " 0.9312365  0.9773831  0.9291531  0.94775844 0.9962226  0.9474189\n",
      " 0.95779127 0.9893495  0.9993298  0.5660309  0.97041017 0.9342795\n",
      " 0.95253295 0.937506   0.52564794 0.86996764 0.8582032  0.72512466\n",
      " 0.9996018  0.99997175]\n",
      "The rewards are: [0.9921651  0.93894583 0.93381315 0.97915286 0.7648866  0.88690346\n",
      " 0.9999062  0.5221859  0.982743   0.99905056 0.9972324  0.96935654\n",
      " 0.99484825 0.51225704 0.9455611  0.52361786 0.6317609  0.8364439\n",
      " 0.99877137 0.99293727 0.9645717  0.6505829  0.89949584 0.9969799\n",
      " 0.9860114  0.94634795 0.99679345 0.9946767  0.82287765 0.9853136\n",
      " 0.9987337  0.9823529 ]\n",
      "The rewards are: [0.922139   0.99839044 0.62002486 0.9944143  0.9256856  0.9611509\n",
      " 0.99976796 0.78483844 0.99450266 0.9992681  0.9996983  0.98981327\n",
      " 0.8587034  0.99177504 0.9873158  0.9507639  0.999006   0.9963617\n",
      " 0.92628986 0.66155887 0.7269212  0.95952    0.9982907  0.99180824\n",
      " 0.9991972  0.97556794 0.9985121  0.99773717 0.9646854  0.9963625\n",
      " 0.94279253 0.68605375]\n",
      "The rewards are: [0.99647456 0.99873    0.9987679  0.99784684 0.9996656  0.9766219\n",
      " 0.8099739  0.9107818  0.95458406 0.99797624 0.9855834  0.9897301\n",
      " 0.99421245 0.9931631  0.9993298  0.9988741  0.9942036  0.9678789\n",
      " 0.99201924 0.99840885 0.9992889  0.9596641  0.9994254  0.99367625\n",
      " 0.9915071  0.9979358  0.9965306  0.9956553  0.95017546 0.940918\n",
      " 0.98672444 0.99848026]\n",
      "The rewards are: [0.8018751  0.99956053 0.9661195  0.7678661  0.998379   0.974566\n",
      " 0.9986187  0.86661786 0.99897754 0.99296254 0.97652256 0.98905283\n",
      " 0.96243405 0.9417757  0.9997881  0.9947556  0.9846066  0.67823726\n",
      " 0.9864563  0.9967809  0.99939585 0.53921217 0.99743384 0.8875426\n",
      " 0.997592   0.99948573 0.9969216  0.9994879  0.9609797  0.94829404\n",
      " 0.94484437 0.993562  ]\n",
      "The rewards are: [0.8712821  0.9999517  0.92648345 0.8146752  0.99309593 0.95076\n",
      " 0.9991825  0.7867796  0.9996087  0.93232375 0.57314533 0.7895578\n",
      " 0.59665555 0.9279139  0.97862625 0.9927256  0.92107785 0.99816614\n",
      " 0.91320443 0.9928519  0.99145573 0.9394347  0.8294881  0.9933816\n",
      " 0.8585583  0.9980718  0.9990953  0.9490434  0.63201267 0.99729425\n",
      " 0.9959396  0.9621999 ]\n",
      "The rewards are: [0.9948486  0.99878114 0.9827869  0.94654804 0.92675036 0.764983\n",
      " 0.9941566  0.99802977 0.7313491  0.99782616 0.99993527 0.99913836\n",
      " 0.99906856 0.9353564  0.99974996 0.99548906 0.95036894 0.9979857\n",
      " 0.9998574  0.9987098  0.94689435 0.9988877  0.83950746 0.98866755\n",
      " 0.99639684 0.9889782  0.99994624 0.999613   0.98836863 0.81019354\n",
      " 0.9176175  0.8426395 ]\n",
      "The rewards are: [0.9793721  0.9915598  0.8447741  0.99858403 0.99078476 0.8707941\n",
      " 0.9711467  0.7312922  0.98756623 0.9980489  0.95227677 0.95449543\n",
      " 0.8438855  0.99789315 0.9979488  0.98953015 0.8800804  0.99964654\n",
      " 0.9969137  0.8272735  0.9873459  0.9901382  0.68704516 0.716949\n",
      " 0.8771633  0.89150023 0.9522777  0.9913735  0.6696683  0.83316034\n",
      " 0.99752146 0.985471  ]\n",
      "The rewards are: [0.99084026 0.99481446 0.98503923 0.9988223  0.73362064 0.7489926\n",
      " 0.9997787  0.9816761  0.99071527 0.9998061  0.9964496  0.9734142\n",
      " 0.9392522  0.9571316  0.9961832  0.9999683  0.62807375 0.92902035\n",
      " 0.9934831  0.99297696 0.83554846 0.9711613  0.99847    0.9893295\n",
      " 0.7498815  0.998719   0.99973696 0.99266887 0.6305643  0.9666245\n",
      " 0.59645325 0.79296863]\n",
      "The rewards are: [0.9933056  0.99870443 0.9999335  0.99823785 0.982192   0.9811412\n",
      " 0.98332953 0.9831376  0.9846501  0.98427284 0.99898475 0.9944885\n",
      " 0.9375071  0.99825436 0.9208545  0.9943169  0.5103065  0.7599374\n",
      " 0.95781076 0.9887143  0.99976283 0.98498535 0.9256971  0.9974619\n",
      " 0.9435875  0.663147   0.9420304  0.9455735  0.9917235  0.9770991\n",
      " 0.7909137  0.98702973]\n",
      "The rewards are: [0.9999528  0.8402328  0.966418   0.9930687  0.96586347 0.99957496\n",
      " 0.99935895 0.9782557  0.9932522  0.9862982  0.94206154 0.8584662\n",
      " 0.998533   0.54663223 0.7008219  0.9585756  0.99201465 0.99730206\n",
      " 0.952961   0.63080454 0.61349386 0.90463805 0.9993326  0.996051\n",
      " 0.9977386  0.9527956  0.9993255  0.99601954 0.99983394 0.9971842\n",
      " 0.98299766 0.99938107]\n",
      "The rewards are: [0.9988589  0.9006265  0.621915   0.74009275 0.8296927  0.62336636\n",
      " 0.99337846 0.81593984 0.9944674  0.7631246  0.9775468  0.61210674\n",
      " 0.99880886 0.9981483  0.99934477 0.8111415  0.93729305 0.9991441\n",
      " 0.99069244 0.99694806 0.9997944  0.99688137 0.95408064 0.9997942\n",
      " 0.9809214  0.9998362  0.98898697 0.9240809  0.9832602  0.9824745\n",
      " 0.9997019  0.87995476]\n",
      "The rewards are: [0.99873775 0.9996076  0.9510288  0.98985213 0.9991829  0.9990528\n",
      " 0.9988427  0.99782974 0.9730666  0.99902415 0.99981123 0.9991793\n",
      " 0.99718493 0.88697606 0.9992435  0.67168045 0.8995464  0.98111045\n",
      " 0.9837843  0.97954476 0.64120406 0.90226465 0.7080006  0.9194053\n",
      " 0.9994079  0.94207406 0.99161196 0.9997751  0.9828876  0.9874758\n",
      " 0.92509544 0.9790964 ]\n",
      "The rewards are: [0.9503548  0.99897254 0.99725914 0.93992794 0.9946163  0.59186727\n",
      " 0.9298043  0.91697353 0.9427463  0.99939454 0.89978456 0.9995577\n",
      " 0.999032   0.83195996 0.99750984 0.79031724 0.9864201  0.9929334\n",
      " 0.9999156  0.8572879  0.83995175 0.9905605  0.94603246 0.65499425\n",
      " 0.92702466 0.97885084 0.9829828  0.99776304 0.9856758  0.9947476\n",
      " 0.9753642  0.999724  ]\n",
      "The rewards are: [0.9877521  0.8421291  0.81018996 0.99782556 0.9683348  0.99915576\n",
      " 0.99694854 0.77400064 0.89056635 0.9998598  0.9957231  0.8564998\n",
      " 0.92368907 0.99909246 0.6428742  0.7160167  0.9962568  0.9989447\n",
      " 0.98578125 0.98722154 0.95201004 0.99438727 0.87002367 0.9998362\n",
      " 0.9997662  0.6162419  0.9085837  0.93529046 0.99933136 0.99874395\n",
      " 0.9326828  0.9938008 ]\n",
      "The rewards are: [0.98810077 0.8457083  0.94527256 0.98692167 0.7290382  0.98702395\n",
      " 0.9854102  0.9933159  0.95637643 0.9963517  0.98042756 0.99814284\n",
      " 0.99846137 0.9996294  0.6010552  0.88500386 0.94420373 0.99988437\n",
      " 0.99833006 0.97759414 0.98000586 0.87524956 0.9989542  0.9998963\n",
      " 0.96033466 0.50213104 0.9923096  0.956811   0.99873513 0.8498519\n",
      " 0.994079   0.8389619 ]\n",
      "The rewards are: [0.9968348  0.9759221  0.72362673 0.58773327 0.9986644  0.99577785\n",
      " 0.8173057  0.9996232  0.53843504 0.9935673  0.99904984 0.53676\n",
      " 0.97514987 0.5772791  0.9941778  0.9118653  0.9874055  0.9970228\n",
      " 0.94386345 0.9900671  0.9358222  0.9930882  0.9207441  0.9973496\n",
      " 0.979885   0.85059464 0.846871   0.9984627  0.90777904 0.58512473\n",
      " 0.7992523  0.98050255]\n",
      "The rewards are: [0.99861884 0.9802971  0.69715536 0.8938904  0.9876182  0.9421037\n",
      " 0.98581135 0.99975044 0.9707281  0.5166288  0.9773008  0.99936575\n",
      " 0.96956426 0.998611   0.9969458  0.9612596  0.872987   0.99594456\n",
      " 0.9934767  0.970018   0.9946601  0.99740064 0.8902489  0.9544884\n",
      " 0.9193086  0.98044455 0.9910954  0.9812602  0.9877894  0.9487143\n",
      " 0.9580222  0.9760342 ]\n",
      "The rewards are: [0.93797326 0.5786765  0.9444812  0.99210256 0.9991411  0.98846406\n",
      " 0.99703157 0.884147   0.9994068  0.9959188  0.99928576 0.8071694\n",
      " 0.7884608  0.9860714  0.9994886  0.99920315 0.99909747 0.9932029\n",
      " 0.999703   0.94367516 0.9844785  0.93531996 0.9941004  0.85324335\n",
      " 0.9662937  0.9503292  0.9697786  0.99899155 0.81860554 0.99763143\n",
      " 0.98530024 0.9999732 ]\n",
      "The rewards are: [0.99697804 0.9894894  0.9832243  0.77025074 0.9916808  0.9779114\n",
      " 0.8748284  0.9485753  0.98214597 0.99778384 0.9354486  0.95339423\n",
      " 0.97268414 0.9920328  0.99908364 0.81640655 0.9996964  0.75795054\n",
      " 0.993618   0.99825126 0.6104167  0.9957562  0.99839514 0.9997243\n",
      " 0.9114855  0.99949944 0.81482714 0.9394386  0.9962291  0.999592\n",
      " 0.9994091  0.6817117 ]\n",
      "The rewards are: [0.93458045 0.93358403 0.96985495 0.998514   0.91171426 0.9619308\n",
      " 0.9999113  0.9975637  0.99936575 0.9682616  0.99510175 0.9646899\n",
      " 0.99640685 0.99924374 0.9769875  0.5574252  0.870056   0.966936\n",
      " 0.9577506  0.9992974  0.99920976 0.7372209  0.9971288  0.9748555\n",
      " 0.97937804 0.99845934 0.9988374  0.9998292  0.99633753 0.8697193\n",
      " 0.94270474 0.9186746 ]\n",
      "The rewards are: [0.99948967 0.9964294  0.9994661  0.98990726 0.55428445 0.99374723\n",
      " 0.998367   0.9994868  0.9913066  0.99792755 0.99862444 0.9614046\n",
      " 0.99776304 0.9843227  0.9935987  0.9842518  0.96203154 0.9986941\n",
      " 0.9824532  0.9991498  0.98873377 0.9434035  0.9958703  0.9668902\n",
      " 0.9403134  0.99870026 0.88227946 0.9932111  0.87022644 0.9990669\n",
      " 0.9971693  0.9961175 ]\n",
      "The rewards are: [0.9701779  0.9968953  0.99954504 0.9959325  0.52735925 0.6999466\n",
      " 0.9927033  0.9760943  0.99982834 0.92672336 0.9933909  0.9979988\n",
      " 0.9100104  0.9883272  0.997494   0.885044   0.98534447 0.9992291\n",
      " 0.7944102  0.8779097  0.9969121  0.9996574  0.7982612  0.9998996\n",
      " 0.99806243 0.9959423  0.8798755  0.83717483 0.9297407  0.9623948\n",
      " 0.8805974  0.6185841 ]\n",
      "The rewards are: [0.92327654 0.77919805 0.9760671  0.9911203  0.84482485 0.7513014\n",
      " 0.93199587 0.99982065 0.8637161  0.98128915 0.997189   0.99842286\n",
      " 0.93497926 0.9939389  0.6316492  0.69971275 0.98590046 0.9991573\n",
      " 0.9872307  0.9941837  0.615179   0.99530077 0.9888737  0.9992085\n",
      " 0.9988632  0.97681606 0.99625164 0.94896    0.9958897  0.8227281\n",
      " 0.9998153  0.9922145 ]\n",
      "The rewards are: [0.96916145 0.89328015 0.8832529  0.99874806 0.9982736  0.9040338\n",
      " 0.61006576 0.98536795 0.9876359  0.99896336 0.99496174 0.96069926\n",
      " 0.9502595  0.9888326  0.99615425 0.9997596  0.9898303  0.7331995\n",
      " 0.82644534 0.9671319  0.567371   0.98281187 0.9941474  0.9357891\n",
      " 0.9993316  0.9998752  0.98586005 0.86334836 0.6438827  0.9548798\n",
      " 0.9897497  0.5151518 ]\n",
      "The rewards are: [0.99950814 0.99905735 0.9968002  0.9822067  0.9978649  0.99982554\n",
      " 0.99937636 0.9837389  0.98767227 0.93961084 0.6743321  0.97887665\n",
      " 0.9982834  0.9951906  0.99897134 0.9693271  0.83596283 0.9996138\n",
      " 0.9904897  0.81393    0.9768131  0.95179737 0.9577923  0.6159735\n",
      " 0.6821747  0.9915338  0.9455522  0.75073516 0.93304384 0.9974813\n",
      " 0.94422394 0.84759784]\n",
      "The rewards are: [0.9998369  0.9265266  0.6987656  0.9749069  0.9996195  0.98892725\n",
      " 0.97260666 0.99746025 0.9999248  0.96645486 0.99505156 0.98901373\n",
      " 0.97682196 0.9034202  0.999869   0.54018134 0.99972826 0.995637\n",
      " 0.9813665  0.95923513 0.9990945  0.9996817  0.91193885 0.99995697\n",
      " 0.5806802  0.9523538  0.99889034 0.67635643 0.9809044  0.9996051\n",
      " 0.9919681  0.57161367]\n",
      "The rewards are: [0.74584395 0.9997662  0.9994716  0.95671815 0.86975944 0.9990858\n",
      " 0.784841   0.7207729  0.5939305  0.981824   0.62112993 0.9511454\n",
      " 0.99891496 0.9835923  0.9992161  0.99969625 0.88149536 0.9981943\n",
      " 0.99073213 0.9916699  0.66277874 0.6393655  0.8843582  0.9989003\n",
      " 0.9991756  0.97285324 0.9171706  0.9993461  0.9760927  0.9993549\n",
      " 0.9701881  0.96644276]\n",
      "The rewards are: [0.91582537 0.9782491  0.90706414 0.94241154 0.99987936 0.99669313\n",
      " 0.96725833 0.9782073  0.78353477 0.96833706 0.91369516 0.96918654\n",
      " 0.76539654 0.99290353 0.99953735 0.9759839  0.99517196 0.9669506\n",
      " 0.9885832  0.9967783  0.9890266  0.9889515  0.9988757  0.9964485\n",
      " 0.9298825  0.72759867 0.63110447 0.60557806 0.9998603  0.9990522\n",
      " 0.99418056 0.76652086]\n",
      "The rewards are: [0.9952023  0.9932728  0.7316754  0.9992168  0.999995   0.98453325\n",
      " 0.57849276 0.9982603  0.9914352  0.69322133 0.90437657 0.99915135\n",
      " 0.98779804 0.8284617  0.8670058  0.92136914 0.9982216  0.99200445\n",
      " 0.99221647 0.9973193  0.52208674 0.9952845  0.9992292  0.99990594\n",
      " 0.83766997 0.98453856 0.9922099  0.9832651  0.99858    0.92950696\n",
      " 0.9995197  0.99942374]\n",
      "The rewards are: [0.9927676  0.97860533 0.9620812  0.99957544 0.9952963  0.95295656\n",
      " 0.9998221  0.9756203  0.9779735  0.88842475 0.96824485 0.9689362\n",
      " 0.82131046 0.8586367  0.98490244 0.9755999  0.9916609  0.98997235\n",
      " 0.981204   0.9979049  0.9698575  0.9984634  0.9656659  0.99902856\n",
      " 0.6333455  0.64518833 0.9999553  0.8224822  0.9792525  0.99881494\n",
      " 0.99882704 0.9888765 ]\n",
      "The rewards are: [0.9998851  0.9693823  0.9906123  0.9928496  0.9998677  0.83885634\n",
      " 0.99069256 0.9974503  0.9037287  0.96758467 0.9906228  0.99424285\n",
      " 0.5283233  0.85797286 0.98474276 0.9533538  0.99967504 0.92080146\n",
      " 0.99864084 0.9865587  0.8898639  0.9995254  0.96968377 0.99980146\n",
      " 0.99791676 0.9673813  0.9570126  0.9314859  0.9991947  0.7886716\n",
      " 0.89466774 0.9160763 ]\n",
      "The rewards are: [0.9983498  0.7120693  0.99995375 0.9640743  0.8988041  0.92366326\n",
      " 0.98185086 0.9988134  0.99930406 0.96486    0.9999943  0.9906974\n",
      " 0.98572403 0.9842516  0.9957669  0.57995504 0.9566552  0.88120306\n",
      " 0.98325896 0.9998776  0.9915039  0.9996012  0.9992773  0.9970162\n",
      " 0.74569434 0.96725565 0.8703271  0.9995933  0.6507969  0.8105315\n",
      " 0.9993486  0.9790102 ]\n",
      "The rewards are: [0.99860674 0.9920757  0.9974043  0.96996874 0.9996619  0.99185646\n",
      " 0.97151494 0.77351886 0.99669147 0.985091   0.97404546 0.9952579\n",
      " 0.9798305  0.9622247  0.9766085  0.997905   0.9852586  0.84070176\n",
      " 0.9627314  0.9988708  0.9995333  0.99786997 0.9993426  0.95276177\n",
      " 0.99670094 0.99331623 0.9959688  0.99790823 0.94431424 0.9744974\n",
      " 0.79825723 0.97438127]\n",
      "The rewards are: [0.5248527  0.999967   0.99540615 0.99758255 0.9979044  0.8783153\n",
      " 0.8924433  0.99920005 0.90029263 0.9952443  0.890827   0.9973616\n",
      " 0.975748   0.94889057 0.9981431  0.9973877  0.98377615 0.90847105\n",
      " 0.9992611  0.99931026 0.97695583 0.9995223  0.99935275 0.98905396\n",
      " 0.9636036  0.9500431  0.99236757 0.96691406 0.9217752  0.98325944\n",
      " 0.9955771  0.82146823]\n",
      "The rewards are: [0.559051   0.99979585 0.93671983 0.9996489  0.9563729  0.6971514\n",
      " 0.99931526 0.9989795  0.9812003  0.9946595  0.8865159  0.9780431\n",
      " 0.856569   0.99491775 0.863947   0.994393   0.99755174 0.99044234\n",
      " 0.9984798  0.6962706  0.9469267  0.99083614 0.9730578  0.80965346\n",
      " 0.9049667  0.935335   0.98844683 0.6560439  0.61357874 0.9987569\n",
      " 0.99623615 0.992159  ]\n",
      "The rewards are: [0.99689734 0.9263868  0.9995962  0.99937785 0.99912316 0.9578184\n",
      " 0.99984765 0.9781276  0.8232477  0.9185195  0.9998317  0.8123367\n",
      " 0.9987984  0.9982243  0.62974566 0.96504796 0.99939346 0.9995216\n",
      " 0.9998964  0.98245203 0.76518923 0.9473227  0.996601   0.99989176\n",
      " 0.9954094  0.99904054 0.97849107 0.9945188  0.9990583  0.99883693\n",
      " 0.5235553  0.98901784]\n",
      "The rewards are: [0.81907153 0.95679694 0.9972128  0.999617   0.96035767 0.98535556\n",
      " 0.9981504  0.8957999  0.99777526 0.9984932  0.99148905 0.9942714\n",
      " 0.97119284 0.99261534 0.9343664  0.98075175 0.98166925 0.99988675\n",
      " 0.9991067  0.9990522  0.99595463 0.97989196 0.9946725  0.99937844\n",
      " 0.9997632  0.99977785 0.9993537  0.99947256 0.9323966  0.60056674\n",
      " 0.9891775  0.9976566 ]\n",
      "The rewards are: [0.99976856 0.9979977  0.99854916 0.8200084  0.9850439  0.99049217\n",
      " 0.99015546 0.96164584 0.99948967 0.81383103 0.8439374  0.9948015\n",
      " 0.99357057 0.89293337 0.9874085  0.99940443 0.98569506 0.9425063\n",
      " 0.88454825 0.99043417 0.90575284 0.9951599  0.9105699  0.999448\n",
      " 0.9353571  0.99968183 0.98340327 0.9976433  0.9366921  0.9976814\n",
      " 0.99916804 0.99769837]\n",
      "The rewards are: [0.9735971  0.9960504  0.9899822  0.99382776 0.98885214 0.89831835\n",
      " 0.8695517  0.99567974 0.7829929  0.9066964  0.98803943 0.99329174\n",
      " 0.74597716 0.98258984 0.97307724 0.8134743  0.97227436 0.9991486\n",
      " 0.9942563  0.9865232  0.9986443  0.999368   0.99501884 0.91108465\n",
      " 0.9951332  0.99755055 0.99447834 0.7702602  0.8600804  0.9671796\n",
      " 0.8750959  0.99725264]\n",
      "The rewards are: [0.9995547  0.9961727  0.99321777 0.51804966 0.9886375  0.99027073\n",
      " 0.9814703  0.7805968  0.9795812  0.99309796 0.99964905 0.8198446\n",
      " 0.9984566  0.9978643  0.9843507  0.94375163 0.982818   0.8188985\n",
      " 0.99723697 0.99860317 0.999461   0.95818394 0.99853504 0.99766374\n",
      " 0.6818633  0.90234035 0.99976975 0.96837777 0.9997718  0.8732447\n",
      " 0.7161188  0.97847646]\n",
      "The rewards are: [0.99904627 0.9998149  0.99673307 0.9110272  0.9764981  0.90787905\n",
      " 0.99343467 0.9702603  0.9840388  0.9950111  0.6551164  0.97832847\n",
      " 0.99889576 0.99930966 0.99436367 0.8980332  0.97143227 0.99220157\n",
      " 0.67929995 0.9998375  0.9995925  0.9982292  0.62825716 0.99752086\n",
      " 0.9995876  0.9917216  0.9810284  0.9797656  0.99901974 0.9882144\n",
      " 0.9831625  0.9997017 ]\n",
      "The rewards are: [0.88093626 0.8988386  0.9637184  0.99738294 0.9906551  0.99644023\n",
      " 0.9994666  0.97577333 0.9980622  0.9948605  0.7512844  0.9966658\n",
      " 0.9851827  0.97577083 0.99378973 0.66702235 0.99865365 0.99211556\n",
      " 0.9986098  0.99620855 0.8674549  0.99962366 0.9984066  0.9898443\n",
      " 0.9873756  0.9986504  0.6264531  0.99996245 0.9914254  0.86265403\n",
      " 0.82319546 0.9986739 ]\n",
      "The rewards are: [0.97501457 0.9789221  0.9988225  0.97686356 0.9701179  0.93426424\n",
      " 0.9433848  0.9968233  0.9952787  0.93796766 0.9983346  0.96491754\n",
      " 0.9999912  0.68408823 0.9983273  0.5488854  0.91924196 0.99915946\n",
      " 0.96096814 0.95940804 0.9908372  0.9787295  0.9982394  0.9657388\n",
      " 0.9996692  0.998618   0.9977984  0.84769636 0.9995295  0.96597856\n",
      " 0.9687629  0.9990621 ]\n",
      "The rewards are: [0.9926137  0.98348546 0.89506966 0.99175876 0.6372856  0.99967206\n",
      " 0.88742864 0.9968919  0.9998648  0.993529   0.9997961  0.99943465\n",
      " 0.99092263 0.9941999  0.8508447  0.93508404 0.99996066 0.99948406\n",
      " 0.9869322  0.82951665 0.9653085  0.9986737  0.98239386 0.9638062\n",
      " 0.9980299  0.5333359  0.7059854  0.8598881  0.9774889  0.99720937\n",
      " 0.98080623 0.8909765 ]\n",
      "The rewards are: [0.9810472  0.99929655 0.95923555 0.9987602  0.9984542  0.808634\n",
      " 0.9976683  0.98342633 0.99782795 0.9772903  0.9937868  0.91794217\n",
      " 0.9923698  0.61572576 0.9980623  0.998609   0.9872089  0.65014845\n",
      " 0.9948066  0.9855542  0.9649231  0.99905676 0.82756865 0.9249631\n",
      " 0.9563353  0.99931467 0.94017184 0.73857003 0.7054146  0.5727392\n",
      " 0.99952376 0.99825245]\n",
      "The rewards are: [0.9989981  0.99735415 0.9959478  0.9644404  0.9727269  0.9806363\n",
      " 0.9954099  0.99979    0.998679   0.99984896 0.98246276 0.97910154\n",
      " 0.9795578  0.9904613  0.98996234 0.9966788  0.982724   0.99228853\n",
      " 0.99733067 0.88762516 0.98584807 0.9721257  0.96367306 0.99479866\n",
      " 0.9999492  0.92234266 0.9769201  0.50710046 0.98969394 0.7445718\n",
      " 0.6506056  0.9890407 ]\n",
      "The rewards are: [0.72343624 0.9952911  0.9990727  0.9895698  0.51646125 0.9846527\n",
      " 0.9981121  0.9983133  0.9985998  0.9931519  0.99862766 0.99896026\n",
      " 0.9383059  0.99988604 0.97617775 0.54757243 0.9959124  0.9645693\n",
      " 0.96764493 0.83033174 0.9635154  0.9856734  0.9997516  0.5121344\n",
      " 0.61031556 0.99483114 0.9920325  0.93819314 0.96143025 0.97701025\n",
      " 0.8213266  0.5994227 ]\n",
      "The rewards are: [0.9982456  0.98509926 0.98653245 0.9782507  0.97903216 0.92155516\n",
      " 0.99375147 0.9978796  0.8335728  0.9930428  0.9965347  0.99768925\n",
      " 0.9499745  0.99926454 0.9863442  0.9994992  0.9867106  0.9312188\n",
      " 0.90607655 0.61356694 0.97679603 0.99969065 0.81907856 0.9789058\n",
      " 0.98440033 0.95067805 0.9530568  0.92623526 0.99931276 0.98668486\n",
      " 0.9014234  0.99939895]\n",
      "The rewards are: [0.99882156 0.99943966 0.9991671  0.9367239  0.9749175  0.95263183\n",
      " 0.8968261  0.9895135  0.99827206 0.5699702  0.9749488  0.99676126\n",
      " 0.99995816 0.95900756 0.9997476  0.9990952  0.9998729  0.9999156\n",
      " 0.5174238  0.999694   0.9759334  0.9977138  0.94616276 0.9416915\n",
      " 0.7090935  0.96846855 0.99371004 0.99496126 0.99843615 0.8632154\n",
      " 0.9952872  0.99979025]\n",
      "The rewards are: [0.99580765 0.9984358  0.9680389  0.96162283 0.7289997  0.9981956\n",
      " 0.99939966 0.9991386  0.69860005 0.78793484 0.9425007  0.9315679\n",
      " 0.9976433  0.96084464 0.9955332  0.9994824  0.50348485 0.98513085\n",
      " 0.8305549  0.94981235 0.8231065  0.9922315  0.9997421  0.9147305\n",
      " 0.7681752  0.98193985 0.9997154  0.9708182  0.6534626  0.98620296\n",
      " 0.98928636 0.99704117]\n",
      "The rewards are: [0.99965334 0.9366923  0.9579385  0.9643511  0.99900657 0.93360895\n",
      " 0.9990853  0.97489357 0.9697882  0.9979729  0.9967638  0.99636793\n",
      " 0.9999697  0.999841   0.9029848  0.9993612  0.9434383  0.99667144\n",
      " 0.7671828  0.8088129  0.998909   0.9998233  0.9993641  0.7682031\n",
      " 0.96298945 0.944695   0.9950099  0.99915135 0.95872235 0.99915004\n",
      " 0.99965453 0.9783054 ]\n",
      "The rewards are: [0.9970847  0.6705243  0.9815788  0.67049545 0.9838013  0.9963684\n",
      " 0.9992054  0.99951327 0.8184962  0.99871504 0.99984956 0.973869\n",
      " 0.80215    0.99998283 0.99979967 0.9999722  0.9992632  0.9994023\n",
      " 0.9963845  0.9612107  0.9996489  0.99929774 0.93817484 0.9996131\n",
      " 0.9993735  0.98733574 0.80904037 0.99538946 0.99440575 0.5741006\n",
      " 0.98672557 0.52607924]\n",
      "The rewards are: [0.9689397  0.9998073  0.99851626 0.9488984  0.9974349  0.8305846\n",
      " 0.9839145  0.9908861  0.96665466 0.67847437 0.8741729  0.99125904\n",
      " 0.90043885 0.9983814  0.9995011  0.9984049  0.9017765  0.98849595\n",
      " 0.8104593  0.99952555 0.9968778  0.9985611  0.9613366  0.8451414\n",
      " 0.9264739  0.9551463  0.98322475 0.9921491  0.993856   0.99914\n",
      " 0.9992176  0.9760501 ]\n",
      "The rewards are: [0.97818065 0.70290434 0.86815673 0.98609805 0.8543149  0.93708575\n",
      " 0.99519914 0.99726367 0.8819666  0.9628735  0.99861836 0.9570301\n",
      " 0.85586715 0.9939838  0.90322214 0.99969697 0.8597244  0.9976452\n",
      " 0.9456302  0.9756497  0.99987996 0.91771096 0.9640898  0.9919046\n",
      " 0.87916404 0.93252903 0.95671326 0.9995951  0.976606   0.96352947\n",
      " 0.9965603  0.99915814]\n",
      "The rewards are: [0.9448048  0.99789387 0.6112877  0.987143   0.99832183 0.94967204\n",
      " 0.98679966 0.99775666 0.9969393  0.99943346 0.98410773 0.9994311\n",
      " 0.57592016 0.99989355 0.99603444 0.99565566 0.92096287 0.99973434\n",
      " 0.99898726 0.97050023 0.9842008  0.9452444  0.6808626  0.97968423\n",
      " 0.9994475  0.9989459  0.7417132  0.8648053  0.86192286 0.99922967\n",
      " 0.9831061  0.99404573]\n",
      "The rewards are: [0.79018116 0.78078276 0.7998318  0.9866854  0.999653   0.99874204\n",
      " 0.5475399  0.98662764 0.99940324 0.6854798  0.96696055 0.99905926\n",
      " 0.951169   0.9962992  0.89680403 0.9138586  0.76583284 0.95993555\n",
      " 0.8609897  0.8341422  0.97428745 0.66892314 0.88733125 0.694925\n",
      " 0.9929543  0.7707914  0.98999643 0.99949646 0.99924797 0.9994023\n",
      " 0.97929525 0.99872345]\n",
      "The rewards are: [0.50311744 0.986654   0.99942905 0.9644743  0.9983285  0.9996086\n",
      " 0.9526649  0.98734134 0.9995371  0.98092526 0.6201005  0.9895308\n",
      " 0.9954046  0.9998122  0.98636335 0.98731905 0.9965249  0.5699757\n",
      " 0.995827   0.90835035 0.9990876  0.6046505  0.99120784 0.8258653\n",
      " 0.99153405 0.99992967 0.9859531  0.99048585 0.88572913 0.8321464\n",
      " 0.8327097  0.9828756 ]\n",
      "The rewards are: [0.92094386 0.99952626 0.8827538  0.9022965  0.999987   0.9703184\n",
      " 0.81070566 0.9021169  0.9781561  0.90732443 0.9997844  0.9995565\n",
      " 0.9933565  0.99934405 0.9939131  0.99106467 0.71943    0.99924785\n",
      " 0.9733393  0.99954575 0.9706749  0.99679595 0.9993181  0.834739\n",
      " 0.9815306  0.98206156 0.9991067  0.9619185  0.99750876 0.9814208\n",
      " 0.78481543 0.81441736]\n",
      "The rewards are: [0.99641186 0.84102225 0.99812514 0.9744995  0.9993106  0.9996964\n",
      " 0.677626   0.87783015 0.96471334 0.99992025 0.99932265 0.9966137\n",
      " 0.9995789  0.9214006  0.9822427  0.85625345 0.9885733  0.9993655\n",
      " 0.6704343  0.9927164  0.98075277 0.99999785 0.9939275  0.9655069\n",
      " 0.9830188  0.98160434 0.9917155  0.8799922  0.79278344 0.99603564\n",
      " 0.8966058  0.97822684]\n",
      "The rewards are: [0.9890115  0.9972727  0.97004974 0.6639889  0.9975248  0.93261915\n",
      " 0.9767322  0.94962335 0.9491058  0.8064777  0.9918811  0.8288607\n",
      " 0.80781966 0.997542   0.999788   0.99664354 0.8513811  0.99993277\n",
      " 0.956243   0.76072454 0.9892474  0.9985481  0.99277556 0.9909916\n",
      " 0.91510195 0.5366544  0.6584121  0.9787143  0.9999031  0.8680297\n",
      " 0.97407556 0.9991309 ]\n",
      "The rewards are: [0.90453357 0.9981451  0.99916625 0.8575728  0.99167717 0.9890961\n",
      " 0.9997998  0.9938763  0.6141005  0.9903352  0.96758014 0.9325467\n",
      " 0.98783803 0.9999161  0.9995196  0.9543938  0.99683505 0.88946193\n",
      " 0.99916935 0.99838746 0.9934777  0.99810827 0.9553944  0.99707294\n",
      " 0.9996772  0.53692406 0.7987784  0.8653603  0.91074896 0.96479934\n",
      " 0.9148813  0.99898523]\n",
      "The rewards are: [0.9339495  0.769183   0.89635247 0.9987477  0.91957843 0.7430826\n",
      " 0.5951753  0.7694461  0.9993304  0.99963856 0.97207683 0.99942315\n",
      " 0.88996387 0.99864775 0.9899732  0.9817883  0.95424026 0.63006127\n",
      " 0.99967897 0.98783976 0.99836415 0.9890709  0.9943322  0.9828598\n",
      " 0.77929014 0.9997453  0.997071   0.9996138  0.68873805 0.9480834\n",
      " 0.99949086 0.9994436 ]\n",
      "The rewards are: [0.8584538  0.99081284 0.9996401  0.91999197 0.7499494  0.83676505\n",
      " 0.999828   0.9992531  0.9833009  0.59165555 0.5356493  0.9985091\n",
      " 0.9629034  0.94668406 0.96367514 0.9896875  0.8957427  0.750021\n",
      " 0.82311356 0.7761146  0.9988813  0.8763477  0.82996804 0.96752733\n",
      " 0.99086845 0.8955807  0.9905207  0.99621564 0.9879125  0.9988856\n",
      " 0.9898436  0.860888  ]\n",
      "The rewards are: [0.99821764 0.9801956  0.9388312  0.89997333 0.9891888  0.6209775\n",
      " 0.99927694 0.8114037  0.94148725 0.99297744 0.9691134  0.50173044\n",
      " 0.9863535  0.99995315 0.7773992  0.99933904 0.99930966 0.9847996\n",
      " 0.8902994  0.6734101  0.9664356  0.88955426 0.8963388  0.9854789\n",
      " 0.9998647  0.99972194 0.5561758  0.999015   0.99717134 0.9983601\n",
      " 0.9803238  0.9495755 ]\n",
      "The rewards are: [0.99961555 0.99844897 0.85806954 0.99963427 0.99778277 0.97853696\n",
      " 0.8222316  0.9935049  0.91983944 0.99161536 0.992405   0.9971692\n",
      " 0.999913   0.75642633 0.9994252  0.9938414  0.97342694 0.8975673\n",
      " 0.9877122  0.99988925 0.88319916 0.989597   0.9992095  0.79935783\n",
      " 0.7183018  0.9625846  0.5985058  0.81071275 0.9641871  0.8693443\n",
      " 0.9364849  0.9975694 ]\n",
      "The rewards are: [0.98926175 0.7526438  0.5110578  0.7689204  0.7789751  0.9974589\n",
      " 0.70652974 0.83815634 0.99234736 0.8510276  0.9996269  0.99092615\n",
      " 0.77507305 0.9812127  0.9209447  0.98703927 0.9683363  0.99854916\n",
      " 0.7195366  0.99713993 0.99215734 0.9989772  0.959725   0.7686468\n",
      " 0.692077   0.9991398  0.63261294 0.81453055 0.9993862  0.99292386\n",
      " 0.999387   0.9727557 ]\n",
      "The rewards are: [0.9981969  0.99955374 0.9956553  0.9994942  0.9723441  0.90162885\n",
      " 0.9986627  0.9972607  0.99907327 0.995994   0.78592306 0.999833\n",
      " 0.8961966  0.99922264 0.997872   0.99758446 0.997764   0.99752516\n",
      " 0.9889648  0.99960023 0.99904126 0.99896157 0.9974101  0.99908197\n",
      " 0.87918574 0.8126349  0.996219   0.9707927  0.5324751  0.56823957\n",
      " 0.9838217  0.99911314]\n",
      "The rewards are: [0.69210625 0.8671299  0.9904344  0.9409796  0.95708764 0.6817726\n",
      " 0.75572586 0.8745992  0.87775433 0.53429615 0.6157146  0.9960139\n",
      " 0.99868983 0.95831925 0.9938262  0.9860676  0.8882873  0.99987435\n",
      " 0.99528366 0.91991186 0.97564745 0.9669608  0.9866034  0.94417006\n",
      " 0.68821305 0.8212439  0.9997048  0.86041486 0.9990175  0.9994906\n",
      " 0.9967289  0.9763667 ]\n",
      "The rewards are: [0.9278272  0.88624287 0.7315898  0.86760604 0.73462033 0.50477326\n",
      " 0.9539166  0.9997236  0.98625803 0.99820316 0.888544   0.9664219\n",
      " 0.6840887  0.79913163 0.9357443  0.9821898  0.9998548  0.81124204\n",
      " 0.94511837 0.97163105 0.99643135 0.9969559  0.99110085 0.9996536\n",
      " 0.9852481  0.9994972  0.9985434  0.9975262  0.9355248  0.98552114\n",
      " 0.9994398  0.98423934]\n",
      "The rewards are: [0.99990463 0.9074941  0.9813318  0.99643636 0.9854349  0.99898344\n",
      " 0.9931874  0.9983291  0.9993674  0.96740156 0.9995382  0.9994837\n",
      " 0.9368916  0.99262285 0.9975204  0.96522886 0.915211   0.99681157\n",
      " 0.7921463  0.99815506 0.86860496 0.9998497  0.9773138  0.90989476\n",
      " 0.980962   0.9975085  0.96777064 0.9519156  0.9388841  0.85511863\n",
      " 0.5930627  0.9987601 ]\n",
      "The rewards are: [0.86838037 0.99374926 0.5451336  0.9741189  0.7474414  0.9987394\n",
      " 0.65738744 0.9935004  0.9982027  0.70490843 0.9963211  0.99607533\n",
      " 0.9307262  0.99658716 0.99907374 0.998664   0.995116   0.8940846\n",
      " 0.59080213 0.92997277 0.9901603  0.99699724 0.77291167 0.9981834\n",
      " 0.9859024  0.9958663  0.88023674 0.9838361  0.8904382  0.9983571\n",
      " 0.7445626  0.88447475]\n",
      "The rewards are: [0.98821425 0.7133839  0.99910694 0.9977684  0.99582857 0.99815303\n",
      " 0.999723   0.80355114 0.99873346 0.99923885 0.9489876  0.9986084\n",
      " 0.97364706 0.9720942  0.99658066 0.94988054 0.6383438  0.99639183\n",
      " 0.64515346 0.98958325 0.999534   0.56500703 0.9900799  0.9986083\n",
      " 0.8513145  0.98337144 0.98652494 0.9751542  0.9994042  0.94742626\n",
      " 0.96843797 0.6345826 ]\n",
      "The rewards are: [0.9212544  0.99892163 0.99996436 0.5812155  0.99846625 0.98893434\n",
      " 0.998979   0.81008077 0.63842195 0.9999362  0.99956316 0.9925045\n",
      " 0.7495491  0.9687997  0.99975437 0.9475651  0.98225695 0.8404071\n",
      " 0.99908805 0.73639625 0.92816144 0.5544175  0.72411513 0.9945041\n",
      " 0.83350986 0.9971788  0.9924601  0.9993981  0.9984018  0.9955374\n",
      " 0.8351353  0.65936625]\n",
      "The rewards are: [0.9810921  0.9997433  0.90914476 0.99803966 0.99987054 0.5831154\n",
      " 0.88976735 0.99477345 0.9994954  0.9684456  0.7493661  0.9858915\n",
      " 0.9961479  0.99998987 0.93133956 0.91097564 0.90535915 0.97416615\n",
      " 0.77580625 0.9967829  0.97241735 0.9970112  0.99922323 0.99968576\n",
      " 0.98569125 0.9802351  0.99970347 0.8392526  0.97101486 0.9997423\n",
      " 0.9658544  0.99987054]\n",
      "The rewards are: [0.9702801  0.9226698  0.9966545  0.9348068  0.99910295 0.9359014\n",
      " 0.70860165 0.88629    0.99921167 0.99700207 0.99771607 0.9038409\n",
      " 0.9846     0.9966665  0.9866605  0.9906019  0.96604365 0.9991148\n",
      " 0.99332136 0.92242634 0.9927603  0.9780116  0.9998568  0.8947401\n",
      " 0.9647373  0.99990416 0.9896031  0.9997243  0.9759713  0.9968496\n",
      " 0.9844281  0.9990439 ]\n",
      "The rewards are: [0.99830025 0.8201323  0.9641128  0.997138   0.9919294  0.9252798\n",
      " 0.85967225 0.9374419  0.9670803  0.99990404 0.9963839  0.99626714\n",
      " 0.9819234  0.91417116 0.9999478  0.69216305 0.9448561  0.94307375\n",
      " 0.9973068  0.98079944 0.98625344 0.9998072  0.91448104 0.75120896\n",
      " 0.9446253  0.79858786 0.9979538  0.8170488  0.9888314  0.7428901\n",
      " 0.9994435  0.99874926]\n",
      "The rewards are: [0.97351384 0.9814347  0.7960214  0.98604465 0.9988882  0.9999162\n",
      " 0.99960953 0.9990434  0.9995627  0.80295646 0.88100284 0.9983864\n",
      " 0.9996038  0.964028   0.9934094  0.80601704 0.9905145  0.97992307\n",
      " 0.98792565 0.6427337  0.91641337 0.99506927 0.9950074  0.9948015\n",
      " 0.9513537  0.6131426  0.99685967 0.9830905  0.8020103  0.99841917\n",
      " 0.9370912  0.9952579 ]\n",
      "The rewards are: [0.9924677  0.78237116 0.9976102  0.54867595 0.6577372  0.99014497\n",
      " 0.96591294 0.9948927  0.9629574  0.99991834 0.7146672  0.97622234\n",
      " 0.99739444 0.6374595  0.9978975  0.9846085  0.99962115 0.93588483\n",
      " 0.9735734  0.9319193  0.99688333 0.7105063  0.99126124 0.97829163\n",
      " 0.63730496 0.8243798  0.99605113 0.99969554 0.62844825 0.72811824\n",
      " 0.9975262  0.96633196]\n",
      "The rewards are: [0.7216013  0.9714594  0.7055512  0.9628369  0.9976157  0.9909547\n",
      " 0.993608   0.99634874 0.7791582  0.5898838  0.9975981  0.8709176\n",
      " 0.99129957 0.9965969  0.6776828  0.9584173  0.9898038  0.9955426\n",
      " 0.96648896 0.99975735 0.9995378  0.63944703 0.9993518  0.92797786\n",
      " 0.97190565 0.9866894  0.9965281  0.99286735 0.99587667 0.9387231\n",
      " 0.99772173 0.99936765]\n",
      "The rewards are: [0.91775274 0.9771798  0.8015421  0.99175525 0.8714916  0.7723043\n",
      " 0.970706   0.9829785  0.88754535 0.9885852  0.9775024  0.8366466\n",
      " 0.986624   0.6797578  0.9982835  0.9995277  0.98813695 0.55669266\n",
      " 0.9999925  0.7301256  0.7595866  0.9979836  0.9938299  0.9999341\n",
      " 0.9661497  0.97664785 0.9697361  0.87513953 0.97933173 0.9998759\n",
      " 0.9783468  0.98676455]\n",
      "The rewards are: [0.99182737 0.97594595 0.99991393 0.9927918  0.7172728  0.99986684\n",
      " 0.9859158  0.9969812  0.92270833 0.9996799  0.9075228  0.992851\n",
      " 0.99965143 0.98613584 0.944166   0.8562257  0.9997048  0.9955179\n",
      " 0.91223377 0.93314296 0.6323889  0.9993795  0.99841654 0.9954861\n",
      " 0.79811805 0.6963373  0.999627   0.99889827 0.9171199  0.9988951\n",
      " 0.97675496 0.9994455 ]\n",
      "The rewards are: [0.9420966  0.5893178  0.95171064 0.9417522  0.9823026  0.6463764\n",
      " 0.9981645  0.9837277  0.90578526 0.9990207  0.9020651  0.80600923\n",
      " 0.99730194 0.9880611  0.57189196 0.9964169  0.656636   0.99979013\n",
      " 0.78174293 0.99951327 0.7132348  0.99654466 0.9998554  0.6234428\n",
      " 0.7233352  0.9555537  0.99854577 0.9979962  0.9982692  0.83314574\n",
      " 0.99887687 0.9890056 ]\n",
      "The rewards are: [0.9747074  0.9955112  0.96234065 0.98063344 0.8863841  0.99754983\n",
      " 0.98469603 0.9998574  0.99224174 0.9996346  0.93652165 0.9725572\n",
      " 0.9990963  0.94849515 0.9847645  0.644706   0.95134306 0.9966775\n",
      " 0.69498116 0.99825877 0.99672806 0.9974483  0.9706665  0.9854372\n",
      " 0.9980319  0.89995825 0.99985754 0.99170023 0.9957301  0.53882563\n",
      " 0.72037077 0.9758596 ]\n",
      "The rewards are: [0.9760197  0.876908   0.99929523 0.9982027  0.99955887 0.76511043\n",
      " 0.93227875 0.89669657 0.7645952  0.99097323 0.97711915 0.9502959\n",
      " 0.8366116  0.8662134  0.74811983 0.9033555  0.997086   0.9872443\n",
      " 0.99924254 0.98957473 0.6485874  0.53735375 0.9998672  0.9988192\n",
      " 0.9926443  0.7548308  0.9998173  0.99099976 0.9868183  0.8790695\n",
      " 0.999443   0.96028006]\n",
      "The rewards are: [0.987387   0.9930056  0.95571864 0.9950164  0.8734125  0.8959546\n",
      " 0.9994342  0.7842236  0.9787457  0.996391   0.9889705  0.99758863\n",
      " 0.88264394 0.991524   0.9952258  0.99943954 0.9434439  0.9989655\n",
      " 0.7068649  0.9930981  0.99793625 0.9619051  0.9653333  0.9994529\n",
      " 0.99800986 0.99391407 0.9459351  0.75703746 0.53498036 0.9914555\n",
      " 0.99840516 0.99788576]\n",
      "The rewards are: [0.9841967  0.98500013 0.81595236 0.999723   0.9997948  0.9911273\n",
      " 0.9998186  0.9996661  0.9825088  0.9989116  0.6219402  0.8746297\n",
      " 0.8658513  0.71166366 0.9890372  0.9801493  0.9820825  0.8495865\n",
      " 0.9233893  0.9806255  0.9012004  0.99944717 0.947462   0.9215095\n",
      " 0.9998745  0.9822755  0.9232059  0.68182355 0.9962023  0.78512734\n",
      " 0.99334466 0.9997472 ]\n",
      "The rewards are: [0.9722764  0.8763561  0.9998622  0.9989027  0.9947226  0.9968425\n",
      " 0.9144533  0.99435353 0.99770015 0.96383756 0.99995863 0.98016846\n",
      " 0.5865107  0.9992731  0.9973742  0.99518174 0.9983271  0.9920257\n",
      " 0.9535145  0.99733585 0.9979936  0.91699404 0.9968849  0.97621626\n",
      " 0.9829009  0.9927354  0.9941803  0.99783236 0.96656966 0.5262623\n",
      " 0.9999399  0.7356202 ]\n",
      "The rewards are: [0.95544636 0.97549397 0.99942684 0.9909253  0.98642135 0.96970886\n",
      " 0.9891061  0.76701015 0.7095207  0.9977859  0.9982798  0.5849104\n",
      " 0.9966366  0.96598256 0.9919452  0.7259982  0.9498372  0.61374366\n",
      " 0.89531964 0.9995447  0.9983845  0.99994373 0.9624163  0.9985917\n",
      " 0.9996283  0.99448967 0.69123214 0.9808594  0.9579432  0.83010274\n",
      " 0.9971751  0.91611046]\n",
      "The rewards are: [0.98461586 0.9725758  0.9972625  0.97151315 0.9996113  0.9133429\n",
      " 0.99985325 0.9634062  0.9985739  0.99941504 0.97338337 0.9542109\n",
      " 0.6623014  0.96033764 0.7303373  0.90049994 0.99971884 0.9806358\n",
      " 0.999308   0.9971987  0.9983461  0.99711907 0.9911806  0.99824226\n",
      " 0.9978502  0.99944705 0.75057054 0.9479297  0.9996625  0.9897569\n",
      " 0.9854408  0.9925189 ]\n",
      "The rewards are: [0.8961154  0.9979954  0.98749524 0.8673811  0.99647623 0.91106033\n",
      " 0.58162415 0.99973255 0.99822897 0.96689147 0.9905957  0.9861913\n",
      " 0.9613983  0.92837656 0.9696405  0.9770123  0.99726486 0.9923178\n",
      " 0.92516583 0.9987406  0.9998996  0.9896751  0.999858   0.99511033\n",
      " 0.99810445 0.9863538  0.9721041  0.99612707 0.80890805 0.98578113\n",
      " 0.99924636 0.9542943 ]\n",
      "The rewards are: [0.9961152  0.95242596 0.99981755 0.96663016 0.9970265  0.9984611\n",
      " 0.9844512  0.9995209  0.9923424  0.99701095 0.94206697 0.5122769\n",
      " 0.9964096  0.9932973  0.9568373  0.98529124 0.9889557  0.9996333\n",
      " 0.99859065 0.9693814  0.86824006 0.9950376  0.9744201  0.5096228\n",
      " 0.9993067  0.9245281  0.9997218  0.97109014 0.9998758  0.9603306\n",
      " 0.9380576  0.9963779 ]\n",
      "The rewards are: [0.9985763  0.9867986  0.98267615 0.5323246  0.99693584 0.7910492\n",
      " 0.9868673  0.9999244  0.9905461  0.87623304 0.9943756  0.7789165\n",
      " 0.9331988  0.9964928  0.99479574 0.99060655 0.9976301  0.64718854\n",
      " 0.9953833  0.9325474  0.94524056 0.9919172  0.6658517  0.91671264\n",
      " 0.9996567  0.7958534  0.95885825 0.99290377 0.99962735 0.98892504\n",
      " 0.9955017  0.92450684]\n",
      "The rewards are: [0.99024045 0.9255061  0.99213845 0.9702396  0.89444655 0.9806018\n",
      " 0.99922    0.9787032  0.9495127  0.85066867 0.9821424  0.96020585\n",
      " 0.99735534 0.8491165  0.9332733  0.9839999  0.9831524  0.9997842\n",
      " 0.99313027 0.99614304 0.997384   0.5066725  0.9988986  0.9886389\n",
      " 0.9946518  0.9859908  0.99847275 0.9761045  0.9990816  0.9985923\n",
      " 0.7515023  0.85631996]\n",
      "The rewards are: [0.99946827 0.9995135  0.9277663  0.9953399  0.9995789  0.9821907\n",
      " 0.99992406 0.9999776  0.9995995  0.8765113  0.9655758  0.97438824\n",
      " 0.980507   0.7347076  0.9959164  0.64831066 0.9997731  0.9999602\n",
      " 0.9989818  0.9107181  0.9835031  0.9706882  0.9849133  0.999736\n",
      " 0.9999782  0.9973986  0.99126124 0.79151964 0.9981791  0.99975735\n",
      " 0.9993856  0.9985551 ]\n",
      "The rewards are: [0.9991769  0.99984217 0.85672796 0.99969876 0.98035526 0.99855167\n",
      " 0.8923234  0.98928225 0.95960844 0.6203556  0.99727017 0.9990382\n",
      " 0.95886266 0.9990876  0.99994123 0.9913794  0.98434746 0.99921834\n",
      " 0.9457991  0.9539846  0.9855468  0.93932563 0.998865   0.9418967\n",
      " 0.78505206 0.998565   0.892933   0.9939737  0.999418   0.5341283\n",
      " 0.8706933  0.9999579 ]\n",
      "The rewards are: [0.9915107  0.7791046  0.9980471  0.9998561  0.889768   0.96605295\n",
      " 0.602515   0.9937716  0.9625763  0.9891678  0.99870765 0.8835214\n",
      " 0.824631   0.99291694 0.99908066 0.92180973 0.96921396 0.99801373\n",
      " 0.9998596  0.9137937  0.999603   0.5939257  0.62206393 0.99074286\n",
      " 0.99851483 0.98610675 0.9378422  0.9996431  0.89062744 0.99980587\n",
      " 0.995837   0.99140364]\n",
      "The rewards are: [0.95036227 0.9986539  0.92043996 0.9915592  0.95232606 0.99610305\n",
      " 0.9480686  0.99986684 0.9993925  0.99990594 0.7461842  0.9998759\n",
      " 0.74352425 0.99959046 0.9773677  0.9936521  0.99918026 0.9994716\n",
      " 0.9276538  0.5065064  0.99613345 0.6746394  0.9928733  0.99982053\n",
      " 0.96455383 0.9967481  0.9436613  0.9795306  0.9370369  0.9755279\n",
      " 0.9998908  0.96621   ]\n",
      "The rewards are: [0.91211843 0.6599158  0.80159193 0.5573886  0.9829311  0.98363185\n",
      " 0.9933583  0.51022327 0.99804175 0.5466797  0.99986315 0.998752\n",
      " 0.9222914  0.8554903  0.9970355  0.9395332  0.91922647 0.7166593\n",
      " 0.99953234 0.90108526 0.99929297 0.9950236  0.6501136  0.9942865\n",
      " 0.994697   0.99885345 0.99053615 0.978832   0.99913126 0.76713103\n",
      " 0.5136459  0.85073674]\n",
      "The rewards are: [0.99890804 0.98992425 0.9993024  0.99610174 0.99607795 0.99764913\n",
      " 0.9226227  0.99971086 0.99363744 0.9999982  0.8627333  0.9798749\n",
      " 0.9979327  0.5069909  0.9664246  0.99797827 0.92536545 0.8783768\n",
      " 0.9997328  0.99663746 0.9927781  0.9882355  0.99714667 0.9947137\n",
      " 0.9999672  0.9988287  0.99972063 0.96096265 0.99513394 0.99780494\n",
      " 0.9684219  0.8598862 ]\n",
      "The rewards are: [0.95899934 0.99497306 0.9992207  0.99993336 0.99791044 0.9891828\n",
      " 0.7107677  0.9818824  0.99997497 0.99991333 0.9241368  0.9887186\n",
      " 0.84589696 0.55982995 0.99438757 0.9518821  0.99793243 0.9922201\n",
      " 0.9982779  0.9991159  0.9997087  0.93756133 0.9315767  0.9997044\n",
      " 0.99349266 0.9621039  0.5242153  0.5379052  0.99996865 0.99258703\n",
      " 0.96824193 0.9986267 ]\n",
      "The rewards are: [0.9855942  0.91059375 0.9994766  0.9994467  0.9014583  0.79313564\n",
      " 0.99930525 0.9864466  0.7704992  0.9340916  0.7772888  0.9992361\n",
      " 0.9625497  0.6241324  0.9921279  0.9984212  0.9971054  0.8053005\n",
      " 0.7401599  0.99904317 0.9928598  0.99991274 0.9834057  0.99327576\n",
      " 0.97521985 0.88885987 0.993353   0.99230087 0.830346   0.99399155\n",
      " 0.95915693 0.7844554 ]\n",
      "The rewards are: [0.9867426  0.9975483  0.9996437  0.999215   0.89644474 0.99876946\n",
      " 0.99708986 0.9939061  0.9994904  0.985892   0.9989311  0.97320753\n",
      " 0.9991442  0.9985757  0.99595225 0.98915523 0.99822396 0.98557985\n",
      " 0.993455   0.9952047  0.78679687 0.8401458  0.9552329  0.9993661\n",
      " 0.99351764 0.99823546 0.99830014 0.9985429  0.91380066 0.8423295\n",
      " 0.99706155 0.97795594]\n",
      "The rewards are: [0.95584786 0.9566781  0.91019803 0.9999254  0.9896953  0.9571451\n",
      " 0.99739826 0.9190628  0.9749076  0.939477   0.9897739  0.70348555\n",
      " 0.9995141  0.99813217 0.9995153  0.87235814 0.9559483  0.9881783\n",
      " 0.997869   0.9980287  0.997494   0.82126445 0.8518249  0.8950218\n",
      " 0.77044576 0.92507714 0.95460004 0.99724305 0.99982303 0.9265863\n",
      " 0.92121464 0.6709777 ]\n",
      "The rewards are: [0.9389649  0.9980616  0.69745576 0.8474609  0.99958366 0.9998921\n",
      " 0.89930207 0.99610716 0.97245544 0.93744934 0.996387   0.99671197\n",
      " 0.9994035  0.86967385 0.6684495  0.9993406  0.9982533  0.86415654\n",
      " 0.9990963  0.9884112  0.9159983  0.9946635  0.9997142  0.9412888\n",
      " 0.9998258  0.98491955 0.99933416 0.5101573  0.79447055 0.9983267\n",
      " 0.8235342  0.9979698 ]\n",
      "The rewards are: [0.94535685 0.99873835 0.99843913 0.99001396 0.55631113 0.6678025\n",
      " 0.96893746 0.50069475 0.99931014 0.9976169  0.98343325 0.9539819\n",
      " 0.99961746 0.98972356 0.6083117  0.9972373  0.8840317  0.8051451\n",
      " 0.6872766  0.9987544  0.9013013  0.99952936 0.9990658  0.99986756\n",
      " 0.9976768  0.98594254 0.99101454 0.9955621  0.9506131  0.99957114\n",
      " 0.9993697  0.9993494 ]\n",
      "The rewards are: [0.9998746  0.98424685 0.97312003 0.9912374  0.99975806 0.88381433\n",
      " 0.99986863 0.9932094  0.99963284 0.9892825  0.9947395  0.95914674\n",
      " 0.9998951  0.9999738  0.93509406 0.9624615  0.9977151  0.98456687\n",
      " 0.9997441  0.9768192  0.9898198  0.99978787 0.96977925 0.8143107\n",
      " 0.84874177 0.99760723 0.86849856 0.7645308  0.9984359  0.8936901\n",
      " 0.9961487  0.95733535]\n",
      "The rewards are: [0.9996238  0.9940562  0.85711217 0.9950492  0.97973067 0.99816966\n",
      " 0.999696   0.88392323 0.99114066 0.9821639  0.90169835 0.9846016\n",
      " 0.7250754  0.52706265 0.9960104  0.97961605 0.99941766 0.99889034\n",
      " 0.97407156 0.89276433 0.9646208  0.9995092  0.9968347  0.9841642\n",
      " 0.5925171  0.95635164 0.97674805 0.97546524 0.99898916 0.9994117\n",
      " 0.9229074  0.82059395]\n",
      "The rewards are: [0.99979025 0.88753283 0.99581546 0.60533464 0.99999046 0.99581003\n",
      " 0.7062673  0.97513777 0.9286252  0.9938141  0.9425134  0.9978532\n",
      " 0.99828076 0.990222   0.9826501  0.9209508  0.9564245  0.9987826\n",
      " 0.99849904 0.9977463  0.9976828  0.99092484 0.88768995 0.9807649\n",
      " 0.9989986  0.9995041  0.9343024  0.9999435  0.9415053  0.8717684\n",
      " 0.9817547  0.99723333]\n",
      "The rewards are: [0.9597863  0.826105   0.9991456  0.9999802  0.56828994 0.98661834\n",
      " 0.9595072  0.9975661  0.9936144  0.59572107 0.9408375  0.7279343\n",
      " 0.9999038  0.927747   0.78740567 0.78751624 0.9942432  0.8310315\n",
      " 0.66985893 0.99932325 0.9909016  0.92124337 0.63111585 0.9999583\n",
      " 0.99934834 0.9996536  0.95081216 0.99892163 0.96715474 0.9840348\n",
      " 0.99715924 0.9997042 ]\n",
      "The rewards are: [0.9867371  0.96928877 0.998711   0.999964   0.9319239  0.6737743\n",
      " 0.99044514 0.9922726  0.9820941  0.9844514  0.9992798  0.96744955\n",
      " 0.8549081  0.93689924 0.9666332  0.97316486 0.99994373 0.53400874\n",
      " 0.66979337 0.9385791  0.9546316  0.80954844 0.99989414 0.9885577\n",
      " 0.99703777 0.9702801  0.9993998  0.99959904 0.9999589  0.9993137\n",
      " 0.91259235 0.99823344]\n",
      "The rewards are: [0.98626626 0.9460507  0.9978643  0.99981874 0.5079559  0.90225774\n",
      " 0.9192221  0.9423864  0.99778867 0.99473083 0.8527089  0.62897676\n",
      " 0.99273247 0.9953927  0.9417835  0.5195571  0.5199259  0.9859969\n",
      " 0.90744054 0.6182631  0.9889501  0.98085785 0.7958771  0.96792966\n",
      " 0.9994586  0.99327505 0.9996118  0.9964355  0.8891337  0.999337\n",
      " 0.999602   0.8330976 ]\n",
      "The rewards are: [0.9976198  0.99977356 0.99389815 0.57106894 0.98062474 0.9945692\n",
      " 0.99881446 0.5004728  0.9972525  0.97634137 0.999057   0.9309491\n",
      " 0.9998919  0.94132674 0.91820955 0.9482248  0.99536693 0.9992982\n",
      " 0.9817931  0.9990246  0.9746742  0.99997866 0.9806717  0.9098441\n",
      " 0.92614293 0.6671828  0.9994222  0.99981636 0.99125904 0.8419977\n",
      " 0.99957246 0.9557707 ]\n",
      "The rewards are: [0.9850852  0.958461   0.9994629  0.973776   0.8283308  0.98700005\n",
      " 0.98673195 0.9979724  0.9982375  0.98821133 0.9986506  0.9741184\n",
      " 0.9613926  0.9850877  0.99888486 0.9993806  0.98496556 0.9618826\n",
      " 0.9958034  0.9999044  0.97292125 0.99874425 0.9620969  0.64913434\n",
      " 0.99498296 0.98508334 0.8854176  0.99511045 0.99895644 0.95107317\n",
      " 0.9777461  0.9778665 ]\n",
      "The rewards are: [0.95585626 0.99916875 0.9568815  0.90830743 0.8650609  0.9954401\n",
      " 0.98764753 0.96734744 0.87278897 0.9760272  0.9924643  0.99646276\n",
      " 0.92394954 0.9997861  0.9602228  0.668146   0.99502254 0.9999676\n",
      " 0.67800575 0.8807938  0.995167   0.9256357  0.99891376 0.9720214\n",
      " 0.9977436  0.9991541  0.99913883 0.98443466 0.88718545 0.92921436\n",
      " 0.83193827 0.9992405 ]\n",
      "The rewards are: [0.9978555  0.6760658  0.88569623 0.82991874 0.99736816 0.99960405\n",
      " 0.8573659  0.99964654 0.9868519  0.99941015 0.9989837  0.9787395\n",
      " 0.9998406  0.9433163  0.8843796  0.97719395 0.89595354 0.97942644\n",
      " 0.90927064 0.9998822  0.9557292  0.977098   0.8552279  0.98392546\n",
      " 0.9893038  0.9919361  0.98476    0.9998621  0.9997472  0.9989569\n",
      " 0.9146526  0.9464323 ]\n",
      "The rewards are: [0.99515295 0.996911   0.9644955  0.9893524  0.9993604  0.99991953\n",
      " 0.99205434 0.9973888  0.99893016 0.9978795  0.9579735  0.9876074\n",
      " 0.9963534  0.9919658  0.98960984 0.9649737  0.9997998  0.99982834\n",
      " 0.9258051  0.99523145 0.98438346 0.9983045  0.99596065 0.9991462\n",
      " 0.9982843  0.9999043  0.99977356 0.99686724 0.87434953 0.838975\n",
      " 0.9214829  0.97417045]\n",
      "The rewards are: [0.9836241  0.9982822  0.8713078  0.93571275 0.99854505 0.974081\n",
      " 0.99953747 0.7793815  0.87986    0.9989808  0.5458522  0.9985298\n",
      " 0.86120343 0.9981306  0.9753621  0.9484895  0.9926065  0.9923819\n",
      " 0.988832   0.9993267  0.9025894  0.9829333  0.99628156 0.99912196\n",
      " 0.9696549  0.7025753  0.7394181  0.99791664 0.99639976 0.8828243\n",
      " 0.9925021  0.99888295]\n",
      "The rewards are: [0.9995322  0.997523   0.9928334  0.9999895  0.9998252  0.8995555\n",
      " 0.99847883 0.9984634  0.99995935 0.9748523  0.9986873  0.5617718\n",
      " 0.997889   0.99832743 0.9242104  0.99984777 0.9993555  0.60736847\n",
      " 0.9909457  0.65395164 0.9179302  0.62663734 0.5321827  0.7693136\n",
      " 0.99838555 0.9989594  0.9075051  0.9990957  0.9992428  0.9910767\n",
      " 0.6470823  0.8291567 ]\n",
      "The rewards are: [0.81972826 0.999925   0.7022622  0.995218   0.9991596  0.7725741\n",
      " 0.99910104 0.98504585 0.8661299  0.99931717 0.99348986 0.7460005\n",
      " 0.9987016  0.99861825 0.95852923 0.9953548  0.9749688  0.9980276\n",
      " 0.9852213  0.9936481  0.9796948  0.9998497  0.9968965  0.98102826\n",
      " 0.9748174  0.99983454 0.999126   0.99119496 0.97939324 0.9985637\n",
      " 0.9533288  0.9221856 ]\n",
      "The rewards are: [0.9914658  0.996633   0.9193991  0.8678659  0.6944604  0.6960612\n",
      " 0.7318589  0.9991653  0.9993794  0.9991283  0.9947573  0.99978155\n",
      " 0.99751616 0.97433496 0.9905405  0.50004065 0.8846775  0.9386867\n",
      " 0.93656474 0.9919423  0.9749426  0.8947844  0.9967642  0.97365505\n",
      " 0.9999256  0.845713   0.7287893  0.952658   0.9992803  0.5814595\n",
      " 0.6023756  0.931217  ]\n",
      "The rewards are: [0.9842083  0.97191745 0.9891027  0.9934366  0.9981352  0.99431616\n",
      " 0.9505298  0.9995931  0.9696997  0.90248376 0.8664344  0.9923969\n",
      " 0.99736184 0.9619311  0.91219735 0.6883821  0.5378512  0.684565\n",
      " 0.9473296  0.99773526 0.6028536  0.97089976 0.99732447 0.85399806\n",
      " 0.77621335 0.99373066 0.9152974  0.99917287 0.9983069  0.88414645\n",
      " 0.9358628  0.99613744]\n",
      "The rewards are: [0.95425254 0.898087   0.96902823 0.9990785  0.9816653  0.5333441\n",
      " 0.9910982  0.9520399  0.9955895  0.8072595  0.82023066 0.9971545\n",
      " 0.99958605 0.9929783  0.99897254 0.98166937 0.7815655  0.9973496\n",
      " 0.99487454 0.99678934 0.98041624 0.9315589  0.9940655  0.9884334\n",
      " 0.9388122  0.99917054 0.9982262  0.98379797 0.9991904  0.99974173\n",
      " 0.9842428  0.99853647]\n",
      "The rewards are: [0.7072679  0.99820375 0.99881727 0.9735955  0.9633532  0.9940078\n",
      " 0.89111006 0.99922454 0.9987154  0.69304955 0.9964174  0.9615059\n",
      " 0.9967818  0.9884725  0.8819508  0.89215434 0.99808455 0.9890149\n",
      " 0.9981744  0.98193365 0.9148755  0.5486567  0.99813557 0.99884903\n",
      " 0.9987915  0.99750274 0.9991041  0.9889653  0.8490857  0.9971698\n",
      " 0.99575776 0.99861133]\n",
      "The rewards are: [0.9999198  0.99926955 0.9998764  0.5401914  0.98374474 0.9979759\n",
      " 0.85313755 0.95548826 0.9968971  0.99854845 0.9966144  0.9513584\n",
      " 0.96187365 0.6314926  0.73915946 0.9948474  0.9986343  0.99530506\n",
      " 0.9952296  0.9991968  0.99394083 0.76756626 0.995865   0.9993106\n",
      " 0.9865682  0.97279763 0.9829252  0.6412383  0.99991775 0.9998653\n",
      " 0.96009433 0.9598154 ]\n",
      "The rewards are: [0.9987447  0.9999193  0.99975413 0.9937914  0.9433693  0.9698154\n",
      " 0.99213    0.9677555  0.99869615 0.9931583  0.980806   0.9865888\n",
      " 0.69711137 0.90057415 0.99921966 0.5182499  0.9995347  0.92994833\n",
      " 0.9236411  0.9991386  0.73851246 0.97949755 0.9976209  0.95445013\n",
      " 0.946127   0.7341977  0.6604243  0.93019086 0.9984932  0.9702608\n",
      " 0.96909374 0.60917336]\n",
      "The rewards are: [0.9919769  0.99965    0.9969733  0.8845742  0.99304575 0.9954711\n",
      " 0.8235596  0.6686464  0.9706157  0.99756074 0.999529   0.89490724\n",
      " 0.94409966 0.88388354 0.9720814  0.99909294 0.8859083  0.97695005\n",
      " 0.98007375 0.9991953  0.99941266 0.7921202  0.81928474 0.91943383\n",
      " 0.99914193 0.9994584  0.99998915 0.9989925  0.9788954  0.99873\n",
      " 0.9511947  0.5863068 ]\n",
      "The rewards are: [0.99971706 0.9668209  0.6063882  0.99672264 0.96438605 0.9795466\n",
      " 0.9977189  0.9574325  0.6623662  0.57774884 0.9175599  0.9667555\n",
      " 0.9452059  0.9997129  0.7087288  0.8713219  0.9994398  0.99944395\n",
      " 0.80333894 0.9272922  0.9987686  0.95061255 0.9994442  0.9873563\n",
      " 0.98070276 0.7664457  0.8721977  0.9991222  0.8150357  0.92574614\n",
      " 0.87982744 0.995004  ]\n",
      "The rewards are: [0.99909306 0.9778502  0.99957293 0.9979371  0.78184545 0.996194\n",
      " 0.99702555 0.99772924 0.97024596 0.98503846 0.98489666 0.9996563\n",
      " 0.5973306  0.9993498  0.98995775 0.7108181  0.99619603 0.88583356\n",
      " 0.9769957  0.99569005 0.75953054 0.99322164 0.5033306  0.9701026\n",
      " 0.59064144 0.99502426 0.8892696  0.96708494 0.9978612  0.6876489\n",
      " 0.8102073  0.99363106]\n",
      "The rewards are: [0.98713624 0.9976096  0.92087746 0.99741554 0.9035019  0.9983183\n",
      " 0.7437334  0.9873332  0.9999769  0.6903696  0.9985696  0.9984097\n",
      " 0.89248127 0.55094534 0.9990182  0.96865696 0.9740383  0.99121314\n",
      " 0.9622702  0.94094115 0.9847104  0.95483977 0.5574901  0.99465525\n",
      " 0.8256446  0.99865025 0.99924004 0.99767464 0.99818915 0.97740513\n",
      " 0.9984748  0.9852261 ]\n",
      "The rewards are: [0.9850391  0.98910636 0.9952106  0.99083555 0.98319477 0.95654315\n",
      " 0.9980952  0.54317176 0.9796062  0.7705088  0.95658845 0.9999471\n",
      " 0.78379864 0.94728273 0.6654     0.9994647  0.9967039  0.98854035\n",
      " 0.94336975 0.99756145 0.97725874 0.91727215 0.99966085 0.98872864\n",
      " 0.99937373 0.92854434 0.87194186 0.9807053  0.9932486  0.62759197\n",
      " 0.91125757 0.99892056]\n",
      "The rewards are: [0.98716843 0.97697794 0.999091   0.83724606 0.9558272  0.99967515\n",
      " 0.99752134 0.9389454  0.9988231  0.5748687  0.83718586 0.99209315\n",
      " 0.9320054  0.9927088  0.99948454 0.9989262  0.9771559  0.9958599\n",
      " 0.71144354 0.99191636 0.9267551  0.9597988  0.9998084  0.9974611\n",
      " 0.9473791  0.9987348  0.9771678  0.76776624 0.9953721  0.9791351\n",
      " 0.99861205 0.99940765]\n",
      "The rewards are: [0.87707204 0.9996313  0.9997794  0.99475515 0.98490703 0.96296406\n",
      " 0.93579286 0.9944899  0.9443318  0.9994758  0.9987363  0.999453\n",
      " 0.9985726  0.9880981  0.80229676 0.99379563 0.99928564 0.97915226\n",
      " 0.9619181  0.8370384  0.97474027 0.99881244 0.94502467 0.90104437\n",
      " 0.7588376  0.9486604  0.99896085 0.9002218  0.9805463  0.9745292\n",
      " 0.8575715  0.9985713 ]\n",
      "The rewards are: [0.997664   0.9991203  0.99915016 0.99990165 0.96547556 0.9790041\n",
      " 0.881193   0.99094075 0.95888764 0.9788159  0.9995788  0.999813\n",
      " 0.9963456  0.99937963 0.77621555 0.8107921  0.62202626 0.6588834\n",
      " 0.9882619  0.99016106 0.852058   0.98947185 0.96344537 0.99009293\n",
      " 0.7048471  0.99990904 0.6556533  0.9900684  0.9899832  0.9875401\n",
      " 0.95302325 0.98974925]\n",
      "The rewards are: [0.9722749  0.96711206 0.6958985  0.93435967 0.9991154  0.99355376\n",
      " 0.9908138  0.9588731  0.9918053  0.99465334 0.7140812  0.9646278\n",
      " 0.954849   0.9997576  0.9953833  0.6279364  0.9074298  0.98098457\n",
      " 0.8186614  0.9268239  0.9997465  0.9982475  0.999765   0.99784935\n",
      " 0.9592965  0.99820817 0.7463902  0.91674715 0.7303432  0.9704788\n",
      " 0.9933795  0.9975733 ]\n",
      "The rewards are: [0.9393408  0.9993591  0.99965656 0.94298524 0.92920995 0.9975902\n",
      " 0.99948955 0.6084587  0.7064327  0.99770975 0.97538644 0.9997944\n",
      " 0.9927384  0.9686535  0.88478756 0.9153824  0.94982064 0.9999325\n",
      " 0.98906696 0.9616409  0.9963043  0.9989213  0.9412933  0.99097365\n",
      " 0.99961483 0.9995988  0.99832255 0.97841185 0.93304384 0.7939567\n",
      " 0.99317425 0.9947371 ]\n",
      "The rewards are: [0.9656095  0.84711194 0.9612127  0.9930046  0.99991786 0.9966287\n",
      " 0.9947613  0.9954483  0.9997874  0.95206183 0.9981262  0.9997305\n",
      " 0.8757418  0.99136704 0.9937069  0.99187136 0.94291675 0.8693633\n",
      " 0.9969831  0.9999386  0.99691534 0.8947355  0.9279813  0.9999833\n",
      " 0.9680678  0.87212586 0.9984939  0.99995136 0.87323225 0.9314194\n",
      " 0.9997501  0.99993074]\n",
      "The rewards are: [0.98494    0.6685695  0.99952626 0.9961216  0.99713194 0.9990245\n",
      " 0.993093   0.9997688  0.95785767 0.99950826 0.9627094  0.99430907\n",
      " 0.99933773 0.9989943  0.997384   0.99944586 0.6301886  0.9948377\n",
      " 0.99776435 0.99838054 0.99906045 0.9973907  0.925372   0.9994504\n",
      " 0.97142076 0.9975405  0.9999981  0.9993136  0.9993063  0.5470312\n",
      " 0.9563282  0.9793128 ]\n",
      "The rewards are: [0.9757565  0.98622745 0.5575721  0.74752134 0.8487215  0.8468262\n",
      " 0.99595803 0.55671394 0.9998938  0.80806684 0.65733856 0.9952538\n",
      " 0.999874   0.9996346  0.9925607  0.9854746  0.9692091  0.9916141\n",
      " 0.9978516  0.990473   0.97023106 0.99938905 0.9980958  0.99671197\n",
      " 0.99804854 0.96223766 0.9846902  0.9413052  0.92760074 0.99982136\n",
      " 0.948826   0.9781659 ]\n",
      "The rewards are: [0.95468956 0.96534    0.5342259  0.999092   0.9920614  0.99921834\n",
      " 0.9989347  0.98494035 0.9991059  0.9991769  0.99544287 0.9953401\n",
      " 0.9761302  0.9995127  0.99957186 0.75775766 0.84669995 0.79377276\n",
      " 0.91034275 0.94837874 0.9955747  0.99879694 0.9671018  0.98516\n",
      " 0.97371495 0.99990976 0.97939086 0.95278925 0.99132955 0.999607\n",
      " 0.5583207  0.94967   ]\n",
      "The rewards are: [0.999485   0.8367232  0.99904555 0.68110114 0.99969923 0.5161703\n",
      " 0.9996081  0.9999459  0.999411   0.99008405 0.9947614  0.9369268\n",
      " 0.99986136 0.995044   0.7794915  0.98263687 0.9993036  0.99916124\n",
      " 0.7732276  0.9783844  0.9948473  0.999225   0.9982699  0.99919194\n",
      " 0.98378366 0.9853479  0.9947154  0.9716428  0.996671   0.90175503\n",
      " 0.9908071  0.995886  ]\n",
      "The rewards are: [0.99260956 0.9999956  0.9992072  0.9297399  0.92821115 0.77133936\n",
      " 0.76510787 0.74838483 0.9749358  0.9977496  0.9979335  0.9916646\n",
      " 0.97342616 0.99999523 0.8612963  0.9373731  0.9618227  0.97367\n",
      " 0.9212148  0.76395196 0.9943269  0.99480104 0.799488   0.8962414\n",
      " 0.94367665 0.9970693  0.99916756 0.9324254  0.99974436 0.74910223\n",
      " 0.8796569  0.9998988 ]\n",
      "The rewards are: [0.65986013 0.96736914 0.99557805 0.88105226 0.996897   0.89687735\n",
      " 0.8734877  0.96403086 0.5868453  0.9900276  0.997931   0.99149936\n",
      " 0.99949014 0.9846865  0.9639962  0.99930525 0.9237174  0.99791354\n",
      " 0.951487   0.96499443 0.9957866  0.99622667 0.9726193  0.98373216\n",
      " 0.98915917 0.9987268  0.9901821  0.83454925 0.81026393 0.99912816\n",
      " 0.9980361  0.99841297]\n",
      "The rewards are: [0.99423814 0.94538677 0.89203227 0.9883676  0.9825401  0.9990909\n",
      " 0.90970916 0.93802905 0.94470125 0.86161757 0.9325559  0.96918947\n",
      " 0.99965596 0.99940157 0.9974656  0.9957111  0.9991744  0.9810012\n",
      " 0.9984681  0.6469368  0.9588823  0.9941393  0.9905387  0.9921821\n",
      " 0.9463631  0.99858224 0.99680114 0.99996376 0.9176935  0.99877304\n",
      " 0.9992454  0.99712354]\n",
      "The rewards are: [0.9870673  0.9977775  0.9177156  0.9955076  0.9907418  0.9981102\n",
      " 0.96846104 0.9992955  0.9988354  0.9952148  0.97373974 0.9999777\n",
      " 0.5486458  0.73073006 0.9987192  0.9910902  0.9829846  0.97157943\n",
      " 0.98919    0.99988484 0.99268335 0.99983    0.99922276 0.97515213\n",
      " 0.99884605 0.7714998  0.97248626 0.9987192  0.9948456  0.9983115\n",
      " 0.99927384 0.8712714 ]\n",
      "The rewards are: [0.99763834 0.6981991  0.8821228  0.97085875 0.99853253 0.9990539\n",
      " 0.8994071  0.9734206  0.7104277  0.9949945  0.99946433 0.98372734\n",
      " 0.6936532  0.99594814 0.9998599  0.8291008  0.99993765 0.9192203\n",
      " 0.6014716  0.99967146 0.991514   0.98402345 0.999141   0.9990251\n",
      " 0.9387689  0.9038891  0.94001496 0.96487594 0.99800485 0.94782054\n",
      " 0.99785113 0.9988819 ]\n",
      "The rewards are: [0.62122065 0.86377126 0.80860645 0.9985109  0.9997272  0.9977684\n",
      " 0.9979798  0.98239756 0.9264535  0.99942434 0.5396712  0.98566425\n",
      " 0.89046466 0.99370146 0.9813937  0.9999541  0.9029063  0.9407832\n",
      " 0.8592753  0.96785486 0.57011247 0.905721   0.9978648  0.98738074\n",
      " 0.9908441  0.9963039  0.96014774 0.92314404 0.9986014  0.998417\n",
      " 0.99963987 0.9999465 ]\n",
      "The rewards are: [0.99543035 0.9995517  0.7038629  0.9553127  0.977095   0.8305369\n",
      " 0.9917748  0.7571252  0.9628112  0.99793494 0.98503137 0.9993864\n",
      " 0.99532    0.98555225 0.99875796 0.7718043  0.99936336 0.98829764\n",
      " 0.9674326  0.85371894 0.87413883 0.6518308  0.9967224  0.9941664\n",
      " 0.9734837  0.9960337  0.9579164  0.99923015 0.99897635 0.98158664\n",
      " 0.8462391  0.90134645]\n",
      "The rewards are: [0.91367286 0.99966216 0.99533916 0.98721874 0.9950599  0.9964515\n",
      " 0.9733376  0.9890832  0.9990375  0.9966169  0.9996001  0.9133307\n",
      " 0.9931763  0.99952626 0.9826499  0.9999367  0.99547595 0.99841535\n",
      " 0.6708121  0.9577374  0.98939264 0.6196359  0.9951486  0.9508936\n",
      " 0.7175474  0.9976419  0.9628396  0.9363453  0.994286   0.99953544\n",
      " 0.9989349  0.99716324]\n",
      "The rewards are: [0.99989974 0.7983909  0.97549    0.99728453 0.9920358  0.78488064\n",
      " 0.94390285 0.99908733 0.99261683 0.9998778  0.5469003  0.99930286\n",
      " 0.9851724  0.99730104 0.9992225  0.9999254  0.9989643  0.97615266\n",
      " 0.7412662  0.999213   0.7812984  0.5252664  0.9848134  0.9975044\n",
      " 0.98230755 0.99908924 0.94215614 0.9982626  0.99874496 0.8155993\n",
      " 0.999686   0.99269813]\n",
      "The rewards are: [0.99981076 0.99541324 0.9933688  0.9995915  0.96294427 0.991087\n",
      " 0.99443924 0.9954501  0.99867177 0.9995585  0.99972135 0.9942812\n",
      " 0.787405   0.99989486 0.99815995 0.9962225  0.99979836 0.9804319\n",
      " 0.90715694 0.9995573  0.9461393  0.9909196  0.9993832  0.8458154\n",
      " 0.963887   0.9745901  0.9949764  0.8869846  0.7953074  0.98090714\n",
      " 0.99333704 0.9997981 ]\n",
      "The rewards are: [0.5761556  0.9200424  0.99969435 0.9718328  0.99721056 0.94273543\n",
      " 0.9951815  0.90706533 0.94457287 0.9366713  0.9998136  0.99686784\n",
      " 0.8552379  0.99640334 0.75555986 0.9983612  0.9991868  0.62513006\n",
      " 0.9955629  0.9993292  0.98578876 0.8657961  0.99450666 0.99973077\n",
      " 0.9995415  0.99741435 0.99926966 0.91700834 0.99971586 0.67582655\n",
      " 0.99897075 0.98787165]\n",
      "The rewards are: [0.9380024  0.9413582  0.97954535 0.8983395  0.9944454  0.9402252\n",
      " 0.9989598  0.662579   0.7726616  0.99846834 0.999808   0.996221\n",
      " 0.981285   0.8667776  0.99679023 0.99356055 0.9720038  0.909376\n",
      " 0.998425   0.9384255  0.869276   0.97649914 0.9833294  0.82719755\n",
      " 0.9870718  0.96199906 0.9989416  0.99872655 0.58309156 0.9978102\n",
      " 0.9091426  0.93609816]\n",
      "The rewards are: [0.9989405  0.9966647  0.99987996 0.9996339  0.94407034 0.9609675\n",
      " 0.99937254 0.6830167  0.9994442  0.9947908  0.94002783 0.75416476\n",
      " 0.99978036 0.9974878  0.8060239  0.9987759  0.9995328  0.98991793\n",
      " 0.96950513 0.9882294  0.99994135 0.994779   0.63584155 0.8553219\n",
      " 0.95386356 0.9867498  0.9863957  0.99622154 0.99963534 0.9338668\n",
      " 0.9871273  0.5723706 ]\n",
      "The rewards are: [0.9990139  0.9256305  0.9845377  0.9995914  0.9728097  0.99819463\n",
      " 0.6700802  0.9999745  0.998596   0.99173295 0.9917659  0.80576885\n",
      " 0.9999801  0.50552744 0.99544394 0.8063926  0.9967168  0.9990916\n",
      " 0.9943389  0.99988043 0.99928313 0.7587872  0.99941266 0.92274463\n",
      " 0.98687243 0.9868732  0.82956886 0.99958116 0.9998956  0.9994586\n",
      " 0.9676377  0.9993401 ]\n",
      "The rewards are: [0.9999783  0.9967399  0.9996369  0.7566562  0.9918339  0.997945\n",
      " 0.99838495 0.99140805 0.9992811  0.99619603 0.94609016 0.9928746\n",
      " 0.98936605 0.9961272  0.9850124  0.9976834  0.9990784  0.9794124\n",
      " 0.7226135  0.55146563 0.99646556 0.973435   0.9965024  0.66524386\n",
      " 0.80517715 0.99985397 0.9926093  0.9901742  0.9786324  0.99869317\n",
      " 0.99785596 0.9400493 ]\n",
      "The rewards are: [0.9798803  0.9845843  0.92940706 0.99975413 0.9700056  0.998018\n",
      " 0.9863973  0.92418236 0.89719564 0.93679214 0.97878736 0.8665005\n",
      " 0.99971014 0.999569   0.9761445  0.96587676 0.9915006  0.9582308\n",
      " 0.9321492  0.9425994  0.9299324  0.947987   0.9681662  0.9997342\n",
      " 0.9744261  0.6201259  0.98972577 0.9000123  0.9999975  0.99636924\n",
      " 0.9609706  0.984951  ]\n",
      "The rewards are: [0.5971562  0.6742815  0.95301896 0.7581866  0.9688419  0.9999546\n",
      " 0.9998903  0.9949057  0.99864024 0.9509671  0.9940983  0.98640245\n",
      " 0.99951506 0.9911669  0.9946043  0.9989225  0.995069   0.9754253\n",
      " 0.9997124  0.5819976  0.99005073 0.99795365 0.99953556 0.9908812\n",
      " 0.9908832  0.6605351  0.99971575 0.99284995 0.9998859  0.95779103\n",
      " 0.93549    0.9804026 ]\n",
      "The rewards are: [0.9531937  0.999033   0.9997429  0.9310625  0.57447886 0.94255185\n",
      " 0.6477709  0.98823637 0.5635966  0.99422246 0.9934395  0.9993235\n",
      " 0.7255093  0.93413854 0.76002425 0.96990067 0.99871385 0.97797537\n",
      " 0.9991468  0.97651666 0.88801926 0.9987457  0.84992015 0.99915516\n",
      " 0.7178744  0.9995708  0.99996614 0.73530906 0.9088422  0.9996177\n",
      " 0.9284505  0.68823314]\n",
      "The rewards are: [0.5471183  0.97709024 0.98734146 0.83964664 0.88959324 0.99763715\n",
      " 0.9981248  0.98087573 0.7220138  0.99952316 0.99992764 0.57425475\n",
      " 0.99615884 0.9053539  0.97668356 0.9986959  0.87142146 0.99188447\n",
      " 0.99957126 0.996157   0.98834723 0.6797087  0.9990694  0.9985514\n",
      " 0.9999418  0.9983107  0.9975605  0.99845636 0.9961117  0.9776725\n",
      " 0.7636697  0.9903436 ]\n",
      "The rewards are: [0.9999018  0.724622   0.99817455 0.94189644 0.9999666  0.9072464\n",
      " 0.9999639  0.95839775 0.94421595 0.9933855  0.9902228  0.79633516\n",
      " 0.99977607 0.9757676  0.9822113  0.9669566  0.9106213  0.96294945\n",
      " 0.53409123 0.99962986 0.98200446 0.99891543 0.99834085 0.6262452\n",
      " 0.99173486 0.9899142  0.697071   0.9422605  0.9474233  0.9135386\n",
      " 0.9566656  0.86639994]\n",
      "The rewards are: [0.9802643  0.9996784  0.9999286  0.52809566 0.8685935  0.9716575\n",
      " 0.99610823 0.9999502  0.9019865  0.69605786 0.9969023  0.9990791\n",
      " 0.93131703 0.99625623 0.99448556 0.99879056 0.97658545 0.8229782\n",
      " 0.99834347 0.9931217  0.91151005 0.920697   0.9807401  0.9998368\n",
      " 0.69712704 0.9950724  0.9997904  0.9980501  0.99999213 0.99158925\n",
      " 0.9961832  0.9975254 ]\n",
      "The rewards are: [0.95711297 0.9937424  0.9938838  0.9969074  0.9969023  0.72670716\n",
      " 0.98826945 0.7673585  0.9921374  0.99986994 0.9792493  0.9830716\n",
      " 0.99194616 0.76940966 0.98792213 0.99772567 0.9904473  0.9798309\n",
      " 0.99921525 0.70096785 0.9873877  0.9536166  0.99817586 0.943634\n",
      " 0.9901906  0.8986698  0.8058563  0.9731198  0.98259604 0.99969935\n",
      " 0.9999049  0.989881  ]\n",
      "The rewards are: [0.9691235  0.9979645  0.89200085 0.9861842  0.9986534  0.89807177\n",
      " 0.9330419  0.9269942  0.9971938  0.8632752  0.99938405 0.9993405\n",
      " 0.9908654  0.98494256 0.99959534 0.82275045 0.9925714  0.9962968\n",
      " 0.99974614 0.98809516 0.9937243  0.9935387  0.9295764  0.9747387\n",
      " 0.99974924 0.99772626 0.9140548  0.9144983  0.6138032  0.9966635\n",
      " 0.8213371  0.9948999 ]\n",
      "The rewards are: [0.9792534  0.99307865 0.99965584 0.99959165 0.99998057 0.9992429\n",
      " 0.77438474 0.9671638  0.9952526  0.9961617  0.9999151  0.78342927\n",
      " 0.9984106  0.93294513 0.8577383  0.9978667  0.963285   0.99644655\n",
      " 0.9307463  0.86544216 0.9832472  0.9979663  0.9299946  0.9945444\n",
      " 0.9870884  0.96817243 0.9999255  0.9865348  0.9941214  0.9422231\n",
      " 0.8642082  0.9935575 ]\n",
      "The rewards are: [0.9971486  0.9974929  0.9917788  0.9953294  0.9993087  0.78041\n",
      " 0.9727684  0.8321475  0.962033   0.98321515 0.9982017  0.8752491\n",
      " 0.99727875 0.9966037  0.9873284  0.9995297  0.837966   0.9998803\n",
      " 0.9999479  0.8770987  0.9815812  0.99977106 0.9978479  0.7338782\n",
      " 0.9439672  0.9532156  0.81706476 0.72467965 0.7753976  0.9886979\n",
      " 0.92956567 0.99296016]\n",
      "The rewards are: [0.99177647 0.997729   0.9831042  0.99035066 0.9961067  0.9752985\n",
      " 0.9923751  0.9999609  0.99118656 0.999181   0.99550503 0.6077765\n",
      " 0.79358643 0.7573865  0.99506986 0.9985324  0.8490998  0.9709216\n",
      " 0.99905413 0.99452055 0.99937266 0.9960614  0.9994116  0.9997445\n",
      " 0.99974483 0.7453047  0.9903729  0.71757436 0.99969065 0.6919532\n",
      " 0.9942697  0.6351215 ]\n",
      "The rewards are: [0.99439806 0.99861205 0.9712691  0.6045866  0.99119395 0.99467814\n",
      " 0.9443491  0.9990834  0.9877604  0.8019536  0.99981457 0.71205205\n",
      " 0.9997582  0.997235   0.88900703 0.9989003  0.9989812  0.60238796\n",
      " 0.99388087 0.99432796 0.98635095 0.9988304  0.9994628  0.97818357\n",
      " 0.53959674 0.99975485 0.7183784  0.9286764  0.88480705 0.9956974\n",
      " 0.8192906  0.9852984 ]\n",
      "The rewards are: [0.99255604 0.97397614 0.9980223  0.998615   0.9958131  0.9904316\n",
      " 0.64087296 0.9991041  0.87932134 0.983197   0.8997964  0.9918983\n",
      " 0.9806143  0.99798226 0.9972248  0.99215454 0.9219991  0.8004724\n",
      " 0.9942321  0.98741585 0.9969199  0.99983907 0.9992737  0.9985507\n",
      " 0.99692935 0.983973   0.9922621  0.99989414 0.9508261  0.97642004\n",
      " 0.99581486 0.70795065]\n",
      "The rewards are: [0.99890125 0.8891772  0.99720275 0.75291103 0.8539958  0.9987865\n",
      " 0.9993787  0.95915496 0.80139035 0.9989422  0.983125   0.9666521\n",
      " 0.69833606 0.99926275 0.9930877  0.6693391  0.92679244 0.99909997\n",
      " 0.9987588  0.75693727 0.98146826 0.8907638  0.99954695 0.98432076\n",
      " 0.9924183  0.9918759  0.771874   0.7204341  0.5248674  0.9998994\n",
      " 0.99996424 0.9938882 ]\n",
      "The rewards are: [0.9985122  0.8531414  0.99432606 0.99613535 0.9950942  0.9416672\n",
      " 0.9994491  0.7391826  0.9775187  0.9892028  0.8212358  0.96297973\n",
      " 0.9997727  0.9979303  0.9922643  0.95320565 0.69719034 0.9998578\n",
      " 0.99895406 0.91549844 0.682888   0.9350224  0.9996124  0.99503183\n",
      " 0.9963923  0.78688323 0.9758646  0.9984987  0.9868765  0.9876987\n",
      " 0.998517   0.684976  ]\n",
      "The rewards are: [0.99935275 0.99611807 0.9992887  0.9928421  0.99563867 0.99820006\n",
      " 0.99995303 0.5810236  0.9998553  0.99997306 0.5095234  0.510852\n",
      " 0.9981864  0.99950767 0.9994764  0.87249094 0.9759126  0.9978097\n",
      " 0.9547213  0.99758744 0.9999833  0.9468283  0.76384217 0.9943363\n",
      " 0.9902181  0.9989498  0.9889543  0.71620387 0.8887531  0.99323434\n",
      " 0.9990345  0.999383  ]\n",
      "The rewards are: [0.9988651  0.944147   0.9759572  0.9274248  0.9143478  0.8989396\n",
      " 0.96183354 0.9994778  0.98704034 0.9999298  0.90717185 0.9988361\n",
      " 0.69927573 0.9993969  0.9288746  0.972111   0.9990558  0.99079645\n",
      " 0.97788835 0.9992067  0.9903358  0.9994097  0.9065193  0.9923233\n",
      " 0.95001113 0.7562519  0.99170226 0.9681705  0.9036239  0.74346495\n",
      " 0.8344904  0.9958365 ]\n",
      "The rewards are: [0.99361527 0.99834967 0.999811   0.9994623  0.67051727 0.8606646\n",
      " 0.99979335 0.9610955  0.9804022  0.9987901  0.99844295 0.9905317\n",
      " 0.99960726 0.5692033  0.98732823 0.9792315  0.899299   0.9965816\n",
      " 0.8184364  0.9985043  0.79647285 0.99079776 0.53715616 0.84500533\n",
      " 0.60845476 0.85074854 0.9753914  0.73502755 0.884682   0.6153887\n",
      " 0.9730603  0.98992074]\n",
      "The rewards are: [0.9989982  0.9545052  0.98987377 0.9991542  0.69781446 0.9860648\n",
      " 0.9992914  0.99923885 0.99757427 0.55426073 0.9948931  0.8084887\n",
      " 0.99919325 0.99625057 0.98643374 0.99935716 0.93303627 0.99369264\n",
      " 0.88813394 0.589464   0.7237948  0.9489063  0.9989225  0.85924906\n",
      " 0.9821374  0.9967188  0.99721897 0.9985511  0.9958973  0.8771408\n",
      " 0.99955744 0.98751926]\n",
      "The rewards are: [0.95749336 0.99966395 0.54468143 0.99717134 0.9975224  0.99727005\n",
      " 0.63928086 0.99872357 0.83946913 0.99981505 0.96844804 0.99480635\n",
      " 0.9969289  0.92870206 0.93632066 0.92459327 0.99882287 0.99332905\n",
      " 0.99147964 0.9998066  0.8169799  0.933337   0.99325126 0.9979876\n",
      " 0.999874   0.9998424  0.99268943 0.8737469  0.9997801  0.9992416\n",
      " 0.9222449  0.9984388 ]\n",
      "The rewards are: [0.9849326  0.72804594 0.9814175  0.9695304  0.99906796 0.9400892\n",
      " 0.99988484 0.8205575  0.9974492  0.93544483 0.9993327  0.99235725\n",
      " 0.9998759  0.8771396  0.98048043 0.99931145 0.99912137 0.9998381\n",
      " 0.5019102  0.9997204  0.9863833  0.9990483  0.51429343 0.99951935\n",
      " 0.9986945  0.8645367  0.99928075 0.9873842  0.97684264 0.62915385\n",
      " 0.9986601  0.99481577]\n",
      "The rewards are: [0.9997192  0.8843032  0.99969065 0.9862096  0.996646   0.85834473\n",
      " 0.9468155  0.999985   0.9508319  0.94198406 0.6133637  0.91380405\n",
      " 0.9944575  0.6661795  0.9882532  0.99933237 0.9903706  0.6333526\n",
      " 0.9997975  0.98844343 0.9897654  0.99766856 0.9977794  0.9960705\n",
      " 0.99498194 0.99659497 0.99698883 0.96651655 0.98979646 0.99204344\n",
      " 0.9934394  0.99988973]\n",
      "The rewards are: [0.9553702  0.98647344 0.9991744  0.5542058  0.77308756 0.97964543\n",
      " 0.99735355 0.9979882  0.984059   0.99686193 0.99794894 0.9967012\n",
      " 0.99965715 0.97695655 0.957272   0.9999424  0.99962676 0.9479739\n",
      " 0.9966408  0.98190224 0.88039476 0.56966984 0.99723417 0.9985783\n",
      " 0.8870279  0.93977135 0.9910528  0.9060599  0.9988782  0.9711042\n",
      " 0.9986777  0.9518792 ]\n",
      "The rewards are: [0.70373034 0.89984816 0.8854758  0.99951947 0.9633709  0.6620426\n",
      " 0.99941957 0.97582823 0.9914677  0.99760276 0.9486346  0.9994461\n",
      " 0.9810821  0.8956417  0.90898705 0.766825   0.94413775 0.97473335\n",
      " 0.93512195 0.9734274  0.95502424 0.9999939  0.99914074 0.5231537\n",
      " 0.9996183  0.98668575 0.9959765  0.97579634 0.99949753 0.95037407\n",
      " 0.9876594  0.999918  ]\n",
      "The rewards are: [0.93833447 0.9742647  0.93184733 0.9856318  0.9993362  0.8769033\n",
      " 0.9996568  0.9599014  0.9951644  0.98890543 0.9943949  0.79550606\n",
      " 0.99687576 0.9668528  0.9908246  0.9117948  0.96213865 0.9384358\n",
      " 0.92236316 0.9442743  0.8897541  0.64233565 0.974865   0.9838186\n",
      " 0.97081155 0.9948197  0.99980503 0.998692   0.99838483 0.9993774\n",
      " 0.9997681  0.8529568 ]\n",
      "The rewards are: [0.996051   0.9898331  0.99484164 0.9991278  0.83127725 0.8675213\n",
      " 0.99989057 0.9997855  0.96007377 0.83498204 0.946556   0.94080544\n",
      " 0.98796403 0.9886395  0.536278   0.9869112  0.84157515 0.9268751\n",
      " 0.999551   0.9748216  0.9997571  0.99982125 0.9229809  0.7022061\n",
      " 0.99963593 0.9999409  0.97257835 0.93196887 0.9796547  0.9997162\n",
      " 0.99976367 0.7582881 ]\n",
      "The rewards are: [0.832184   0.9110732  0.6126868  0.9536681  0.98861396 0.9625075\n",
      " 0.9963791  0.77537006 0.5178459  0.99423766 0.9991429  0.5241815\n",
      " 0.82187366 0.99161375 0.9994116  0.99561226 0.9876968  0.999803\n",
      " 0.99089456 0.99821484 0.998524   0.99951863 0.95228976 0.9969675\n",
      " 0.9758365  0.9783039  0.96499443 0.7338596  0.9998661  0.999511\n",
      " 0.998109   0.6837761 ]\n",
      "The rewards are: [0.90179056 0.589859   0.9998447  0.98386085 0.99926704 0.9988626\n",
      " 0.5511095  0.981212   0.99948597 0.9822971  0.9851643  0.97230095\n",
      " 0.9991215  0.99987996 0.88536245 0.9918777  0.9964934  0.99979573\n",
      " 0.99927026 0.9977441  0.9998586  0.99258065 0.9932234  0.9992673\n",
      " 0.9995858  0.6014407  0.9979062  0.770721   0.52582407 0.99325526\n",
      " 0.99983454 0.8214949 ]\n",
      "The rewards are: [0.9904889  0.97857124 0.99890316 0.9998085  0.9961696  0.9677348\n",
      " 0.9661981  0.82085556 0.99896336 0.9971276  0.98049885 0.6533544\n",
      " 0.9957833  0.9999895  0.9975412  0.987407   0.98965645 0.718757\n",
      " 0.6489227  0.7578768  0.99489105 0.9999049  0.99947566 0.8239034\n",
      " 0.93920225 0.9992705  0.9993814  0.98735374 0.99944645 0.8516275\n",
      " 0.95655406 0.73776776]\n",
      "The rewards are: [0.99081147 0.95341367 0.9824918  0.99967086 0.99999166 0.98355246\n",
      " 0.9977586  0.9855075  0.9665265  0.8396893  0.76327866 0.9827648\n",
      " 0.99023235 0.5133356  0.9968458  0.9993875  0.96715385 0.7977661\n",
      " 0.6068071  0.9977139  0.9854864  0.99990845 0.7156331  0.94227076\n",
      " 0.78859645 0.97128016 0.914623   0.92280823 0.969531   0.988897\n",
      " 0.9644313  0.6246768 ]\n",
      "The rewards are: [0.9998971  0.9417221  0.99992025 0.67433304 0.97772604 0.84602886\n",
      " 0.9524091  0.9667254  0.986672   0.8109185  0.9426478  0.98382264\n",
      " 0.99882215 0.9642309  0.861064   0.99933004 0.9763763  0.96439505\n",
      " 0.98334426 0.93785423 0.9866588  0.9993356  0.99874    0.9982279\n",
      " 0.95969397 0.6865449  0.9434456  0.7624249  0.9973539  0.9974625\n",
      " 0.9301167  0.99789536]\n",
      "The rewards are: [0.9972257  0.8768383  0.97731805 0.98631036 0.9960757  0.8623399\n",
      " 0.99982196 0.56160665 0.9815077  0.99844885 0.9767204  0.74532694\n",
      " 0.96900886 0.99811304 0.999035   0.97149855 0.9805839  0.70239866\n",
      " 0.99982494 0.9994155  0.9056723  0.9953176  0.99885345 0.98033583\n",
      " 0.9977901  0.9999516  0.9706951  0.9823387  0.9959021  0.96937984\n",
      " 0.99727887 0.9960515 ]\n",
      "The rewards are: [0.991089   0.9994504  0.74619675 0.9954886  0.90596706 0.99975306\n",
      " 0.96525407 0.99730587 0.99903    0.9781285  0.99615085 0.7195647\n",
      " 0.8680109  0.99961334 0.9984035  0.82124037 0.8163623  0.9968374\n",
      " 0.5735571  0.99951243 0.9930943  0.9937236  0.9675327  0.9826859\n",
      " 0.9999     0.99661356 0.99954116 0.9711     0.9885612  0.9776929\n",
      " 0.99992216 0.94012713]\n",
      "The rewards are: [0.9998542  0.8792586  0.951378   0.9572814  0.9975164  0.9939976\n",
      " 0.99980694 0.9989742  0.82263577 0.99831367 0.99988973 0.99978155\n",
      " 0.9674104  0.9830904  0.9537253  0.8936783  0.9882839  0.9976617\n",
      " 0.9974669  0.9915183  0.998691   0.9995116  0.97989815 0.9795228\n",
      " 0.99281764 0.94965625 0.9782994  0.9999906  0.99729747 0.9751271\n",
      " 0.9995084  0.9972811 ]\n",
      "The rewards are: [0.96362156 0.9999994  0.99839574 0.9475792  0.9675078  0.9553119\n",
      " 0.997218   0.59835553 0.99373984 0.99352646 0.9397956  0.9747312\n",
      " 0.9982815  0.9989286  0.9560904  0.9963726  0.98308635 0.9987698\n",
      " 0.95572364 0.9676184  0.9870848  0.997486   0.99187225 0.9985511\n",
      " 0.99976987 0.9849215  0.9991805  0.86131907 0.99479264 0.9769999\n",
      " 0.980179   0.9987919 ]\n",
      "The rewards are: [0.97415316 0.8461981  0.99592304 0.9989126  0.997101   0.9527456\n",
      " 0.9943851  0.82964873 0.9997594  0.99956757 0.9330458  0.95938575\n",
      " 0.9985461  0.9943071  0.8454018  0.98644626 0.9965894  0.95438075\n",
      " 0.90223175 0.8677724  0.99290997 0.9591679  0.9641702  0.865621\n",
      " 0.9999757  0.9890247  0.9992593  0.9728863  0.99946076 0.9078932\n",
      " 0.999622   0.9971522 ]\n",
      "The rewards are: [0.9996517  0.9990638  0.77521765 0.99883324 0.978115   0.7665582\n",
      " 0.9808288  0.8548947  0.99785125 0.85805374 0.9999857  0.9997824\n",
      " 0.99847025 0.9965101  0.99907994 0.99977857 0.9995901  0.9995881\n",
      " 0.9671719  0.9379407  0.9990375  0.99944526 0.9971818  0.9980914\n",
      " 0.97395444 0.5652373  0.9893339  0.976891   0.90219176 0.6899905\n",
      " 0.92570317 0.99979025]\n",
      "The rewards are: [0.97673064 0.58332664 0.99932027 0.9819093  0.9603466  0.9973562\n",
      " 0.88215095 0.9999769  0.5880197  0.83443505 0.99972624 0.81009233\n",
      " 0.89344704 0.99775285 0.99961406 0.99845684 0.9969319  0.97212064\n",
      " 0.95216113 0.9966108  0.9947089  0.99895144 0.89422333 0.9999453\n",
      " 0.999373   0.6549093  0.9992355  0.5380779  0.98990446 0.9989008\n",
      " 0.96978843 0.9768064 ]\n",
      "The rewards are: [0.9680848  0.9994137  0.99842703 0.99912924 0.9424929  0.99999845\n",
      " 0.6731324  0.95312244 0.9367855  0.99949837 0.97710234 0.87257975\n",
      " 0.9568634  0.99916387 0.8646987  0.9926717  0.99978906 0.8820148\n",
      " 0.97081786 0.9990446  0.9995592  0.7657004  0.97023004 0.9955538\n",
      " 0.7129672  0.9980375  0.9997265  0.981871   0.9914863  0.9842365\n",
      " 0.999848   0.999843  ]\n",
      "The rewards are: [0.99997663 0.97837275 0.99983084 0.9923982  0.9990854  0.9878941\n",
      " 0.97315866 0.99468035 0.9727269  0.84470224 0.9999186  0.9128093\n",
      " 0.99872535 0.9874148  0.59108454 0.9128874  0.9991026  0.97705907\n",
      " 0.8092273  0.9357647  0.93657416 0.9555644  0.52398753 0.71929365\n",
      " 0.9979674  0.9993488  0.9973895  0.99986756 0.9694499  0.9846503\n",
      " 0.9956962  0.7040236 ]\n",
      "The rewards are: [0.9975478  0.99914956 0.9996898  0.9991461  0.99997747 0.9614433\n",
      " 0.9976636  0.98531795 0.9846705  0.9996117  0.9964617  0.99962187\n",
      " 0.9977214  0.8764186  0.98661906 0.57054937 0.9617837  0.99910897\n",
      " 0.9335838  0.6396926  0.7982521  0.99920255 0.77504826 0.9984668\n",
      " 0.99579775 0.9998597  0.99843556 0.8086641  0.9993789  0.95618224\n",
      " 0.998287   0.99914634]\n",
      "The rewards are: [0.99660254 0.9742941  0.9981141  0.904389   0.9984946  0.99590766\n",
      " 0.99449337 0.88630235 0.9997366  0.9979437  0.99432606 0.9996834\n",
      " 0.9028441  0.99868125 0.96827435 0.99789065 0.99895895 0.99976224\n",
      " 0.9998374  0.9931329  0.7704745  0.99954516 0.9986559  0.97584426\n",
      " 0.99663097 0.99354434 0.99963486 0.8499001  0.99660814 0.99959797\n",
      " 0.99564666 0.99566287]\n",
      "The rewards are: [0.99648166 0.9994035  0.91784775 0.9987463  0.95816463 0.9904207\n",
      " 0.9948284  0.7769721  0.99929535 0.99815637 0.853741   0.56161773\n",
      " 0.97395575 0.9982736  0.9992506  0.9892547  0.9999962  0.5213695\n",
      " 0.9996107  0.8997046  0.9647849  0.89903617 0.9996136  0.99782014\n",
      " 0.9691993  0.99757725 0.980859   0.8508581  0.9990761  0.9999453\n",
      " 0.80855083 0.9600564 ]\n",
      "The rewards are: [0.9049148  0.9962702  0.9884149  0.87077206 0.99548304 0.9943878\n",
      " 0.99845815 0.99995387 0.9677434  0.97272927 0.84793675 0.69959646\n",
      " 0.753686   0.98988616 0.8455393  0.87397474 0.99899346 0.9071626\n",
      " 0.99978465 0.7597968  0.99305165 0.92299044 0.999967   0.9658939\n",
      " 0.6822539  0.9649907  0.9875038  0.9912872  0.99969184 0.99831426\n",
      " 0.9773852  0.9800915 ]\n",
      "The rewards are: [0.9907039  0.99996436 0.80546623 0.99893373 0.96296704 0.99726665\n",
      " 0.97556233 0.99745923 0.9998628  0.9839421  0.9779729  0.79132706\n",
      " 0.9985227  0.99888843 0.9993975  0.9855084  0.508127   0.9145694\n",
      " 0.8863767  0.99735415 0.9975006  0.9631866  0.9941922  0.9530421\n",
      " 0.97642183 0.66490376 0.9998394  0.99969923 0.9847984  0.998362\n",
      " 0.8975109  0.9992495 ]\n",
      "The rewards are: [0.99963355 0.987701   0.9775459  0.8721714  0.99421895 0.5493123\n",
      " 0.9665936  0.99926585 0.97737134 0.9714594  0.9995142  0.99713635\n",
      " 0.9534202  0.9999981  0.9995247  0.9282386  0.9994143  0.85946834\n",
      " 0.92075163 0.98864424 0.99506456 0.9999304  0.99390703 0.99654394\n",
      " 0.92530745 0.9999542  0.98910224 0.9678315  0.9933147  0.9986148\n",
      " 0.995243   0.5670038 ]\n",
      "The rewards are: [0.9940446  0.9983292  0.97978014 0.6453663  0.8744314  0.92691624\n",
      " 0.98943835 0.981888   0.9992256  0.98026764 0.9954057  0.9995516\n",
      " 0.99763703 0.58054346 0.9653138  0.61255085 0.9831134  0.9990125\n",
      " 0.82146096 0.99314475 0.95668924 0.9872491  0.9955727  0.5785856\n",
      " 0.999461   0.8567697  0.9475703  0.97946703 0.99450004 0.9921678\n",
      " 0.8225053  0.842634  ]\n",
      "The rewards are: [0.99334866 0.97418946 0.98062277 0.9955676  0.99381447 0.9998832\n",
      " 0.6675438  0.99386394 0.99492306 0.9991322  0.99964976 0.996585\n",
      " 0.98211265 0.9912759  0.6210086  0.99054575 0.99992967 0.9289876\n",
      " 0.9870868  0.99988747 0.748449   0.9641237  0.9998548  0.99494123\n",
      " 0.99868053 0.9461366  0.9996426  0.95716375 0.99357456 0.99739933\n",
      " 0.9741098  0.99008244]\n",
      "The rewards are: [0.9607172  0.99699116 0.9987931  0.998481   0.9962107  0.99883443\n",
      " 0.99270517 0.99874735 0.99983764 0.99903655 0.8416874  0.9846239\n",
      " 0.7860194  0.9700467  0.99849594 0.992829   0.8828897  0.8946105\n",
      " 0.9403293  0.61099035 0.9633534  0.9976306  0.9882265  0.9985342\n",
      " 0.588126   0.999241   0.96896994 0.99512094 0.9997751  0.9837928\n",
      " 0.99942434 0.8563651 ]\n",
      "The rewards are: [0.97055435 0.98690456 0.52174073 0.9997416  0.99942064 0.96603906\n",
      " 0.8312731  0.9989374  0.9917157  0.5240169  0.99689734 0.9991148\n",
      " 0.9996495  0.9371241  0.9984238  0.63087314 0.9989606  0.990553\n",
      " 0.99977    0.9586938  0.96058047 0.5748128  0.9994842  0.9591442\n",
      " 0.99867415 0.9986804  0.9996087  0.98333204 0.990862   0.7714353\n",
      " 0.9821045  0.99983144]\n",
      "The rewards are: [0.98565185 0.9961946  0.9999666  0.999684   0.7994573  0.805328\n",
      " 0.7381147  0.9956019  0.99877375 0.9999502  0.99239665 0.98729765\n",
      " 0.97887576 0.9993369  0.9979723  0.98430634 0.8917816  0.9996724\n",
      " 0.99163693 0.99124396 0.99986875 0.99994826 0.99893636 0.9988589\n",
      " 0.73439693 0.98562664 0.98148084 0.9976279  0.99181914 0.6692269\n",
      " 0.70023286 0.9929281 ]\n",
      "The rewards are: [0.6621951  0.9991781  0.9963881  0.93714017 0.9489747  0.81858885\n",
      " 0.94504684 0.8448899  0.8202542  0.78261524 0.9992254  0.97346467\n",
      " 0.99929416 0.9625554  0.98263377 0.9278772  0.9977316  0.99717003\n",
      " 0.99696964 0.9302877  0.99560815 0.9974406  0.99203813 0.99624443\n",
      " 0.9996051  0.99917406 0.9502549  0.99337864 0.9894894  0.9367694\n",
      " 0.99968064 0.9998963 ]\n",
      "The rewards are: [0.7595117  0.9178938  0.9979405  0.6560196  0.99770653 0.8014707\n",
      " 0.99954385 0.9395273  0.99214196 0.8993646  0.9620441  0.9997296\n",
      " 0.9748418  0.9993687  0.97582924 0.9977531  0.8000864  0.5383305\n",
      " 0.99738914 0.9994342  0.9220873  0.9585056  0.96929854 0.83695203\n",
      " 0.97748166 0.9738737  0.99974614 0.70498854 0.9730539  0.9916945\n",
      " 0.9788224  0.999426  ]\n",
      "The rewards are: [0.89985883 0.99064445 0.6830398  0.7501217  0.9976133  0.74333775\n",
      " 0.92984223 0.9978229  0.9109969  0.97839624 0.9983695  0.9458332\n",
      " 0.9996942  0.5248305  0.9937523  0.999025   0.95163476 0.9986778\n",
      " 0.9999099  0.98387396 0.99910307 0.9918515  0.99643195 0.9964156\n",
      " 0.9999014  0.9948186  0.9985154  0.99793434 0.99579525 0.98208743\n",
      " 0.99580127 0.9988778 ]\n",
      "The rewards are: [0.99983275 0.99916613 0.750561   0.9797871  0.9459926  0.98946595\n",
      " 0.9885923  0.99183863 0.998415   0.98062193 0.9675281  0.9899575\n",
      " 0.9997961  0.9994369  0.99247783 0.7568105  0.8904209  0.98028344\n",
      " 0.9986255  0.9477993  0.89732254 0.947016   0.999851   0.9900203\n",
      " 0.9985525  0.8848097  0.9877223  0.9971796  0.99966514 0.9853727\n",
      " 0.99704355 0.99486166]\n",
      "The rewards are: [0.99323684 0.9924454  0.99835783 0.7521518  0.98664665 0.9937464\n",
      " 0.9988638  0.7673088  0.99913776 0.87771505 0.99994564 0.9957189\n",
      " 0.96364725 0.91930676 0.9976156  0.8059971  0.9914761  0.92408144\n",
      " 0.9939374  0.9823583  0.9721562  0.9996886  0.9881665  0.7845674\n",
      " 0.9997993  0.9820219  0.9922112  0.9997991  0.9971758  0.77677685\n",
      " 0.7088574  0.9993674 ]\n",
      "The rewards are: [0.99960047 0.9989957  0.97120667 0.9994024  0.99651504 0.9347984\n",
      " 0.8886638  0.99969757 0.97529954 0.999918   0.98833954 0.6797025\n",
      " 0.986784   0.958305   0.99816114 0.99822384 0.89643216 0.85498315\n",
      " 0.97777826 0.6285631  0.99983966 0.9885643  0.98678803 0.9950826\n",
      " 0.98792136 0.9751584  0.9995621  0.9936652  0.9997899  0.9999504\n",
      " 0.8764633  0.8564699 ]\n",
      "The rewards are: [0.9898768  0.74881303 0.99928975 0.9079335  0.99961805 0.9965527\n",
      " 0.9359915  0.9741323  0.9990326  0.844653   0.9853801  0.7441219\n",
      " 0.93130505 0.9815538  0.89231116 0.9958217  0.87389827 0.998706\n",
      " 0.9773221  0.8936689  0.97178066 0.99883014 0.67729944 0.9991273\n",
      " 0.99650973 0.92497504 0.87094384 0.9422389  0.9897954  0.7891622\n",
      " 0.8075641  0.8692612 ]\n",
      "The rewards are: [0.9998883  0.9973031  0.9620028  0.98667693 0.9896864  0.9983164\n",
      " 0.8772239  0.9995536  0.9966995  0.99759656 0.77367127 0.9993144\n",
      " 0.99514693 0.9870122  0.9992312  0.9791397  0.5816927  0.99913627\n",
      " 0.97318125 0.99815077 0.9998609  0.8750266  0.9943863  0.98957366\n",
      " 0.9897251  0.9368862  0.9919653  0.9868628  0.9330633  0.7090607\n",
      " 0.99972445 0.99839264]\n",
      "The rewards are: [0.9862277  0.99890304 0.65881735 0.990307   0.9969035  0.9996877\n",
      " 0.97222376 0.9984921  0.9997316  0.9989219  0.7831772  0.9994943\n",
      " 0.998422   0.99017847 0.9834894  0.9791322  0.9573395  0.99932134\n",
      " 0.9994455  0.99883    0.9992285  0.97925264 0.62067574 0.9991636\n",
      " 0.9962896  0.9996119  0.9998778  0.9997838  0.8654111  0.9981414\n",
      " 0.9956285  0.5049836 ]\n",
      "The rewards are: [0.99993825 0.99816775 0.9975606  0.9560775  0.9118613  0.98761535\n",
      " 0.8285866  0.80228436 0.93139166 0.96357065 0.9975152  0.999663\n",
      " 0.99602544 0.983497   0.99499714 0.99988806 0.9990753  0.9579943\n",
      " 0.83105594 0.99595046 0.5064297  0.99050003 0.99967015 0.72384113\n",
      " 0.9999614  0.913389   0.9868775  0.9997458  0.9990295  0.97765964\n",
      " 0.74031234 0.99957174]\n",
      "The rewards are: [0.98211825 0.9992969  0.997717   0.9932619  0.96225905 0.9992919\n",
      " 0.9995029  0.9402123  0.64541364 0.98308647 0.95208687 0.9997625\n",
      " 0.80163336 0.99988735 0.99985874 0.99791175 0.8806024  0.99971455\n",
      " 0.9999702  0.98141336 0.9999857  0.9999492  0.97021836 0.6073717\n",
      " 0.99906164 0.81396663 0.99969864 0.9576967  0.99884677 0.99993384\n",
      " 0.5679827  0.9999275 ]\n",
      "The rewards are: [0.9996263  0.9996574  0.99802315 0.9138626  0.5451497  0.9668053\n",
      " 0.9999076  0.9991998  0.9679997  0.9960847  0.9815097  0.99606556\n",
      " 0.98756975 0.9517018  0.7992448  0.9538747  0.99864167 0.9983783\n",
      " 0.97885257 0.9962924  0.9697929  0.9714149  0.9971307  0.9941977\n",
      " 0.9885055  0.9997229  0.69903225 0.99977773 0.9196121  0.7675538\n",
      " 0.99993086 0.9778284 ]\n",
      "The rewards are: [0.99801254 0.9450134  0.9918784  0.99374086 0.66038805 0.51720023\n",
      " 0.99907935 0.9520192  0.99438983 0.8904555  0.99918467 0.9977829\n",
      " 0.7980348  0.9993199  0.9999752  0.99995506 0.96383035 0.9877417\n",
      " 0.9962767  0.9970118  0.9606982  0.96292216 0.8033586  0.9996294\n",
      " 0.98163545 0.9644947  0.9961379  0.78590983 0.98906577 0.998086\n",
      " 0.9911299  0.98715544]\n",
      "The rewards are: [0.658762   0.9726845  0.5600654  0.9994128  0.9488163  0.99965346\n",
      " 0.99500424 0.99953437 0.99611557 0.9983736  0.9839612  0.9999335\n",
      " 0.99890983 0.99991417 0.9999881  0.8821683  0.99455726 0.9978371\n",
      " 0.775572   0.99949574 0.57989657 0.9955403  0.984746   0.99981624\n",
      " 0.99964106 0.9994609  0.99995255 0.9905297  0.9871028  0.8931717\n",
      " 0.7015323  0.9950707 ]\n",
      "The rewards are: [0.9123389  0.9636993  0.9997845  0.98910964 0.9985997  0.99199307\n",
      " 0.99042165 0.9943891  0.9887884  0.99605125 0.84917086 0.9974477\n",
      " 0.9464099  0.9488809  0.99390054 0.99819225 0.9951698  0.99212426\n",
      " 0.99879384 0.93267775 0.9996649  0.9999409  0.98653907 0.98712236\n",
      " 0.99842286 0.99612    0.99964607 0.50306827 0.9994485  0.99556726\n",
      " 0.9996685  0.99998736]\n",
      "The rewards are: [0.99538237 0.9969073  0.9848008  0.9481203  0.9989195  0.99390006\n",
      " 0.9975151  0.8831018  0.9975247  0.891947   0.99911624 0.993652\n",
      " 0.9986786  0.9784248  0.9995758  0.90733886 0.99126536 0.954497\n",
      " 0.9888603  0.9390825  0.9996166  0.99572206 0.99967813 0.9747898\n",
      " 0.9991714  0.995395   0.991058   0.99974746 0.99112904 0.997771\n",
      " 0.99327844 0.9381678 ]\n",
      "The rewards are: [0.99902034 0.9998374  0.99961627 0.9849627  0.9997756  0.9994137\n",
      " 0.7602903  0.9683967  0.72445506 0.7079653  0.9979736  0.9602233\n",
      " 0.998803   0.99956626 0.9991142  0.9975673  0.8381082  0.9991084\n",
      " 0.8896093  0.9809765  0.99936026 0.99491185 0.99199307 0.99284315\n",
      " 0.99911743 0.99993324 0.99784744 0.99052763 0.99963355 0.99442804\n",
      " 0.9853526  0.7154567 ]\n",
      "The rewards are: [0.9973641  0.9997811  0.98864925 0.99768615 0.9129215  0.99607277\n",
      " 0.9457801  0.9999789  0.9944463  0.74607086 0.89723873 0.91932195\n",
      " 0.99841714 0.8613718  0.9871021  0.7987403  0.9817654  0.74805874\n",
      " 0.89100474 0.9991042  0.91958624 0.9997421  0.91500324 0.9964659\n",
      " 0.5408311  0.999728   0.6166148  0.99865806 0.9998047  0.9977888\n",
      " 0.981991   0.9928712 ]\n",
      "The rewards are: [0.99555415 0.9998692  0.9826048  0.9999237  0.998868   0.9386693\n",
      " 0.9958729  0.8666     0.9926805  0.9982368  0.99365616 0.8979615\n",
      " 0.99874073 0.8502773  0.9947535  0.99984264 0.99826425 0.9357294\n",
      " 0.98253745 0.99552804 0.62514496 0.9685357  0.760469   0.9322482\n",
      " 0.9997806  0.9990934  0.996342   0.9995653  0.99849784 0.698527\n",
      " 0.99965715 0.9981085 ]\n",
      "The rewards are: [0.99888223 0.95790076 0.999426   0.83589655 0.9997867  0.99725026\n",
      " 0.860596   0.99767214 0.94173396 0.97527474 0.939904   0.9956222\n",
      " 0.9857816  0.97895813 0.94873685 0.9964043  0.99509996 0.8391782\n",
      " 0.97857225 0.975938   0.996342   0.6387905  0.9982957  0.998083\n",
      " 0.9978871  0.53170353 0.97611564 0.98980075 0.97919124 0.77992755\n",
      " 0.5515694  0.99997425]\n",
      "The rewards are: [0.9923315  0.9968861  0.9981931  0.804715   0.81337327 0.77407014\n",
      " 0.9963652  0.9770439  0.54003304 0.9997837  0.98445463 0.9694622\n",
      " 0.9721062  0.9958806  0.9354268  0.9979354  0.9981963  0.80296975\n",
      " 0.99979895 0.9749135  0.9830686  0.9940759  0.9999738  0.9956939\n",
      " 0.73006314 0.9998665  0.89806116 0.99892825 0.64504474 0.9998024\n",
      " 0.9590477  0.9814705 ]\n",
      "The rewards are: [0.99227625 0.96655154 0.9372622  0.58001155 0.99757606 0.7602543\n",
      " 0.9998204  0.97575605 0.99039674 0.9709319  0.8107943  0.7767001\n",
      " 0.98617595 0.92581725 0.9994128  0.9961002  0.99507195 0.84182614\n",
      " 0.947933   0.9532954  0.9999554  0.999754   0.8967339  0.9607347\n",
      " 0.739276   0.96163905 0.9999392  0.95727724 0.9989831  0.98448825\n",
      " 0.92086583 0.92555976]\n",
      "The rewards are: [0.95813227 0.84440446 0.98722583 0.9968526  0.99925214 0.6663306\n",
      " 0.99226165 0.99936944 0.959849   0.87665075 0.9993772  0.99758637\n",
      " 0.94985735 0.95189714 0.9967334  0.9219143  0.99597496 0.9998901\n",
      " 0.99859005 0.9943796  0.9951422  0.99063104 0.99450994 0.99965227\n",
      " 0.98352814 0.99836427 0.9784096  0.9801375  0.9881981  0.98199\n",
      " 0.70043445 0.9992347 ]\n",
      "The rewards are: [0.9987458  0.99490744 0.9997427  0.926567   0.7004533  0.99967146\n",
      " 0.76665986 0.96273106 0.7343819  0.99867225 0.9990243  0.9996222\n",
      " 0.93534654 0.9529028  0.7973811  0.8205552  0.99949765 0.99933064\n",
      " 0.9989912  0.92832875 0.9093822  0.8832173  0.99885    0.98443824\n",
      " 0.9995906  0.9570215  0.98932785 0.9839992  0.9994024  0.98149306\n",
      " 0.997626   0.9618631 ]\n",
      "The rewards are: [0.99982077 0.99919313 0.99964774 0.99348325 0.63683844 0.99967897\n",
      " 0.9951709  0.99923766 0.8906215  0.9999076  0.7241706  0.92531633\n",
      " 0.8890126  0.9988248  0.9999901  0.9889731  0.9897684  0.99980265\n",
      " 0.99279565 0.9994086  0.9561663  0.987733   0.9858779  0.9915183\n",
      " 0.9965036  0.98817796 0.99256283 0.99999356 0.9836532  0.6861354\n",
      " 0.99239504 0.91560316]\n",
      "The rewards are: [0.9997651  0.9992956  0.8878724  0.99936336 0.7778732  0.99978584\n",
      " 0.99369884 0.98843175 0.9990921  0.9992981  0.65894204 0.7551841\n",
      " 0.99877316 0.78797966 0.9999578  0.9986908  0.99312687 0.98657995\n",
      " 0.99961483 0.841814   0.85074466 0.99958295 0.9973152  0.9848504\n",
      " 0.9742086  0.5744865  0.8138257  0.98556596 0.70891273 0.96034116\n",
      " 0.99791163 0.62057644]\n",
      "The rewards are: [0.6637206  0.85698646 0.85088533 0.9896841  0.9951382  0.6031331\n",
      " 0.9796967  0.9986971  0.9991285  0.9441489  0.99651235 0.95118123\n",
      " 0.95498985 0.7275074  0.9997198  0.5494279  0.9996232  0.99974805\n",
      " 0.99132746 0.9998944  0.7261945  0.99455476 0.9969932  0.9918995\n",
      " 0.9168314  0.9998623  0.99975747 0.98101497 0.99974114 0.99991524\n",
      " 0.9980421  0.9995745 ]\n",
      "The rewards are: [0.9912378  0.99802387 0.99834883 0.97734606 0.8899647  0.97711015\n",
      " 0.9995881  0.999233   0.9997646  0.97521895 0.9980009  0.8945499\n",
      " 0.9993113  0.9975763  0.9133707  0.9980326  0.9999198  0.9946361\n",
      " 0.953932   0.99478215 0.990299   0.862176   0.96522754 0.99986494\n",
      " 0.9999572  0.98250383 0.9150195  0.64398324 0.9488024  0.9969914\n",
      " 0.89176667 0.50977814]\n",
      "The rewards are: [0.7815424  0.99085957 0.999767   0.9997856  0.71587354 0.9979861\n",
      " 0.6450949  0.9987866  0.9967129  0.9989048  0.9897774  0.9983896\n",
      " 0.9652632  0.85909706 0.9962794  0.998895   0.91190356 0.99658406\n",
      " 0.999091   0.96310425 0.99886453 0.91231287 0.9965939  0.8233113\n",
      " 0.9993567  0.9996165  0.9966396  0.9946708  0.84557885 0.91792345\n",
      " 0.81417775 0.99778384]\n",
      "The rewards are: [0.98464847 0.8813535  0.9979532  0.9327515  0.9999312  0.8816748\n",
      " 0.99977714 0.57409805 0.9990269  0.8302734  0.97693324 0.98672986\n",
      " 0.8066045  0.88926995 0.9955272  0.8552334  0.9130725  0.9754268\n",
      " 0.9989888  0.8232048  0.99423605 0.9914888  0.9951579  0.82529134\n",
      " 0.9882317  0.9107661  0.99210393 0.8926478  0.89370924 0.9955304\n",
      " 0.994021   0.9897967 ]\n",
      "The rewards are: [0.9804304  0.54305416 0.6492798  0.94168603 0.91005236 0.99844724\n",
      " 0.639626   0.99651897 0.9959793  0.9955746  0.9989568  0.9997929\n",
      " 0.9960855  0.99448156 0.99333304 0.9978003  0.7163849  0.999508\n",
      " 0.9844481  0.9973126  0.98349494 0.99990463 0.9460989  0.9969606\n",
      " 0.9798148  0.9996574  0.99956197 0.8048945  0.6303232  0.9994548\n",
      " 0.99722594 0.99372125]\n",
      "The rewards are: [0.676175   0.9911006  0.9999708  0.9953447  0.9967631  0.9777027\n",
      " 0.9907312  0.96058136 0.96486735 0.9990276  0.9707602  0.9974343\n",
      " 0.99928916 0.928018   0.875033   0.99852717 0.66063577 0.92674047\n",
      " 0.9855209  0.9907707  0.99959344 0.9314538  0.99605066 0.94728327\n",
      " 0.9993007  0.9988464  0.9930854  0.9931866  0.9995376  0.98986125\n",
      " 0.9926166  0.933234  ]\n",
      "The rewards are: [0.9755609  0.97500515 0.99974984 0.9994838  0.98172945 0.99644214\n",
      " 0.8235045  0.9982705  0.9940555  0.9895034  0.9738376  0.9999442\n",
      " 0.99929214 0.9721057  0.56120735 0.99931073 0.95802665 0.75345474\n",
      " 0.9939354  0.88939524 0.8995724  0.99935156 0.9986083  0.93306565\n",
      " 0.9999331  0.98847467 0.9434546  0.9594818  0.9991366  0.9991571\n",
      " 0.9986732  0.9741658 ]\n",
      "The rewards are: [0.94152784 0.99668163 0.9986166  0.6818352  0.98662484 0.9901931\n",
      " 0.9991141  0.9790511  0.9920374  0.60204333 0.57121575 0.99971\n",
      " 0.98551524 0.9917     0.99844307 0.949135   0.9995511  0.9985775\n",
      " 0.9853898  0.6030953  0.9993131  0.9835382  0.998845   0.98704916\n",
      " 0.99953485 0.9930059  0.9904745  0.56085795 0.99230146 0.9944469\n",
      " 0.9595519  0.9928167 ]\n",
      "The rewards are: [0.9978613  0.79520833 0.99891937 0.9943241  0.99932396 0.990437\n",
      " 0.91733134 0.99969685 0.9756437  0.9823956  0.91538817 0.99635243\n",
      " 0.9265807  0.99143374 0.8987766  0.99242085 0.7295994  0.99841654\n",
      " 0.99974984 0.9999976  0.8340322  0.99790597 0.7744659  0.9929167\n",
      " 0.98162156 0.9997303  0.9925196  0.9989176  0.9059873  0.96837527\n",
      " 0.6680257  0.90549666]\n",
      "The rewards are: [0.9996301  0.999097   0.9993766  0.98751265 0.99712986 0.9213995\n",
      " 0.9973073  0.6856388  0.9953702  0.95107436 0.9965867  0.930061\n",
      " 0.9701127  0.9906166  0.9720487  0.84628356 0.91463304 0.9675143\n",
      " 0.9852459  0.9807772  0.921534   0.9413818  0.9405108  0.99469095\n",
      " 0.98740524 0.85554373 0.99973017 0.9904772  0.95478314 0.8000041\n",
      " 0.99684745 0.99000275]\n",
      "The rewards are: [0.99802196 0.9914323  0.99968064 0.9360076  0.99995613 0.9995716\n",
      " 0.903597   0.96863973 0.9938328  0.9995233  0.9997813  0.99768233\n",
      " 0.9989512  0.9834593  0.98876125 0.99940646 0.99521196 0.9983165\n",
      " 0.94550943 0.63922983 0.8735449  0.9924885  0.9983998  0.99970347\n",
      " 0.98120224 0.9996847  0.9879545  0.9986572  0.8934787  0.99997044\n",
      " 0.9960134  0.5175881 ]\n",
      "The rewards are: [0.99994564 0.8158359  0.9945661  0.98771983 0.99970716 0.9883564\n",
      " 0.8140726  0.9470214  0.7182646  0.99946254 0.7775566  0.99625105\n",
      " 0.99969685 0.8848018  0.99975425 0.99799526 0.9998684  0.94514436\n",
      " 0.9994288  0.99960107 0.8957328  0.95225525 0.87027115 0.9997404\n",
      " 0.99937147 0.9997656  0.8805674  0.9984615  0.9522037  0.99978787\n",
      " 0.9031716  0.9996178 ]\n",
      "The rewards are: [0.5761712  0.95049125 0.62306774 0.9916009  0.9939746  0.9994617\n",
      " 0.9788084  0.99923813 0.9955279  0.9115603  0.96831614 0.9952187\n",
      " 0.99874663 0.9709263  0.88278526 0.99852705 0.9961933  0.75262165\n",
      " 0.97096103 0.9994081  0.5445775  0.8408601  0.9999896  0.95377\n",
      " 0.9823185  0.9994248  0.9839229  0.9852953  0.70151764 0.9966366\n",
      " 0.9914655  0.72973347]\n",
      "The rewards are: [0.9572578  0.86665833 0.9989611  0.98396575 0.96188605 0.9994624\n",
      " 0.9865159  0.9993315  0.98869145 0.9681625  0.79255813 0.99669445\n",
      " 0.9617756  0.9427542  0.99998736 0.9736744  0.87104756 0.9906846\n",
      " 0.98881733 0.93746394 0.97016114 0.86362755 0.6251034  0.9991844\n",
      " 0.999681   0.9414863  0.99986136 0.99852175 0.99742657 0.6438298\n",
      " 0.9999374  0.96858406]\n",
      "The rewards are: [0.91516    0.9911289  0.6143615  0.585188   0.994898   0.92897373\n",
      " 0.94609094 0.9976585  0.6468999  0.7596805  0.99633574 0.71332294\n",
      " 0.997218   0.88667214 0.8618303  0.9982931  0.99357295 0.98911613\n",
      " 0.98701805 0.6146521  0.94127965 0.99873    0.858098   0.9881102\n",
      " 0.6383777  0.9980416  0.9975979  0.9983822  0.9894371  0.9996319\n",
      " 0.54128915 0.9562205 ]\n",
      "The rewards are: [0.93276197 0.9835285  0.96251017 0.75151896 0.99904853 0.98999804\n",
      " 0.9920439  0.929028   0.9950547  0.9983431  0.9621972  0.9883709\n",
      " 0.9917327  0.89659095 0.9999782  0.99701476 0.8285103  0.8709386\n",
      " 0.9455313  0.7264372  0.80057806 0.9589921  0.9993261  0.9934629\n",
      " 0.6865665  0.99945384 0.9970036  0.8540007  0.9998988  0.9990023\n",
      " 0.51881534 0.89109206]\n",
      "The rewards are: [0.940709   0.9993231  0.9999068  0.9991351  0.7915055  0.88400537\n",
      " 0.99804425 0.99994373 0.9842532  0.9903619  0.5414447  0.99846303\n",
      " 0.998941   0.7257067  0.82666314 0.9997515  0.5219601  0.9918514\n",
      " 0.99047625 0.99981266 0.9985638  0.9995571  0.9220723  0.9640069\n",
      " 0.63959014 0.999113   0.9997303  0.99902964 0.60547894 0.99038434\n",
      " 0.754031   0.6397912 ]\n",
      "The rewards are: [0.9903666  0.9969277  0.6095875  0.98657006 0.9605467  0.9942676\n",
      " 0.9864668  0.9954542  0.95292723 0.99976605 0.99461997 0.9993299\n",
      " 0.93417716 0.9642371  0.99930096 0.95606446 0.99957925 0.99108595\n",
      " 0.9359858  0.99997044 0.99545276 0.99995255 0.9851028  0.9995586\n",
      " 0.73379254 0.6555154  0.9923724  0.96899444 0.9666503  0.988901\n",
      " 0.885075   0.9833921 ]\n",
      "The rewards are: [0.80285686 0.99612135 0.9433503  0.9296716  0.9996076  0.98669434\n",
      " 0.9935515  0.7063367  0.9619867  0.9647352  0.53482544 0.6345489\n",
      " 0.9969042  0.99970835 0.50214726 0.99855715 0.9973399  0.9792641\n",
      " 0.9983069  0.9930033  0.87000334 0.5235859  0.99971133 0.99606496\n",
      " 0.9124463  0.9984188  0.99933535 0.8208074  0.90703654 0.99218047\n",
      " 0.88072336 0.9909697 ]\n",
      "The rewards are: [0.76906365 0.9971144  0.99933857 0.9807335  0.9993892  0.99663216\n",
      " 0.99922407 0.68401426 0.9995894  0.92652047 0.9961553  0.99958736\n",
      " 0.8409406  0.92378175 0.9990932  0.974495   0.9950399  0.9993019\n",
      " 0.99871564 0.99963737 0.9952696  0.9844994  0.8188078  0.84320897\n",
      " 0.96690506 0.6545309  0.99320906 0.9995671  0.9172135  0.95461994\n",
      " 0.94027406 0.94019186]\n",
      "The rewards are: [0.99672544 0.9239083  0.92381644 0.8666579  0.9417151  0.7708295\n",
      " 0.9972625  0.99976283 0.99889934 0.99522483 0.97921467 0.9923035\n",
      " 0.97805685 0.9999634  0.9999362  0.90468943 0.98155814 0.98655754\n",
      " 0.9882626  0.81777376 0.99896824 0.99283123 0.77118886 0.9997681\n",
      " 0.99857414 0.99060297 0.9977088  0.99918944 0.97997725 0.9811298\n",
      " 0.99978215 0.99948066]\n",
      "The rewards are: [0.98060304 0.9971118  0.99442637 0.9999212  0.7266069  0.99670416\n",
      " 0.9352772  0.99945587 0.9410893  0.99999726 0.9999819  0.9854483\n",
      " 0.99664426 0.9569523  0.9989366  0.7708836  0.995106   0.9153555\n",
      " 0.9962627  0.82956403 0.9962495  0.8748439  0.98684305 0.9866172\n",
      " 0.9757673  0.9998381  0.9416867  0.9977215  0.65409994 0.96144384\n",
      " 0.96663684 0.64553607]\n",
      "The rewards are: [0.8930251  0.99907565 0.71663076 0.55242574 0.9152154  0.99956876\n",
      " 0.9898258  0.9999336  0.99986446 0.63315433 0.9994636  0.9985911\n",
      " 0.99929726 0.84031826 0.9371713  0.9834593  0.9984629  0.86658245\n",
      " 0.974647   0.65980256 0.9975683  0.97672606 0.9981875  0.9681778\n",
      " 0.9969199  0.9986303  0.6723091  0.9995646  0.9994753  0.7790474\n",
      " 0.63902485 0.99884844]\n",
      "The rewards are: [0.9831821  0.9892727  0.98078823 0.8759436  0.9991891  0.90654296\n",
      " 0.9997619  0.9658223  0.92577577 0.9106993  0.9951605  0.91730976\n",
      " 0.9990408  0.99681586 0.9981651  0.99265045 0.6273606  0.9762975\n",
      " 0.9994506  0.8204179  0.99896    0.88726044 0.99986994 0.65411633\n",
      " 0.9996762  0.71304834 0.9950718  0.930903   0.99983716 0.9883951\n",
      " 0.9988438  0.574848  ]\n",
      "The rewards are: [0.8225638  0.9242524  0.99947315 0.99875057 0.99234736 0.9883889\n",
      " 0.99973005 0.953523   0.99571747 0.9997253  0.5771695  0.5839307\n",
      " 0.7608655  0.9258208  0.97605306 0.8328979  0.99650913 0.970155\n",
      " 0.9992403  0.9899156  0.99198323 0.99892575 0.99900925 0.7782877\n",
      " 0.9536844  0.99222356 0.76617634 0.9996325  0.99106807 0.9995771\n",
      " 0.9983531  0.9989887 ]\n",
      "The rewards are: [0.9921411  0.9498254  0.81663126 0.75735664 0.999757   0.9998455\n",
      " 0.689296   0.9974197  0.88042384 0.614458   0.989446   0.9997749\n",
      " 0.9572223  0.9840875  0.93272823 0.99998164 0.9987791  0.89522403\n",
      " 0.5984203  0.9911775  0.9896305  0.9759891  0.96915734 0.9996227\n",
      " 0.9980361  0.9972947  0.9998872  0.9969964  0.6501054  0.9990495\n",
      " 0.8949858  0.9012508 ]\n",
      "The rewards are: [0.9818782  0.99386966 0.9995295  0.7910086  0.9934801  0.9996723\n",
      " 0.9047726  0.9982267  0.99989724 0.8594886  0.9997311  0.9529406\n",
      " 0.9497203  0.9984712  0.99989986 0.85905176 0.99972385 0.8797186\n",
      " 0.92105716 0.926518   0.96399474 0.9809163  0.9522208  0.98517376\n",
      " 0.99784243 0.95595324 0.75033224 0.9878556  0.8954026  0.85423005\n",
      " 0.9471033  0.8378106 ]\n",
      "The rewards are: [0.96038985 0.7874195  0.9715186  0.5260033  0.50843483 0.9764889\n",
      " 0.9832624  0.50354534 0.8863079  0.89844024 0.99977595 0.9984249\n",
      " 0.99996984 0.58116376 0.99984694 0.9893867  0.99148554 0.7988649\n",
      " 0.93758714 0.98927796 0.9880442  0.99794644 0.99968517 0.9998857\n",
      " 0.99620855 0.5251507  0.9993286  0.80170536 0.99936897 0.99898046\n",
      " 0.5205125  0.99988925]\n",
      "The rewards are: [0.9088542  0.94444203 0.9994991  0.9647007  0.99985504 0.99936074\n",
      " 0.9510889  0.9965533  0.9966043  0.9998987  0.96683675 0.7109326\n",
      " 0.99831474 0.9987627  0.51686925 0.9999287  0.94668543 0.9940533\n",
      " 0.5795981  0.5365433  0.9772568  0.9592811  0.99223375 0.9586815\n",
      " 0.95505226 0.5391381  0.99300694 0.9999616  0.946352   0.8471262\n",
      " 0.93757623 0.9992938 ]\n",
      "The rewards are: [0.9897591  0.9994035  0.97133386 0.99845684 0.99982893 0.99207157\n",
      " 0.9625665  0.9966793  0.99858654 0.935092   0.9804627  0.9969171\n",
      " 0.9825842  0.62817466 0.9993894  0.8735704  0.976989   0.56204104\n",
      " 0.99992096 0.9767469  0.940151   0.99499243 0.9884101  0.99998355\n",
      " 0.9841538  0.99971336 0.996011   0.98945963 0.999877   0.993722\n",
      " 0.9867033  0.98672175]\n",
      "The rewards are: [0.99883455 0.84799534 0.999899   0.6634597  0.9999882  0.9994419\n",
      " 0.72772276 0.75820535 0.8178769  0.9788286  0.9937815  0.80248797\n",
      " 0.9850898  0.91935444 0.99151784 0.9983146  0.83052194 0.93755347\n",
      " 0.84255236 0.7169318  0.9897569  0.97223747 0.99286795 0.9724334\n",
      " 0.99750805 0.5319237  0.9767312  0.93375    0.9204044  0.999818\n",
      " 0.999845   0.9517801 ]\n",
      "The rewards are: [0.7040056  0.9998983  0.96339613 0.9998216  0.99955195 0.9952414\n",
      " 0.7977394  0.998882   0.94364077 0.98463446 0.7076406  0.93911654\n",
      " 0.6972166  0.99964786 0.99989724 0.98996526 0.99077386 0.9985109\n",
      " 0.9922098  0.9986613  0.8317049  0.62070775 0.97396064 0.9454304\n",
      " 0.9943961  0.9997577  0.9963264  0.9697907  0.99033654 0.9963972\n",
      " 0.99925345 0.9992562 ]\n",
      "The rewards are: [0.9603672  0.98797834 0.9984428  0.98787457 0.99117786 0.9651218\n",
      " 0.9958062  0.99643815 0.9782364  0.98582053 0.751159   0.9879804\n",
      " 0.97922266 0.82782197 0.96989757 0.9865362  0.9919962  0.99205846\n",
      " 0.9995739  0.95528287 0.99998486 0.994331   0.7673107  0.5320733\n",
      " 0.97932976 0.9995863  0.9749878  0.9840295  0.56871045 0.99837214\n",
      " 0.9756433  0.7740902 ]\n",
      "The rewards are: [0.99069816 0.997165   0.99865353 0.99497956 0.99024534 0.81831694\n",
      " 0.99913764 0.9969651  0.9999082  0.78393996 0.9977412  0.99914134\n",
      " 0.99937063 0.99938786 0.9995852  0.9986155  0.98140645 0.98950726\n",
      " 0.9848852  0.8886814  0.976757   0.8376901  0.9989876  0.9792341\n",
      " 0.99654883 0.6814423  0.93607324 0.9802421  0.97840506 0.9853925\n",
      " 0.9997981  0.9939347 ]\n",
      "The rewards are: [0.99927765 0.9624198  0.90499485 0.9992773  0.99790883 0.99988997\n",
      " 0.78881156 0.9923666  0.95475304 0.9992213  0.99838924 0.99937195\n",
      " 0.91077423 0.8291001  0.69213146 0.90611327 0.9917971  0.9274912\n",
      " 0.6413606  0.99952364 0.99990153 0.74469435 0.99845576 0.99913317\n",
      " 0.9876566  0.9817075  0.999845   0.9950117  0.99763036 0.96979797\n",
      " 0.8651161  0.9504486 ]\n",
      "The rewards are: [0.9704725  0.9653598  0.99815935 0.96681297 0.9528135  0.9698579\n",
      " 0.8448149  0.9996301  0.99988306 0.99959475 0.9995933  0.87525487\n",
      " 0.9655444  0.99567395 0.98450214 0.9997466  0.9964623  0.9939857\n",
      " 0.99205714 0.9940777  0.9998566  0.9998851  0.98491526 0.99527115\n",
      " 0.99991107 0.99965763 0.8177026  0.999684   0.98040956 0.91929597\n",
      " 0.72748554 0.9420858 ]\n",
      "The rewards are: [0.96746236 0.9877408  0.83183587 0.9993136  0.9983601  0.9937976\n",
      " 0.93636745 0.9066469  0.99826956 0.7381364  0.9433395  0.9893735\n",
      " 0.999622   0.97195363 0.9999063  0.56361294 0.99847    0.972223\n",
      " 0.98601425 0.8863223  0.9659335  0.97787637 0.9831867  0.96213865\n",
      " 0.9936133  0.9978241  0.8562786  0.91829115 0.98063457 0.53941613\n",
      " 0.9682928  0.9821883 ]\n",
      "The rewards are: [0.99947935 0.93980867 0.5698725  0.5162542  0.9982862  0.9957075\n",
      " 0.75310016 0.99002725 0.99550915 0.98926204 0.9894433  0.9993862\n",
      " 0.99983716 0.9960724  0.99992394 0.99874425 0.99944    0.82995766\n",
      " 0.99902034 0.99864846 0.9915387  0.99907124 0.99104476 0.99846673\n",
      " 0.9524638  0.7191326  0.9168986  0.9996338  0.64943904 0.9579355\n",
      " 0.9995608  0.71650875]\n",
      "The rewards are: [0.83029234 0.9994344  0.9988483  0.9857578  0.99157214 0.97546345\n",
      " 0.7128946  0.9999633  0.7914541  0.9756731  0.9936846  0.9624045\n",
      " 0.94339275 0.98318154 0.9995121  0.99833715 0.9874824  0.99274105\n",
      " 0.98842174 0.8734432  0.91842896 0.9997156  0.9816595  0.9995173\n",
      " 0.99900025 0.99853826 0.50749296 0.956731   0.9961926  0.9700726\n",
      " 0.9917005  0.99763584]\n",
      "The rewards are: [0.99780494 0.99636984 0.98907846 0.6381586  0.92530704 0.9999473\n",
      " 0.99926656 0.9000776  0.99718046 0.99912995 0.87929225 0.9983683\n",
      " 0.99145013 0.9999825  0.6917406  0.5854488  0.7105236  0.96374786\n",
      " 0.9999585  0.84494984 0.9896874  0.9252054  0.92353636 0.79154295\n",
      " 0.9993513  0.99997306 0.9880427  0.9999691  0.99809057 0.97151786\n",
      " 0.7553812  0.9959027 ]\n",
      "The rewards are: [0.9545644  0.9996481  0.9916391  0.9572981  0.9859363  0.99913764\n",
      " 0.9988883  0.98498267 0.9941514  0.8129079  0.9545024  0.9990662\n",
      " 0.93306345 0.99879044 0.99986565 0.95608366 0.9999813  0.9257486\n",
      " 0.86832464 0.99788696 0.840686   0.9999217  0.99873894 0.9995326\n",
      " 0.9991953  0.99947935 0.8341685  0.9999254  0.99953365 0.99431497\n",
      " 0.99995923 0.93338984]\n",
      "The rewards are: [0.99801755 0.98384523 0.99550134 0.98488325 0.9984158  0.92870325\n",
      " 0.9780653  0.99991393 0.96765524 0.99268097 0.99073243 0.95088613\n",
      " 0.91341364 0.9107392  0.98143494 0.9272759  0.96645665 0.8358873\n",
      " 0.9486918  0.99991155 0.8674762  0.99963176 0.5899654  0.9734851\n",
      " 0.99808085 0.8833062  0.8726947  0.992593   0.9943885  0.7947463\n",
      " 0.95444375 0.8829701 ]\n",
      "The rewards are: [0.9989126  0.88187504 0.6233766  0.9458386  0.9370766  0.99830186\n",
      " 0.99983037 0.9388819  0.9988049  0.94592845 0.99663275 0.9977254\n",
      " 0.968177   0.9802346  0.99216425 0.9964832  0.7513223  0.9232998\n",
      " 0.8727433  0.97268957 0.8935027  0.9994764  0.80641294 0.99907196\n",
      " 0.99758613 0.99982977 0.99995077 0.9578298  0.9999709  0.99885786\n",
      " 0.9947614  0.9948318 ]\n",
      "The rewards are: [0.99943537 0.9632139  0.9281231  0.9989134  0.8949423  0.995419\n",
      " 0.99571085 0.99938893 0.97509515 0.99726784 0.99938536 0.99985147\n",
      " 0.9701855  0.990593   0.9720805  0.8518111  0.9425968  0.999218\n",
      " 0.9860422  0.8837081  0.9972046  0.9880613  0.7825469  0.9901916\n",
      " 0.99908924 0.66860384 0.99907815 0.9981451  0.98893726 0.93805623\n",
      " 0.99504375 0.9647727 ]\n",
      "The rewards are: [0.9993882  0.9997043  0.95625716 0.9993936  0.9395348  0.97007847\n",
      " 0.9871975  0.9950559  0.80684924 0.99904054 0.9812019  0.99434125\n",
      " 0.9593192  0.98916924 0.64615524 0.99682826 0.93847954 0.7883063\n",
      " 0.99410397 0.98209846 0.9991615  0.99981016 0.9874455  0.99586725\n",
      " 0.9849915  0.99961156 0.9900698  0.9890465  0.9842312  0.9998981\n",
      " 0.9224298  0.99951124]\n",
      "The rewards are: [0.9225791  0.9968736  0.9234123  0.9501509  0.99981517 0.99902964\n",
      " 0.92887247 0.99866223 0.9964212  0.6287638  0.97309947 0.9914506\n",
      " 0.9941983  0.98713535 0.9960252  0.9971752  0.99968123 0.7901288\n",
      " 0.99930775 0.99980575 0.9999554  0.99940515 0.9279014  0.84297556\n",
      " 0.74316573 0.99955434 0.92384636 0.9956246  0.99971575 0.9987066\n",
      " 0.57957333 0.9877652 ]\n",
      "The rewards are: [0.6304431  0.99951327 0.9999851  0.99861586 0.982055   0.9797411\n",
      " 0.9975539  0.99342185 0.96649295 0.9988341  0.999998   0.9798797\n",
      " 0.9996871  0.98840374 0.9454668  0.99732935 0.9996916  0.99954635\n",
      " 0.9802791  0.99552625 0.97728443 0.88272554 0.99902844 0.9428151\n",
      " 0.990829   0.9999378  0.9983444  0.7274636  0.9389038  0.96993107\n",
      " 0.87389374 0.99635917]\n",
      "The rewards are: [0.9774285  0.77457464 0.94991887 0.7388016  0.9593269  0.86599666\n",
      " 0.9023274  0.9360282  0.9264579  0.9853167  0.96068454 0.9934269\n",
      " 0.7890121  0.9949232  0.9922123  0.99877495 0.99998724 0.99907625\n",
      " 0.6167296  0.9998803  0.9785785  0.94098264 0.9991372  0.9939703\n",
      " 0.9967746  0.99994314 0.7139908  0.9253445  0.9809254  0.94432926\n",
      " 0.9403064  0.9999137 ]\n",
      "The rewards are: [0.9978739  0.99963033 0.9662139  0.99445665 0.96532404 0.99990475\n",
      " 0.99863344 0.7475775  0.965888   0.9945134  0.9997931  0.9962296\n",
      " 0.9781437  0.9538588  0.96610785 0.93184227 0.99985385 0.9973635\n",
      " 0.632106   0.9680558  0.95838875 0.9986738  0.6365352  0.9981793\n",
      " 0.999642   0.9812593  0.5094811  0.5099149  0.9808008  0.9971318\n",
      " 0.7229973  0.9958967 ]\n",
      "The rewards are: [0.99822885 0.99943835 0.7481569  0.98598194 0.95708406 0.99530846\n",
      " 0.95256376 0.99600214 0.922388   0.9999722  0.9988913  0.9752739\n",
      " 0.98062587 0.9872688  0.99919206 0.8003776  0.9998524  0.9219565\n",
      " 0.79197806 0.7247318  0.9949137  0.99903524 0.9999002  0.9837213\n",
      " 0.99479383 0.99965286 0.99917847 0.9999964  0.9919795  0.97307295\n",
      " 0.9998728  0.86420435]\n",
      "The rewards are: [0.9945364  0.8072326  0.99982494 0.99860954 0.99712545 0.980409\n",
      " 0.78621894 0.9996673  0.9993773  0.73787796 0.9804294  0.9809109\n",
      " 0.99989426 0.68133634 0.9934237  0.99745435 0.9901647  0.9998066\n",
      " 0.99995244 0.9396787  0.8960572  0.8998175  0.9881213  0.9936505\n",
      " 0.9992568  0.9958072  0.98448193 0.9586826  0.9275666  0.99344856\n",
      " 0.98208284 0.85944194]\n",
      "The rewards are: [0.7848648  0.9967135  0.92364186 0.99694663 0.99927336 0.9922984\n",
      " 0.9653468  0.99906474 0.999835   0.9995334  0.99940693 0.5395191\n",
      " 0.97024024 0.9913913  0.99948126 0.9986461  0.6240272  0.99284863\n",
      " 0.9998989  0.9989072  0.99898297 0.9998103  0.99973947 0.6740191\n",
      " 0.9999871  0.96198136 0.98410946 0.9830403  0.99797124 0.99145424\n",
      " 0.9984871  0.980247  ]\n",
      "The rewards are: [0.6754658  0.99184483 0.99475104 0.9997582  0.9998889  0.954076\n",
      " 0.878092   0.9978276  0.99190724 0.99995494 0.9832465  0.9874515\n",
      " 0.7051371  0.9995553  0.6540827  0.86778384 0.96501297 0.99865913\n",
      " 0.80950904 0.57452047 0.9998865  0.99936515 0.7403106  0.99011934\n",
      " 0.9931799  0.99997115 0.61594284 0.9118075  0.87955713 0.9954218\n",
      " 0.9682487  0.9980071 ]\n",
      "The rewards are: [0.9998641  0.99207896 0.9994259  0.8242714  0.99705863 0.8095676\n",
      " 0.9978846  0.76468277 0.99843055 0.8899978  0.9787714  0.99124205\n",
      " 0.9740646  0.9027444  0.99915624 0.97384495 0.95284486 0.9926077\n",
      " 0.9815894  0.52512175 0.8534931  0.61271966 0.9977254  0.81166327\n",
      " 0.9818677  0.98432124 0.9851366  0.9678342  0.9974686  0.6433953\n",
      " 0.6541869  0.9846319 ]\n",
      "The rewards are: [0.9683894  0.99558085 0.99748695 0.99975747 0.88889587 0.9202037\n",
      " 0.99366236 0.97844386 0.917367   0.9801002  0.99443346 0.96778375\n",
      " 0.823602   0.99918    0.99858403 0.9897927  0.98838985 0.94461316\n",
      " 0.99810153 0.99765503 0.9771153  0.9932708  0.96348864 0.9994623\n",
      " 0.9999473  0.8279296  0.9968503  0.98017305 0.99769694 0.76818514\n",
      " 0.9505325  0.5226624 ]\n",
      "The rewards are: [0.95336217 0.9993399  0.9668137  0.99898416 0.9813627  0.98696923\n",
      " 0.9870207  0.7630293  0.9978732  0.59657884 0.82246464 0.9821436\n",
      " 0.99506277 0.985747   0.9993455  0.99872106 0.87777215 0.9952918\n",
      " 0.99978775 0.9965371  0.57453007 0.99740785 0.67375124 0.9972995\n",
      " 0.93063843 0.982932   0.9999604  0.9972921  0.99766785 0.99032474\n",
      " 0.65573984 0.9815466 ]\n",
      "The rewards are: [0.9997068  0.97147274 0.8966932  0.8745924  0.99985075 0.9995216\n",
      " 0.9994935  0.5803385  0.7993584  0.9992937  0.99988985 0.9525939\n",
      " 0.9874155  0.99981743 0.99948657 0.9971064  0.7718425  0.9975981\n",
      " 0.95414215 0.6427203  0.6901506  0.7613562  0.99368286 0.9974969\n",
      " 0.9288667  0.9988103  0.81723845 0.96562696 0.75965506 0.95807624\n",
      " 0.9334261  0.9989692 ]\n",
      "The rewards are: [0.9207484  0.9999367  0.9591579  0.9442852  0.9734957  0.8310588\n",
      " 0.8941298  0.9992385  0.9988355  0.9758051  0.9995123  0.99997365\n",
      " 0.5105745  0.9686765  0.9526252  0.99885535 0.9985869  0.97850126\n",
      " 0.9798457  0.9979189  0.95304286 0.9622545  0.9987679  0.99757713\n",
      " 0.99800223 0.9891656  0.9983247  0.9967534  0.99401075 0.72724247\n",
      " 0.9100816  0.88378453]\n",
      "The rewards are: [0.9411733  0.5983892  0.9971963  0.99399465 0.94670606 0.99956983\n",
      " 0.64494246 0.9708745  0.99648094 0.998722   0.99624395 0.97397614\n",
      " 0.999186   0.99942446 0.9972518  0.9985923  0.9834004  0.8651509\n",
      " 0.9395699  0.9994357  0.9982876  0.98437595 0.5654456  0.78835416\n",
      " 0.99526054 0.99899596 0.96268004 0.98460495 0.9938969  0.96999365\n",
      " 0.99994636 0.9855091 ]\n",
      "The rewards are: [0.9455454  0.99888486 0.9880822  0.99940455 0.9090764  0.9945028\n",
      " 0.999767   0.9999374  0.9936319  0.80413336 0.5079624  0.96256214\n",
      " 0.9963582  0.99521244 0.993909   0.8044978  0.9516543  0.99976355\n",
      " 0.98100567 0.9994137  0.9399739  0.9992913  0.9747181  0.9989742\n",
      " 0.99988544 0.79056734 0.9995803  0.99941325 0.93408006 0.9869932\n",
      " 0.9948026  0.956658  ]\n",
      "The rewards are: [0.8906436  0.6652662  0.97842926 0.99950016 0.9562496  0.9952944\n",
      " 0.88403356 0.99723804 0.99983644 0.99977213 0.7417807  0.94477874\n",
      " 0.99962413 0.7164912  0.6751509  0.99844474 0.99206936 0.65447235\n",
      " 0.99977094 0.99768233 0.99963236 0.99979514 0.98570573 0.992258\n",
      " 0.99921894 0.9999621  0.9987301  0.9967713  0.9991364  0.99039257\n",
      " 0.50437516 0.9995147 ]\n",
      "The rewards are: [0.9953452  0.9510063  0.9993368  0.8728099  0.8485252  0.99578923\n",
      " 0.7803901  0.7390075  0.7548946  0.9983858  0.9974572  0.99872005\n",
      " 0.9997931  0.9926105  0.9986526  0.69584274 0.99991584 0.9993899\n",
      " 0.99860364 0.99573874 0.9457517  0.99239963 0.9795996  0.9987783\n",
      " 0.94966304 0.9969683  0.995073   0.6264     0.9929114  0.5914247\n",
      " 0.99414295 0.9968227 ]\n",
      "The rewards are: [0.998899   0.5763881  0.9874533  0.98304325 0.9990152  0.985014\n",
      " 0.97586846 0.9814966  0.999995   0.98567027 0.999046   0.98603004\n",
      " 0.9983854  0.8588818  0.999724   0.99401075 0.987812   0.94563615\n",
      " 0.9837413  0.9998301  0.9694305  0.95782757 0.9962836  0.9386055\n",
      " 0.99424666 0.97369915 0.9750854  0.94787043 0.95169437 0.94281226\n",
      " 0.99672097 0.96453595]\n",
      "The rewards are: [0.99008864 0.9805455  0.9948724  0.99793017 0.995893   0.9888592\n",
      " 0.99491996 0.61578876 0.67077065 0.54567844 0.9235714  0.9716247\n",
      " 0.9986266  0.97849715 0.74594784 0.9993394  0.9991283  0.99653506\n",
      " 0.9876588  0.9729973  0.9939553  0.70910734 0.9939506  0.93712986\n",
      " 0.8414099  0.55441725 0.5661366  0.99972576 0.99918467 0.9976044\n",
      " 0.9943105  0.9992799 ]\n",
      "The rewards are: [0.9998666  0.9995301  0.9931051  0.94169927 0.9009475  0.97276783\n",
      " 0.9323329  0.9986507  0.9955446  0.9971058  0.9983797  0.99100643\n",
      " 0.71444905 0.99880147 0.86084825 0.9458082  0.99720323 0.99990296\n",
      " 0.9984479  0.9219008  0.5217598  0.62188286 0.84267634 0.9998528\n",
      " 0.9997304  0.9970113  0.9694709  0.9837239  0.9998779  0.5042776\n",
      " 0.81043315 0.8207129 ]\n",
      "The rewards are: [0.9986187  0.80888623 0.95947045 0.9363587  0.9813188  0.96937907\n",
      " 0.9979785  0.9995671  0.94627845 0.5945777  0.6285557  0.9941041\n",
      " 0.9998134  0.99977154 0.93805873 0.99998295 0.9997315  0.9293933\n",
      " 0.8810063  0.9998399  0.9280646  0.9972071  0.9994648  0.8404136\n",
      " 0.9590523  0.98675495 0.9123039  0.9859488  0.98482186 0.94753\n",
      " 0.997783   0.99998033]\n",
      "The rewards are: [0.58796245 0.99984396 0.987745   0.51724577 0.99360114 0.99933136\n",
      " 0.9404988  0.9981893  0.99997604 0.90927714 0.9932856  0.99957913\n",
      " 0.98429304 0.97085226 0.7252998  0.98692304 0.9851178  0.9995647\n",
      " 0.99927825 0.73601025 0.9984291  0.9999497  0.96943027 0.5973246\n",
      " 0.9984403  0.74139243 0.9974892  0.9888621  0.7245778  0.99485034\n",
      " 0.998836   0.9985941 ]\n",
      "The rewards are: [0.5161872  0.99961805 0.6389765  0.9997447  0.99700063 0.986452\n",
      " 0.99311584 0.9727171  0.9961128  0.99850935 0.9670902  0.65497625\n",
      " 0.99720037 0.99896467 0.99597555 0.6249958  0.9789296  0.91937125\n",
      " 0.9993561  0.9472904  0.9767411  0.9959638  0.999423   0.72734636\n",
      " 0.9961087  0.96201885 0.9927914  0.98507535 0.98598653 0.93170804\n",
      " 0.99993443 0.63811773]\n",
      "The rewards are: [0.99570507 0.99725074 0.9995815  0.85047853 0.99968076 0.98054254\n",
      " 0.9997693  0.9998275  0.9977882  0.99080545 0.978366   0.99420196\n",
      " 0.99806434 0.99690944 0.9737091  0.97764057 0.9879061  0.9978229\n",
      " 0.9959829  0.99966455 0.9583121  0.9752447  0.9978739  0.9972274\n",
      " 0.98517954 0.5519004  0.99938524 0.9256866  0.99971014 0.9958383\n",
      " 0.86253107 0.9995876 ]\n",
      "The rewards are: [0.9842712  0.98838377 0.9985638  0.99986064 0.99649376 0.9972748\n",
      " 0.96750927 0.9982015  0.9627093  0.9987276  0.99424285 0.94343543\n",
      " 0.9997713  0.97076786 0.9958269  0.9999689  0.9996908  0.9999814\n",
      " 0.94621354 0.98860544 0.50046957 0.6112299  0.9833836  0.6790647\n",
      " 0.7581683  0.9361421  0.7787286  0.8909735  0.994451   0.9690911\n",
      " 0.9627778  0.72435594]\n",
      "The rewards are: [0.9982809  0.99545836 0.59438646 0.9931467  0.99989665 0.99742377\n",
      " 0.99992716 0.96708953 0.962341   0.9140701  0.99971753 0.99577576\n",
      " 0.99545467 0.8254898  0.99988437 0.99782276 0.85501343 0.9560271\n",
      " 0.97686005 0.9424641  0.766707   0.99474746 0.99504834 0.9986602\n",
      " 0.98399943 0.91242945 0.9999033  0.5026758  0.996618   0.9865762\n",
      " 0.99911934 0.98303556]\n",
      "The rewards are: [0.98958266 0.99871564 0.9586128  0.99593085 0.9978434  0.9997043\n",
      " 0.9734588  0.9567692  0.98303866 0.9999546  0.9919666  0.9999962\n",
      " 0.99522275 0.8589145  0.9993968  0.97797966 0.9986791  0.9969612\n",
      " 0.98650163 0.7936184  0.9998779  0.9985038  0.9900568  0.9943803\n",
      " 0.9983152  0.8675563  0.99605954 0.9416074  0.99878436 0.99481577\n",
      " 0.9667985  0.9712692 ]\n",
      "The rewards are: [0.99989235 0.97999007 0.99156874 0.86553305 0.87741286 0.9975889\n",
      " 0.9768677  0.65476763 0.8292804  0.99949    0.9455063  0.9960718\n",
      " 0.9998735  0.9962769  0.99933296 0.51106656 0.82842577 0.9994789\n",
      " 0.99356115 0.99973077 0.9952987  0.9998437  0.8834955  0.9996476\n",
      " 0.94799405 0.89177907 0.7360871  0.97324    0.9979486  0.97776276\n",
      " 0.96641237 0.9896718 ]\n",
      "The rewards are: [0.54618543 0.5758923  0.99481356 0.9777247  0.99763536 0.97562486\n",
      " 0.550502   0.5259782  0.6791799  0.9986518  0.99975735 0.99930596\n",
      " 0.9644091  0.9760108  0.99871325 0.9885987  0.88609767 0.99982566\n",
      " 0.6982662  0.8552872  0.94548494 0.9976776  0.9909691  0.9996848\n",
      " 0.9819405  0.97316575 0.99823284 0.9928135  0.5421097  0.7635871\n",
      " 0.9996369  0.9826124 ]\n",
      "The rewards are: [0.99757963 0.9915821  0.9993724  0.99784803 0.9994604  0.99973863\n",
      " 0.9760454  0.99460524 0.98386395 0.6121727  0.9881782  0.99265116\n",
      " 0.99822026 0.9342438  0.80251646 0.9948368  0.99512863 0.6223639\n",
      " 0.9954071  0.9935342  0.72705424 0.99890697 0.9982591  0.99743444\n",
      " 0.8203299  0.9999826  0.97271395 0.6603703  0.99771833 0.9983577\n",
      " 0.93060106 0.9947266 ]\n",
      "The rewards are: [0.99910647 0.7308509  0.96557695 0.7319393  0.99901354 0.993913\n",
      " 0.9943586  0.9428414  0.96068543 0.99711585 0.71542513 0.9802034\n",
      " 0.6097159  0.7044823  0.93920827 0.51108736 0.99263656 0.91809267\n",
      " 0.9995171  0.93041617 0.99421    0.99227023 0.9086396  0.99824405\n",
      " 0.9980118  0.9999542  0.9998976  0.57505375 0.99935764 0.5948941\n",
      " 0.9840066  0.99806195]\n",
      "The rewards are: [0.9996487  0.98826516 0.9765855  0.9995509  0.9911398  0.8749904\n",
      " 0.946609   0.9998741  0.99987674 0.9999794  0.988818   0.99878854\n",
      " 0.99996364 0.99463    0.9999578  0.99285734 0.9961302  0.5037824\n",
      " 0.91623    0.99983144 0.96492344 0.99644333 0.9841197  0.97404987\n",
      " 0.9806631  0.9310028  0.9844706  0.8391819  0.880006   0.8242044\n",
      " 0.6508456  0.8352088 ]\n",
      "The rewards are: [0.9997079  0.9306067  0.99984276 0.9999913  0.9905566  0.98511106\n",
      " 0.9925944  0.9999908  0.99811894 0.8477787  0.9997917  0.7295499\n",
      " 0.9992816  0.9994407 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHFCAYAAAAHcXhbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+XklEQVR4nO3dd3hUZf7+8XtIB5NIMQUSA9K7lF26hA4KIuiKuiog+IMFFURkQVSCy4KAZpVVQAUCrDSlCC6ChBZRQAFBpQhIDZhIJxBgSHl+f/jNbIYkJBmSTA6+X9d1rst5TvvMc06G21NtxhgjAAAAiyrh7gIAAABuBWEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGxc7s2bNls9kcg6enp0JDQ/XYY4/p4MGD7i6vwFSsWFF9+vTJdTqbzabnnnsu23GLFy+WzWbTxo0bHW1RUVGy2Wz5quXKlSuKiopyWs4fWXx8vJ577jlVrlxZvr6+Kl26tNq2batFixblazkZ2+LMmTOFVGnhyev+WVjrttlsGjhwYJZxGzdulM1m0+LFix1tGb8Zvr6+OnbsWJZ5IiMjVadOnUKtGe5FmEGxFRMToy1btmjt2rV67rnntGLFCrVs2VLnz593d2nFWv/+/bVly5Z8zXPlyhWNHTuWMCPpm2++Ub169bR8+XINGTJEq1ev1uzZsx2Bunfv3vojvAVm2bJleu2119xaw8yZM7V///48T2+32/Xqq68WYkUorjzdXQCQkzp16qhx48aSfv8/q7S0NI0ZM0afffaZ+vbt6+bqcnflyhWVLFmyyNcbFhamsLCwIl/vrbp69ar8/PzcWsOFCxfUs2dPBQYG6ttvv1VwcLBjXPfu3VWvXj2NHDlS9957r1588UU3Vpo/aWlpSk1NlY+PT57nadCgQSFWlLtmzZpp7969euWVV7RkyZI8zdO5c2fNnz9fw4cPV/369Qu5QhQnHJmBZWQEm99++82pffv27XrwwQdVpkwZ+fr6qkGDBvrkk08c45OSkuTp6anJkyc72s6cOaMSJUooMDBQqampjvYXXnhBd911l+P/vGNjY9W9e3eFhYXJ19dXVapU0YABA7KcNsg4nfD999/rkUceUenSpVW5cmVJUkpKikaMGKGQkBCVLFlSLVu21HfffVewnZNNLZmtX79ekZGRKlu2rPz8/HT33Xfr4Ycf1pUrV3T06FHdddddkqSxY8c6Tu9lPsXw9ddfq127dvL391fJkiXVvHlzrVy5Msu6v/76azVr1ky+vr6qUKGCXnvtNc2YMUM2m01Hjx51TFexYkV17dpVS5cuVYMGDeTr66uxY8dKkt5//33dd999CgoKUqlSpVS3bl1NmjRJKSkpTuvKOHWwZcsWNW/eXH5+fqpYsaJiYmIkSStXrlTDhg1VsmRJ1a1bV6tXr86172bMmKFTp07pzTffdAoyGUaMGKEaNWpowoQJTvvNrcptH5ak06dPa9CgQapVq5buuOMOBQUFqW3bttq0aZPTdEePHpXNZtOkSZM0btw4VapUST4+PtqwYYNj39izZ48ef/xxBQYGKjg4WM8884wuXrzotJwbTzNlnN5ZsGCBRo8erfLlyysgIEDt27fPcvTEGKPx48crIiJCvr6+aty4sWJjYxUZGanIyMg89UmZMmU0cuRILV26VFu3bs3TPCNGjFDZsmX197//PU/T4/ZBmIFlHDlyRJJUrVo1R9uGDRvUokULXbhwQdOnT9fy5ct17733qlevXpo9e7YkKSAgQH/605+0du1ax3zr1q2Tj4+PLl265BQs1q5dq7Zt2zrCwKFDh9SsWTNNmzZNa9as0euvv65vv/1WLVu2zPKPqyT17NlTVapU0aeffqrp06dLkp599lm99dZbevrpp7V8+XI9/PDD6tmzZ75OlxljlJqammVIT0/Pdd6jR4/qgQcekLe3t2bNmqXVq1frzTffVKlSpXT9+nWFhoY6/qHv16+ftmzZoi1btjhOMcTFxalt27a6ePGiZs6cqQULFsjf31/dunVzuobkxx9/VIcOHXTlyhXNmTNH06dP1/fff69//vOf2db1/fff6+WXX9YLL7yg1atX6+GHH3b0+RNPPKH//Oc/+u9//6t+/fpp8uTJGjBgQJZlJCYmqm/fvurfv7+WL1+uunXr6plnntEbb7yhUaNGacSIEVqyZInuuOMOPfTQQ/r1119v2lexsbHy8PBQt27dsh1vs9n04IMP6vTp09q5c2eufZ8XedmHJencuXOSpDFjxmjlypWKiYnRPffco8jIyGxPD06ZMkXr16/XW2+9pVWrVqlGjRqOcQ8//LCqVaumJUuWaOTIkZo/f36ejzS98sorOnbsmGbMmKEPP/xQBw8eVLdu3ZSWluaYZvTo0Ro9erQ6d+6s5cuXa+DAgerfv78OHDiQr74ZMmSIKlSooBEjRuRpen9/f7366qv68ssvtX79+nytCxZngGImJibGSDJbt241KSkp5tKlS2b16tUmJCTE3HfffSYlJcUxbY0aNUyDBg2c2owxpmvXriY0NNSkpaUZY4x59dVXjZ+fn7l27Zoxxpj+/fubzp07m3r16pmxY8caY4w5efKkkWQ+/PDDbOtKT083KSkp5tixY0aSWb58uWPcmDFjjCTz+uuvO82zb98+I8m8+OKLTu3z5s0zkkzv3r1z7Q9JuQ4bNmzIUkuGxYsXG0lm165dOa7j9OnTRpIZM2ZMlnFNmzY1QUFB5tKlS4621NRUU6dOHRMWFmbS09ONMcb85S9/MaVKlTKnT592TJeWlmZq1aplJJkjR4442iMiIoyHh4fZv3//Tb97WlqaSUlJMXPnzjUeHh7m3LlzjnGtW7c2ksz27dsdbWfPnjUeHh7Gz8/PnDx50tG+a9cuI8lMmTLlpuurUaOGCQkJuek006ZNM5LMp59+etPpjPnftsjcJ9mtMy/78I1SU1NNSkqKadeunenRo4ej/ciRI0aSqVy5srl+/Xq29UyaNMmpfdCgQcbX19exLY35fRtl3j83bNhgJJn777/fad5PPvnESDJbtmwxxhhz7tw54+PjY3r16uU03ZYtW4wk07p16xz7IvO6H3jgAWOMMR999JGRZD7//HOnOjL3f8ZvxrZt24zdbjf33HOPady4seP7tG7d2tSuXTvX9cK6ODKDYqtp06by8vKSv7+/OnfurNKlS2v58uXy9Pz9Uq9ffvlFP//8s/76179KktMRi/vvv18JCQmOw9/t2rXT1atXtXnzZkm/H4Hp0KGD2rdvr9jYWEebJLVv395Rw6lTpzRw4ECFh4fL09NTXl5eioiIkCTt27cvS80ZRxcybNiwQZIcNWZ49NFHHd8jLx599FFt27YtyzBx4sRc57333nvl7e2t//f//p/mzJmjw4cP53m9ycnJ+vbbb/XII4/ojjvucLR7eHjoqaee0okTJxx9nHEEp1y5co7pSpQooUcffTTbZderV8/pKFuGnTt36sEHH1TZsmXl4eEhLy8vPf3000pLS8vyf/ahoaFq1KiR43OZMmUUFBSke++9V+XLl3e016xZU5KyvdMlv8z/nYLMOHpnsjlqllf52Yclafr06WrYsKF8fX0d++O6deuy3RcffPBBeXl5ZbveBx980OlzvXr1dO3aNZ06dSrXmrObV/pf327dulV2uz3Ldm/atKkqVqyY6/Jv1LdvX9WqVUsjR47M05FIb29vjRs3Ttu3b89yqg63L8IMiq25c+dq27ZtWr9+vQYMGKB9+/bp8ccfd4zPuHZm+PDh8vLychoGDRokSY5rW5o3b66SJUtq7dq1+uWXX3T06FFHmPn22291+fJlrV27Vvfcc48qVaokSUpPT1fHjh21dOlSjRgxQuvWrdN3333nOH9/9erVLDWHhoY6fT579qwkKSQkxKnd09NTZcuWzXNf3HXXXWrcuHGW4Z577sl13sqVK2vt2rUKCgrS4MGDVblyZVWuXFnvvvturvOeP39expgs30uSIyxkfMezZ89me51Jdm1S1r6SpOPHj6tVq1Y6efKk3n33XW3atEnbtm3T+++/Lylrn5cpUybLMry9vbO0e3t7S5KuXbuWbS0Z7r77bp0+fVrJyck5TpNx7U94eLgkac6cOVn2v7zKzz4cHR2tv/3tb2rSpImWLFmirVu3atu2bercuXOe9sXMbtz3Mi4Mzm45+Z03Y3/Iz75wMx4eHho/frz27NmjOXPm5Gmexx57TA0bNtTo0aOzPR2M2w93M6HYqlmzpuOi3zZt2igtLU0zZszQ4sWL9cgjjziOAIwaNUo9e/bMdhnVq1eX9Ps/Zi1bttTatWsVFhamkJAQ1a1b1xEGNm7cqHXr1qlr166OeXfv3q0ffvhBs2fPVu/evR3tv/zyS44133jhbcYPf2JioipUqOBoT01NdfzoF4VWrVqpVatWSktL0/bt2/Xvf/9bQ4cOVXBwsB577LEc5ytdurRKlCihhISELOMyrj/J2A5ly5bNcnG29Pt3z052z8L57LPPlJycrKVLlzqOgEnSrl27bvr9CkrHjh21Zs0aff7559n2izFGK1asUNmyZR13y3Tr1k3btm1zaX352Yc//vhjRUZGatq0aU7jL126lO18+X3WUEHJ2Odz2hdcOTrTvXt3tWjRQmPGjNGHH36Y6/Q2m00TJ05Uhw4d8jQ9rI8jM7CMSZMmqXTp0nr99deVnp6u6tWrq2rVqvrhhx+yPWrRuHFj+fv7O+Zv3769duzYoSVLljhOJZUqVUpNmzbVv//9b/36669Op5gy/jG48XbWDz74IM81Z9y5MW/ePKf2Tz75pEDvhskrDw8PNWnSxHGk4/vvv5eU8/+ZlypVSk2aNNHSpUudxqWnp+vjjz9WWFiY41RR69attX79eqc7vdLT0/Xpp5/mub7s+twYo48++ig/X9Nl/fr1U3BwsEaNGpXtKZdJkybp559/1sCBAx01li1bNst+l1f52YdtNluWffHHH3/M9zOFCluTJk3k4+OT5QGDW7duvaXTfBMnTlR8fLymTJmSp+nbt2+vDh066I033tDly5ddXi+sgSMzsIzSpUs77lCZP3++nnzySX3wwQfq0qWLOnXqpD59+qhChQo6d+6c9u3bp++//97pH9J27dopLS1N69atczpc3b59e40ZM0Y2m01t27Z1tNeoUUOVK1fWyJEjZYxRmTJl9PnnnzuuscmLmjVr6sknn9Q777wjLy8vtW/fXrt379Zbb72lgICAgumYXEyfPl3r16/XAw88oLvvvlvXrl3TrFmzJP3v+iB/f39FRERo+fLlateuncqUKaNy5cqpYsWKmjBhgjp06KA2bdpo+PDh8vb21tSpU7V7924tWLDAEUBGjx6tzz//XO3atdPo0aPl5+en6dOnO07ZlCiR+/87dejQQd7e3nr88cc1YsQIXbt2TdOmTSuyByXeeeedWrJkibp27apGjRrp5ZdfVv369ZWUlKRFixZp3rx56tChg6KiovK13M8//9wpWGd45JFH8rwPd+3aVf/4xz80ZswYtW7dWvv379cbb7yhSpUquSUY56RMmTIaNmyYJkyYoNKlS6tHjx46ceKExo4dq9DQ0DztB9lp0aKFunfvruXLl+d5nokTJ6pRo0Y6deqUateu7dJ6YRHuvPoYyE7mOxNudPXqVXP33XebqlWrmtTUVGOMMT/88IN59NFHTVBQkPHy8jIhISGmbdu2Zvr06U7zpqenm3LlyhlJTne6fPPNN0aSadiwYZb17d2713To0MH4+/ub0qVLm7/85S/m+PHjWe78udldK3a73bz00ksmKCjI+Pr6mqZNm5otW7ZkuVskJ5LM4MGDsx336aef5no305YtW0yPHj1MRESE8fHxMWXLljWtW7c2K1ascFrW2rVrTYMGDYyPj0+WO602bdpk2rZta0qVKmX8/PxM06ZNHXeXZLZp0ybTpEkT4+PjY0JCQszLL79sJk6caCSZCxcuOKbLfLfKjT7//HNTv3594+vraypUqGBefvlls2rVqizfM6c7VHJa9s368UbHjh0zgwYNMpUqVTJeXl6Ou8beeOMNx36XFxnbIqchQ172YbvdboYPH24qVKhgfH19TcOGDc1nn31mevfubSIiIhzTZdzNNHny5BzruXE/zfibu/GOs+zuZrrxLq6M9cXExDja0tPTzbhx40xYWJjx9vY29erVM//9739N/fr1ne68yklO23Dv3r3Gw8Pjpncz3eiJJ54wkrib6TZnM+YP8FxuAG7TsWNHHT16NN/PGClOfvrpJ7Vq1Ur33nuvVq1a5fYnFVvRkSNHVKNGDY0ZM0avvPKKu8vBbYbTTAAKzLBhw9SgQQOFh4fr3LlzmjdvnmJjYzVz5kx3l3ZL6tatq+XLl6tTp07q2bOnli9f7rhDCln98MMPWrBggZo3b66AgADt379fkyZNUkBAgPr16+fu8nAbIswAKDBpaWl6/fXXlZiYKJvNplq1auk///mPnnzySXeXdstat26d663d+F2pUqW0fft2zZw5UxcuXFBgYKAiIyP1z3/+06Xbs4HccJoJAABYGrdmAwAASyPMAAAASyPMAAAAS7vtLwBOT0/Xr7/+Kn9/f7c93hsAAOSPMUaXLl1S+fLlc33Y4m0fZn799VfHC+EAAIC1xMfHKyws7KbT3PZhJuMR4vHx8UX2+HgAAHBrkpKSFB4enu2rQG5024eZjFNLAQEBhBkAACwmL5eIcAEwAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNLeGmWnTpqlevXoKCAhQQECAmjVrplWrVjnGG2MUFRWl8uXLy8/PT5GRkdqzZ48bKwYAAMWNW8NMWFiY3nzzTW3fvl3bt29X27Zt1b17d0dgmTRpkqKjo/Xee+9p27ZtCgkJUYcOHXTp0iV3lg0AAIoRmzHGuLuIzMqUKaPJkyfrmWeeUfny5TV06FD9/e9/lyTZ7XYFBwdr4sSJGjBgQJ6Wl5SUpMDAQF28eFEBAQGFWToAACgg+fn3u9hcM5OWlqaFCxcqOTlZzZo105EjR5SYmKiOHTs6pvHx8VHr1q21efNmN1YKAACKE093F/DTTz+pWbNmunbtmu644w4tW7ZMtWrVcgSW4OBgp+mDg4N17NixHJdnt9tlt9sdn5OSkgqncAAAUCy4/chM9erVtWvXLm3dulV/+9vf1Lt3b+3du9cx3mazOU1vjMnSltmECRMUGBjoGMLDwwutdgAA4H5uDzPe3t6qUqWKGjdurAkTJqh+/fp69913FRISIklKTEx0mv7UqVNZjtZkNmrUKF28eNExxMfHF2r9AADAvdweZm5kjJHdblelSpUUEhKi2NhYx7jr168rLi5OzZs3z3F+Hx8fx63eGQMAALh9ufWamVdeeUVdunRReHi4Ll26pIULF2rjxo1avXq1bDabhg4dqvHjx6tq1aqqWrWqxo8fr5IlS+qJJ55wZ9kAAKAYcWuY+e233/TUU08pISFBgYGBqlevnlavXq0OHTpIkkaMGKGrV69q0KBBOn/+vJo0aaI1a9bI39/fnWUDAIBipNg9Z6ag8ZwZAACsx5LPmQEAAHAFYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFiaW8PMhAkT9Kc//Un+/v4KCgrSQw89pP379ztN06dPH9lsNqehadOmbqoYAAAUN24NM3FxcRo8eLC2bt2q2NhYpaamqmPHjkpOTnaarnPnzkpISHAMX3zxhZsqBgAAxY2nO1e+evVqp88xMTEKCgrSjh07dN999znafXx8FBISUtTlAQAACyhW18xcvHhRklSmTBmn9o0bNyooKEjVqlXTs88+q1OnTrmjPAAAUAzZjDHG3UVIkjFG3bt31/nz57Vp0yZH+6JFi3THHXcoIiJCR44c0WuvvabU1FTt2LFDPj4+WZZjt9tlt9sdn5OSkhQeHq6LFy8qICCgSL4LAAC4NUlJSQoMDMzTv9/F5sjMc889px9//FELFixwau/Vq5ceeOAB1alTR926ddOqVat04MABrVy5MtvlTJgwQYGBgY4hPDy8UOuOiooq1OUDAFBcvN2rq7tLyFaxCDPPP/+8VqxYoQ0bNigsLOym04aGhioiIkIHDx7MdvyoUaN08eJFxxAfH18YJQMAgGLCrRcAG2P0/PPPa9myZdq4caMqVaqU6zxnz55VfHy8QkNDsx3v4+OT7eknAABwe3LrkZnBgwfr448/1vz58+Xv76/ExEQlJibq6tWrkqTLly9r+PDh2rJli44ePaqNGzeqW7duKleunHr06OHO0gEAQDHh1iMz06ZNkyRFRkY6tcfExKhPnz7y8PDQTz/9pLlz5+rChQsKDQ1VmzZttGjRIvn7+7uhYgAAUNy4/TTTzfj5+enLL78somoAAIAVFYsLgAEAAFxFmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAPlWceRKd5fgQJgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACW5tYwM2HCBP3pT3+Sv7+/goKC9NBDD2n//v1O0xhjFBUVpfLly8vPz0+RkZHas2ePmyoGAADFjVvDTFxcnAYPHqytW7cqNjZWqamp6tixo5KTkx3TTJo0SdHR0Xrvvfe0bds2hYSEqEOHDrp06ZIbKwcAAMWFpztXvnr1aqfPMTExCgoK0o4dO3TffffJGKN33nlHo0ePVs+ePSVJc+bMUXBwsObPn68BAwa4o2wAAFCMFKtrZi5evChJKlOmjCTpyJEjSkxMVMeOHR3T+Pj4qHXr1tq8ebNbagQAAMWLW4/MZGaM0bBhw9SyZUvVqVNHkpSYmChJCg4Odpo2ODhYx44dy3Y5drtddrvd8TkpKamQKgYAAMVBsTky89xzz+nHH3/UggULsoyz2WxOn40xWdoyTJgwQYGBgY4hPDy8UOoFAOCPru6cuu4uQVIxCTPPP/+8VqxYoQ0bNigsLMzRHhISIul/R2gynDp1KsvRmgyjRo3SxYsXHUN8fHzhFQ4AANzOpTBz5MiRAlm5MUbPPfecli5dqvXr16tSpUpO4ytVqqSQkBDFxsY62q5fv664uDg1b94822X6+PgoICDAaQAAALcvl8JMlSpV1KZNG3388ce6du2ayysfPHiwPv74Y82fP1/+/v5KTExUYmKirl69Kun300tDhw7V+PHjtWzZMu3evVt9+vRRyZIl9cQTT7i8XgAAcPtwKcz88MMPatCggV566SWFhIRowIAB+u677/K9nGnTpunixYuKjIxUaGioY1i0aJFjmhEjRmjo0KEaNGiQGjdurJMnT2rNmjXy9/d3pXQAAHCbcSnM1KlTR9HR0Tp58qRiYmKUmJioli1bqnbt2oqOjtbp06fztBxjTLZDnz59HNPYbDZFRUUpISFB165dU1xcnONuJwAAgFu6ANjT01M9evTQJ598ookTJ+rQoUMaPny4wsLC9PTTTyshIaGg6gQAAMjWLYWZ7du3a9CgQQoNDVV0dLSGDx+uQ4cOaf369Tp58qS6d+9eUHUCAABky6WH5kVHRysmJkb79+/X/fffr7lz5+r+++9XiRK/Z6NKlSrpgw8+UI0aNQq0WAAAgBu5FGamTZumZ555Rn379nU8C+ZGd999t2bOnHlLxQEAAOTGpTBz8ODBXKfx9vZW7969XVk8AABAnrl0zUxMTIw+/fTTLO2ffvqp5syZc8tFAQAA5JVLYebNN99UuXLlsrQHBQVp/Pjxt1wUAABAXrkUZo4dO5bl1QOSFBERoePHj99yUQAAAHnlUpgJCgrSjz/+mKX9hx9+UNmyZW+5KAAAgLxyKcw89thjeuGFF7RhwwalpaUpLS1N69ev15AhQ/TYY48VdI0AAAA5culupnHjxunYsWNq166dPD1/X0R6erqefvpprpkBAABFyqUw4+3trUWLFukf//iHfvjhB/n5+alu3bqKiIgo6PoAAABuyqUwk6FatWqqVq1aQdUCAACQby6FmbS0NM2ePVvr1q3TqVOnlJ6e7jR+/fr1BVIcAABAblwKM0OGDNHs2bP1wAMPqE6dOrLZbAVdFwAAQJ64FGYWLlyoTz75RPfff39B1wMAAJAvLt2a7e3trSpVqhR0LQAAoJipOHKlu0vIlUth5qWXXtK7774rY0xB1wMAAJAvLp1m+vrrr7VhwwatWrVKtWvXlpeXl9P4pUuXFkhxAAAAuXEpzNx5553q0aNHQdcCAACQby6FmZiYmIKuAwAAwCUuXTMjSampqVq7dq0++OADXbp0SZL066+/6vLlywVWHAAAQG5cOjJz7Ngxde7cWcePH5fdbleHDh3k7++vSZMm6dq1a5o+fXpB1wkAAJAtl47MDBkyRI0bN9b58+fl5+fnaO/Ro4fWrVtXYMUBAADkxuW7mb755ht5e3s7tUdEROjkyZMFUhgAAEBeuHRkJj09XWlpaVnaT5w4IX9//1suCgAAIK9cCjMdOnTQO++84/hss9l0+fJljRkzhlccAACAIuVSmPnXv/6luLg41apVS9euXdMTTzyhihUr6uTJk5o4cWJB1wgAAIqJqKgod5eQhUvXzJQvX167du3SggUL9P333ys9PV39+vXTX//6V6cLggEAAAqbS2FGkvz8/PTMM8/omWeeKch6AAAA8sWlMDN37tybjn/66addKgYAACC/XAozQ4YMcfqckpKiK1euyNvbWyVLliTMAACAIuPSBcDnz593Gi5fvqz9+/erZcuWWrBgQUHXCAAAkCOX3810o6pVq+rNN9/MctQGAACgMBVYmJEkDw8P/frrrwW5SAAAgJty6ZqZFStWOH02xighIUHvvfeeWrRoUSCFAQAA5IVLYeahhx5y+myz2XTXXXepbdu2evvttwuiLgAAgDxxKcykp6cXdB0AAAAuKdBrZgAAAIqaS0dmhg0bludpo6OjXVkFAABAnrgUZnbu3Knvv/9eqampql69uiTpwIED8vDwUMOGDR3T2Wy2gqkSAAAgBy6FmW7dusnf319z5sxR6dKlJf3+IL2+ffuqVatWeumllwq0SAAAgJy4dM3M22+/rQkTJjiCjCSVLl1a48aN424mAABQpFwKM0lJSfrtt9+ytJ86dUqXLl265aIAAADyyqUw06NHD/Xt21eLFy/WiRMndOLECS1evFj9+vVTz54987ycr776St26dVP58uVls9n02WefOY3v06ePbDab09C0aVNXSgYAALcpl66ZmT59uoYPH64nn3xSKSkpvy/I01P9+vXT5MmT87yc5ORk1a9fX3379tXDDz+c7TSdO3dWTEyM47O3t7crJQMAgNuUS2GmZMmSmjp1qiZPnqxDhw7JGKMqVaqoVKlS+VpOly5d1KVLl5tO4+Pjo5CQEFfKBAAAfwC39NC8hIQEJSQkqFq1aipVqpSMMQVVl8PGjRsVFBSkatWq6dlnn9WpU6cKfB0AAMC6XAozZ8+eVbt27VStWjXdf//9SkhIkCT179+/QG/L7tKli+bNm6f169fr7bff1rZt29S2bVvZ7fYc57Hb7UpKSnIaAADA7culMPPiiy/Ky8tLx48fV8mSJR3tvXr10urVqwusuF69eumBBx5QnTp11K1bN61atUoHDhzQypUrc5xnwoQJCgwMdAzh4eEFVg8AACh+XAoza9as0cSJExUWFubUXrVqVR07dqxACstOaGioIiIidPDgwRynGTVqlC5evOgY4uPjC60eAADgfi5dAJycnOx0RCbDmTNn5OPjc8tF5eTs2bOKj49XaGhojtP4+PgUag0AAKB4cenIzH333ae5c+c6PttsNqWnp2vy5Mlq06ZNnpdz+fJl7dq1S7t27ZIkHTlyRLt27dLx48d1+fJlDR8+XFu2bNHRo0e1ceNGdevWTeXKlVOPHj1cKRsAANyGXDoyM3nyZEVGRmr79u26fv26RowYoT179ujcuXP65ptv8ryc7du3O4WfjLdx9+7dW9OmTdNPP/2kuXPn6sKFCwoNDVWbNm20aNEi+fv7u1I2AAC4DbkUZmrVqqUff/xR06ZNk4eHh5KTk9WzZ08NHjz4pqeAbhQZGXnT27m//PJLV8oDAAB/IPkOMykpKerYsaM++OADjR07tjBqAgAAyLN8XzPj5eWl3bt3y2azFUY9AAAA+eLSBcBPP/20Zs6cWdC1AAAA5JtL18xcv35dM2bMUGxsrBo3bpzlnUzR0dEFUhwAAEBu8hVmDh8+rIoVK2r37t1q2LChJOnAgQNO03D6CQAAFKV8hZmqVasqISFBGzZskPT76wamTJmi4ODgQikOAAC4T8iGXfJ1dxF5kK9rZm68jXrVqlVKTk4u0IIAAADyw6ULgDPc7BkxAAAARSFfYcZms2W5JoZrZAAAgDvl65oZY4z69OnjeJHjtWvXNHDgwCx3My1durTgKgQAALiJfIWZ3r17O31+8sknC7QYAACA/MpXmImJiSmsOgAAAFxySxcAAwAAuBthBgAAWBphBgAAWBphBgAAWBphBgAAODkxctNNx4ds2FU0heQRYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAGQRFRXl7hLyjDADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTBTnEUFFtqi3+7VtdCWDQC4vdSdU9fdJdwUYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFiaW8PMV199pW7duql8+fKy2Wz67LPPnMYbYxQVFaXy5cvLz89PkZGR2rNnj3uKBQAAxZJbw0xycrLq16+v9957L9vxkyZNUnR0tN577z1t27ZNISEh6tChgy5dulTElQIAgOLK050r79Kli7p06ZLtOGOM3nnnHY0ePVo9e/aUJM2ZM0fBwcGaP3++BgwYUJSlAgCAYqrYXjNz5MgRJSYmqmPHjo42Hx8ftW7dWps3b3ZjZQAAoDhx65GZm0lMTJQkBQcHO7UHBwfr2LFjOc5nt9tlt9sdn5OSkgqnQAAAUCwU2yMzGWw2m9NnY0yWtswmTJigwMBAxxAeHl7YJWrd+sqFvg4AAJC9YhtmQkJCJP3vCE2GU6dOZTlak9moUaN08eJFxxAfH1+odQIAAPcqtmGmUqVKCgkJUWxsrKPt+vXriouLU/PmzXOcz8fHRwEBAU4DAAC4fbn1mpnLly/rl19+cXw+cuSIdu3apTJlyujuu+/W0KFDNX78eFWtWlVVq1bV+PHjVbJkST3xxBNurBoAABQnbg0z27dvV5s2bRyfhw0bJknq3bu3Zs+erREjRujq1asaNGiQzp8/ryZNmmjNmjXy9/d3V8kAAKCYcWuYiYyMlDEmx/E2m01RUVGKiooquqIAAIClFNtrZgAAAPKCMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAwG3o7V5dC3R57w9cX6DLK0iEGQAAYGmEGQAAYGmEGQAAYGmEGQAAYGmEGQAAYGmEGQAAYGmEGQAAYGmEGQAAYGmEGQAAYGmEGQAAYGmEGRS4kA273F0CAOAPhDADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAIAF1Z1TN8dx+2rULMJK3I8wAwAALI0wAwAALI0wAwAALI0wAwAALI0wAwAALK1Yh5moqCjZbDanISQkxN1lAQCAYsTT3QXkpnbt2lq7dq3js4eHhxurAQAAxU2xDzOenp4cjQEAADkq1qeZJOngwYMqX768KlWqpMcee0yHDx92d0kAAKAYKdZHZpo0aaK5c+eqWrVq+u233zRu3Dg1b95ce/bsUdmyZbOdx263y263Oz4nJSUVVbkAAMANivWRmS5duujhhx9W3bp11b59e61cuVKSNGfOnBznmTBhggIDAx1DeHh4UZVbKG72uGpYi1W3ZcWRK91dAlAkoqKiCnR5J0ZuKtDlZVaYf5fvD1xfaMsuLMU6zNyoVKlSqlu3rg4ePJjjNKNGjdLFixcdQ3x8fBFWCAAAilqxPs10I7vdrn379qlVq1Y5TuPj4yMfH58irAoAALhTsT4yM3z4cMXFxenIkSP69ttv9cgjjygpKUm9e/d2d2kAAKCYKNZHZk6cOKHHH39cZ86c0V133aWmTZtq69atioiIcHdpAACgmCjWYWbhwoXuLgEAABRzxfo0EwAAQG4IMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIM39gPGr79lGY2xJ/HPtq1HR3CS4rzrWHbNglRQXmOP5WX3Xydq+ujt+AP+rrRwgzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzBaS4Pr5/3frKBVjJ7S0qKor+coOcXsVwq69oKKxtmZe/9bd7dS2UdReEW310vrsU1m9s3Tl19f7A9blus/zuTxm/23mdLz+/85mXmfk1Djdb1+3+mgPCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCTAEqiseEh2zYVajLf3/g+lt+jPyNivOj3YvarbyaIrdl3uxR5oW937gqo/aoqKg8z5OX/SljH87LI9xd2SYZf+vs27/L/NsXFRWVZX+7lX662esuctrnb+VVFiEbduW43xTEKwEy7/OF9ncZFejyrFZ93QVhBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphpoDtq1Hzpo/udnoE9/89cjqvj2fPeOT7jY/Uztxed05dvT9wvd7u1TVPj4hft75yjo/oLohHbe+rUdOpxvzWkNPyMvdHhsyvYijMx/dn1JAhT+vK9Hjx3LZ3xvJceax45loK4jUH2c0bFRXltM1u7I+c2m+U0/e78dH4mbn0OohMf2c3PgI/8/60bn1ll/ebnObLWFdBPCL+xsf636yfcqolu22T3e9RRn/k5/H9OW2b7Noz/07lReYab7ZfFcXrWAp8W97Cqwfyva7bGGEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYmiXCzNSpU1WpUiX5+vqqUaNG2rTpj3F1NgAAyF2xDzOLFi3S0KFDNXr0aO3cuVOtWrVSly5ddPz4cXeXBgAAioFiH2aio6PVr18/9e/fXzVr1tQ777yj8PBwTZs2zd2lAQCAYqBYh5nr169rx44d6tixo1N7x44dtXnzZjdVBQAAihNPdxdwM2fOnFFaWpqCg4Od2oODg5WYmJjtPHa7XXa73fH54sWLkqSkpKRCqdFutys5OV3p9itKu5qmy2lpupaSkuP6LtmTlZyc/vt4u5GSknKe3m6UdjVNV68n65LdS3abXenJl5Vuv+I0vd1uV1JSkqOGq9eTZU9JcdSW3bKvpaQ4asm8vIx1JSUlKT35skv9lrnGjP7IqDE7N9ZwM5fTnPsj8zy3WvvN+uvGGjJPk6d1ZdqW9pvsH5mXl3Y1LU/fIeN7JyenK9122WlbJiUlZWnPbl05yW7bZN7nM7axU3/k0H6jG/ftjGkzvvcle3K22zi3/pPkvG/b/vd35vT3J+f96Wb95NRn//d3lpTpb/fGfsxoz1hXXrdlbt8p8zIyL/Nmf18Zbvydypg+8+9Rxt9rdr8NN5OxLZOSkmS32536I7ttlte/hYzvnXlbZtSe27bMa3/f+Jt5429s5m2ZedvnJst+9X+/9zf+nidl+m3Ia83Z/ZuTXT9ltGf8+5CfbXnjvzk59VNB7Ns5yViuMSb3iU0xdvLkSSPJbN682al93Lhxpnr16tnOM2bMGCOJgYGBgYGB4TYY4uPjc80LxfrITLly5eTh4ZHlKMypU6eyHK3JMGrUKA0bNszxOT09XefOnVPZsmVls9luuaakpCSFh4crPj5eAQEBt7w85Iy+Ljr0ddGiv4sOfV10CrqvjTG6dOmSypcvn+u0xTrMeHt7q1GjRoqNjVWPHj0c7bGxserevXu28/j4+MjHx8ep7c477yzw2gICAvjDKCL0ddGhr4sW/V106OuiU5B9HRgYmKfpinWYkaRhw4bpqaeeUuPGjdWsWTN9+OGHOn78uAYOHOju0gAAQDFQ7MNMr169dPbsWb3xxhtKSEhQnTp19MUXXygiIsLdpQEAgGKg2IcZSRo0aJAGDRrk7jIk/X4aa8yYMVlOZaHg0ddFh74uWvR30aGvi447+9pmTF7ueQIAACieivVD8wAAAHJDmAEAAJZGmAEAAJZGmAEAAJZGmMnG1KlTValSJfn6+qpRo0batGlTjtNu3LhRNpsty/Dzzz8XYcXWlZ++ln5/B83o0aMVEREhHx8fVa5cWbNmzSqiaq0tP33dp0+fbPfr2rVrF2HF1pXf/XrevHmqX7++SpYsqdDQUPXt21dnz54tomqtLb99/f7776tmzZry8/NT9erVNXfu3CKq1Nq++uordevWTeXLl5fNZtNnn32W6zxxcXFq1KiRfH19dc8992j69OmFV+Ctv0Hp9rJw4ULj5eVlPvroI7N3714zZMgQU6pUKXPs2LFsp9+wYYORZPbv328SEhIcQ2pqahFXbj357WtjjHnwwQdNkyZNTGxsrDly5Ij59ttvzTfffFOEVVtTfvv6woULTvtzfHy8KVOmjBkzZkzRFm5B+e3rTZs2mRIlSph3333XHD582GzatMnUrl3bPPTQQ0VcufXkt6+nTp1q/P39zcKFC82hQ4fMggULzB133GFWrFhRxJVbzxdffGFGjx5tlixZYiSZZcuW3XT6w4cPm5IlS5ohQ4aYvXv3mo8++sh4eXmZxYsXF0p9hJkb/PnPfzYDBw50aqtRo4YZOXJkttNnhJnz588XQXW3l/z29apVq0xgYKA5e/ZsUZR3W8lvX99o2bJlxmazmaNHjxZGebeV/Pb15MmTzT333OPUNmXKFBMWFlZoNd4u8tvXzZo1M8OHD3dqGzJkiGnRokWh1Xg7ykuYGTFihKlRo4ZT24ABA0zTpk0LpSZOM2Vy/fp17dixQx07dnRq79ixozZv3nzTeRs0aKDQ0FC1a9dOGzZsKMwybwuu9PWKFSvUuHFjTZo0SRUqVFC1atU0fPhwXb16tShKtqxb2a8zzJw5U+3bt+fJ27lwpa+bN2+uEydO6IsvvpAxRr/99psWL16sBx54oChKtixX+tput8vX19epzc/PT999951SUlIKrdY/oi1btmTZNp06ddL27dsLpa8JM5mcOXNGaWlpWd7IHRwcnOXN3RlCQ0P14YcfasmSJVq6dKmqV6+udu3a6auvviqKki3Llb4+fPiwvv76a+3evVvLli3TO++8o8WLF2vw4MFFUbJludLXmSUkJGjVqlXq379/YZV423Clr5s3b6558+apV69e8vb2VkhIiO688079+9//LoqSLcuVvu7UqZNmzJihHTt2yBij7du3a9asWUpJSdGZM2eKouw/jMTExGy3TWpqaqH0tSVeZ1DUbDab02djTJa2DNWrV1f16tUdn5s1a6b4+Hi99dZbuu+++wq1zttBfvo6PT1dNptN8+bNc7xJNTo6Wo888ojef/99+fn5FXq9Vpafvs5s9uzZuvPOO/XQQw8VUmW3n/z09d69e/XCCy/o9ddfV6dOnZSQkKCXX35ZAwcO1MyZM4uiXEvLT1+/9tprSkxMVNOmTWWMUXBwsPr06aNJkybJw8OjKMr9Q8lu22TXXhA4MpNJuXLl5OHhkSXVnzp1KkvCvJmmTZvq4MGDBV3ebcWVvg4NDVWFChWcXglfs2ZNGWN04sSJQq3Xym5lvzbGaNasWXrqqafk7e1dmGXeFlzp6wkTJqhFixZ6+eWXVa9ePXXq1ElTp07VrFmzlJCQUBRlW5Irfe3n56dZs2bpypUrOnr0qI4fP66KFSvK399f5cqVK4qy/zBCQkKy3Taenp4qW7Zsga+PMJOJt7e3GjVqpNjYWKf22NhYNW/ePM/L2blzp0JDQwu6vNuKK33dokUL/frrr7p8+bKj7cCBAypRooTCwsIKtV4ru5X9Oi4uTr/88ov69etXmCXeNlzp6ytXrqhECeef4oyjBIZX5+XoVvZrLy8vhYWFycPDQwsXLlTXrl2zbAPcmmbNmmXZNmvWrFHjxo3l5eVV8CsslMuKLSzjVr+ZM2eavXv3mqFDh5pSpUo57uIYOXKkeeqppxzT/+tf/zLLli0zBw4cMLt37zYjR440ksySJUvc9RUsI799fenSJRMWFmYeeeQRs2fPHhMXF2eqVq1q+vfv766vYBn57esMTz75pGnSpElRl2tp+e3rmJgY4+npaaZOnWoOHTpkvv76a9O4cWPz5z//2V1fwTLy29f79+83//nPf8yBAwfMt99+a3r16mXKlCljjhw54qZvYB2XLl0yO3fuNDt37jSSTHR0tNm5c6fjNvgb+zrj1uwXX3zR7N2718ycOZNbs4va+++/byIiIoy3t7dp2LChiYuLc4zr3bu3ad26tePzxIkTTeXKlY2vr68pXbq0admypVm5cqUbqram/PS1Mcbs27fPtG/f3vj5+ZmwsDAzbNgwc+XKlSKu2pry29cXLlwwfn5+5sMPPyziSq0vv309ZcoUU6tWLePn52dCQ0PNX//6V3PixIkirtqa8tPXe/fuNffee6/x8/MzAQEBpnv37ubnn392Q9XWk/EYkhuH3r17G2Oy3683btxoGjRoYLy9vU3FihXNtGnTCq0+mzEcxwQAANbFSUIAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAyEafPn14uSZgEYQZAIWmT58+stlsstls8vT01N13362//e1vOn/+vLtLA3AbIcwAKFSdO3dWQkKCjh49qhkzZujzzz/XoEGD3F2WQ0pKirtLAHCLCDMACpWPj49CQkIUFhamjh07qlevXlqzZo1jfExMjGrWrClfX1/VqFFDU6dOdYx7+OGH9fzzzzs+Dx06VDabTXv27JEkpaamyt/fX19++aUkafXq1WrZsqXuvPNOlS1bVl27dtWhQ4cc8x89elQ2m02ffPKJIiMj5evrq48//lhpaWkaNmyYY74RI0bwxmrAQggzAIrM4cOHtXr1anl5eUmSPvroI40ePVr//Oc/tW/fPo0fP16vvfaa5syZI0mKjIzUxo0bHfPHxcWpXLlyiouLkyRt27ZN165dU4sWLSRJycnJGjZsmLZt26Z169apRIkS6tGjh9LT053q+Pvf/64XXnhB+/btU6dOnfT2229r1qxZmjlzpr7++mudO3dOy5YtK4IeAVAgCu0VlgD+8Hr37m08PDxMqVKljK+vr+NNu9HR0cYYY8LDw838+fOd5vnHP/5hmjVrZowx5scffzQ2m82cPn3anDt3znh5eZlx48aZv/zlL8YYY8aPH2+aNGmS4/pPnTplJJmffvrJGGPMkSNHjCTzzjvvOE0XGhpq3nzzTcfnlJQUExYWZrp3737LfQCg8Hm6N0oBuN21adNG06ZN05UrVzRjxgwdOHBAzz//vE6fPq34+Hj169dPzz77rGP61NRUBQYGSpLq1KmjsmXLKi4uTl5eXqpfv74efPBBTZkyRZK0ceNGtW7d2jHvoUOH9Nprr2nr1q06c+aM44jM8ePHVadOHcd0jRs3dvz3xYsXlZCQoGbNmjnaPD091bhxY041ARZBmAFQqEqVKqUqVapIkqZMmaI2bdpo7Nixeu655yT9fqqpSZMmTvN4eHhIkmw2m+677z5t3LhR3t7eioyMVJ06dZSWlqaffvpJmzdv1tChQx3zdevWTeHh4froo49Uvnx5paenq06dOrp+/XqWmgDcPrhmBkCRGjNmjN566y2lpaWpQoUKOnz4sKpUqeI0VKpUyTF9xnUzGzduVGRkpGw2m1q1aqW33npLV69edVwvc/bsWe3bt0+vvvqq2rVrp5o1a+bpFvDAwECFhoZq69atjrbU1FTt2LGj4L88gELBkRkARSoyMlK1a9fW+PHjFRUVpRdeeEEBAQHq0qWL7Ha7tm/frvPnz2vYsGGO6YcMGSJPT0+1atXK0fbSSy+pYcOGCggIkCSVLl1aZcuW1YcffqjQ0FAdP35cI0eOzFNNQ4YM0ZtvvqmqVauqZs2aio6O1oULFwrl+wMoeByZAVDkhg0bpo8++kidOnXSjBkzNHv2bNWtW1etW7fW7NmznY7M1KlTR+XKlVP9+vUdwaV169ZKS0tzul6mRIkSWrhwoXbs2KE6deroxRdf1OTJk/NUz0svvaSnn35affr0UbNmzeTv768ePXoU7JcGUGhshivcAACAhXFkBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWBphBgAAWNr/BzmX+FtFyfHLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model using Q-learning REINFORCEMENT LEARNING Technique\n",
    "# NAME: Q_learning\n",
    "# PARAMETERS:Call the Q_learning function with the following parameters:\n",
    "#            X_train_vectors: Training input data (features)\n",
    "#            y_train: Training target labels\n",
    "#            model: The trained neural network model\n",
    "#            Adam(learning_rate): Adam optimizer with specified learning rate\n",
    "#            epochs: Number of training epochs\n",
    "#            batch_size: Batch size for training\n",
    "#            gamma: Discount factor for rewards\n",
    "# PURPOSE: This is used to call the function named Q_learning with the provided arguments as input parameters.The purpose of this line of code is to invoke the Q_learning function and pass in the required input parameters for it to train the model with the reinforcement technique . \n",
    "# PRECONDITION: X_train_lstm, y_train, model3, epochs, batch_size, gamma, and learning_rate should be appropriately defined and initialized before this function call.\n",
    "# POSTCONDITION: The model's weights and biases being updated based on the policy gradient algorithm, the function is designed to update the model's parameters during training.\n",
    "\n",
    "q_learning(X_train_lstm, y_train, model3, optimizer, epochs=1, batch_size=32, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90e6d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# Evaluation of the LSTM model #######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bfdd3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "logits_q_lstm = model3(X_test_lstm) #logits is a tensor of shape (m, k), where m is the number of test examples and k is the number of classes. It is obtained by passing the test feature matrix X_test_vectors (which is in sparse format and converted to a dense numpy array using toarray()) through the neural network model model\n",
    "predictions_q_lstm = np.argmax(logits_q_lstm.numpy(), axis=1) #predictions is a numpy array of shape (m,) that contains the predicted class labels for the test examples. It is obtained by taking the argmax of the logits tensor along the second axis (i.e., the axis corresponding to the classes). This returns the index of the class with the highest probability for each test example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95ca7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "logits_pg_lstm = model2(X_test_lstm) #logits is a tensor of shape (m, k), where m is the number of test examples and k is the number of classes. It is obtained by passing the test feature matrix X_test_vectors (which is in sparse format and converted to a dense numpy array using toarray()) through the neural network model model\n",
    "predictions_pg_lstm = np.argmax(logits_pg_lstm.numpy(), axis=1) #predictions is a numpy array of shape (m,) that contains the predicted class labels for the test examples. It is obtained by taking the argmax of the logits tensor along the second axis (i.e., the axis corresponding to the classes). This returns the index of the class with the highest probability for each test example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f601fdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Q-Learning is of LSTM model : 0.9507795100222717\n"
     ]
    }
   ],
   "source": [
    "# accuracy for the Q-Learning model after Reinforcement algorithm training\n",
    "accuracy_q_lstm = np.mean(predictions_q_lstm == y_test) #calculates the accuracy of a LSTM model's predictions on a test set by comparing the predicted labels to the ground truth labels and computing the proportion of correct predictions.\n",
    "print(\"Accuracy of Q-Learning is of LSTM model :\", accuracy_q_lstm) #prints out the accuracy of the LSTM model's predictions on a test set, which was computed earlier and stored in the variable accuracy_q_lstm. The output will be a string that includes the text \"Accuracy of Q-Learning is of LSTM model :\" followed by the value of accuracy_q_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03a5ce9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Policy gradient of LSTM model is : 0.9473273942093541\n"
     ]
    }
   ],
   "source": [
    "# accuracy for the Policy Gradient model after Reinforcement algorithm training\n",
    "accuracy_pg_lstm = np.mean(predictions_pg_lstm == y_test) #computes the accuracy of a LSTM model's predictions on a test set for a policy gradient algorithm, and stores the resulting value in the variable accuracy_pg_lstm. The accuracy is calculated by comparing the predicted labels to the ground truth labels and computing the proportion of correct predictions using a NumPy function.\n",
    "print(\"Accuracy of Policy gradient of LSTM model is :\", accuracy_pg_lstm) #prints out the accuracy of the LSTM model's predictions on a test set using a policy gradient algorithm, which was computed earlier and stored in the variable accuracy_pg_lstm. The output will be a string that includes the text \"Accuracy of Policy gradient of LSTM model is :\" followed by the value of accuracy_pg_lstm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41d4dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Q-learning of LSTM model is: 0.9475930756461939\n"
     ]
    }
   ],
   "source": [
    "# f1 score for the Q-Learning model after Reinforcement algorithm training\n",
    "from sklearn.metrics import f1_score # imports the f1_score function from the sklearn.metrics module.\n",
    "score_q_lstm = f1_score(y_test,predictions_q_lstm) #calculates the F1 score of the predicted labels predictions compared to the true labels y_test, using the f1_score function. The resulting score is assigned to the variable score\n",
    "print(\"F1-score of Q-learning of LSTM model is:\",score_q_lstm) # prints the F1 score, which was calculated in the previous line, along with the label \"F1-score:\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58564587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Policy gradient of LSTM model is: 0.9440567711413365\n"
     ]
    }
   ],
   "source": [
    "# f1 score for the Policy gradient model after Reinforcement algorithm training\n",
    "from sklearn.metrics import f1_score # imports the f1_score function from the sklearn.metrics module.\n",
    "score_pg_lstm = f1_score(y_test,predictions_pg_lstm) #calculates the F1 score of the predicted labels predictions compared to the true labels y_test, using the f1_score function. The resulting score is assigned to the variable score\n",
    "print(\"F1-score of Policy gradient of LSTM model is:\",score_pg_lstm) # prints the F1 score, which was calculated in the previous line, along with the label \"F1-score:\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e1b86116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report of Q-Learning of LSTM model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      4773\n",
      "           1       0.95      0.95      0.95      4207\n",
      "\n",
      "    accuracy                           0.95      8980\n",
      "   macro avg       0.95      0.95      0.95      8980\n",
      "weighted avg       0.95      0.95      0.95      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for Q-Learning model after Reinforcement algorithm training\n",
    "from sklearn.metrics import classification_report #imports the classification_report function from the sklearn.metrics module, which can be used to generate a report on the classification performance of a model.\n",
    "print(\"classification report of Q-Learning of LSTM model:\") #This line of code is a print statement that displays a message on the screen indicating that the classification report for the Q-Learning of LSTM model will be displayed next. A classification report is a table that summarizes the performance of a classification model on a set of test data, and it typically includes metrics such as precision, recall, and F1-score for each class in the dataset.\n",
    "print(classification_report(y_test,predictions_q_lstm)) #generates a classification report based on the predicted labels predictions and the true labels y_test, using the classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "48df97ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Q-Learning of LSTM model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix # imports the confusion_matrix function from the sklearn.metrics module,\n",
    "import seaborn as sns #imports the seaborn library, \n",
    "print(\"Confusion Matrix of Q-Learning of LSTM model:\") #This line of code is a print statement that displays a message on the screen indicating that the confusion matrix for the Q-Learning of LSTM model will be displayed\n",
    "cm = confusion_matrix(y_test, predictions_q_lstm) #computes the confusion matrix for the Q-Learning of LSTM model by calling the confusion_matrix function from the sklearn.metrics library.\n",
    "sns.heatmap(cm, annot=True, cmap='Blues') #generates a heatmap visualization of the confusion matrix for the Q-Learning of LSTM model using the heatmap function from the seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "47d61307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report of Policy gradient of LSTM model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      4773\n",
      "           1       0.94      0.95      0.94      4207\n",
      "\n",
      "    accuracy                           0.95      8980\n",
      "   macro avg       0.95      0.95      0.95      8980\n",
      "weighted avg       0.95      0.95      0.95      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for Policy gradient model after Reinforcement algorithm training\n",
    "from sklearn.metrics import classification_report #imports the classification_report function from the sklearn.metrics module, which can be used to generate a report on the classification performance of a model.\n",
    "print(\"classification report of Policy gradient of LSTM model:\") #prints the classification report\n",
    "print(classification_report(y_test,predictions_pg_lstm)) #generates a classification report based on the predicted labels predictions and the true labels y_test, using the classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d26d60f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Policy gradient of LSTM model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix # imports the confusion_matrix function from the sklearn.metrics module,\n",
    "import seaborn as sns #imports the seaborn library,\n",
    "print(\"Confusion Matrix of Policy gradient of LSTM model:\") #This line of code is a print statement that displays a message on the screen indicating that the confusion matrix for the Policy Gradient of LSTM model will be displayed\n",
    "cm = confusion_matrix(y_test, predictions_pg_lstm) #computes the confusion matrix for the Q-Learning of LSTM model by calling the confusion_matrix function from the sklearn.metrics library.\n",
    "sns.heatmap(cm, annot=True, cmap='Blues') #generates a heatmap visualization of the confusion matrix for the Q-Learning of LSTM model using the heatmap function from the seaborn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "efda6622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # imports the matplotlib.pyplot library under the alias plt. matplotlib\n",
    "\n",
    "# Example accuracy scores\n",
    "accuracy_scores = [accuracy_q_lstm, accuracy_pg_lstm] #creates a Python list called accuracy_scores that contains the accuracy scores for both the Q-Learning and Policy Gradient models of the LSTM.\n",
    "\n",
    "# Model names\n",
    "model_names = ['Q-Learning', 'Policy Gradient'] #creates a Python list called model_names that contains the names of the two models used in the analysis, i.e., Q-Learning and Policy Gradient.\n",
    "\n",
    "colors = ['black', 'blue'] # list of colors for each bar\n",
    "\n",
    "# Set up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 6)) #creates a new plot using matplotlib with a size of 8 inches by 6 inches. The plot will be rendered on a single axis, which is stored in the variable ax, and can be further customized using ax methods.\n",
    "# Add the bars to the plot\n",
    "for i in range(len(model_names)): # loop is used to iterate through the list of model names and accuracy scores, and a new bar is added to the plot for each model.\n",
    "    ax.bar(model_names[i], accuracy_scores[i], color=colors[i]) #code adds a new bar to the bar chart for the ith model in model_names\n",
    "\n",
    "    # Add the accuracy score as text to the bar\n",
    "    ax.text(model_names[i], accuracy_scores[i] + 0.01, round(accuracy_scores[i], 5), ha='center') #code adds a label to the top of each bar in the bar chart.\n",
    "\n",
    "# Add labels and titles\n",
    "ax.set_xlabel('Model') # code adds a label to the x-axis of the bar chart indicating that it represents the \"Model\" category.\n",
    "ax.set_ylabel('Accuracy Score') #adds a label to the y-axis of the bar chart indicating that it represents the \"Accuracy Score\" category.\n",
    "ax.set_title('Comparison of Model Accuracy Scores Bet Q-Learning and Policy Gradient of LSTM model') # code sets the title of the bar chart to \"Comparison of Model Accuracy Scores Bet Q-Learning and Policy Gradient of LSTM model\".\n",
    "\n",
    "# Display the chart\n",
    "plt.show() #line of code displays the bar chart on the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c990edb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # imports the pyplot module from the matplotlib library under the alias plt.\n",
    "\n",
    "\n",
    "# define model names and their respective F1 scores\n",
    "model_names = ['Q-Learning', 'Policy Gradient'] # creates a list of two model names, 'Q-Learning' and 'Policy Gradient'.\n",
    "f1_scores = [score_q_lstm, score_pg_lstm] # creates a list of two F1 scores for two models.\n",
    "colors = ['black', 'blue'] # list of colors for each bar\n",
    "# Set up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 6)) #creates a new plot using matplotlib with a size of 8 inches by 6 inches. The plot will be rendered on a single axis, which is stored in the variable ax, and can be further customized using ax methods.\n",
    "# Add the bars to the plot\n",
    "for i in range(len(model_names)): # loop is used to iterate through the list of model names and accuracy scores, and a new bar is added to the plot for each model.\n",
    "    ax.bar(model_names[i], f1_scores[i], color=colors[i]) #code adds a new bar to the bar chart for the ith model in model_names\n",
    "\n",
    "    # Add the accuracy score as text to the bar\n",
    "    ax.text(model_names[i], f1_scores[i] + 0.01, round(f1_scores[i], 5), ha='center') #adds text labels to a bar chart to display the F1 scores for each bar, using the text() method of a Matplotlib Axes object.\n",
    "\n",
    "\n",
    "# add labels to the chart\n",
    "plt.title('Comparison of Model F1 Scores Bet Q-Learning and Policy Gradient of LSTM model') #sets the title of a plot comparing the F1 scores of Q-Learning and Policy Gradient of an LSTM model.\n",
    "plt.xlabel('Models') # sets the x-axis label of a plot as \"Models\".\n",
    "plt.ylabel('F1 Scores') #sets the y-axis label of a plot as \"F1 Scores\".\n",
    "\n",
    "# display the chart\n",
    "plt.show() # displays the plot that has been created using the previous commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37b3668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### Evaluation of the full Code ###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac270828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Metrix of Q-Learning and Policy Gradient with NN and LSTM model \n",
      "\n",
      "            Q_learning  Policy_gradient\n",
      "NN_model      0.952784         0.951336\n",
      "LSTM_model    0.950780         0.947327\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Metrix\n",
    "\n",
    "# Create a dictionary with the data\n",
    "accuracy_data = {'Q_learning': [accuracy_q, accuracy_q_lstm], \n",
    "        'Policy_gradient': [accuracy_pg, accuracy_pg_lstm]} # creates a dictionary accuracy_data with accuracy values for Q-learning and Policy Gradient models, with and without LSTM, stored in lists.\n",
    "\n",
    "# Create a Pandas dataframe with the data\n",
    "df_accuracy = pd.DataFrame(accuracy_data ,index=['NN_model', 'LSTM_model']) # converts the accuracy_data dictionary into a Pandas DataFrame named df_accuracy with row indexes 'NN_model' and 'LSTM_model'.\n",
    "\n",
    "print(\"Accuracy Metrix of Q-Learning and Policy Gradient with NN and LSTM model \") # prints Accuracy Metrix of Q-Learning and Policy Gradient with NN and LSTM model\n",
    "print(\"\")\n",
    "# Print the dataframe\n",
    "print(df_accuracy) #Prints dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4cded4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score Metrix of Q-Learning and Policy Gradient with NN and LSTM model \n",
      "\n",
      "            Q_learning  Policy_gradient\n",
      "NN_model      0.949464         0.948057\n",
      "LSTM_model    0.947593         0.944057\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Metrix\n",
    "\n",
    "# Create a dictionary with the data\n",
    "F1_score_data = {'Q_learning': [score_q, score_q_lstm], # creates a dictionary F1score with accuracy values for Q-learning and Policy Gradient models, with and without LSTM, stored in lists.\n",
    "\n",
    "        'Policy_gradient': [score_pg, score_pg_lstm]}\n",
    "\n",
    "# Create a Pandas dataframe with the data\n",
    "df_F1_score = pd.DataFrame(F1_score_data ,index=['NN_model', 'LSTM_model']) # converts the accuracy_data dictionary into a Pandas DataFrame named df_accuracy with row indexes 'NN_model' and 'LSTM_model'.\n",
    "\n",
    "\n",
    "print(\"F1 score Metrix of Q-Learning and Policy Gradient with NN and LSTM model \") #prints F1 score Metrix of Q-Learning and Policy Gradient with NN and LSTM model\n",
    "print(\"\")\n",
    "# Print the dataframe\n",
    "print(df_F1_score) #prints df_F1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d4db647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #importing matplotlib library\n",
    "\n",
    "# accuracy scores\n",
    "accuracy_scores = [accuracy_q, accuracy_pg, accuracy_q_lstm, accuracy_pg_lstm] #creates a list accuracy_scores that contains the accuracy values for four different models, Q-Learning, Policy Gradient, Q-Learning with LSTM, and Policy Gradient with LSTM.\n",
    "\n",
    "# Model names\n",
    "model_names = ['Q-Learning_NN', 'Policy Gradient_NN', 'Q-Learning_LSTM', 'Policy Gradient_LSTM'] #creates a list model_names that contains the accuracy values for four different models, Q-Learning, Policy Gradient, Q-Learning with LSTM, and Policy Gradient with LSTM.\n",
    "\n",
    "colors = ['green', 'red' ,'Black', 'Blue'] # list of colors for each bar\n",
    "\n",
    "# Set up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 6)) #creates a new figure with a single subplot using plt.subplots() function and assigns it to the variables fig and ax. The figsize argument sets the size of the figure in inches to 8 inches in width and 6 inches in height.\n",
    "# Add the bars to the plot\n",
    "for i in range(len(model_names)): #creates a bar chart by looping through each index in model_names and plotting a bar on the ax subplot using the bar() function. \n",
    "    ax.bar(model_names[i], accuracy_scores[i], color=colors[i]) #The height of the bar is set to the corresponding value in accuracy_scores, and the color of the bar is set to the corresponding color in colors.\n",
    "\n",
    "    # Add the accuracy score as text to the bar\n",
    "    ax.text(model_names[i], accuracy_scores[i] + 0.01, round(accuracy_scores[i], 5), ha='center') #adds text labels to each bar in the chart by using the text() function of the ax subplot. The label text is the rounded value of the corresponding accuracy score from accuracy_scores. The ha parameter sets the horizontal alignment of the label to the center of the bar.\n",
    "\n",
    "# Add labels and titles\n",
    "ax.set_xlabel('Model') #sets the label of the x-axis of the chart to 'Model' using the set_xlabel() function of the ax subplot.\n",
    "ax.set_ylabel('Accuracy Score') #sets the label of the y-axis of the chart to 'Accuracy Score' using the set_ylabel() function of the ax subplot.\n",
    "ax.set_title('Comparison of Model Accuracy Scores Bet Q-Learning and Policy Gradient between NN and LSTM model') #sets the title of the chart to 'Comparison of Model Accuracy Scores Bet Q-Learning and Policy Gradient between NN and LSTM model' using the set_title() function of the ax subplot.\n",
    "# Display the chart\n",
    "plt.show() #displays the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f5fd1196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #This imports the matplotlib library and renames it as \"plt\" for easier reference in the code\n",
    "\n",
    "\n",
    "\n",
    "# Model names\n",
    "model_names = ['Q-Learning_NN', 'Policy Gradient_NN', 'Q-Learning_LSTM', 'Policy Gradient_LSTM'] #This defines a list of model names as strings.\n",
    "f1_scores = [score_q, score_pg, score_q_lstm, score_pg_lstm] #This defines a list of F1 scores for each model. It assumes that the variables \"score_q\", \"score_pg\", \"score_q_lstm\", and \"score_pg_lstm\" have already been defined in the code.\n",
    "colors = ['green', 'red' ,'Black', 'Blue']  # list of colors for each bar\n",
    "# Set up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 6)) #This creates a new figure and axes object for the plot with a specified size.\n",
    "# Add the bars to the plot\n",
    "for i in range(len(model_names)): #This for loop iterates through each model name and F1 score and adds a bar to the chart for each. The ax.text() function is used to add the F1 score as text to each bar.\n",
    "    ax.bar(model_names[i], f1_scores[i], color=colors[i]) #This loop iterates over the model_names and f1_scores lists and adds a bar to the chart for each model. The color of each bar is determined by the corresponding color in the colors list. The loop also adds a text label to the top of each bar displaying the F1 score for that model.\n",
    "\n",
    "    # Add the accuracy score as text to the bar\n",
    "    ax.text(model_names[i], f1_scores[i] + 0.01, round(f1_scores[i], 5), ha='center') #this line of code adds a text label to the top of the corresponding bar. The text displays the F1 score for the corresponding model, and it is centered horizontally above the bar. By adding the text labels to the chart, the reader can more easily compare the F1 scores of the different models.\n",
    "\n",
    "# add labels to the chart\n",
    "plt.title('Comparison of Model F1 Scores Bet Q-Learning and Policy Gradient of LSTM model') #This line sets the title of the chart to 'Comparison of Model F1 Scores Bet Q-Learning and Policy Gradient of LSTM model'.\n",
    "plt.xlabel('Models') #This line sets the label of the x-axis to 'Models'.\n",
    "plt.ylabel('F1 Scores') #This line sets the label of the y-axis to 'F1 Scores'.\n",
    "# display the chart\n",
    "plt.show() #This line displays the chart. Once all the necessary data has been added to the chart, plt.show() is called to actually display the chart in a separate window or notebook output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df333bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835aef48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
